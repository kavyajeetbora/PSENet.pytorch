{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSENet_trial_run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/PSENet.pytorch/blob/master/PSENet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UByxwp0F3QUp",
        "colab_type": "text"
      },
      "source": [
        "## Installing softwares and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSEHnmCxK_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99kqKlHoYkz",
        "colab_type": "code",
        "outputId": "ebc5ae8c-e2da-4b85-fe7c-0d34911f8968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install pyclipper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyclipper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/67/2691f7cbb28fb9dbf423f2302fe489f9cee34d9a50a743c95032a24ac597/pyclipper-1.1.0.post1-cp36-cp36m-manylinux1_x86_64.whl (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 81kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 92kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pyclipper\n",
            "Successfully installed pyclipper-1.1.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoynOlfnIW1",
        "colab_type": "code",
        "outputId": "30e9613d-6e87-4e8b-fab6-8402f4c5a38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhJ-6yyXcnRx",
        "colab_type": "code",
        "outputId": "f6b1a2bc-ad3f-4d15-d0b7-270afb174095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import shutil, os\n",
        "os.chdir('/content')\n",
        "directory = '/content/cloned-repo'\n",
        "if os.path.exists(directory):\n",
        "  shutil.rmtree(directory)\n",
        "\n",
        "!git clone https://github.com/kavyajeetbora/PSENet.pytorch.git /content/cloned-repo\n",
        "print(\"Cloned the repository\")\n",
        "os.chdir('/content/cloned-repo')\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/cloned-repo'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 418 (delta 8), reused 0 (delta 0), pack-reused 400\u001b[K\n",
            "Receiving objects: 100% (418/418), 8.14 MiB | 11.44 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Cloned the repository\n",
            "cal_recall\t\t LICENSE\t\tPSENet_trial_run.ipynb\n",
            "config.py\t\t models\t\t\tREADME.md\n",
            "dataset\t\t\t predict.py\t\ttrain.py\n",
            "eval.py\t\t\t pse\t\t\tutils\n",
            "imgs\t\t\t PSENet.ipynb\n",
            "install_dependencies.sh  PSENet_training.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrOmfo6_3X2I",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the data and setting up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLMxTujlm0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping the files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def unzip_files(file,output_dir):\n",
        "  with ZipFile(file, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall(output_dir)\n",
        "  print('Extracted to',output_dir)\n",
        "\n",
        "def make_directory(directory):\n",
        "  if os.path.isdir(directory):\n",
        "    shutil.rmtree(directory)\n",
        "  \n",
        "  os.mkdir(directory)\n",
        "  print('Created a new directory')\n",
        "\n",
        "training_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Training Set/Random 5000.zip'\n",
        "test_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Test Set/real_Image_dataset_Detection.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJ6xb5u2dgg",
        "colab_type": "code",
        "outputId": "18d7b89e-3185-4bcc-b6eb-5d41233d98e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# make directories\n",
        "make_directory('Training Set')\n",
        "make_directory('Test Set')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created a new directory\n",
            "Created a new directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSaSXr-m-K4",
        "colab_type": "code",
        "outputId": "3ecec17b-b507-4bff-9e24-16bd5a4a5a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(training_data_zip,'Training Set')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Training Set\n",
            "CPU times: user 3.45 s, sys: 1.28 s, total: 4.73 s\n",
            "Wall time: 9.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPn5aW9nSxu",
        "colab_type": "code",
        "outputId": "632f7550-8296-4294-a89d-4619fc0d7e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(test_data_zip,'Test Set')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Test Set\n",
            "CPU times: user 439 ms, sys: 90 ms, total: 529 ms\n",
            "Wall time: 3.56 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSeyluknVH4",
        "colab_type": "code",
        "outputId": "48dcef22-825b-4637-96eb-e85d04dbc9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Images')))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOp4JsZ6nXvn",
        "colab_type": "code",
        "outputId": "8b65f560-233b-4e5c-b994-28ffa5a1a531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Annotations')))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvg89mXn8zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset.data_utils import *\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JeHTz3G6Lyj",
        "colab_type": "code",
        "outputId": "f516b3f5-553a-4aaa-cef5-1ed7b49336d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = MyDataset('Training Set',transform=transforms.ToTensor())\n",
        "len(train_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLKMn-5SBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9a9PsyF3dqo",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9x221Ya0RBGO",
        "outputId": "5f072dbb-2f01-4e7e-cd34-4d2210ead207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "!chmod +x install_dependencies.sh # make shell script executable\n",
        "!./install_dependencies.sh # run the shell script"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.6/dist-packages (1.1.0.post1)\n",
            "Collecting Polygon3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/a0/d07a4f3e80ed7020a33f3111db217f54ac44a485ff45da3c21ce49f65041/Polygon3-3.0.8.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Polygon3\n",
            "  Building wheel for Polygon3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Polygon3: filename=Polygon3-3.0.8-cp36-cp36m-linux_x86_64.whl size=101495 sha256=c540abd6bbc4f806a02f08e94f8972117f1297297737f63bbf6400343db88ed0\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/32/f1/5525b233996d9d99cbce2f0a8da60d137ddddc555d3e8b0e2a\n",
            "Successfully built Polygon3\n",
            "Installing collected packages: Polygon3\n",
            "Successfully installed Polygon3-3.0.8\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/68/4d/892728b0c14547224f0ac40884e722a3d00cb54e7a146aea0b3186806c9e/colorlog-4.0.2-py2.py3-none-any.whl\n",
            "Installing collected packages: colorlog\n",
            "Successfully installed colorlog-4.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD4GuTKC3wXY",
        "colab_type": "code",
        "outputId": "a63acb26-0697-4908-bd92-6d7bb0d5e28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make: Entering directory '/content/cloned-repo/pse'\n",
            "make: 'pse.so' is up to date.\n",
            "make: Leaving directory '/content/cloned-repo/pse'\n",
            "2019-11-23 08:08:05 \u001b[32mINFO     \u001b[0m utils.py: logger init finished\u001b[0m\n",
            "2019-11-23 08:08:06 \u001b[32mINFO     \u001b[0m train.py: {'Lambda': 0.7,\n",
            " 'OHEM_ratio': 3,\n",
            " 'backbone': 'resnet18',\n",
            " 'checkpoint': '',\n",
            " 'data_shape': 640,\n",
            " 'display_input_images': False,\n",
            " 'display_interval': 10,\n",
            " 'display_output_images': False,\n",
            " 'end_lr': 1e-07,\n",
            " 'epochs': 5,\n",
            " 'gpu_id': '0',\n",
            " 'lr': 0.0001,\n",
            " 'lr_decay_step': [200, 400],\n",
            " 'lr_gamma': 0.1,\n",
            " 'm': 0.5,\n",
            " 'n': 6,\n",
            " 'output_dir': '/content/drive/My Drive/PSENet',\n",
            " 'pretrained': False,\n",
            " 'pretrained_path': '/content/drive/My Drive/PSENet/PSENet_resnet18.pth',\n",
            " 'restart_training': False,\n",
            " 'scale': 1,\n",
            " 'seed': 2,\n",
            " 'show_images_interval': 50,\n",
            " 'start_epoch': 0,\n",
            " 'testroot': 'Test Set',\n",
            " 'train_batch_size': 4,\n",
            " 'trainroot': 'Training Set',\n",
            " 'warm_up_epoch': 6,\n",
            " 'warm_up_lr': 1e-05,\n",
            " 'weight_decay': 0.0005,\n",
            " 'workers': 12}\u001b[0m\n",
            "2019-11-23 08:08:06 \u001b[32mINFO     \u001b[0m train.py: train with gpu 0 and pytorch 1.3.1\u001b[0m\n",
            "2019-11-23 08:08:17 \u001b[32mINFO     \u001b[0m train.py: train dataset has 12500 samples,3125 in dataloader\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "2019-11-23 08:08:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [0/3125], step: 0, 3.255 samples/sec, batch_loss: 0.1779, batch_loss_c: 0.1906, batch_loss_s: 0.1484, time:12.2898, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:08:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [10/3125], step: 10, 7.920 samples/sec, batch_loss: 0.1205, batch_loss_c: 0.1224, batch_loss_s: 0.1161, time:5.0503, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:08:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [20/3125], step: 20, 7.965 samples/sec, batch_loss: 0.1080, batch_loss_c: 0.1061, batch_loss_s: 0.1125, time:5.0220, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:08:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [30/3125], step: 30, 7.226 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.0997, batch_loss_s: 0.1005, time:5.5354, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:08:50 \u001b[32mINFO     \u001b[0m train.py: [0/5], [40/3125], step: 40, 7.763 samples/sec, batch_loss: 0.3429, batch_loss_c: 0.3409, batch_loss_s: 0.3476, time:5.1528, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:08:55 \u001b[32mINFO     \u001b[0m train.py: [0/5], [50/3125], step: 50, 8.234 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3152, batch_loss_s: 0.3238, time:4.8578, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:00 \u001b[32mINFO     \u001b[0m train.py: [0/5], [60/3125], step: 60, 8.044 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1019, batch_loss_s: 0.1168, time:4.9729, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [70/3125], step: 70, 9.289 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.1029, batch_loss_s: 0.0908, time:4.3060, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [80/3125], step: 80, 8.732 samples/sec, batch_loss: 0.2319, batch_loss_c: 0.2728, batch_loss_s: 0.1364, time:4.5809, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [90/3125], step: 90, 7.500 samples/sec, batch_loss: 0.5928, batch_loss_c: 0.6004, batch_loss_s: 0.5751, time:5.3333, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [100/3125], step: 100, 8.048 samples/sec, batch_loss: 0.5154, batch_loss_c: 0.5044, batch_loss_s: 0.5410, time:4.9703, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [110/3125], step: 110, 8.742 samples/sec, batch_loss: 0.1549, batch_loss_c: 0.1566, batch_loss_s: 0.1508, time:4.5755, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:28 \u001b[32mINFO     \u001b[0m train.py: [0/5], [120/3125], step: 120, 8.612 samples/sec, batch_loss: 0.1184, batch_loss_c: 0.1237, batch_loss_s: 0.1062, time:4.6449, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:33 \u001b[32mINFO     \u001b[0m train.py: [0/5], [130/3125], step: 130, 8.803 samples/sec, batch_loss: 0.1711, batch_loss_c: 0.1946, batch_loss_s: 0.1161, time:4.5437, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [140/3125], step: 140, 8.258 samples/sec, batch_loss: 0.3625, batch_loss_c: 0.3670, batch_loss_s: 0.3520, time:4.8437, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:42 \u001b[32mINFO     \u001b[0m train.py: [0/5], [150/3125], step: 150, 8.467 samples/sec, batch_loss: 0.4954, batch_loss_c: 0.4783, batch_loss_s: 0.5352, time:4.7241, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [160/3125], step: 160, 8.403 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3372, batch_loss_s: 0.3408, time:4.7599, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [170/3125], step: 170, 8.592 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0803, batch_loss_s: 0.0852, time:4.6555, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:09:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [180/3125], step: 180, 8.133 samples/sec, batch_loss: 0.1729, batch_loss_c: 0.1837, batch_loss_s: 0.1475, time:4.9184, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [190/3125], step: 190, 7.709 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1126, batch_loss_s: 0.1128, time:5.1888, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [200/3125], step: 200, 7.926 samples/sec, batch_loss: 0.3108, batch_loss_c: 0.3028, batch_loss_s: 0.3294, time:5.0469, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:12 \u001b[32mINFO     \u001b[0m train.py: [0/5], [210/3125], step: 210, 8.521 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0747, batch_loss_s: 0.1034, time:4.6945, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:17 \u001b[32mINFO     \u001b[0m train.py: [0/5], [220/3125], step: 220, 7.274 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3066, batch_loss_s: 0.3564, time:5.4992, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:22 \u001b[32mINFO     \u001b[0m train.py: [0/5], [230/3125], step: 230, 8.662 samples/sec, batch_loss: 0.3583, batch_loss_c: 0.3569, batch_loss_s: 0.3614, time:4.6180, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:27 \u001b[32mINFO     \u001b[0m train.py: [0/5], [240/3125], step: 240, 7.934 samples/sec, batch_loss: 0.2154, batch_loss_c: 0.2095, batch_loss_s: 0.2291, time:5.0415, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:32 \u001b[32mINFO     \u001b[0m train.py: [0/5], [250/3125], step: 250, 8.000 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0792, batch_loss_s: 0.0906, time:4.9999, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [260/3125], step: 260, 7.147 samples/sec, batch_loss: 0.1385, batch_loss_c: 0.1494, batch_loss_s: 0.1131, time:5.5969, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:42 \u001b[32mINFO     \u001b[0m train.py: [0/5], [270/3125], step: 270, 8.355 samples/sec, batch_loss: 0.1834, batch_loss_c: 0.2170, batch_loss_s: 0.1049, time:4.7874, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [280/3125], step: 280, 8.259 samples/sec, batch_loss: 0.1373, batch_loss_c: 0.1595, batch_loss_s: 0.0854, time:4.8433, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [290/3125], step: 290, 8.110 samples/sec, batch_loss: 0.2989, batch_loss_c: 0.2784, batch_loss_s: 0.3467, time:4.9325, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:10:58 \u001b[32mINFO     \u001b[0m train.py: [0/5], [300/3125], step: 300, 7.211 samples/sec, batch_loss: 0.1784, batch_loss_c: 0.1228, batch_loss_s: 0.3082, time:5.5468, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [310/3125], step: 310, 7.154 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1115, batch_loss_s: 0.1325, time:5.5912, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [320/3125], step: 320, 8.288 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0910, batch_loss_s: 0.0811, time:4.8265, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [330/3125], step: 330, 7.273 samples/sec, batch_loss: 0.1797, batch_loss_c: 0.1767, batch_loss_s: 0.1865, time:5.5001, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [340/3125], step: 340, 7.946 samples/sec, batch_loss: 0.3512, batch_loss_c: 0.3502, batch_loss_s: 0.3536, time:5.0342, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [350/3125], step: 350, 8.032 samples/sec, batch_loss: 0.3629, batch_loss_c: 0.3719, batch_loss_s: 0.3421, time:4.9802, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:28 \u001b[32mINFO     \u001b[0m train.py: [0/5], [360/3125], step: 360, 8.138 samples/sec, batch_loss: 0.2004, batch_loss_c: 0.2353, batch_loss_s: 0.1190, time:4.9152, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [370/3125], step: 370, 7.538 samples/sec, batch_loss: 0.1733, batch_loss_c: 0.1917, batch_loss_s: 0.1305, time:5.3065, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [380/3125], step: 380, 7.162 samples/sec, batch_loss: 0.3706, batch_loss_c: 0.3966, batch_loss_s: 0.3099, time:5.5854, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:44 \u001b[32mINFO     \u001b[0m train.py: [0/5], [390/3125], step: 390, 8.939 samples/sec, batch_loss: 0.2136, batch_loss_c: 0.2679, batch_loss_s: 0.0867, time:4.4747, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [400/3125], step: 400, 8.334 samples/sec, batch_loss: 0.3073, batch_loss_c: 0.3067, batch_loss_s: 0.3089, time:4.7995, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [410/3125], step: 410, 7.724 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1084, batch_loss_s: 0.0891, time:5.1790, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:11:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [420/3125], step: 420, 8.417 samples/sec, batch_loss: 0.1849, batch_loss_c: 0.2178, batch_loss_s: 0.1082, time:4.7524, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [430/3125], step: 430, 7.336 samples/sec, batch_loss: 0.3708, batch_loss_c: 0.3899, batch_loss_s: 0.3262, time:5.4528, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [440/3125], step: 440, 7.995 samples/sec, batch_loss: 0.1378, batch_loss_c: 0.1577, batch_loss_s: 0.0913, time:5.0029, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [450/3125], step: 450, 7.525 samples/sec, batch_loss: 0.1475, batch_loss_c: 0.1750, batch_loss_s: 0.0833, time:5.3157, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [460/3125], step: 460, 7.383 samples/sec, batch_loss: 0.1233, batch_loss_c: 0.1328, batch_loss_s: 0.1010, time:5.4182, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [470/3125], step: 470, 7.299 samples/sec, batch_loss: 0.3053, batch_loss_c: 0.3048, batch_loss_s: 0.3065, time:5.4802, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [480/3125], step: 480, 7.429 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0846, batch_loss_s: 0.0753, time:5.3843, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:36 \u001b[32mINFO     \u001b[0m train.py: [0/5], [490/3125], step: 490, 7.851 samples/sec, batch_loss: 0.1584, batch_loss_c: 0.1752, batch_loss_s: 0.1193, time:5.0948, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:41 \u001b[32mINFO     \u001b[0m train.py: [0/5], [500/3125], step: 500, 7.186 samples/sec, batch_loss: 0.3040, batch_loss_c: 0.2958, batch_loss_s: 0.3230, time:5.5667, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:46 \u001b[32mINFO     \u001b[0m train.py: [0/5], [510/3125], step: 510, 8.072 samples/sec, batch_loss: 0.3296, batch_loss_c: 0.3179, batch_loss_s: 0.3568, time:4.9555, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [520/3125], step: 520, 7.475 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0924, batch_loss_s: 0.1033, time:5.3508, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:12:56 \u001b[32mINFO     \u001b[0m train.py: [0/5], [530/3125], step: 530, 8.657 samples/sec, batch_loss: 0.1343, batch_loss_c: 0.1501, batch_loss_s: 0.0973, time:4.6205, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:01 \u001b[32mINFO     \u001b[0m train.py: [0/5], [540/3125], step: 540, 8.463 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1243, batch_loss_s: 0.1396, time:4.7264, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:06 \u001b[32mINFO     \u001b[0m train.py: [0/5], [550/3125], step: 550, 8.549 samples/sec, batch_loss: 0.1132, batch_loss_c: 0.1271, batch_loss_s: 0.0807, time:4.6787, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:11 \u001b[32mINFO     \u001b[0m train.py: [0/5], [560/3125], step: 560, 7.792 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1082, batch_loss_s: 0.1112, time:5.1338, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:16 \u001b[32mINFO     \u001b[0m train.py: [0/5], [570/3125], step: 570, 7.694 samples/sec, batch_loss: 0.1670, batch_loss_c: 0.1798, batch_loss_s: 0.1371, time:5.1992, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:21 \u001b[32mINFO     \u001b[0m train.py: [0/5], [580/3125], step: 580, 8.360 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.0956, batch_loss_s: 0.1037, time:4.7849, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:26 \u001b[32mINFO     \u001b[0m train.py: [0/5], [590/3125], step: 590, 7.677 samples/sec, batch_loss: 0.3394, batch_loss_c: 0.3336, batch_loss_s: 0.3531, time:5.2107, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [600/3125], step: 600, 8.027 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1265, batch_loss_s: 0.1022, time:4.9831, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:36 \u001b[32mINFO     \u001b[0m train.py: [0/5], [610/3125], step: 610, 7.930 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.0991, batch_loss_s: 0.1167, time:5.0441, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:41 \u001b[32mINFO     \u001b[0m train.py: [0/5], [620/3125], step: 620, 7.622 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0849, batch_loss_s: 0.1047, time:5.2483, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:46 \u001b[32mINFO     \u001b[0m train.py: [0/5], [630/3125], step: 630, 7.720 samples/sec, batch_loss: 0.1352, batch_loss_c: 0.1412, batch_loss_s: 0.1213, time:5.1813, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [640/3125], step: 640, 7.449 samples/sec, batch_loss: 0.3437, batch_loss_c: 0.3435, batch_loss_s: 0.3441, time:5.3700, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:13:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [650/3125], step: 650, 7.711 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1454, batch_loss_s: 0.1113, time:5.1872, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [660/3125], step: 660, 7.107 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1155, batch_loss_s: 0.0955, time:5.6281, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [670/3125], step: 670, 7.275 samples/sec, batch_loss: 0.0948, batch_loss_c: 0.0935, batch_loss_s: 0.0977, time:5.4980, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:13 \u001b[32mINFO     \u001b[0m train.py: [0/5], [680/3125], step: 680, 7.824 samples/sec, batch_loss: 0.1228, batch_loss_c: 0.1255, batch_loss_s: 0.1166, time:5.1127, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:18 \u001b[32mINFO     \u001b[0m train.py: [0/5], [690/3125], step: 690, 8.019 samples/sec, batch_loss: 0.2022, batch_loss_c: 0.2372, batch_loss_s: 0.1206, time:4.9881, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [700/3125], step: 700, 7.861 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1189, batch_loss_s: 0.1028, time:5.0882, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [710/3125], step: 710, 7.398 samples/sec, batch_loss: 0.2278, batch_loss_c: 0.2041, batch_loss_s: 0.2832, time:5.4068, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [720/3125], step: 720, 8.042 samples/sec, batch_loss: 0.3308, batch_loss_c: 0.3309, batch_loss_s: 0.3305, time:4.9740, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [730/3125], step: 730, 7.470 samples/sec, batch_loss: 0.1188, batch_loss_c: 0.1136, batch_loss_s: 0.1310, time:5.3549, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [740/3125], step: 740, 7.251 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1289, batch_loss_s: 0.1284, time:5.5164, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:50 \u001b[32mINFO     \u001b[0m train.py: [0/5], [750/3125], step: 750, 7.795 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1029, batch_loss_s: 0.1650, time:5.1313, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:14:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [760/3125], step: 760, 8.855 samples/sec, batch_loss: 0.2376, batch_loss_c: 0.2399, batch_loss_s: 0.2320, time:4.5173, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:00 \u001b[32mINFO     \u001b[0m train.py: [0/5], [770/3125], step: 770, 7.457 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1384, batch_loss_s: 0.1102, time:5.3638, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:05 \u001b[32mINFO     \u001b[0m train.py: [0/5], [780/3125], step: 780, 8.042 samples/sec, batch_loss: 0.2512, batch_loss_c: 0.2408, batch_loss_s: 0.2756, time:4.9736, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [790/3125], step: 790, 8.155 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1041, batch_loss_s: 0.1155, time:4.9051, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:15 \u001b[32mINFO     \u001b[0m train.py: [0/5], [800/3125], step: 800, 7.827 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0725, batch_loss_s: 0.0701, time:5.1107, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [810/3125], step: 810, 8.518 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1121, batch_loss_s: 0.1029, time:4.6958, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [820/3125], step: 820, 8.694 samples/sec, batch_loss: 0.2031, batch_loss_c: 0.2407, batch_loss_s: 0.1155, time:4.6009, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [830/3125], step: 830, 8.261 samples/sec, batch_loss: 0.2006, batch_loss_c: 0.2286, batch_loss_s: 0.1354, time:4.8418, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [840/3125], step: 840, 7.783 samples/sec, batch_loss: 0.1603, batch_loss_c: 0.1689, batch_loss_s: 0.1403, time:5.1391, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [850/3125], step: 850, 7.993 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3081, batch_loss_s: 0.3533, time:5.0044, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [860/3125], step: 860, 8.671 samples/sec, batch_loss: 0.1380, batch_loss_c: 0.1471, batch_loss_s: 0.1168, time:4.6130, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [870/3125], step: 870, 7.475 samples/sec, batch_loss: 0.3172, batch_loss_c: 0.3127, batch_loss_s: 0.3276, time:5.3509, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [880/3125], step: 880, 8.301 samples/sec, batch_loss: 0.3430, batch_loss_c: 0.3466, batch_loss_s: 0.3346, time:4.8186, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:15:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [890/3125], step: 890, 7.585 samples/sec, batch_loss: 0.1101, batch_loss_c: 0.0943, batch_loss_s: 0.1470, time:5.2736, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [900/3125], step: 900, 7.688 samples/sec, batch_loss: 0.1295, batch_loss_c: 0.1323, batch_loss_s: 0.1228, time:5.2027, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [910/3125], step: 910, 7.998 samples/sec, batch_loss: 0.3489, batch_loss_c: 0.3511, batch_loss_s: 0.3437, time:5.0014, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [920/3125], step: 920, 7.495 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.0886, batch_loss_s: 0.1097, time:5.3371, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [930/3125], step: 930, 8.459 samples/sec, batch_loss: 0.1687, batch_loss_c: 0.1766, batch_loss_s: 0.1503, time:4.7288, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [940/3125], step: 940, 7.683 samples/sec, batch_loss: 0.3567, batch_loss_c: 0.3541, batch_loss_s: 0.3630, time:5.2062, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [950/3125], step: 950, 8.485 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0700, batch_loss_s: 0.0826, time:4.7141, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [960/3125], step: 960, 8.248 samples/sec, batch_loss: 0.1699, batch_loss_c: 0.1826, batch_loss_s: 0.1403, time:4.8495, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [970/3125], step: 970, 8.276 samples/sec, batch_loss: 0.3292, batch_loss_c: 0.3286, batch_loss_s: 0.3306, time:4.8332, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:44 \u001b[32mINFO     \u001b[0m train.py: [0/5], [980/3125], step: 980, 7.794 samples/sec, batch_loss: 0.0859, batch_loss_c: 0.0876, batch_loss_s: 0.0821, time:5.1319, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [990/3125], step: 990, 7.901 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.0959, batch_loss_s: 0.1134, time:5.0628, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1000/3125], step: 1000, 8.741 samples/sec, batch_loss: 0.3352, batch_loss_c: 0.3383, batch_loss_s: 0.3278, time:4.5760, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:16:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1010/3125], step: 1010, 7.917 samples/sec, batch_loss: 0.5749, batch_loss_c: 0.5782, batch_loss_s: 0.5672, time:5.0525, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1020/3125], step: 1020, 8.781 samples/sec, batch_loss: 0.0794, batch_loss_c: 0.0797, batch_loss_s: 0.0786, time:4.5551, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1030/3125], step: 1030, 8.141 samples/sec, batch_loss: 0.3228, batch_loss_c: 0.3177, batch_loss_s: 0.3345, time:4.9134, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:13 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1040/3125], step: 1040, 7.902 samples/sec, batch_loss: 0.1569, batch_loss_c: 0.1763, batch_loss_s: 0.1118, time:5.0619, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:18 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1050/3125], step: 1050, 8.189 samples/sec, batch_loss: 0.1291, batch_loss_c: 0.1426, batch_loss_s: 0.0975, time:4.8845, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1060/3125], step: 1060, 7.692 samples/sec, batch_loss: 0.1820, batch_loss_c: 0.1846, batch_loss_s: 0.1760, time:5.2002, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:28 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1070/3125], step: 1070, 8.169 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0895, batch_loss_s: 0.0905, time:4.8965, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:33 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1080/3125], step: 1080, 8.112 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0698, batch_loss_s: 0.0885, time:4.9310, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1090/3125], step: 1090, 7.988 samples/sec, batch_loss: 0.1214, batch_loss_c: 0.1304, batch_loss_s: 0.1005, time:5.0076, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1100/3125], step: 1100, 8.083 samples/sec, batch_loss: 0.1069, batch_loss_c: 0.1049, batch_loss_s: 0.1116, time:4.9484, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:48 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1110/3125], step: 1110, 7.476 samples/sec, batch_loss: 0.3921, batch_loss_c: 0.3989, batch_loss_s: 0.3765, time:5.3503, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1120/3125], step: 1120, 7.101 samples/sec, batch_loss: 0.1318, batch_loss_c: 0.1261, batch_loss_s: 0.1451, time:5.6330, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:17:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1130/3125], step: 1130, 7.878 samples/sec, batch_loss: 0.1139, batch_loss_c: 0.1186, batch_loss_s: 0.1028, time:5.0771, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1140/3125], step: 1140, 8.121 samples/sec, batch_loss: 0.5014, batch_loss_c: 0.4850, batch_loss_s: 0.5399, time:4.9257, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1150/3125], step: 1150, 8.259 samples/sec, batch_loss: 0.1664, batch_loss_c: 0.1706, batch_loss_s: 0.1565, time:4.8431, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1160/3125], step: 1160, 7.393 samples/sec, batch_loss: 0.2688, batch_loss_c: 0.2485, batch_loss_s: 0.3163, time:5.4106, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1170/3125], step: 1170, 6.523 samples/sec, batch_loss: 0.3474, batch_loss_c: 0.3567, batch_loss_s: 0.3255, time:6.1325, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:26 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1180/3125], step: 1180, 7.693 samples/sec, batch_loss: 0.1583, batch_loss_c: 0.1601, batch_loss_s: 0.1542, time:5.1997, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1190/3125], step: 1190, 7.197 samples/sec, batch_loss: 0.1382, batch_loss_c: 0.1447, batch_loss_s: 0.1229, time:5.5579, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:37 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1200/3125], step: 1200, 6.872 samples/sec, batch_loss: 0.1869, batch_loss_c: 0.1999, batch_loss_s: 0.1566, time:5.8211, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1210/3125], step: 1210, 6.913 samples/sec, batch_loss: 0.3152, batch_loss_c: 0.3125, batch_loss_s: 0.3216, time:5.7865, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1220/3125], step: 1220, 6.757 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1216, batch_loss_s: 0.0847, time:5.9197, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:18:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1230/3125], step: 1230, 7.928 samples/sec, batch_loss: 0.2357, batch_loss_c: 0.2185, batch_loss_s: 0.2758, time:5.0452, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:00 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1240/3125], step: 1240, 6.782 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0916, batch_loss_s: 0.1013, time:5.8977, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1250/3125], step: 1250, 8.289 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0909, batch_loss_s: 0.1068, time:4.8257, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:10 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1260/3125], step: 1260, 7.359 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0834, batch_loss_s: 0.0971, time:5.4357, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:16 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1270/3125], step: 1270, 7.072 samples/sec, batch_loss: 0.2160, batch_loss_c: 0.2549, batch_loss_s: 0.1253, time:5.6561, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:21 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1280/3125], step: 1280, 8.031 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1037, batch_loss_s: 0.1122, time:4.9810, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1290/3125], step: 1290, 8.382 samples/sec, batch_loss: 0.1367, batch_loss_c: 0.1435, batch_loss_s: 0.1207, time:4.7723, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:30 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1300/3125], step: 1300, 7.825 samples/sec, batch_loss: 0.3099, batch_loss_c: 0.2960, batch_loss_s: 0.3424, time:5.1116, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:35 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1310/3125], step: 1310, 8.733 samples/sec, batch_loss: 0.3913, batch_loss_c: 0.4058, batch_loss_s: 0.3577, time:4.5802, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:40 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1320/3125], step: 1320, 8.086 samples/sec, batch_loss: 0.2619, batch_loss_c: 0.2879, batch_loss_s: 0.2011, time:4.9466, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1330/3125], step: 1330, 7.663 samples/sec, batch_loss: 0.1870, batch_loss_c: 0.2160, batch_loss_s: 0.1193, time:5.2200, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:50 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1340/3125], step: 1340, 8.389 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.1151, batch_loss_s: 0.1035, time:4.7681, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:19:55 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1350/3125], step: 1350, 8.488 samples/sec, batch_loss: 0.2827, batch_loss_c: 0.2654, batch_loss_s: 0.3231, time:4.7126, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:00 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1360/3125], step: 1360, 8.199 samples/sec, batch_loss: 0.2308, batch_loss_c: 0.1907, batch_loss_s: 0.3242, time:4.8787, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:05 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1370/3125], step: 1370, 8.034 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1481, batch_loss_s: 0.1474, time:4.9787, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:10 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1380/3125], step: 1380, 7.244 samples/sec, batch_loss: 0.3374, batch_loss_c: 0.3227, batch_loss_s: 0.3718, time:5.5218, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:15 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1390/3125], step: 1390, 8.368 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1294, batch_loss_s: 0.1065, time:4.7803, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1400/3125], step: 1400, 8.125 samples/sec, batch_loss: 0.2824, batch_loss_c: 0.2703, batch_loss_s: 0.3106, time:4.9232, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1410/3125], step: 1410, 7.799 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1257, batch_loss_s: 0.0952, time:5.1289, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1420/3125], step: 1420, 8.812 samples/sec, batch_loss: 0.1404, batch_loss_c: 0.1578, batch_loss_s: 0.0996, time:4.5392, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1430/3125], step: 1430, 8.227 samples/sec, batch_loss: 0.1045, batch_loss_c: 0.0967, batch_loss_s: 0.1226, time:4.8618, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1440/3125], step: 1440, 8.003 samples/sec, batch_loss: 0.1866, batch_loss_c: 0.2102, batch_loss_s: 0.1315, time:4.9983, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1450/3125], step: 1450, 7.417 samples/sec, batch_loss: 0.2035, batch_loss_c: 0.2176, batch_loss_s: 0.1706, time:5.3932, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:50 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1460/3125], step: 1460, 7.836 samples/sec, batch_loss: 0.2471, batch_loss_c: 0.2527, batch_loss_s: 0.2342, time:5.1046, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:20:55 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1470/3125], step: 1470, 8.265 samples/sec, batch_loss: 0.2919, batch_loss_c: 0.2738, batch_loss_s: 0.3340, time:4.8395, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:00 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1480/3125], step: 1480, 7.404 samples/sec, batch_loss: 0.1693, batch_loss_c: 0.1581, batch_loss_s: 0.1952, time:5.4027, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:05 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1490/3125], step: 1490, 7.875 samples/sec, batch_loss: 0.2367, batch_loss_c: 0.2845, batch_loss_s: 0.1251, time:5.0796, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:10 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1500/3125], step: 1500, 8.523 samples/sec, batch_loss: 0.3175, batch_loss_c: 0.3218, batch_loss_s: 0.3075, time:4.6934, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:15 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1510/3125], step: 1510, 8.262 samples/sec, batch_loss: 0.0768, batch_loss_c: 0.0764, batch_loss_s: 0.0777, time:4.8412, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1520/3125], step: 1520, 7.946 samples/sec, batch_loss: 0.3441, batch_loss_c: 0.3440, batch_loss_s: 0.3445, time:5.0338, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1530/3125], step: 1530, 7.163 samples/sec, batch_loss: 0.3370, batch_loss_c: 0.3454, batch_loss_s: 0.3174, time:5.5842, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1540/3125], step: 1540, 7.269 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0774, batch_loss_s: 0.0870, time:5.5030, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:36 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1550/3125], step: 1550, 7.431 samples/sec, batch_loss: 0.1370, batch_loss_c: 0.1325, batch_loss_s: 0.1473, time:5.3832, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:42 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1560/3125], step: 1560, 7.074 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.0988, batch_loss_s: 0.1080, time:5.6548, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1570/3125], step: 1570, 8.504 samples/sec, batch_loss: 0.1407, batch_loss_c: 0.1442, batch_loss_s: 0.1325, time:4.7039, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1580/3125], step: 1580, 7.307 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.0945, batch_loss_s: 0.0996, time:5.4743, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:21:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1590/3125], step: 1590, 8.556 samples/sec, batch_loss: 0.2606, batch_loss_c: 0.2837, batch_loss_s: 0.2067, time:4.6751, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1600/3125], step: 1600, 8.137 samples/sec, batch_loss: 0.2962, batch_loss_c: 0.2882, batch_loss_s: 0.3146, time:4.9157, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:06 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1610/3125], step: 1610, 9.165 samples/sec, batch_loss: 0.1481, batch_loss_c: 0.1736, batch_loss_s: 0.0884, time:4.3646, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:11 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1620/3125], step: 1620, 8.465 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1271, batch_loss_s: 0.0839, time:4.7255, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:16 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1630/3125], step: 1630, 8.187 samples/sec, batch_loss: 0.1783, batch_loss_c: 0.2050, batch_loss_s: 0.1161, time:4.8856, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1640/3125], step: 1640, 8.446 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0883, batch_loss_s: 0.0736, time:4.7359, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1650/3125], step: 1650, 7.875 samples/sec, batch_loss: 0.2252, batch_loss_c: 0.2201, batch_loss_s: 0.2371, time:5.0793, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:30 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1660/3125], step: 1660, 8.752 samples/sec, batch_loss: 0.4476, batch_loss_c: 0.4344, batch_loss_s: 0.4784, time:4.5702, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:35 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1670/3125], step: 1670, 8.747 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0732, batch_loss_s: 0.0757, time:4.5729, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:40 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1680/3125], step: 1680, 7.339 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0848, batch_loss_s: 0.1084, time:5.4506, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1690/3125], step: 1690, 7.547 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1094, batch_loss_s: 0.1099, time:5.3003, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:51 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1700/3125], step: 1700, 7.109 samples/sec, batch_loss: 0.3272, batch_loss_c: 0.3267, batch_loss_s: 0.3284, time:5.6268, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:22:56 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1710/3125], step: 1710, 8.338 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.3159, batch_loss_s: 0.3215, time:4.7972, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:01 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1720/3125], step: 1720, 7.525 samples/sec, batch_loss: 0.2069, batch_loss_c: 0.1959, batch_loss_s: 0.2324, time:5.3160, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:06 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1730/3125], step: 1730, 8.348 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1199, batch_loss_s: 0.1223, time:4.7914, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:11 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1740/3125], step: 1740, 7.737 samples/sec, batch_loss: 0.0852, batch_loss_c: 0.0882, batch_loss_s: 0.0782, time:5.1697, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:16 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1750/3125], step: 1750, 7.526 samples/sec, batch_loss: 0.1581, batch_loss_c: 0.1722, batch_loss_s: 0.1254, time:5.3150, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:21 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1760/3125], step: 1760, 7.904 samples/sec, batch_loss: 0.1209, batch_loss_c: 0.1237, batch_loss_s: 0.1144, time:5.0607, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:26 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1770/3125], step: 1770, 8.435 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1191, batch_loss_s: 0.1363, time:4.7423, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1780/3125], step: 1780, 7.909 samples/sec, batch_loss: 0.1839, batch_loss_c: 0.1946, batch_loss_s: 0.1592, time:5.0575, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:36 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1790/3125], step: 1790, 8.349 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1156, batch_loss_s: 0.0883, time:4.7912, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:41 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1800/3125], step: 1800, 7.342 samples/sec, batch_loss: 0.2845, batch_loss_c: 0.2645, batch_loss_s: 0.3312, time:5.4478, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1810/3125], step: 1810, 7.877 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1316, batch_loss_s: 0.1433, time:5.0780, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1820/3125], step: 1820, 7.526 samples/sec, batch_loss: 0.0734, batch_loss_c: 0.0714, batch_loss_s: 0.0783, time:5.3148, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:23:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1830/3125], step: 1830, 7.073 samples/sec, batch_loss: 0.3864, batch_loss_c: 0.3883, batch_loss_s: 0.3820, time:5.6551, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1840/3125], step: 1840, 7.291 samples/sec, batch_loss: 0.3323, batch_loss_c: 0.3320, batch_loss_s: 0.3331, time:5.4863, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1850/3125], step: 1850, 7.445 samples/sec, batch_loss: 0.1612, batch_loss_c: 0.1800, batch_loss_s: 0.1175, time:5.3728, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1860/3125], step: 1860, 6.970 samples/sec, batch_loss: 0.2915, batch_loss_c: 0.2778, batch_loss_s: 0.3236, time:5.7388, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1870/3125], step: 1870, 7.821 samples/sec, batch_loss: 0.2747, batch_loss_c: 0.2612, batch_loss_s: 0.3060, time:5.1145, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1880/3125], step: 1880, 7.607 samples/sec, batch_loss: 0.1071, batch_loss_c: 0.0885, batch_loss_s: 0.1504, time:5.2585, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:30 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1890/3125], step: 1890, 7.439 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1184, batch_loss_s: 0.0875, time:5.3770, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:35 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1900/3125], step: 1900, 7.486 samples/sec, batch_loss: 0.3514, batch_loss_c: 0.3625, batch_loss_s: 0.3255, time:5.3433, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:40 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1910/3125], step: 1910, 7.607 samples/sec, batch_loss: 0.0621, batch_loss_c: 0.0583, batch_loss_s: 0.0708, time:5.2580, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:46 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1920/3125], step: 1920, 6.642 samples/sec, batch_loss: 0.1387, batch_loss_c: 0.1410, batch_loss_s: 0.1335, time:6.0225, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1930/3125], step: 1930, 7.397 samples/sec, batch_loss: 0.1815, batch_loss_c: 0.1842, batch_loss_s: 0.1750, time:5.4077, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:24:58 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1940/3125], step: 1940, 7.096 samples/sec, batch_loss: 0.3888, batch_loss_c: 0.4180, batch_loss_s: 0.3206, time:5.6372, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1950/3125], step: 1950, 8.466 samples/sec, batch_loss: 0.3115, batch_loss_c: 0.3085, batch_loss_s: 0.3186, time:4.7247, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1960/3125], step: 1960, 7.775 samples/sec, batch_loss: 0.1772, batch_loss_c: 0.2045, batch_loss_s: 0.1134, time:5.1448, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:12 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1970/3125], step: 1970, 8.517 samples/sec, batch_loss: 0.3056, batch_loss_c: 0.3021, batch_loss_s: 0.3139, time:4.6967, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:17 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1980/3125], step: 1980, 7.807 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1280, batch_loss_s: 0.1014, time:5.1234, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:22 \u001b[32mINFO     \u001b[0m train.py: [0/5], [1990/3125], step: 1990, 7.869 samples/sec, batch_loss: 0.1213, batch_loss_c: 0.1228, batch_loss_s: 0.1176, time:5.0832, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:28 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2000/3125], step: 2000, 7.187 samples/sec, batch_loss: 0.3063, batch_loss_c: 0.2932, batch_loss_s: 0.3367, time:5.5659, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:33 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2010/3125], step: 2010, 7.952 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1404, batch_loss_s: 0.1277, time:5.0301, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2020/3125], step: 2020, 8.096 samples/sec, batch_loss: 0.1498, batch_loss_c: 0.1592, batch_loss_s: 0.1276, time:4.9408, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2030/3125], step: 2030, 8.496 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1220, batch_loss_s: 0.0930, time:4.7080, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2040/3125], step: 2040, 8.535 samples/sec, batch_loss: 0.1861, batch_loss_c: 0.1616, batch_loss_s: 0.2434, time:4.6864, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2050/3125], step: 2050, 8.007 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0956, batch_loss_s: 0.0855, time:4.9955, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:25:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2060/3125], step: 2060, 7.984 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0901, batch_loss_s: 0.0787, time:5.0099, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2070/3125], step: 2070, 8.355 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.0982, batch_loss_s: 0.1137, time:4.7876, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2080/3125], step: 2080, 8.572 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.0956, batch_loss_s: 0.1241, time:4.6662, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:12 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2090/3125], step: 2090, 7.804 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0815, batch_loss_s: 0.0849, time:5.1257, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:17 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2100/3125], step: 2100, 8.095 samples/sec, batch_loss: 0.2893, batch_loss_c: 0.2801, batch_loss_s: 0.3109, time:4.9412, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:22 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2110/3125], step: 2110, 8.018 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0751, batch_loss_s: 0.0912, time:4.9887, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:27 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2120/3125], step: 2120, 7.596 samples/sec, batch_loss: 0.2933, batch_loss_c: 0.2759, batch_loss_s: 0.3337, time:5.2662, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:32 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2130/3125], step: 2130, 8.241 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0828, batch_loss_s: 0.0869, time:4.8540, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:37 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2140/3125], step: 2140, 7.414 samples/sec, batch_loss: 0.1935, batch_loss_c: 0.2014, batch_loss_s: 0.1749, time:5.3953, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:42 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2150/3125], step: 2150, 8.164 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.0962, batch_loss_s: 0.1132, time:4.8995, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2160/3125], step: 2160, 8.280 samples/sec, batch_loss: 0.2078, batch_loss_c: 0.2192, batch_loss_s: 0.1810, time:4.8311, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2170/3125], step: 2170, 7.704 samples/sec, batch_loss: 0.3277, batch_loss_c: 0.3224, batch_loss_s: 0.3401, time:5.1924, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:26:58 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2180/3125], step: 2180, 7.301 samples/sec, batch_loss: 0.1339, batch_loss_c: 0.1457, batch_loss_s: 0.1063, time:5.4787, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2190/3125], step: 2190, 8.269 samples/sec, batch_loss: 0.3667, batch_loss_c: 0.3848, batch_loss_s: 0.3243, time:4.8373, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2200/3125], step: 2200, 8.191 samples/sec, batch_loss: 0.2796, batch_loss_c: 0.2710, batch_loss_s: 0.2996, time:4.8832, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:13 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2210/3125], step: 2210, 7.508 samples/sec, batch_loss: 0.1661, batch_loss_c: 0.1816, batch_loss_s: 0.1299, time:5.3275, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:18 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2220/3125], step: 2220, 7.619 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0856, batch_loss_s: 0.0854, time:5.2498, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2230/3125], step: 2230, 8.128 samples/sec, batch_loss: 0.3381, batch_loss_c: 0.3459, batch_loss_s: 0.3200, time:4.9216, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:27 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2240/3125], step: 2240, 8.743 samples/sec, batch_loss: 0.1184, batch_loss_c: 0.1321, batch_loss_s: 0.0863, time:4.5751, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:32 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2250/3125], step: 2250, 8.334 samples/sec, batch_loss: 0.3263, batch_loss_c: 0.3283, batch_loss_s: 0.3214, time:4.7996, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:37 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2260/3125], step: 2260, 7.879 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1325, batch_loss_s: 0.0907, time:5.0765, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:42 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2270/3125], step: 2270, 8.312 samples/sec, batch_loss: 0.2260, batch_loss_c: 0.2744, batch_loss_s: 0.1132, time:4.8125, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:47 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2280/3125], step: 2280, 8.815 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0721, batch_loss_s: 0.0793, time:4.5377, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:52 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2290/3125], step: 2290, 8.371 samples/sec, batch_loss: 0.2719, batch_loss_c: 0.2761, batch_loss_s: 0.2619, time:4.7785, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:27:57 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2300/3125], step: 2300, 7.830 samples/sec, batch_loss: 0.1680, batch_loss_c: 0.1920, batch_loss_s: 0.1121, time:5.1084, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2310/3125], step: 2310, 7.370 samples/sec, batch_loss: 0.3022, batch_loss_c: 0.2815, batch_loss_s: 0.3504, time:5.4273, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2320/3125], step: 2320, 8.628 samples/sec, batch_loss: 0.2384, batch_loss_c: 0.2733, batch_loss_s: 0.1568, time:4.6363, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:12 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2330/3125], step: 2330, 7.545 samples/sec, batch_loss: 0.2003, batch_loss_c: 0.1856, batch_loss_s: 0.2346, time:5.3019, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:17 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2340/3125], step: 2340, 7.608 samples/sec, batch_loss: 0.2412, batch_loss_c: 0.2746, batch_loss_s: 0.1631, time:5.2578, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2350/3125], step: 2350, 7.475 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0816, batch_loss_s: 0.0760, time:5.3510, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:27 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2360/3125], step: 2360, 8.323 samples/sec, batch_loss: 0.3237, batch_loss_c: 0.3050, batch_loss_s: 0.3672, time:4.8060, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:32 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2370/3125], step: 2370, 7.946 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0725, batch_loss_s: 0.0817, time:5.0341, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2380/3125], step: 2380, 7.410 samples/sec, batch_loss: 0.3524, batch_loss_c: 0.3570, batch_loss_s: 0.3417, time:5.3979, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2390/3125], step: 2390, 7.268 samples/sec, batch_loss: 0.1258, batch_loss_c: 0.1186, batch_loss_s: 0.1426, time:5.5036, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2400/3125], step: 2400, 7.603 samples/sec, batch_loss: 0.1655, batch_loss_c: 0.1905, batch_loss_s: 0.1070, time:5.2613, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:53 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2410/3125], step: 2410, 8.640 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1274, batch_loss_s: 0.1113, time:4.6296, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:28:58 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2420/3125], step: 2420, 7.965 samples/sec, batch_loss: 0.3136, batch_loss_c: 0.3150, batch_loss_s: 0.3103, time:5.0221, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:03 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2430/3125], step: 2430, 7.944 samples/sec, batch_loss: 0.3285, batch_loss_c: 0.3315, batch_loss_s: 0.3215, time:5.0350, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2440/3125], step: 2440, 8.321 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1471, batch_loss_s: 0.1152, time:4.8072, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:13 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2450/3125], step: 2450, 7.836 samples/sec, batch_loss: 0.2873, batch_loss_c: 0.2861, batch_loss_s: 0.2902, time:5.1048, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:18 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2460/3125], step: 2460, 8.872 samples/sec, batch_loss: 0.3267, batch_loss_c: 0.3224, batch_loss_s: 0.3369, time:4.5087, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2470/3125], step: 2470, 7.322 samples/sec, batch_loss: 0.1359, batch_loss_c: 0.1370, batch_loss_s: 0.1333, time:5.4630, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:28 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2480/3125], step: 2480, 7.656 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1055, batch_loss_s: 0.1012, time:5.2243, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:33 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2490/3125], step: 2490, 8.163 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.0956, batch_loss_s: 0.0983, time:4.9001, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2500/3125], step: 2500, 8.050 samples/sec, batch_loss: 0.2069, batch_loss_c: 0.2395, batch_loss_s: 0.1306, time:4.9692, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2510/3125], step: 2510, 8.869 samples/sec, batch_loss: 0.1123, batch_loss_c: 0.1089, batch_loss_s: 0.1202, time:4.5103, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:48 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2520/3125], step: 2520, 7.469 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0943, batch_loss_s: 0.1003, time:5.3553, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2530/3125], step: 2530, 7.352 samples/sec, batch_loss: 0.1126, batch_loss_c: 0.1218, batch_loss_s: 0.0912, time:5.4405, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:29:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2540/3125], step: 2540, 7.346 samples/sec, batch_loss: 0.1630, batch_loss_c: 0.1959, batch_loss_s: 0.0860, time:5.4448, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2550/3125], step: 2550, 8.054 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1054, batch_loss_s: 0.0980, time:4.9663, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:09 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2560/3125], step: 2560, 7.325 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0870, batch_loss_s: 0.0893, time:5.4607, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2570/3125], step: 2570, 8.263 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0708, batch_loss_s: 0.0887, time:4.8408, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2580/3125], step: 2580, 8.109 samples/sec, batch_loss: 0.1384, batch_loss_c: 0.1616, batch_loss_s: 0.0841, time:4.9329, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2590/3125], step: 2590, 8.239 samples/sec, batch_loss: 0.1586, batch_loss_c: 0.1584, batch_loss_s: 0.1590, time:4.8552, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2600/3125], step: 2600, 7.480 samples/sec, batch_loss: 0.3317, batch_loss_c: 0.3361, batch_loss_s: 0.3216, time:5.3473, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:35 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2610/3125], step: 2610, 7.740 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0777, batch_loss_s: 0.1043, time:5.1678, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:40 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2620/3125], step: 2620, 7.504 samples/sec, batch_loss: 0.0764, batch_loss_c: 0.0768, batch_loss_s: 0.0755, time:5.3306, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2630/3125], step: 2630, 7.877 samples/sec, batch_loss: 0.1359, batch_loss_c: 0.1472, batch_loss_s: 0.1095, time:5.0781, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:51 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2640/3125], step: 2640, 6.880 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1040, batch_loss_s: 0.1001, time:5.8138, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:30:56 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2650/3125], step: 2650, 7.549 samples/sec, batch_loss: 0.1643, batch_loss_c: 0.1661, batch_loss_s: 0.1600, time:5.2987, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:02 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2660/3125], step: 2660, 7.224 samples/sec, batch_loss: 0.1349, batch_loss_c: 0.1384, batch_loss_s: 0.1267, time:5.5372, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:07 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2670/3125], step: 2670, 7.494 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1271, batch_loss_s: 0.0872, time:5.3378, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:12 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2680/3125], step: 2680, 7.859 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.1624, batch_loss_s: 0.1633, time:5.0900, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:18 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2690/3125], step: 2690, 7.371 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0845, batch_loss_s: 0.1002, time:5.4268, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:23 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2700/3125], step: 2700, 7.860 samples/sec, batch_loss: 0.3084, batch_loss_c: 0.3051, batch_loss_s: 0.3160, time:5.0887, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:27 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2710/3125], step: 2710, 8.871 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0793, batch_loss_s: 0.0907, time:4.5089, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:32 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2720/3125], step: 2720, 7.910 samples/sec, batch_loss: 0.1907, batch_loss_c: 0.2048, batch_loss_s: 0.1577, time:5.0571, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:38 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2730/3125], step: 2730, 7.500 samples/sec, batch_loss: 0.2906, batch_loss_c: 0.3576, batch_loss_s: 0.1344, time:5.3330, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:43 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2740/3125], step: 2740, 7.416 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.0989, batch_loss_s: 0.1067, time:5.3934, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:48 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2750/3125], step: 2750, 8.092 samples/sec, batch_loss: 0.3330, batch_loss_c: 0.3328, batch_loss_s: 0.3334, time:4.9430, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:53 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2760/3125], step: 2760, 7.807 samples/sec, batch_loss: 0.4885, batch_loss_c: 0.4822, batch_loss_s: 0.5031, time:5.1235, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:31:58 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2770/3125], step: 2770, 8.048 samples/sec, batch_loss: 0.3164, batch_loss_c: 0.3085, batch_loss_s: 0.3350, time:4.9699, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2780/3125], step: 2780, 7.058 samples/sec, batch_loss: 0.2153, batch_loss_c: 0.2399, batch_loss_s: 0.1578, time:5.6672, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:08 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2790/3125], step: 2790, 8.264 samples/sec, batch_loss: 0.3626, batch_loss_c: 0.3616, batch_loss_s: 0.3651, time:4.8404, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:13 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2800/3125], step: 2800, 8.339 samples/sec, batch_loss: 0.3008, batch_loss_c: 0.2918, batch_loss_s: 0.3218, time:4.7970, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:19 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2810/3125], step: 2810, 7.091 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0772, batch_loss_s: 0.0867, time:5.6406, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:24 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2820/3125], step: 2820, 8.573 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1192, batch_loss_s: 0.1301, time:4.6660, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:29 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2830/3125], step: 2830, 8.060 samples/sec, batch_loss: 0.1376, batch_loss_c: 0.1454, batch_loss_s: 0.1194, time:4.9626, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:34 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2840/3125], step: 2840, 7.335 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1319, batch_loss_s: 0.1383, time:5.4536, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:39 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2850/3125], step: 2850, 8.011 samples/sec, batch_loss: 0.2474, batch_loss_c: 0.2577, batch_loss_s: 0.2233, time:4.9932, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:44 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2860/3125], step: 2860, 7.598 samples/sec, batch_loss: 0.2602, batch_loss_c: 0.2259, batch_loss_s: 0.3404, time:5.2645, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:49 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2870/3125], step: 2870, 8.600 samples/sec, batch_loss: 0.0976, batch_loss_c: 0.0964, batch_loss_s: 0.1005, time:4.6512, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2880/3125], step: 2880, 7.858 samples/sec, batch_loss: 0.3522, batch_loss_c: 0.3599, batch_loss_s: 0.3341, time:5.0903, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:32:59 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2890/3125], step: 2890, 7.991 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1416, batch_loss_s: 0.0833, time:5.0054, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:04 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2900/3125], step: 2900, 7.536 samples/sec, batch_loss: 0.0828, batch_loss_c: 0.0786, batch_loss_s: 0.0928, time:5.3078, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:10 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2910/3125], step: 2910, 7.451 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0796, batch_loss_s: 0.0795, time:5.3683, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:14 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2920/3125], step: 2920, 8.579 samples/sec, batch_loss: 0.2918, batch_loss_c: 0.2867, batch_loss_s: 0.3036, time:4.6627, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:20 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2930/3125], step: 2930, 7.161 samples/sec, batch_loss: 0.3772, batch_loss_c: 0.3724, batch_loss_s: 0.3883, time:5.5856, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:25 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2940/3125], step: 2940, 7.985 samples/sec, batch_loss: 0.1217, batch_loss_c: 0.1178, batch_loss_s: 0.1309, time:5.0092, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:30 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2950/3125], step: 2950, 7.592 samples/sec, batch_loss: 0.1543, batch_loss_c: 0.1587, batch_loss_s: 0.1440, time:5.2685, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:35 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2960/3125], step: 2960, 7.665 samples/sec, batch_loss: 0.3152, batch_loss_c: 0.3152, batch_loss_s: 0.3152, time:5.2185, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:40 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2970/3125], step: 2970, 8.360 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1352, batch_loss_s: 0.0928, time:4.7845, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:45 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2980/3125], step: 2980, 7.718 samples/sec, batch_loss: 0.2727, batch_loss_c: 0.2548, batch_loss_s: 0.3143, time:5.1826, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:51 \u001b[32mINFO     \u001b[0m train.py: [0/5], [2990/3125], step: 2990, 6.994 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1154, batch_loss_s: 0.1187, time:5.7190, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:33:56 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3000/3125], step: 3000, 8.153 samples/sec, batch_loss: 0.1892, batch_loss_c: 0.2211, batch_loss_s: 0.1148, time:4.9061, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:01 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3010/3125], step: 3010, 8.352 samples/sec, batch_loss: 0.3212, batch_loss_c: 0.3152, batch_loss_s: 0.3353, time:4.7890, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:06 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3020/3125], step: 3020, 7.821 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.1036, batch_loss_s: 0.0799, time:5.1145, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:11 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3030/3125], step: 3030, 8.448 samples/sec, batch_loss: 0.3255, batch_loss_c: 0.3275, batch_loss_s: 0.3209, time:4.7346, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:16 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3040/3125], step: 3040, 7.937 samples/sec, batch_loss: 0.1425, batch_loss_c: 0.1549, batch_loss_s: 0.1134, time:5.0399, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:21 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3050/3125], step: 3050, 8.179 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1627, batch_loss_s: 0.0838, time:4.8905, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:26 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3060/3125], step: 3060, 7.604 samples/sec, batch_loss: 0.1679, batch_loss_c: 0.2109, batch_loss_s: 0.0675, time:5.2603, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:31 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3070/3125], step: 3070, 7.627 samples/sec, batch_loss: 0.4360, batch_loss_c: 0.4488, batch_loss_s: 0.4063, time:5.2442, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:37 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3080/3125], step: 3080, 7.431 samples/sec, batch_loss: 0.1897, batch_loss_c: 0.2147, batch_loss_s: 0.1315, time:5.3828, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:41 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3090/3125], step: 3090, 8.025 samples/sec, batch_loss: 0.0938, batch_loss_c: 0.0953, batch_loss_s: 0.0906, time:4.9844, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:46 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3100/3125], step: 3100, 8.592 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1009, batch_loss_s: 0.1085, time:4.6557, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:50 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3110/3125], step: 3110, 10.457 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0790, batch_loss_s: 0.0958, time:3.8254, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:54 \u001b[32mINFO     \u001b[0m train.py: [0/5], [3120/3125], step: 3120, 10.063 samples/sec, batch_loss: 0.2230, batch_loss_c: 0.2000, batch_loss_s: 0.2768, time:3.9751, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:34:56 \u001b[32mINFO     \u001b[0m train.py: [0/5], train_loss: 0.2092, time: 1598.6790, lr: 0.0001\u001b[0m\n",
            "2019-11-23 08:35:01 \u001b[32mINFO     \u001b[0m train.py: [1/5], [0/3125], step: 3125, 8.144 samples/sec, batch_loss: 0.1039, batch_loss_c: 0.1058, batch_loss_s: 0.0995, time:4.9116, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:08 \u001b[32mINFO     \u001b[0m train.py: [1/5], [10/3125], step: 3135, 5.641 samples/sec, batch_loss: 0.3695, batch_loss_c: 0.3899, batch_loss_s: 0.3221, time:7.0911, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [20/3125], step: 3145, 8.439 samples/sec, batch_loss: 0.1193, batch_loss_c: 0.1286, batch_loss_s: 0.0975, time:4.7400, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:18 \u001b[32mINFO     \u001b[0m train.py: [1/5], [30/3125], step: 3155, 8.093 samples/sec, batch_loss: 0.2261, batch_loss_c: 0.2434, batch_loss_s: 0.1857, time:4.9426, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:23 \u001b[32mINFO     \u001b[0m train.py: [1/5], [40/3125], step: 3165, 7.948 samples/sec, batch_loss: 0.3333, batch_loss_c: 0.3283, batch_loss_s: 0.3452, time:5.0326, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:28 \u001b[32mINFO     \u001b[0m train.py: [1/5], [50/3125], step: 3175, 8.264 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0857, batch_loss_s: 0.0941, time:4.8404, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:32 \u001b[32mINFO     \u001b[0m train.py: [1/5], [60/3125], step: 3185, 8.570 samples/sec, batch_loss: 0.3812, batch_loss_c: 0.3885, batch_loss_s: 0.3642, time:4.6677, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:37 \u001b[32mINFO     \u001b[0m train.py: [1/5], [70/3125], step: 3195, 8.705 samples/sec, batch_loss: 0.1394, batch_loss_c: 0.1479, batch_loss_s: 0.1195, time:4.5951, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:42 \u001b[32mINFO     \u001b[0m train.py: [1/5], [80/3125], step: 3205, 7.570 samples/sec, batch_loss: 0.1388, batch_loss_c: 0.1510, batch_loss_s: 0.1103, time:5.2838, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [90/3125], step: 3215, 8.079 samples/sec, batch_loss: 0.2487, batch_loss_c: 0.2602, batch_loss_s: 0.2220, time:4.9512, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:51 \u001b[32mINFO     \u001b[0m train.py: [1/5], [100/3125], step: 3225, 8.978 samples/sec, batch_loss: 0.4860, batch_loss_c: 0.4978, batch_loss_s: 0.4584, time:4.4555, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:35:56 \u001b[32mINFO     \u001b[0m train.py: [1/5], [110/3125], step: 3235, 8.562 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0658, batch_loss_s: 0.0709, time:4.6716, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:01 \u001b[32mINFO     \u001b[0m train.py: [1/5], [120/3125], step: 3245, 8.145 samples/sec, batch_loss: 0.1474, batch_loss_c: 0.1770, batch_loss_s: 0.0784, time:4.9109, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:06 \u001b[32mINFO     \u001b[0m train.py: [1/5], [130/3125], step: 3255, 8.318 samples/sec, batch_loss: 0.1407, batch_loss_c: 0.1511, batch_loss_s: 0.1162, time:4.8089, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:11 \u001b[32mINFO     \u001b[0m train.py: [1/5], [140/3125], step: 3265, 8.518 samples/sec, batch_loss: 0.5226, batch_loss_c: 0.5082, batch_loss_s: 0.5562, time:4.6961, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [150/3125], step: 3275, 8.450 samples/sec, batch_loss: 0.2082, batch_loss_c: 0.2559, batch_loss_s: 0.0969, time:4.7336, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [160/3125], step: 3285, 8.448 samples/sec, batch_loss: 0.1644, batch_loss_c: 0.1555, batch_loss_s: 0.1853, time:4.7349, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [170/3125], step: 3295, 8.114 samples/sec, batch_loss: 0.1243, batch_loss_c: 0.1452, batch_loss_s: 0.0756, time:4.9299, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [180/3125], step: 3305, 8.231 samples/sec, batch_loss: 0.1285, batch_loss_c: 0.1352, batch_loss_s: 0.1129, time:4.8598, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [190/3125], step: 3315, 7.912 samples/sec, batch_loss: 0.1326, batch_loss_c: 0.1427, batch_loss_s: 0.1092, time:5.0558, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [200/3125], step: 3325, 8.801 samples/sec, batch_loss: 0.2062, batch_loss_c: 0.2546, batch_loss_s: 0.0934, time:4.5450, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [210/3125], step: 3335, 8.339 samples/sec, batch_loss: 0.1729, batch_loss_c: 0.1916, batch_loss_s: 0.1291, time:4.7968, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [220/3125], step: 3345, 7.790 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3062, batch_loss_s: 0.3318, time:5.1346, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [230/3125], step: 3355, 8.793 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1520, batch_loss_s: 0.1087, time:4.5488, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:36:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [240/3125], step: 3365, 8.371 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3253, batch_loss_s: 0.3005, time:4.7785, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [250/3125], step: 3375, 7.553 samples/sec, batch_loss: 0.1639, batch_loss_c: 0.1557, batch_loss_s: 0.1829, time:5.2959, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:08 \u001b[32mINFO     \u001b[0m train.py: [1/5], [260/3125], step: 3385, 8.942 samples/sec, batch_loss: 0.1273, batch_loss_c: 0.1309, batch_loss_s: 0.1188, time:4.4732, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [270/3125], step: 3395, 8.141 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1695, batch_loss_s: 0.1069, time:4.9135, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [280/3125], step: 3405, 7.832 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1387, batch_loss_s: 0.1459, time:5.1072, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [290/3125], step: 3415, 7.344 samples/sec, batch_loss: 0.1403, batch_loss_c: 0.1655, batch_loss_s: 0.0816, time:5.4466, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:29 \u001b[32mINFO     \u001b[0m train.py: [1/5], [300/3125], step: 3425, 7.486 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1165, batch_loss_s: 0.1162, time:5.3434, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:34 \u001b[32mINFO     \u001b[0m train.py: [1/5], [310/3125], step: 3435, 7.997 samples/sec, batch_loss: 0.3415, batch_loss_c: 0.3387, batch_loss_s: 0.3479, time:5.0022, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [320/3125], step: 3445, 7.896 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1451, batch_loss_s: 0.1163, time:5.0661, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [330/3125], step: 3455, 7.430 samples/sec, batch_loss: 0.1987, batch_loss_c: 0.2228, batch_loss_s: 0.1424, time:5.3836, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [340/3125], step: 3465, 8.603 samples/sec, batch_loss: 0.5650, batch_loss_c: 0.5542, batch_loss_s: 0.5903, time:4.6493, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [350/3125], step: 3475, 7.884 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0925, batch_loss_s: 0.1019, time:5.0734, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:37:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [360/3125], step: 3485, 8.592 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1344, batch_loss_s: 0.1035, time:4.6557, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [370/3125], step: 3495, 8.253 samples/sec, batch_loss: 0.7777, batch_loss_c: 0.7662, batch_loss_s: 0.8044, time:4.8465, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [380/3125], step: 3505, 7.441 samples/sec, batch_loss: 0.2433, batch_loss_c: 0.2907, batch_loss_s: 0.1327, time:5.3758, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [390/3125], step: 3515, 7.364 samples/sec, batch_loss: 0.3186, batch_loss_c: 0.3138, batch_loss_s: 0.3298, time:5.4322, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [400/3125], step: 3525, 7.729 samples/sec, batch_loss: 0.4266, batch_loss_c: 0.4626, batch_loss_s: 0.3424, time:5.1754, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [410/3125], step: 3535, 7.829 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1649, batch_loss_s: 0.0735, time:5.1089, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [420/3125], step: 3545, 8.702 samples/sec, batch_loss: 0.1078, batch_loss_c: 0.1115, batch_loss_s: 0.0993, time:4.5965, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [430/3125], step: 3555, 7.628 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0677, batch_loss_s: 0.0810, time:5.2438, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [440/3125], step: 3565, 8.196 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0810, batch_loss_s: 0.0827, time:4.8801, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [450/3125], step: 3575, 7.060 samples/sec, batch_loss: 0.0772, batch_loss_c: 0.0758, batch_loss_s: 0.0805, time:5.6654, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:51 \u001b[32mINFO     \u001b[0m train.py: [1/5], [460/3125], step: 3585, 7.125 samples/sec, batch_loss: 0.1363, batch_loss_c: 0.1291, batch_loss_s: 0.1530, time:5.6142, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:38:57 \u001b[32mINFO     \u001b[0m train.py: [1/5], [470/3125], step: 3595, 7.176 samples/sec, batch_loss: 0.1401, batch_loss_c: 0.1690, batch_loss_s: 0.0726, time:5.5742, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:02 \u001b[32mINFO     \u001b[0m train.py: [1/5], [480/3125], step: 3605, 7.445 samples/sec, batch_loss: 0.2937, batch_loss_c: 0.2748, batch_loss_s: 0.3378, time:5.3729, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:07 \u001b[32mINFO     \u001b[0m train.py: [1/5], [490/3125], step: 3615, 7.349 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0931, batch_loss_s: 0.0797, time:5.4431, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [500/3125], step: 3625, 6.933 samples/sec, batch_loss: 0.1960, batch_loss_c: 0.2148, batch_loss_s: 0.1522, time:5.7699, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [510/3125], step: 3635, 7.379 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1256, batch_loss_s: 0.1072, time:5.4204, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [520/3125], step: 3645, 7.643 samples/sec, batch_loss: 0.2956, batch_loss_c: 0.2923, batch_loss_s: 0.3035, time:5.2337, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:29 \u001b[32mINFO     \u001b[0m train.py: [1/5], [530/3125], step: 3655, 7.248 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0852, batch_loss_s: 0.0891, time:5.5188, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [540/3125], step: 3665, 7.754 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1205, batch_loss_s: 0.0995, time:5.1589, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [550/3125], step: 3675, 8.659 samples/sec, batch_loss: 0.1524, batch_loss_c: 0.1640, batch_loss_s: 0.1253, time:4.6194, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [560/3125], step: 3685, 8.777 samples/sec, batch_loss: 0.2293, batch_loss_c: 0.2205, batch_loss_s: 0.2498, time:4.5571, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:48 \u001b[32mINFO     \u001b[0m train.py: [1/5], [570/3125], step: 3695, 8.744 samples/sec, batch_loss: 0.1664, batch_loss_c: 0.1909, batch_loss_s: 0.1092, time:4.5747, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [580/3125], step: 3705, 7.759 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1051, batch_loss_s: 0.1044, time:5.1550, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:39:58 \u001b[32mINFO     \u001b[0m train.py: [1/5], [590/3125], step: 3715, 8.158 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0635, batch_loss_s: 0.0773, time:4.9030, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [600/3125], step: 3725, 7.823 samples/sec, batch_loss: 0.3059, batch_loss_c: 0.2924, batch_loss_s: 0.3375, time:5.1132, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [610/3125], step: 3735, 7.732 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1765, batch_loss_s: 0.0740, time:5.1734, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [620/3125], step: 3745, 8.242 samples/sec, batch_loss: 0.1476, batch_loss_c: 0.1513, batch_loss_s: 0.1388, time:4.8535, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [630/3125], step: 3755, 7.623 samples/sec, batch_loss: 0.2501, batch_loss_c: 0.2822, batch_loss_s: 0.1753, time:5.2471, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:23 \u001b[32mINFO     \u001b[0m train.py: [1/5], [640/3125], step: 3765, 8.877 samples/sec, batch_loss: 0.0984, batch_loss_c: 0.0959, batch_loss_s: 0.1043, time:4.5062, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:28 \u001b[32mINFO     \u001b[0m train.py: [1/5], [650/3125], step: 3775, 8.406 samples/sec, batch_loss: 0.1156, batch_loss_c: 0.1171, batch_loss_s: 0.1121, time:4.7583, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:33 \u001b[32mINFO     \u001b[0m train.py: [1/5], [660/3125], step: 3785, 8.433 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1190, batch_loss_s: 0.0587, time:4.7433, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [670/3125], step: 3795, 7.856 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1099, batch_loss_s: 0.1099, time:5.0913, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [680/3125], step: 3805, 6.818 samples/sec, batch_loss: 0.1556, batch_loss_c: 0.1586, batch_loss_s: 0.1485, time:5.8667, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [690/3125], step: 3815, 7.602 samples/sec, batch_loss: 0.1119, batch_loss_c: 0.1092, batch_loss_s: 0.1184, time:5.2619, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:40:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [700/3125], step: 3825, 8.154 samples/sec, batch_loss: 0.2081, batch_loss_c: 0.2185, batch_loss_s: 0.1837, time:4.9055, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [710/3125], step: 3835, 6.930 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0883, batch_loss_s: 0.0888, time:5.7717, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [720/3125], step: 3845, 8.020 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1049, batch_loss_s: 0.1245, time:4.9874, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [730/3125], step: 3855, 8.204 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1240, batch_loss_s: 0.1009, time:4.8759, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [740/3125], step: 3865, 8.478 samples/sec, batch_loss: 0.1613, batch_loss_c: 0.1815, batch_loss_s: 0.1142, time:4.7184, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [750/3125], step: 3875, 7.010 samples/sec, batch_loss: 0.3446, batch_loss_c: 0.3301, batch_loss_s: 0.3784, time:5.7064, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [760/3125], step: 3885, 8.462 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0620, batch_loss_s: 0.0862, time:4.7268, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [770/3125], step: 3895, 7.876 samples/sec, batch_loss: 0.9747, batch_loss_c: 0.9639, batch_loss_s: 1.0000, time:5.0790, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [780/3125], step: 3905, 8.196 samples/sec, batch_loss: 0.2531, batch_loss_c: 0.2703, batch_loss_s: 0.2131, time:4.8806, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [790/3125], step: 3915, 7.708 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0813, batch_loss_s: 0.0857, time:5.1895, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [800/3125], step: 3925, 8.305 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1326, batch_loss_s: 0.1489, time:4.8163, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [810/3125], step: 3935, 8.040 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1077, batch_loss_s: 0.0962, time:4.9753, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [820/3125], step: 3945, 8.349 samples/sec, batch_loss: 0.1740, batch_loss_c: 0.1999, batch_loss_s: 0.1135, time:4.7908, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:41:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [830/3125], step: 3955, 8.698 samples/sec, batch_loss: 0.4537, batch_loss_c: 0.5006, batch_loss_s: 0.3442, time:4.5990, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [840/3125], step: 3965, 8.512 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1248, batch_loss_s: 0.1099, time:4.6993, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [850/3125], step: 3975, 7.360 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0939, batch_loss_s: 0.1004, time:5.4349, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [860/3125], step: 3985, 7.257 samples/sec, batch_loss: 0.4317, batch_loss_c: 0.4786, batch_loss_s: 0.3222, time:5.5117, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [870/3125], step: 3995, 8.620 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.0986, batch_loss_s: 0.1148, time:4.6402, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [880/3125], step: 4005, 8.716 samples/sec, batch_loss: 0.1123, batch_loss_c: 0.1150, batch_loss_s: 0.1061, time:4.5892, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [890/3125], step: 4015, 7.029 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1521, batch_loss_s: 0.0862, time:5.6910, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [900/3125], step: 4025, 8.050 samples/sec, batch_loss: 0.0849, batch_loss_c: 0.0838, batch_loss_s: 0.0872, time:4.9692, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [910/3125], step: 4035, 8.784 samples/sec, batch_loss: 0.1694, batch_loss_c: 0.1804, batch_loss_s: 0.1438, time:4.5535, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [920/3125], step: 4045, 8.288 samples/sec, batch_loss: 0.3187, batch_loss_c: 0.3808, batch_loss_s: 0.1739, time:4.8261, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [930/3125], step: 4055, 7.700 samples/sec, batch_loss: 0.3221, batch_loss_c: 0.3929, batch_loss_s: 0.1568, time:5.1946, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [940/3125], step: 4065, 7.848 samples/sec, batch_loss: 0.1516, batch_loss_c: 0.1693, batch_loss_s: 0.1104, time:5.0966, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:42:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [950/3125], step: 4075, 8.476 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1288, batch_loss_s: 0.1175, time:4.7194, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [960/3125], step: 4085, 8.734 samples/sec, batch_loss: 0.3316, batch_loss_c: 0.3226, batch_loss_s: 0.3525, time:4.5797, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:08 \u001b[32mINFO     \u001b[0m train.py: [1/5], [970/3125], step: 4095, 9.255 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1527, batch_loss_s: 0.1333, time:4.3220, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [980/3125], step: 4105, 8.702 samples/sec, batch_loss: 0.3442, batch_loss_c: 0.3461, batch_loss_s: 0.3399, time:4.5968, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:17 \u001b[32mINFO     \u001b[0m train.py: [1/5], [990/3125], step: 4115, 8.316 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1090, batch_loss_s: 0.1000, time:4.8101, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:22 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1000/3125], step: 4125, 7.815 samples/sec, batch_loss: 0.1784, batch_loss_c: 0.1843, batch_loss_s: 0.1645, time:5.1185, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:27 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1010/3125], step: 4135, 8.475 samples/sec, batch_loss: 0.5182, batch_loss_c: 0.5020, batch_loss_s: 0.5559, time:4.7200, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:32 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1020/3125], step: 4145, 7.506 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1357, batch_loss_s: 0.0916, time:5.3288, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1030/3125], step: 4155, 7.963 samples/sec, batch_loss: 0.1494, batch_loss_c: 0.1688, batch_loss_s: 0.1042, time:5.0234, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:43 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1040/3125], step: 4165, 7.881 samples/sec, batch_loss: 0.2012, batch_loss_c: 0.2398, batch_loss_s: 0.1110, time:5.0756, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1050/3125], step: 4175, 8.426 samples/sec, batch_loss: 0.3969, batch_loss_c: 0.4141, batch_loss_s: 0.3570, time:4.7470, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:53 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1060/3125], step: 4185, 7.209 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.2874, batch_loss_s: 0.3566, time:5.5489, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:43:58 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1070/3125], step: 4195, 8.282 samples/sec, batch_loss: 0.3547, batch_loss_c: 0.3601, batch_loss_s: 0.3423, time:4.8296, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:03 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1080/3125], step: 4205, 7.703 samples/sec, batch_loss: 0.4171, batch_loss_c: 0.4535, batch_loss_s: 0.3320, time:5.1926, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:08 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1090/3125], step: 4215, 8.617 samples/sec, batch_loss: 0.1471, batch_loss_c: 0.1538, batch_loss_s: 0.1315, time:4.6418, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1100/3125], step: 4225, 7.662 samples/sec, batch_loss: 0.1388, batch_loss_c: 0.1465, batch_loss_s: 0.1208, time:5.2207, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:17 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1110/3125], step: 4235, 8.503 samples/sec, batch_loss: 0.1067, batch_loss_c: 0.1078, batch_loss_s: 0.1041, time:4.7045, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:22 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1120/3125], step: 4245, 8.209 samples/sec, batch_loss: 0.1948, batch_loss_c: 0.2451, batch_loss_s: 0.0773, time:4.8729, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:28 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1130/3125], step: 4255, 7.711 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.1062, batch_loss_s: 0.0844, time:5.1873, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:33 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1140/3125], step: 4265, 7.336 samples/sec, batch_loss: 0.1817, batch_loss_c: 0.2054, batch_loss_s: 0.1263, time:5.4527, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1150/3125], step: 4275, 8.201 samples/sec, batch_loss: 0.4148, batch_loss_c: 0.3650, batch_loss_s: 0.5311, time:4.8776, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1160/3125], step: 4285, 7.096 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.0993, batch_loss_s: 0.0914, time:5.6368, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1170/3125], step: 4295, 7.170 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0963, batch_loss_s: 0.0723, time:5.5791, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:44:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1180/3125], step: 4305, 6.518 samples/sec, batch_loss: 0.1132, batch_loss_c: 0.1212, batch_loss_s: 0.0946, time:6.1365, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1190/3125], step: 4315, 8.074 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1584, batch_loss_s: 0.1562, time:4.9539, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1200/3125], step: 4325, 8.536 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.1628, batch_loss_s: 0.2977, time:4.6863, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1210/3125], step: 4335, 7.840 samples/sec, batch_loss: 0.4140, batch_loss_c: 0.4426, batch_loss_s: 0.3474, time:5.1021, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1220/3125], step: 4345, 6.640 samples/sec, batch_loss: 0.1594, batch_loss_c: 0.1704, batch_loss_s: 0.1337, time:6.0240, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1230/3125], step: 4355, 8.407 samples/sec, batch_loss: 0.4186, batch_loss_c: 0.4379, batch_loss_s: 0.3734, time:4.7582, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1240/3125], step: 4365, 8.156 samples/sec, batch_loss: 0.5357, batch_loss_c: 0.5223, batch_loss_s: 0.5670, time:4.9042, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1250/3125], step: 4375, 8.339 samples/sec, batch_loss: 0.1648, batch_loss_c: 0.1709, batch_loss_s: 0.1506, time:4.7966, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:36 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1260/3125], step: 4385, 7.561 samples/sec, batch_loss: 0.3693, batch_loss_c: 0.3654, batch_loss_s: 0.3783, time:5.2905, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:41 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1270/3125], step: 4395, 7.610 samples/sec, batch_loss: 0.3591, batch_loss_c: 0.3573, batch_loss_s: 0.3633, time:5.2561, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:46 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1280/3125], step: 4405, 8.265 samples/sec, batch_loss: 0.5843, batch_loss_c: 0.5910, batch_loss_s: 0.5688, time:4.8395, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:51 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1290/3125], step: 4415, 8.574 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0908, batch_loss_s: 0.0873, time:4.6651, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:45:56 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1300/3125], step: 4425, 8.025 samples/sec, batch_loss: 0.1209, batch_loss_c: 0.1194, batch_loss_s: 0.1244, time:4.9841, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:01 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1310/3125], step: 4435, 7.517 samples/sec, batch_loss: 0.1616, batch_loss_c: 0.1751, batch_loss_s: 0.1302, time:5.3213, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:06 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1320/3125], step: 4445, 8.426 samples/sec, batch_loss: 0.5587, batch_loss_c: 0.6001, batch_loss_s: 0.4620, time:4.7470, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:11 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1330/3125], step: 4455, 7.688 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0813, batch_loss_s: 0.0729, time:5.2032, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1340/3125], step: 4465, 7.473 samples/sec, batch_loss: 0.1626, batch_loss_c: 0.1203, batch_loss_s: 0.2613, time:5.3528, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1350/3125], step: 4475, 8.408 samples/sec, batch_loss: 0.3757, batch_loss_c: 0.3761, batch_loss_s: 0.3749, time:4.7573, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1360/3125], step: 4485, 7.999 samples/sec, batch_loss: 0.1382, batch_loss_c: 0.1381, batch_loss_s: 0.1382, time:5.0005, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1370/3125], step: 4495, 7.630 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0919, batch_loss_s: 0.0939, time:5.2428, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:36 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1380/3125], step: 4505, 7.735 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1341, batch_loss_s: 0.1010, time:5.1715, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:41 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1390/3125], step: 4515, 7.788 samples/sec, batch_loss: 0.4542, batch_loss_c: 0.4206, batch_loss_s: 0.5325, time:5.1360, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1400/3125], step: 4525, 7.705 samples/sec, batch_loss: 0.1398, batch_loss_c: 0.1418, batch_loss_s: 0.1351, time:5.1916, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:51 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1410/3125], step: 4535, 8.390 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1077, batch_loss_s: 0.0876, time:4.7674, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:46:57 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1420/3125], step: 4545, 7.791 samples/sec, batch_loss: 0.1223, batch_loss_c: 0.1296, batch_loss_s: 0.1053, time:5.1339, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:02 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1430/3125], step: 4555, 7.416 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0928, batch_loss_s: 0.1023, time:5.3935, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:07 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1440/3125], step: 4565, 7.472 samples/sec, batch_loss: 0.3044, batch_loss_c: 0.3000, batch_loss_s: 0.3149, time:5.3535, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:12 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1450/3125], step: 4575, 8.213 samples/sec, batch_loss: 0.2598, batch_loss_c: 0.2293, batch_loss_s: 0.3309, time:4.8706, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:18 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1460/3125], step: 4585, 7.252 samples/sec, batch_loss: 0.4004, batch_loss_c: 0.4231, batch_loss_s: 0.3476, time:5.5156, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:23 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1470/3125], step: 4595, 7.529 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1171, batch_loss_s: 0.1015, time:5.3124, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:28 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1480/3125], step: 4605, 8.612 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0880, batch_loss_s: 0.0937, time:4.6444, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:33 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1490/3125], step: 4615, 7.463 samples/sec, batch_loss: 0.3308, batch_loss_c: 0.3209, batch_loss_s: 0.3540, time:5.3600, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1500/3125], step: 4625, 7.606 samples/sec, batch_loss: 0.3166, batch_loss_c: 0.3146, batch_loss_s: 0.3214, time:5.2589, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1510/3125], step: 4635, 7.051 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0672, batch_loss_s: 0.0799, time:5.6733, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1520/3125], step: 4645, 7.199 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0726, batch_loss_s: 0.0987, time:5.5560, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:47:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1530/3125], step: 4655, 7.590 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0957, batch_loss_s: 0.0867, time:5.2703, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1540/3125], step: 4665, 7.367 samples/sec, batch_loss: 0.0937, batch_loss_c: 0.0897, batch_loss_s: 0.1030, time:5.4297, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1550/3125], step: 4675, 8.443 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1190, batch_loss_s: 0.1197, time:4.7376, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1560/3125], step: 4685, 8.374 samples/sec, batch_loss: 0.5083, batch_loss_c: 0.4922, batch_loss_s: 0.5458, time:4.7766, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1570/3125], step: 4695, 8.676 samples/sec, batch_loss: 0.3369, batch_loss_c: 0.3356, batch_loss_s: 0.3399, time:4.6104, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1580/3125], step: 4705, 7.818 samples/sec, batch_loss: 0.1688, batch_loss_c: 0.1793, batch_loss_s: 0.1444, time:5.1167, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1590/3125], step: 4715, 7.971 samples/sec, batch_loss: 0.2848, batch_loss_c: 0.2705, batch_loss_s: 0.3182, time:5.0180, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:29 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1600/3125], step: 4725, 8.594 samples/sec, batch_loss: 0.1341, batch_loss_c: 0.1371, batch_loss_s: 0.1271, time:4.6543, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:34 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1610/3125], step: 4735, 7.614 samples/sec, batch_loss: 0.5328, batch_loss_c: 0.5398, batch_loss_s: 0.5164, time:5.2535, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1620/3125], step: 4745, 7.790 samples/sec, batch_loss: 0.1895, batch_loss_c: 0.2057, batch_loss_s: 0.1518, time:5.1350, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1630/3125], step: 4755, 8.854 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0587, batch_loss_s: 0.0775, time:4.5176, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1640/3125], step: 4765, 8.428 samples/sec, batch_loss: 0.3676, batch_loss_c: 0.3894, batch_loss_s: 0.3166, time:4.7463, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1650/3125], step: 4775, 7.629 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0700, batch_loss_s: 0.0808, time:5.2429, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:48:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1660/3125], step: 4785, 8.656 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0819, batch_loss_s: 0.1032, time:4.6213, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1670/3125], step: 4795, 7.627 samples/sec, batch_loss: 0.6291, batch_loss_c: 0.5885, batch_loss_s: 0.7239, time:5.2443, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1680/3125], step: 4805, 8.109 samples/sec, batch_loss: 0.3080, batch_loss_c: 0.3034, batch_loss_s: 0.3187, time:4.9326, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1690/3125], step: 4815, 7.787 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1309, batch_loss_s: 0.0965, time:5.1368, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:18 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1700/3125], step: 4825, 8.966 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0762, batch_loss_s: 0.0938, time:4.4615, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1710/3125], step: 4835, 7.649 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1250, batch_loss_s: 0.0959, time:5.2291, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:29 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1720/3125], step: 4845, 7.402 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1479, batch_loss_s: 0.0754, time:5.4042, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:34 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1730/3125], step: 4855, 8.108 samples/sec, batch_loss: 0.2095, batch_loss_c: 0.2329, batch_loss_s: 0.1548, time:4.9333, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1740/3125], step: 4865, 8.001 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0900, batch_loss_s: 0.0903, time:4.9991, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1750/3125], step: 4875, 8.307 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.0955, batch_loss_s: 0.0984, time:4.8155, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1760/3125], step: 4885, 6.682 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1036, batch_loss_s: 0.1079, time:5.9860, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:49:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1770/3125], step: 4895, 7.617 samples/sec, batch_loss: 0.3675, batch_loss_c: 0.3704, batch_loss_s: 0.3606, time:5.2515, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1780/3125], step: 4905, 8.066 samples/sec, batch_loss: 0.2783, batch_loss_c: 0.2519, batch_loss_s: 0.3400, time:4.9593, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1790/3125], step: 4915, 8.104 samples/sec, batch_loss: 0.2954, batch_loss_c: 0.2864, batch_loss_s: 0.3164, time:4.9360, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1800/3125], step: 4925, 7.496 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0918, batch_loss_s: 0.0841, time:5.3361, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1810/3125], step: 4935, 8.359 samples/sec, batch_loss: 0.3019, batch_loss_c: 0.2876, batch_loss_s: 0.3352, time:4.7853, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1820/3125], step: 4945, 7.641 samples/sec, batch_loss: 0.1092, batch_loss_c: 0.1136, batch_loss_s: 0.0988, time:5.2348, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1830/3125], step: 4955, 8.258 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1341, batch_loss_s: 0.1045, time:4.8437, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1840/3125], step: 4965, 8.292 samples/sec, batch_loss: 0.5601, batch_loss_c: 0.5640, batch_loss_s: 0.5508, time:4.8241, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1850/3125], step: 4975, 8.709 samples/sec, batch_loss: 0.2626, batch_loss_c: 0.2403, batch_loss_s: 0.3147, time:4.5929, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1860/3125], step: 4985, 8.092 samples/sec, batch_loss: 0.0888, batch_loss_c: 0.0898, batch_loss_s: 0.0864, time:4.9432, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1870/3125], step: 4995, 8.221 samples/sec, batch_loss: 0.1775, batch_loss_c: 0.1876, batch_loss_s: 0.1540, time:4.8658, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:49 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1880/3125], step: 5005, 8.318 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0858, batch_loss_s: 0.0942, time:4.8087, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:50:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1890/3125], step: 5015, 7.116 samples/sec, batch_loss: 0.3518, batch_loss_c: 0.3552, batch_loss_s: 0.3440, time:5.6210, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1900/3125], step: 5025, 8.253 samples/sec, batch_loss: 0.1532, batch_loss_c: 0.1798, batch_loss_s: 0.0910, time:4.8468, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1910/3125], step: 5035, 8.103 samples/sec, batch_loss: 0.0755, batch_loss_c: 0.0725, batch_loss_s: 0.0826, time:4.9366, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1920/3125], step: 5045, 7.718 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0862, batch_loss_s: 0.0876, time:5.1824, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1930/3125], step: 5055, 8.088 samples/sec, batch_loss: 0.1329, batch_loss_c: 0.1336, batch_loss_s: 0.1312, time:4.9454, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1940/3125], step: 5065, 7.877 samples/sec, batch_loss: 0.1182, batch_loss_c: 0.1327, batch_loss_s: 0.0843, time:5.0783, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1950/3125], step: 5075, 6.703 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0894, batch_loss_s: 0.0830, time:5.9671, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:32 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1960/3125], step: 5085, 6.590 samples/sec, batch_loss: 0.1446, batch_loss_c: 0.1476, batch_loss_s: 0.1378, time:6.0698, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1970/3125], step: 5095, 7.042 samples/sec, batch_loss: 0.4609, batch_loss_c: 0.4981, batch_loss_s: 0.3743, time:5.6802, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:42 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1980/3125], step: 5105, 8.227 samples/sec, batch_loss: 0.2109, batch_loss_c: 0.2165, batch_loss_s: 0.1980, time:4.8619, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [1990/3125], step: 5115, 8.158 samples/sec, batch_loss: 0.1253, batch_loss_c: 0.1319, batch_loss_s: 0.1101, time:4.9033, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:53 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2000/3125], step: 5125, 7.687 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0846, batch_loss_s: 0.0984, time:5.2033, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:51:57 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2010/3125], step: 5135, 8.531 samples/sec, batch_loss: 0.1890, batch_loss_c: 0.1994, batch_loss_s: 0.1647, time:4.6890, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:02 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2020/3125], step: 5145, 7.683 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0983, batch_loss_s: 0.0799, time:5.2061, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:08 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2030/3125], step: 5155, 7.445 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1262, batch_loss_s: 0.1156, time:5.3726, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:13 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2040/3125], step: 5165, 7.879 samples/sec, batch_loss: 0.1658, batch_loss_c: 0.1901, batch_loss_s: 0.1092, time:5.0767, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:18 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2050/3125], step: 5175, 7.718 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1154, batch_loss_s: 0.0836, time:5.1828, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:23 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2060/3125], step: 5185, 8.514 samples/sec, batch_loss: 0.1097, batch_loss_c: 0.1230, batch_loss_s: 0.0788, time:4.6979, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:28 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2070/3125], step: 5195, 8.467 samples/sec, batch_loss: 0.3207, batch_loss_c: 0.3226, batch_loss_s: 0.3161, time:4.7244, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:33 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2080/3125], step: 5205, 7.757 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0689, batch_loss_s: 0.0766, time:5.1564, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:38 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2090/3125], step: 5215, 8.039 samples/sec, batch_loss: 0.1349, batch_loss_c: 0.1462, batch_loss_s: 0.1083, time:4.9755, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:43 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2100/3125], step: 5225, 8.017 samples/sec, batch_loss: 0.3098, batch_loss_c: 0.2955, batch_loss_s: 0.3432, time:4.9892, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:48 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2110/3125], step: 5235, 7.377 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.1013, batch_loss_s: 0.0967, time:5.4222, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:54 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2120/3125], step: 5245, 6.815 samples/sec, batch_loss: 0.1383, batch_loss_c: 0.1437, batch_loss_s: 0.1256, time:5.8697, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:52:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2130/3125], step: 5255, 7.735 samples/sec, batch_loss: 0.4455, batch_loss_c: 0.4445, batch_loss_s: 0.4480, time:5.1715, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2140/3125], step: 5265, 8.008 samples/sec, batch_loss: 0.4058, batch_loss_c: 0.4409, batch_loss_s: 0.3238, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2150/3125], step: 5275, 8.220 samples/sec, batch_loss: 0.1539, batch_loss_c: 0.1683, batch_loss_s: 0.1204, time:4.8660, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2160/3125], step: 5285, 8.395 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0857, batch_loss_s: 0.0855, time:4.7645, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2170/3125], step: 5295, 7.500 samples/sec, batch_loss: 0.1385, batch_loss_c: 0.1629, batch_loss_s: 0.0814, time:5.3335, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:24 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2180/3125], step: 5305, 8.416 samples/sec, batch_loss: 0.1316, batch_loss_c: 0.1281, batch_loss_s: 0.1397, time:4.7529, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:29 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2190/3125], step: 5315, 7.771 samples/sec, batch_loss: 0.3051, batch_loss_c: 0.2946, batch_loss_s: 0.3298, time:5.1472, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:34 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2200/3125], step: 5325, 7.586 samples/sec, batch_loss: 0.4025, batch_loss_c: 0.4296, batch_loss_s: 0.3392, time:5.2731, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:39 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2210/3125], step: 5335, 8.351 samples/sec, batch_loss: 0.4998, batch_loss_c: 0.4800, batch_loss_s: 0.5460, time:4.7897, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:44 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2220/3125], step: 5345, 7.371 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1370, batch_loss_s: 0.1058, time:5.4268, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2230/3125], step: 5355, 7.064 samples/sec, batch_loss: 0.3433, batch_loss_c: 0.3454, batch_loss_s: 0.3382, time:5.6626, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:53:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2240/3125], step: 5365, 7.614 samples/sec, batch_loss: 0.1998, batch_loss_c: 0.2196, batch_loss_s: 0.1536, time:5.2537, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2250/3125], step: 5375, 8.345 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3678, batch_loss_s: 0.1839, time:4.7933, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:06 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2260/3125], step: 5385, 7.256 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0937, batch_loss_s: 0.0892, time:5.5127, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:11 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2270/3125], step: 5395, 7.562 samples/sec, batch_loss: 0.1442, batch_loss_c: 0.1556, batch_loss_s: 0.1178, time:5.2898, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:17 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2280/3125], step: 5405, 7.227 samples/sec, batch_loss: 0.0941, batch_loss_c: 0.0921, batch_loss_s: 0.0986, time:5.5345, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:22 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2290/3125], step: 5415, 7.922 samples/sec, batch_loss: 0.3594, batch_loss_c: 0.3719, batch_loss_s: 0.3304, time:5.0490, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2300/3125], step: 5425, 8.832 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1102, batch_loss_s: 0.0908, time:4.5288, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2310/3125], step: 5435, 8.959 samples/sec, batch_loss: 0.3027, batch_loss_c: 0.2990, batch_loss_s: 0.3112, time:4.4649, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2320/3125], step: 5445, 8.178 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1177, batch_loss_s: 0.1140, time:4.8911, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2330/3125], step: 5455, 9.046 samples/sec, batch_loss: 0.0684, batch_loss_c: 0.0638, batch_loss_s: 0.0793, time:4.4219, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2340/3125], step: 5465, 7.519 samples/sec, batch_loss: 0.3708, batch_loss_c: 0.3739, batch_loss_s: 0.3637, time:5.3198, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2350/3125], step: 5475, 8.081 samples/sec, batch_loss: 0.1911, batch_loss_c: 0.2156, batch_loss_s: 0.1339, time:4.9500, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2360/3125], step: 5485, 8.658 samples/sec, batch_loss: 0.3940, batch_loss_c: 0.4187, batch_loss_s: 0.3365, time:4.6198, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:54:59 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2370/3125], step: 5495, 8.557 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0923, batch_loss_s: 0.0837, time:4.6744, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:04 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2380/3125], step: 5505, 8.252 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.0934, batch_loss_s: 0.1136, time:4.8471, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2390/3125], step: 5515, 7.735 samples/sec, batch_loss: 0.1650, batch_loss_c: 0.1640, batch_loss_s: 0.1674, time:5.1716, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2400/3125], step: 5525, 7.564 samples/sec, batch_loss: 0.1534, batch_loss_c: 0.1613, batch_loss_s: 0.1349, time:5.2885, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:20 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2410/3125], step: 5535, 8.417 samples/sec, batch_loss: 0.1757, batch_loss_c: 0.1896, batch_loss_s: 0.1431, time:4.7522, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2420/3125], step: 5545, 7.532 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0736, batch_loss_s: 0.0877, time:5.3108, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2430/3125], step: 5555, 7.997 samples/sec, batch_loss: 0.0580, batch_loss_c: 0.0545, batch_loss_s: 0.0662, time:5.0017, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2440/3125], step: 5565, 8.103 samples/sec, batch_loss: 0.1177, batch_loss_c: 0.1257, batch_loss_s: 0.0991, time:4.9364, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2450/3125], step: 5575, 7.964 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.0866, batch_loss_s: 0.1175, time:5.0227, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2460/3125], step: 5585, 7.224 samples/sec, batch_loss: 0.2309, batch_loss_c: 0.2146, batch_loss_s: 0.2687, time:5.5368, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2470/3125], step: 5595, 7.908 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1235, batch_loss_s: 0.1251, time:5.0579, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:55:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2480/3125], step: 5605, 7.844 samples/sec, batch_loss: 0.0580, batch_loss_c: 0.0557, batch_loss_s: 0.0635, time:5.0993, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:01 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2490/3125], step: 5615, 7.388 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0847, batch_loss_s: 0.0881, time:5.4144, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:06 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2500/3125], step: 5625, 7.409 samples/sec, batch_loss: 0.1665, batch_loss_c: 0.1823, batch_loss_s: 0.1297, time:5.3989, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:11 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2510/3125], step: 5635, 8.104 samples/sec, batch_loss: 0.1260, batch_loss_c: 0.1412, batch_loss_s: 0.0906, time:4.9359, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2520/3125], step: 5645, 8.690 samples/sec, batch_loss: 0.5703, batch_loss_c: 0.5772, batch_loss_s: 0.5544, time:4.6028, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2530/3125], step: 5655, 7.298 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1070, batch_loss_s: 0.1001, time:5.4812, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:27 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2540/3125], step: 5665, 7.674 samples/sec, batch_loss: 0.0648, batch_loss_c: 0.0563, batch_loss_s: 0.0845, time:5.2126, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2550/3125], step: 5675, 8.235 samples/sec, batch_loss: 0.1326, batch_loss_c: 0.1336, batch_loss_s: 0.1303, time:4.8573, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:37 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2560/3125], step: 5685, 7.272 samples/sec, batch_loss: 0.1255, batch_loss_c: 0.1303, batch_loss_s: 0.1142, time:5.5005, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:42 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2570/3125], step: 5695, 8.004 samples/sec, batch_loss: 0.2129, batch_loss_c: 0.1919, batch_loss_s: 0.2619, time:4.9976, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2580/3125], step: 5705, 7.730 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1082, batch_loss_s: 0.1185, time:5.1747, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:52 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2590/3125], step: 5715, 7.759 samples/sec, batch_loss: 0.2745, batch_loss_c: 0.2541, batch_loss_s: 0.3220, time:5.1551, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:56:58 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2600/3125], step: 5725, 7.226 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1521, batch_loss_s: 0.0750, time:5.5357, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:03 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2610/3125], step: 5735, 7.297 samples/sec, batch_loss: 0.3944, batch_loss_c: 0.3991, batch_loss_s: 0.3836, time:5.4814, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:09 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2620/3125], step: 5745, 7.390 samples/sec, batch_loss: 0.2087, batch_loss_c: 0.2126, batch_loss_s: 0.1995, time:5.4131, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:14 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2630/3125], step: 5755, 7.284 samples/sec, batch_loss: 0.2790, batch_loss_c: 0.2875, batch_loss_s: 0.2591, time:5.4917, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2640/3125], step: 5765, 7.551 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1141, batch_loss_s: 0.1115, time:5.2974, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:25 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2650/3125], step: 5775, 7.676 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1335, batch_loss_s: 0.1364, time:5.2110, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:30 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2660/3125], step: 5785, 7.436 samples/sec, batch_loss: 0.1180, batch_loss_c: 0.1190, batch_loss_s: 0.1157, time:5.3795, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2670/3125], step: 5795, 7.696 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.2163, batch_loss_s: 0.1436, time:5.1976, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2680/3125], step: 5805, 7.983 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0951, batch_loss_s: 0.0776, time:5.0103, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2690/3125], step: 5815, 8.157 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1576, batch_loss_s: 0.1626, time:4.9040, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2700/3125], step: 5825, 9.017 samples/sec, batch_loss: 0.5352, batch_loss_c: 0.5308, batch_loss_s: 0.5453, time:4.4360, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:57:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2710/3125], step: 5835, 8.107 samples/sec, batch_loss: 0.4331, batch_loss_c: 0.4242, batch_loss_s: 0.4538, time:4.9338, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2720/3125], step: 5845, 7.805 samples/sec, batch_loss: 0.1369, batch_loss_c: 0.1424, batch_loss_s: 0.1241, time:5.1252, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2730/3125], step: 5855, 6.900 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3073, batch_loss_s: 0.3269, time:5.7974, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:11 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2740/3125], step: 5865, 7.789 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0828, batch_loss_s: 0.0901, time:5.1357, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2750/3125], step: 5875, 7.988 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0866, batch_loss_s: 0.0971, time:5.0074, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2760/3125], step: 5885, 7.248 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1138, batch_loss_s: 0.1248, time:5.5191, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2770/3125], step: 5895, 8.499 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1411, batch_loss_s: 0.0881, time:4.7064, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2780/3125], step: 5905, 8.542 samples/sec, batch_loss: 0.1587, batch_loss_c: 0.1718, batch_loss_s: 0.1280, time:4.6827, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:35 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2790/3125], step: 5915, 8.850 samples/sec, batch_loss: 0.2080, batch_loss_c: 0.2247, batch_loss_s: 0.1691, time:4.5198, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:40 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2800/3125], step: 5925, 8.616 samples/sec, batch_loss: 0.1279, batch_loss_c: 0.1477, batch_loss_s: 0.0816, time:4.6427, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2810/3125], step: 5935, 8.103 samples/sec, batch_loss: 0.2718, batch_loss_c: 0.2545, batch_loss_s: 0.3122, time:4.9366, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:50 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2820/3125], step: 5945, 7.799 samples/sec, batch_loss: 0.3245, batch_loss_c: 0.3266, batch_loss_s: 0.3195, time:5.1288, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:58:55 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2830/3125], step: 5955, 7.785 samples/sec, batch_loss: 0.1455, batch_loss_c: 0.1500, batch_loss_s: 0.1350, time:5.1381, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:00 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2840/3125], step: 5965, 7.233 samples/sec, batch_loss: 0.1383, batch_loss_c: 0.1562, batch_loss_s: 0.0965, time:5.5305, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:05 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2850/3125], step: 5975, 7.983 samples/sec, batch_loss: 0.3446, batch_loss_c: 0.3478, batch_loss_s: 0.3373, time:5.0109, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:10 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2860/3125], step: 5985, 8.298 samples/sec, batch_loss: 0.3460, batch_loss_c: 0.3466, batch_loss_s: 0.3445, time:4.8205, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:15 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2870/3125], step: 5995, 7.653 samples/sec, batch_loss: 0.2750, batch_loss_c: 0.2582, batch_loss_s: 0.3141, time:5.2266, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2880/3125], step: 6005, 7.600 samples/sec, batch_loss: 0.3133, batch_loss_c: 0.2954, batch_loss_s: 0.3549, time:5.2629, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2890/3125], step: 6015, 8.027 samples/sec, batch_loss: 0.3316, batch_loss_c: 0.3295, batch_loss_s: 0.3365, time:4.9831, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2900/3125], step: 6025, 8.183 samples/sec, batch_loss: 0.3452, batch_loss_c: 0.3445, batch_loss_s: 0.3470, time:4.8884, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:36 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2910/3125], step: 6035, 7.197 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.0997, batch_loss_s: 0.1058, time:5.5577, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:41 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2920/3125], step: 6045, 7.832 samples/sec, batch_loss: 0.2314, batch_loss_c: 0.1879, batch_loss_s: 0.3329, time:5.1072, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:47 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2930/3125], step: 6055, 7.574 samples/sec, batch_loss: 0.4181, batch_loss_c: 0.4157, batch_loss_s: 0.4237, time:5.2814, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:52 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2940/3125], step: 6065, 7.339 samples/sec, batch_loss: 0.1496, batch_loss_c: 0.1611, batch_loss_s: 0.1228, time:5.4505, lr:0.0001\u001b[0m\n",
            "2019-11-23 08:59:57 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2950/3125], step: 6075, 8.195 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1018, batch_loss_s: 0.1153, time:4.8811, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:02 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2960/3125], step: 6085, 8.184 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0874, batch_loss_s: 0.0739, time:4.8876, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:07 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2970/3125], step: 6095, 7.796 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1067, batch_loss_s: 0.1015, time:5.1311, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:12 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2980/3125], step: 6105, 8.562 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0834, batch_loss_s: 0.0859, time:4.6717, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [2990/3125], step: 6115, 8.542 samples/sec, batch_loss: 0.0646, batch_loss_c: 0.0632, batch_loss_s: 0.0677, time:4.6828, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3000/3125], step: 6125, 8.156 samples/sec, batch_loss: 0.5241, batch_loss_c: 0.5121, batch_loss_s: 0.5522, time:4.9045, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:26 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3010/3125], step: 6135, 8.238 samples/sec, batch_loss: 0.1517, batch_loss_c: 0.1664, batch_loss_s: 0.1172, time:4.8555, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:31 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3020/3125], step: 6145, 8.180 samples/sec, batch_loss: 0.1736, batch_loss_c: 0.2031, batch_loss_s: 0.1048, time:4.8902, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:36 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3030/3125], step: 6155, 8.563 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1342, batch_loss_s: 0.1076, time:4.6710, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:41 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3040/3125], step: 6165, 7.891 samples/sec, batch_loss: 0.0585, batch_loss_c: 0.0546, batch_loss_s: 0.0678, time:5.0691, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:45 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3050/3125], step: 6175, 8.417 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0704, batch_loss_s: 0.0865, time:4.7526, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:51 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3060/3125], step: 6185, 7.632 samples/sec, batch_loss: 0.1779, batch_loss_c: 0.1813, batch_loss_s: 0.1698, time:5.2412, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:00:56 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3070/3125], step: 6195, 6.959 samples/sec, batch_loss: 0.1466, batch_loss_c: 0.1753, batch_loss_s: 0.0796, time:5.7475, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:01 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3080/3125], step: 6205, 8.204 samples/sec, batch_loss: 0.1285, batch_loss_c: 0.1292, batch_loss_s: 0.1269, time:4.8759, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:07 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3090/3125], step: 6215, 7.450 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1293, batch_loss_s: 0.0789, time:5.3690, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:12 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3100/3125], step: 6225, 8.112 samples/sec, batch_loss: 0.1761, batch_loss_c: 0.2076, batch_loss_s: 0.1025, time:4.9308, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:16 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3110/3125], step: 6235, 10.115 samples/sec, batch_loss: 0.2764, batch_loss_c: 0.2771, batch_loss_s: 0.2745, time:3.9544, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:19 \u001b[32mINFO     \u001b[0m train.py: [1/5], [3120/3125], step: 6245, 10.210 samples/sec, batch_loss: 0.1732, batch_loss_c: 0.2110, batch_loss_s: 0.0848, time:3.9176, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:21 \u001b[32mINFO     \u001b[0m train.py: [1/5], train_loss: 0.2045, time: 1585.3696, lr: 0.0001\u001b[0m\n",
            "2019-11-23 09:01:27 \u001b[32mINFO     \u001b[0m train.py: [2/5], [0/3125], step: 6250, 6.731 samples/sec, batch_loss: 0.2252, batch_loss_c: 0.2434, batch_loss_s: 0.1826, time:5.9425, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:34 \u001b[32mINFO     \u001b[0m train.py: [2/5], [10/3125], step: 6260, 6.588 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3157, batch_loss_s: 0.3203, time:6.0720, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [20/3125], step: 6270, 8.593 samples/sec, batch_loss: 0.1530, batch_loss_c: 0.1696, batch_loss_s: 0.1141, time:4.6551, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [30/3125], step: 6280, 8.107 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1487, batch_loss_s: 0.1166, time:4.9339, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:48 \u001b[32mINFO     \u001b[0m train.py: [2/5], [40/3125], step: 6290, 8.408 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1286, batch_loss_s: 0.1052, time:4.7572, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:53 \u001b[32mINFO     \u001b[0m train.py: [2/5], [50/3125], step: 6300, 8.061 samples/sec, batch_loss: 0.2386, batch_loss_c: 0.2628, batch_loss_s: 0.1822, time:4.9624, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:01:58 \u001b[32mINFO     \u001b[0m train.py: [2/5], [60/3125], step: 6310, 8.156 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1014, batch_loss_s: 0.1085, time:4.9044, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [70/3125], step: 6320, 9.025 samples/sec, batch_loss: 0.3414, batch_loss_c: 0.3385, batch_loss_s: 0.3481, time:4.4323, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [80/3125], step: 6330, 9.101 samples/sec, batch_loss: 0.3164, batch_loss_c: 0.3115, batch_loss_s: 0.3278, time:4.3952, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:12 \u001b[32mINFO     \u001b[0m train.py: [2/5], [90/3125], step: 6340, 7.956 samples/sec, batch_loss: 0.2757, batch_loss_c: 0.2591, batch_loss_s: 0.3143, time:5.0279, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [100/3125], step: 6350, 8.212 samples/sec, batch_loss: 0.2316, batch_loss_c: 0.2347, batch_loss_s: 0.2244, time:4.8709, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [110/3125], step: 6360, 8.314 samples/sec, batch_loss: 0.3096, batch_loss_c: 0.3115, batch_loss_s: 0.3054, time:4.8111, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [120/3125], step: 6370, 8.599 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0920, batch_loss_s: 0.0935, time:4.6517, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [130/3125], step: 6380, 8.287 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1124, batch_loss_s: 0.1184, time:4.8271, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [140/3125], step: 6390, 7.999 samples/sec, batch_loss: 0.1644, batch_loss_c: 0.1806, batch_loss_s: 0.1265, time:5.0004, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [150/3125], step: 6400, 9.166 samples/sec, batch_loss: 0.3362, batch_loss_c: 0.3380, batch_loss_s: 0.3322, time:4.3637, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [160/3125], step: 6410, 8.749 samples/sec, batch_loss: 0.3380, batch_loss_c: 0.3515, batch_loss_s: 0.3065, time:4.5718, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:49 \u001b[32mINFO     \u001b[0m train.py: [2/5], [170/3125], step: 6420, 8.726 samples/sec, batch_loss: 0.1383, batch_loss_c: 0.1453, batch_loss_s: 0.1219, time:4.5838, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:02:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [180/3125], step: 6430, 7.515 samples/sec, batch_loss: 0.3630, batch_loss_c: 0.3746, batch_loss_s: 0.3360, time:5.3230, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:00 \u001b[32mINFO     \u001b[0m train.py: [2/5], [190/3125], step: 6440, 7.770 samples/sec, batch_loss: 0.3021, batch_loss_c: 0.2973, batch_loss_s: 0.3131, time:5.1478, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:05 \u001b[32mINFO     \u001b[0m train.py: [2/5], [200/3125], step: 6450, 7.719 samples/sec, batch_loss: 0.1564, batch_loss_c: 0.1559, batch_loss_s: 0.1576, time:5.1822, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:10 \u001b[32mINFO     \u001b[0m train.py: [2/5], [210/3125], step: 6460, 8.164 samples/sec, batch_loss: 0.1184, batch_loss_c: 0.1181, batch_loss_s: 0.1192, time:4.8997, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [220/3125], step: 6470, 7.727 samples/sec, batch_loss: 0.3505, batch_loss_c: 0.3570, batch_loss_s: 0.3353, time:5.1766, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [230/3125], step: 6480, 8.085 samples/sec, batch_loss: 0.1427, batch_loss_c: 0.1438, batch_loss_s: 0.1402, time:4.9473, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [240/3125], step: 6490, 8.403 samples/sec, batch_loss: 0.3819, batch_loss_c: 0.4026, batch_loss_s: 0.3338, time:4.7601, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [250/3125], step: 6500, 7.028 samples/sec, batch_loss: 0.1090, batch_loss_c: 0.1048, batch_loss_s: 0.1188, time:5.6917, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [260/3125], step: 6510, 8.628 samples/sec, batch_loss: 0.1341, batch_loss_c: 0.1426, batch_loss_s: 0.1143, time:4.6363, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [270/3125], step: 6520, 8.614 samples/sec, batch_loss: 0.1052, batch_loss_c: 0.1128, batch_loss_s: 0.0873, time:4.6436, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [280/3125], step: 6530, 8.002 samples/sec, batch_loss: 0.3132, batch_loss_c: 0.3127, batch_loss_s: 0.3143, time:4.9987, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [290/3125], step: 6540, 7.900 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.0895, batch_loss_s: 0.1075, time:5.0632, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:03:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [300/3125], step: 6550, 7.285 samples/sec, batch_loss: 0.1339, batch_loss_c: 0.1507, batch_loss_s: 0.0945, time:5.4905, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:01 \u001b[32mINFO     \u001b[0m train.py: [2/5], [310/3125], step: 6560, 6.727 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3290, batch_loss_s: 0.3042, time:5.9462, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [320/3125], step: 6570, 7.109 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0654, batch_loss_s: 0.0705, time:5.6267, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:12 \u001b[32mINFO     \u001b[0m train.py: [2/5], [330/3125], step: 6580, 7.936 samples/sec, batch_loss: 0.2082, batch_loss_c: 0.2453, batch_loss_s: 0.1219, time:5.0404, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:17 \u001b[32mINFO     \u001b[0m train.py: [2/5], [340/3125], step: 6590, 7.816 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0814, batch_loss_s: 0.1139, time:5.1178, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:22 \u001b[32mINFO     \u001b[0m train.py: [2/5], [350/3125], step: 6600, 8.173 samples/sec, batch_loss: 0.3498, batch_loss_c: 0.3550, batch_loss_s: 0.3378, time:4.8942, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:27 \u001b[32mINFO     \u001b[0m train.py: [2/5], [360/3125], step: 6610, 8.395 samples/sec, batch_loss: 0.3195, batch_loss_c: 0.3163, batch_loss_s: 0.3271, time:4.7646, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:32 \u001b[32mINFO     \u001b[0m train.py: [2/5], [370/3125], step: 6620, 8.286 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.1028, batch_loss_s: 0.1011, time:4.8273, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [380/3125], step: 6630, 8.330 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0828, batch_loss_s: 0.0894, time:4.8019, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [390/3125], step: 6640, 7.908 samples/sec, batch_loss: 0.2465, batch_loss_c: 0.2201, batch_loss_s: 0.3080, time:5.0584, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [400/3125], step: 6650, 7.844 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0785, batch_loss_s: 0.0816, time:5.0996, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:52 \u001b[32mINFO     \u001b[0m train.py: [2/5], [410/3125], step: 6660, 6.880 samples/sec, batch_loss: 0.2008, batch_loss_c: 0.2029, batch_loss_s: 0.1958, time:5.8139, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:04:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [420/3125], step: 6670, 8.519 samples/sec, batch_loss: 0.3213, batch_loss_c: 0.3256, batch_loss_s: 0.3113, time:4.6953, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [430/3125], step: 6680, 7.965 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0738, batch_loss_s: 0.0812, time:5.0217, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [440/3125], step: 6690, 7.393 samples/sec, batch_loss: 0.1973, batch_loss_c: 0.1544, batch_loss_s: 0.2976, time:5.4104, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:13 \u001b[32mINFO     \u001b[0m train.py: [2/5], [450/3125], step: 6700, 7.700 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0926, batch_loss_s: 0.1013, time:5.1949, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:18 \u001b[32mINFO     \u001b[0m train.py: [2/5], [460/3125], step: 6710, 7.744 samples/sec, batch_loss: 0.0734, batch_loss_c: 0.0726, batch_loss_s: 0.0754, time:5.1652, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:24 \u001b[32mINFO     \u001b[0m train.py: [2/5], [470/3125], step: 6720, 6.881 samples/sec, batch_loss: 0.3539, batch_loss_c: 0.3537, batch_loss_s: 0.3545, time:5.8134, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:29 \u001b[32mINFO     \u001b[0m train.py: [2/5], [480/3125], step: 6730, 6.954 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.0991, batch_loss_s: 0.0888, time:5.7518, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [490/3125], step: 6740, 7.266 samples/sec, batch_loss: 0.1243, batch_loss_c: 0.1247, batch_loss_s: 0.1235, time:5.5051, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [500/3125], step: 6750, 8.201 samples/sec, batch_loss: 0.2116, batch_loss_c: 0.2293, batch_loss_s: 0.1703, time:4.8777, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [510/3125], step: 6760, 7.591 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1387, batch_loss_s: 0.0971, time:5.2691, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [520/3125], step: 6770, 8.281 samples/sec, batch_loss: 0.5184, batch_loss_c: 0.5101, batch_loss_s: 0.5379, time:4.8306, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [530/3125], step: 6780, 8.254 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1061, batch_loss_s: 0.1024, time:4.8464, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:05:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [540/3125], step: 6790, 8.736 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1632, batch_loss_s: 0.0904, time:4.5786, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [550/3125], step: 6800, 8.738 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1510, batch_loss_s: 0.1480, time:4.5774, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [560/3125], step: 6810, 8.390 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0873, batch_loss_s: 0.0848, time:4.7674, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:13 \u001b[32mINFO     \u001b[0m train.py: [2/5], [570/3125], step: 6820, 8.887 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0848, batch_loss_s: 0.0719, time:4.5008, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:18 \u001b[32mINFO     \u001b[0m train.py: [2/5], [580/3125], step: 6830, 8.413 samples/sec, batch_loss: 0.1355, batch_loss_c: 0.1406, batch_loss_s: 0.1237, time:4.7546, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:23 \u001b[32mINFO     \u001b[0m train.py: [2/5], [590/3125], step: 6840, 8.037 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0842, batch_loss_s: 0.0929, time:4.9770, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:27 \u001b[32mINFO     \u001b[0m train.py: [2/5], [600/3125], step: 6850, 8.650 samples/sec, batch_loss: 0.2102, batch_loss_c: 0.2035, batch_loss_s: 0.2257, time:4.6245, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:33 \u001b[32mINFO     \u001b[0m train.py: [2/5], [610/3125], step: 6860, 7.750 samples/sec, batch_loss: 0.3104, batch_loss_c: 0.3097, batch_loss_s: 0.3120, time:5.1611, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [620/3125], step: 6870, 7.052 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1371, batch_loss_s: 0.0901, time:5.6725, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [630/3125], step: 6880, 7.828 samples/sec, batch_loss: 0.1777, batch_loss_c: 0.1929, batch_loss_s: 0.1421, time:5.1101, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:49 \u001b[32mINFO     \u001b[0m train.py: [2/5], [640/3125], step: 6890, 7.422 samples/sec, batch_loss: 0.1662, batch_loss_c: 0.1939, batch_loss_s: 0.1016, time:5.3894, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [650/3125], step: 6900, 7.865 samples/sec, batch_loss: 0.1914, batch_loss_c: 0.2116, batch_loss_s: 0.1443, time:5.0857, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:06:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [660/3125], step: 6910, 8.141 samples/sec, batch_loss: 0.3366, batch_loss_c: 0.3474, batch_loss_s: 0.3114, time:4.9131, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:03 \u001b[32mINFO     \u001b[0m train.py: [2/5], [670/3125], step: 6920, 8.714 samples/sec, batch_loss: 0.1957, batch_loss_c: 0.2036, batch_loss_s: 0.1772, time:4.5905, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [680/3125], step: 6930, 7.701 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1317, batch_loss_s: 0.1407, time:5.1938, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:14 \u001b[32mINFO     \u001b[0m train.py: [2/5], [690/3125], step: 6940, 8.112 samples/sec, batch_loss: 0.3733, batch_loss_c: 0.3842, batch_loss_s: 0.3478, time:4.9307, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:19 \u001b[32mINFO     \u001b[0m train.py: [2/5], [700/3125], step: 6950, 7.209 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1043, batch_loss_s: 0.0994, time:5.5489, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [710/3125], step: 6960, 7.397 samples/sec, batch_loss: 0.3195, batch_loss_c: 0.3182, batch_loss_s: 0.3226, time:5.4076, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [720/3125], step: 6970, 7.973 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1130, batch_loss_s: 0.1068, time:5.0167, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [730/3125], step: 6980, 8.041 samples/sec, batch_loss: 0.1643, batch_loss_c: 0.1682, batch_loss_s: 0.1551, time:4.9744, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [740/3125], step: 6990, 7.786 samples/sec, batch_loss: 0.4578, batch_loss_c: 0.4679, batch_loss_s: 0.4343, time:5.1377, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [750/3125], step: 7000, 7.464 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1137, batch_loss_s: 0.0994, time:5.3594, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [760/3125], step: 7010, 8.129 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1531, batch_loss_s: 0.0982, time:4.9206, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [770/3125], step: 7020, 8.754 samples/sec, batch_loss: 0.4755, batch_loss_c: 0.4845, batch_loss_s: 0.4545, time:4.5692, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:07:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [780/3125], step: 7030, 8.663 samples/sec, batch_loss: 0.5647, batch_loss_c: 0.5586, batch_loss_s: 0.5790, time:4.6174, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [790/3125], step: 7040, 7.911 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0803, batch_loss_s: 0.0821, time:5.0565, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [800/3125], step: 7050, 7.846 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1295, batch_loss_s: 0.1267, time:5.0982, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:14 \u001b[32mINFO     \u001b[0m train.py: [2/5], [810/3125], step: 7060, 8.068 samples/sec, batch_loss: 0.3941, batch_loss_c: 0.3788, batch_loss_s: 0.4300, time:4.9577, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:19 \u001b[32mINFO     \u001b[0m train.py: [2/5], [820/3125], step: 7070, 8.906 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1335, batch_loss_s: 0.1063, time:4.4913, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:24 \u001b[32mINFO     \u001b[0m train.py: [2/5], [830/3125], step: 7080, 8.029 samples/sec, batch_loss: 0.3094, batch_loss_c: 0.3017, batch_loss_s: 0.3273, time:4.9819, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:28 \u001b[32mINFO     \u001b[0m train.py: [2/5], [840/3125], step: 7090, 8.683 samples/sec, batch_loss: 0.1933, batch_loss_c: 0.2310, batch_loss_s: 0.1054, time:4.6065, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:33 \u001b[32mINFO     \u001b[0m train.py: [2/5], [850/3125], step: 7100, 7.839 samples/sec, batch_loss: 0.1415, batch_loss_c: 0.1581, batch_loss_s: 0.1026, time:5.1025, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [860/3125], step: 7110, 8.031 samples/sec, batch_loss: 0.2146, batch_loss_c: 0.2207, batch_loss_s: 0.2004, time:4.9805, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:44 \u001b[32mINFO     \u001b[0m train.py: [2/5], [870/3125], step: 7120, 7.396 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0699, batch_loss_s: 0.0728, time:5.4081, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:49 \u001b[32mINFO     \u001b[0m train.py: [2/5], [880/3125], step: 7130, 8.480 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0666, batch_loss_s: 0.0789, time:4.7172, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [890/3125], step: 7140, 7.348 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1368, batch_loss_s: 0.1518, time:5.4434, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:08:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [900/3125], step: 7150, 8.283 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1475, batch_loss_s: 0.1047, time:4.8294, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [910/3125], step: 7160, 8.071 samples/sec, batch_loss: 0.0772, batch_loss_c: 0.0733, batch_loss_s: 0.0862, time:4.9561, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [920/3125], step: 7170, 8.385 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.2916, batch_loss_s: 0.3352, time:4.7701, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:13 \u001b[32mINFO     \u001b[0m train.py: [2/5], [930/3125], step: 7180, 8.189 samples/sec, batch_loss: 0.5340, batch_loss_c: 0.5224, batch_loss_s: 0.5609, time:4.8848, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:18 \u001b[32mINFO     \u001b[0m train.py: [2/5], [940/3125], step: 7190, 8.132 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.3077, batch_loss_s: 0.3092, time:4.9186, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:23 \u001b[32mINFO     \u001b[0m train.py: [2/5], [950/3125], step: 7200, 8.229 samples/sec, batch_loss: 0.4313, batch_loss_c: 0.4358, batch_loss_s: 0.4207, time:4.8611, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:28 \u001b[32mINFO     \u001b[0m train.py: [2/5], [960/3125], step: 7210, 8.025 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1153, batch_loss_s: 0.1080, time:4.9842, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:33 \u001b[32mINFO     \u001b[0m train.py: [2/5], [970/3125], step: 7220, 8.165 samples/sec, batch_loss: 0.3112, batch_loss_c: 0.3141, batch_loss_s: 0.3046, time:4.8989, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [980/3125], step: 7230, 8.485 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1027, batch_loss_s: 0.1031, time:4.7142, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [990/3125], step: 7240, 7.908 samples/sec, batch_loss: 0.2948, batch_loss_c: 0.2790, batch_loss_s: 0.3317, time:5.0583, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:48 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1000/3125], step: 7250, 7.621 samples/sec, batch_loss: 0.1996, batch_loss_c: 0.2373, batch_loss_s: 0.1117, time:5.2485, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1010/3125], step: 7260, 6.909 samples/sec, batch_loss: 0.3079, batch_loss_c: 0.3019, batch_loss_s: 0.3221, time:5.7899, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:09:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1020/3125], step: 7270, 8.660 samples/sec, batch_loss: 0.1220, batch_loss_c: 0.1263, batch_loss_s: 0.1122, time:4.6189, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1030/3125], step: 7280, 7.716 samples/sec, batch_loss: 0.1000, batch_loss_c: 0.1008, batch_loss_s: 0.0982, time:5.1839, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1040/3125], step: 7290, 8.136 samples/sec, batch_loss: 0.2806, batch_loss_c: 0.2730, batch_loss_s: 0.2985, time:4.9165, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:14 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1050/3125], step: 7300, 7.837 samples/sec, batch_loss: 0.2388, batch_loss_c: 0.2868, batch_loss_s: 0.1270, time:5.1038, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:19 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1060/3125], step: 7310, 7.279 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0935, batch_loss_s: 0.0896, time:5.4955, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:24 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1070/3125], step: 7320, 8.194 samples/sec, batch_loss: 0.2939, batch_loss_c: 0.2873, batch_loss_s: 0.3094, time:4.8816, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:29 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1080/3125], step: 7330, 8.944 samples/sec, batch_loss: 0.1650, batch_loss_c: 0.1761, batch_loss_s: 0.1390, time:4.4723, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:34 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1090/3125], step: 7340, 7.190 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0999, batch_loss_s: 0.0978, time:5.5633, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:39 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1100/3125], step: 7350, 8.478 samples/sec, batch_loss: 0.2981, batch_loss_c: 0.2726, batch_loss_s: 0.3578, time:4.7181, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1110/3125], step: 7360, 8.752 samples/sec, batch_loss: 0.3284, batch_loss_c: 0.3305, batch_loss_s: 0.3235, time:4.5703, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:49 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1120/3125], step: 7370, 7.652 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.1030, batch_loss_s: 0.0980, time:5.2272, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1130/3125], step: 7380, 8.257 samples/sec, batch_loss: 0.1423, batch_loss_c: 0.1429, batch_loss_s: 0.1409, time:4.8441, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:10:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1140/3125], step: 7390, 7.822 samples/sec, batch_loss: 0.2523, batch_loss_c: 0.3134, batch_loss_s: 0.1097, time:5.1139, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1150/3125], step: 7400, 8.052 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0674, batch_loss_s: 0.0788, time:4.9679, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1160/3125], step: 7410, 7.801 samples/sec, batch_loss: 0.1378, batch_loss_c: 0.1623, batch_loss_s: 0.0805, time:5.1278, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:14 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1170/3125], step: 7420, 7.583 samples/sec, batch_loss: 0.3190, batch_loss_c: 0.3231, batch_loss_s: 0.3093, time:5.2753, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:19 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1180/3125], step: 7430, 8.833 samples/sec, batch_loss: 0.2286, batch_loss_c: 0.2353, batch_loss_s: 0.2127, time:4.5286, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:24 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1190/3125], step: 7440, 7.341 samples/sec, batch_loss: 0.1997, batch_loss_c: 0.1971, batch_loss_s: 0.2056, time:5.4487, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:29 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1200/3125], step: 7450, 7.621 samples/sec, batch_loss: 0.2965, batch_loss_c: 0.2839, batch_loss_s: 0.3257, time:5.2485, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1210/3125], step: 7460, 7.227 samples/sec, batch_loss: 0.1513, batch_loss_c: 0.1522, batch_loss_s: 0.1495, time:5.5350, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1220/3125], step: 7470, 8.308 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1116, batch_loss_s: 0.1046, time:4.8146, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1230/3125], step: 7480, 7.183 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1101, batch_loss_s: 0.0960, time:5.5685, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1240/3125], step: 7490, 7.551 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0757, batch_loss_s: 0.0921, time:5.2970, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:11:56 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1250/3125], step: 7500, 7.877 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.2853, batch_loss_s: 0.3211, time:5.0782, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:00 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1260/3125], step: 7510, 9.250 samples/sec, batch_loss: 0.5662, batch_loss_c: 0.5671, batch_loss_s: 0.5640, time:4.3241, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:05 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1270/3125], step: 7520, 8.433 samples/sec, batch_loss: 0.1087, batch_loss_c: 0.1054, batch_loss_s: 0.1163, time:4.7434, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:10 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1280/3125], step: 7530, 7.944 samples/sec, batch_loss: 0.1521, batch_loss_c: 0.1165, batch_loss_s: 0.2352, time:5.0353, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1290/3125], step: 7540, 7.611 samples/sec, batch_loss: 0.3700, batch_loss_c: 0.3700, batch_loss_s: 0.3701, time:5.2554, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1300/3125], step: 7550, 7.673 samples/sec, batch_loss: 0.2573, batch_loss_c: 0.2501, batch_loss_s: 0.2741, time:5.2129, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1310/3125], step: 7560, 7.530 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.2913, batch_loss_s: 0.3475, time:5.3118, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1320/3125], step: 7570, 8.282 samples/sec, batch_loss: 0.3315, batch_loss_c: 0.3358, batch_loss_s: 0.3215, time:4.8296, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1330/3125], step: 7580, 7.508 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0779, batch_loss_s: 0.0907, time:5.3275, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1340/3125], step: 7590, 7.625 samples/sec, batch_loss: 0.0922, batch_loss_c: 0.0882, batch_loss_s: 0.1016, time:5.2457, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:47 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1350/3125], step: 7600, 6.982 samples/sec, batch_loss: 0.2928, batch_loss_c: 0.2838, batch_loss_s: 0.3139, time:5.7290, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:52 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1360/3125], step: 7610, 7.335 samples/sec, batch_loss: 0.1265, batch_loss_c: 0.1302, batch_loss_s: 0.1181, time:5.4533, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:12:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1370/3125], step: 7620, 8.064 samples/sec, batch_loss: 0.3257, batch_loss_c: 0.3302, batch_loss_s: 0.3152, time:4.9602, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1380/3125], step: 7630, 8.465 samples/sec, batch_loss: 0.4195, batch_loss_c: 0.4575, batch_loss_s: 0.3309, time:4.7252, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1390/3125], step: 7640, 7.720 samples/sec, batch_loss: 0.1292, batch_loss_c: 0.1218, batch_loss_s: 0.1463, time:5.1813, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:12 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1400/3125], step: 7650, 8.527 samples/sec, batch_loss: 0.3267, batch_loss_c: 0.3303, batch_loss_s: 0.3183, time:4.6910, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1410/3125], step: 7660, 8.238 samples/sec, batch_loss: 0.4890, batch_loss_c: 0.4621, batch_loss_s: 0.5518, time:4.8558, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1420/3125], step: 7670, 7.932 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1339, batch_loss_s: 0.0977, time:5.0431, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1430/3125], step: 7680, 8.652 samples/sec, batch_loss: 0.3379, batch_loss_c: 0.3369, batch_loss_s: 0.3403, time:4.6233, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1440/3125], step: 7690, 8.136 samples/sec, batch_loss: 0.3429, batch_loss_c: 0.3413, batch_loss_s: 0.3466, time:4.9165, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1450/3125], step: 7700, 8.225 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1035, batch_loss_s: 0.1156, time:4.8634, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:42 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1460/3125], step: 7710, 7.067 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1182, batch_loss_s: 0.1144, time:5.6602, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1470/3125], step: 7720, 8.508 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0844, batch_loss_s: 0.0932, time:4.7014, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:51 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1480/3125], step: 7730, 8.477 samples/sec, batch_loss: 0.3272, batch_loss_c: 0.3284, batch_loss_s: 0.3244, time:4.7188, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:13:56 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1490/3125], step: 7740, 7.663 samples/sec, batch_loss: 0.3389, batch_loss_c: 0.3450, batch_loss_s: 0.3247, time:5.2196, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:01 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1500/3125], step: 7750, 8.520 samples/sec, batch_loss: 0.1558, batch_loss_c: 0.1610, batch_loss_s: 0.1435, time:4.6948, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1510/3125], step: 7760, 7.864 samples/sec, batch_loss: 0.1267, batch_loss_c: 0.1173, batch_loss_s: 0.1488, time:5.0863, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1520/3125], step: 7770, 7.776 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0737, batch_loss_s: 0.0952, time:5.1442, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1530/3125], step: 7780, 7.921 samples/sec, batch_loss: 0.3701, batch_loss_c: 0.3631, batch_loss_s: 0.3864, time:5.0497, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1540/3125], step: 7790, 7.646 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0877, batch_loss_s: 0.0948, time:5.2313, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:27 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1550/3125], step: 7800, 7.614 samples/sec, batch_loss: 0.1595, batch_loss_c: 0.1625, batch_loss_s: 0.1525, time:5.2532, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:32 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1560/3125], step: 7810, 8.148 samples/sec, batch_loss: 0.4950, batch_loss_c: 0.4793, batch_loss_s: 0.5316, time:4.9094, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1570/3125], step: 7820, 8.343 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0757, batch_loss_s: 0.0879, time:4.7942, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1580/3125], step: 7830, 8.439 samples/sec, batch_loss: 0.3114, batch_loss_c: 0.3102, batch_loss_s: 0.3142, time:4.7400, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1590/3125], step: 7840, 7.856 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1451, batch_loss_s: 0.0868, time:5.0917, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:52 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1600/3125], step: 7850, 7.491 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0803, batch_loss_s: 0.0919, time:5.3394, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:14:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1610/3125], step: 7860, 7.320 samples/sec, batch_loss: 0.3436, batch_loss_c: 0.3503, batch_loss_s: 0.3278, time:5.4647, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1620/3125], step: 7870, 8.778 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1162, batch_loss_s: 0.1075, time:4.5568, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1630/3125], step: 7880, 8.685 samples/sec, batch_loss: 0.0744, batch_loss_c: 0.0603, batch_loss_s: 0.1075, time:4.6055, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1640/3125], step: 7890, 8.244 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1276, batch_loss_s: 0.0900, time:4.8520, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1650/3125], step: 7900, 8.438 samples/sec, batch_loss: 0.1599, batch_loss_c: 0.1762, batch_loss_s: 0.1218, time:4.7403, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1660/3125], step: 7910, 8.108 samples/sec, batch_loss: 0.1618, batch_loss_c: 0.1631, batch_loss_s: 0.1589, time:4.9331, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1670/3125], step: 7920, 8.462 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1504, batch_loss_s: 0.1042, time:4.7271, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1680/3125], step: 7930, 8.509 samples/sec, batch_loss: 0.1224, batch_loss_c: 0.1119, batch_loss_s: 0.1468, time:4.7008, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1690/3125], step: 7940, 8.327 samples/sec, batch_loss: 0.4265, batch_loss_c: 0.4325, batch_loss_s: 0.4123, time:4.8036, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1700/3125], step: 7950, 8.463 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1266, batch_loss_s: 0.1305, time:4.7266, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1710/3125], step: 7960, 7.996 samples/sec, batch_loss: 0.1481, batch_loss_c: 0.1639, batch_loss_s: 0.1112, time:5.0023, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1720/3125], step: 7970, 7.706 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0759, batch_loss_s: 0.0754, time:5.1905, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1730/3125], step: 7980, 8.820 samples/sec, batch_loss: 0.3125, batch_loss_c: 0.3143, batch_loss_s: 0.3082, time:4.5352, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:15:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1740/3125], step: 7990, 8.015 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0961, batch_loss_s: 0.0849, time:4.9907, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:04 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1750/3125], step: 8000, 7.908 samples/sec, batch_loss: 0.8060, batch_loss_c: 0.8163, batch_loss_s: 0.7818, time:5.0584, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:09 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1760/3125], step: 8010, 7.913 samples/sec, batch_loss: 0.1464, batch_loss_c: 0.1496, batch_loss_s: 0.1388, time:5.0548, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1770/3125], step: 8020, 7.651 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1165, batch_loss_s: 0.0812, time:5.2281, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1780/3125], step: 8030, 7.279 samples/sec, batch_loss: 0.3222, batch_loss_c: 0.3194, batch_loss_s: 0.3290, time:5.4954, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1790/3125], step: 8040, 7.950 samples/sec, batch_loss: 0.1179, batch_loss_c: 0.1150, batch_loss_s: 0.1246, time:5.0312, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1800/3125], step: 8050, 7.832 samples/sec, batch_loss: 0.3369, batch_loss_c: 0.3422, batch_loss_s: 0.3244, time:5.1070, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1810/3125], step: 8060, 8.220 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0966, batch_loss_s: 0.0989, time:4.8664, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1820/3125], step: 8070, 7.942 samples/sec, batch_loss: 0.3075, batch_loss_c: 0.2794, batch_loss_s: 0.3732, time:5.0363, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1830/3125], step: 8080, 8.104 samples/sec, batch_loss: 0.3230, batch_loss_c: 0.3133, batch_loss_s: 0.3457, time:4.9359, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1840/3125], step: 8090, 8.099 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1126, batch_loss_s: 0.1191, time:4.9390, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:16:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1850/3125], step: 8100, 8.233 samples/sec, batch_loss: 0.1598, batch_loss_c: 0.1616, batch_loss_s: 0.1556, time:4.8588, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:00 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1860/3125], step: 8110, 8.054 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0884, batch_loss_s: 0.1023, time:4.9667, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:05 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1870/3125], step: 8120, 7.499 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1151, batch_loss_s: 0.1049, time:5.3338, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:10 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1880/3125], step: 8130, 8.466 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2866, batch_loss_s: 0.3007, time:4.7250, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1890/3125], step: 8140, 7.794 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0605, batch_loss_s: 0.0694, time:5.1319, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1900/3125], step: 8150, 7.836 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3163, batch_loss_s: 0.3054, time:5.1048, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1910/3125], step: 8160, 8.072 samples/sec, batch_loss: 0.3674, batch_loss_c: 0.3598, batch_loss_s: 0.3853, time:4.9556, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1920/3125], step: 8170, 6.805 samples/sec, batch_loss: 0.5751, batch_loss_c: 0.5844, batch_loss_s: 0.5534, time:5.8780, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:37 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1930/3125], step: 8180, 7.319 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0789, batch_loss_s: 0.0786, time:5.4651, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:42 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1940/3125], step: 8190, 7.664 samples/sec, batch_loss: 0.5759, batch_loss_c: 0.5797, batch_loss_s: 0.5672, time:5.2189, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:47 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1950/3125], step: 8200, 7.590 samples/sec, batch_loss: 0.2783, batch_loss_c: 0.2608, batch_loss_s: 0.3193, time:5.2703, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:53 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1960/3125], step: 8210, 6.692 samples/sec, batch_loss: 0.1684, batch_loss_c: 0.1999, batch_loss_s: 0.0949, time:5.9775, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:17:58 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1970/3125], step: 8220, 8.330 samples/sec, batch_loss: 0.1613, batch_loss_c: 0.1878, batch_loss_s: 0.0995, time:4.8020, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1980/3125], step: 8230, 8.892 samples/sec, batch_loss: 0.4136, batch_loss_c: 0.4316, batch_loss_s: 0.3717, time:4.4986, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [1990/3125], step: 8240, 7.877 samples/sec, batch_loss: 0.1744, batch_loss_c: 0.2091, batch_loss_s: 0.0934, time:5.0779, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:13 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2000/3125], step: 8250, 7.755 samples/sec, batch_loss: 0.3025, batch_loss_c: 0.2995, batch_loss_s: 0.3093, time:5.1579, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:18 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2010/3125], step: 8260, 7.220 samples/sec, batch_loss: 0.1803, batch_loss_c: 0.1765, batch_loss_s: 0.1892, time:5.5398, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:23 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2020/3125], step: 8270, 7.651 samples/sec, batch_loss: 0.1663, batch_loss_c: 0.1769, batch_loss_s: 0.1417, time:5.2278, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:28 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2030/3125], step: 8280, 8.451 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3193, batch_loss_s: 0.3120, time:4.7331, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:33 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2040/3125], step: 8290, 8.040 samples/sec, batch_loss: 0.1803, batch_loss_c: 0.2028, batch_loss_s: 0.1279, time:4.9753, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2050/3125], step: 8300, 8.600 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1794, batch_loss_s: 0.1072, time:4.6510, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2060/3125], step: 8310, 7.574 samples/sec, batch_loss: 0.2309, batch_loss_c: 0.2298, batch_loss_s: 0.2336, time:5.2812, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:48 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2070/3125], step: 8320, 8.327 samples/sec, batch_loss: 0.1707, batch_loss_c: 0.1954, batch_loss_s: 0.1131, time:4.8034, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:53 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2080/3125], step: 8330, 8.247 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1072, batch_loss_s: 0.1067, time:4.8502, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:18:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2090/3125], step: 8340, 8.308 samples/sec, batch_loss: 0.3554, batch_loss_c: 0.3469, batch_loss_s: 0.3753, time:4.8147, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:03 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2100/3125], step: 8350, 7.581 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0842, batch_loss_s: 0.0778, time:5.2766, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:08 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2110/3125], step: 8360, 8.193 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0931, batch_loss_s: 0.0771, time:4.8823, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:13 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2120/3125], step: 8370, 7.696 samples/sec, batch_loss: 0.3155, batch_loss_c: 0.3166, batch_loss_s: 0.3128, time:5.1973, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:18 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2130/3125], step: 8380, 7.498 samples/sec, batch_loss: 0.1850, batch_loss_c: 0.2319, batch_loss_s: 0.0756, time:5.3350, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:23 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2140/3125], step: 8390, 8.455 samples/sec, batch_loss: 0.1929, batch_loss_c: 0.2387, batch_loss_s: 0.0860, time:4.7309, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:28 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2150/3125], step: 8400, 8.008 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0866, batch_loss_s: 0.1018, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:33 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2160/3125], step: 8410, 7.830 samples/sec, batch_loss: 0.1046, batch_loss_c: 0.1020, batch_loss_s: 0.1106, time:5.1085, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:38 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2170/3125], step: 8420, 8.058 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1336, batch_loss_s: 0.1134, time:4.9639, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2180/3125], step: 8430, 7.492 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3068, batch_loss_s: 0.3278, time:5.3393, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:49 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2190/3125], step: 8440, 7.673 samples/sec, batch_loss: 0.5484, batch_loss_c: 0.5475, batch_loss_s: 0.5505, time:5.2129, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:54 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2200/3125], step: 8450, 7.650 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0937, batch_loss_s: 0.0806, time:5.2289, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:19:59 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2210/3125], step: 8460, 7.892 samples/sec, batch_loss: 0.3875, batch_loss_c: 0.3824, batch_loss_s: 0.3994, time:5.0682, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:03 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2220/3125], step: 8470, 8.726 samples/sec, batch_loss: 0.5331, batch_loss_c: 0.5342, batch_loss_s: 0.5304, time:4.5840, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:08 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2230/3125], step: 8480, 7.947 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1141, batch_loss_s: 0.1144, time:5.0335, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:14 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2240/3125], step: 8490, 7.338 samples/sec, batch_loss: 0.3306, batch_loss_c: 0.3103, batch_loss_s: 0.3780, time:5.4510, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:19 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2250/3125], step: 8500, 7.959 samples/sec, batch_loss: 0.1118, batch_loss_c: 0.1141, batch_loss_s: 0.1066, time:5.0258, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:24 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2260/3125], step: 8510, 8.075 samples/sec, batch_loss: 0.5548, batch_loss_c: 0.5622, batch_loss_s: 0.5375, time:4.9533, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:29 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2270/3125], step: 8520, 7.957 samples/sec, batch_loss: 0.2657, batch_loss_c: 0.2519, batch_loss_s: 0.2978, time:5.0270, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:34 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2280/3125], step: 8530, 7.945 samples/sec, batch_loss: 0.3798, batch_loss_c: 0.3998, batch_loss_s: 0.3332, time:5.0343, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:39 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2290/3125], step: 8540, 8.192 samples/sec, batch_loss: 0.2025, batch_loss_c: 0.2078, batch_loss_s: 0.1901, time:4.8825, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:44 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2300/3125], step: 8550, 7.912 samples/sec, batch_loss: 0.1436, batch_loss_c: 0.1708, batch_loss_s: 0.0801, time:5.0559, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2310/3125], step: 8560, 6.785 samples/sec, batch_loss: 0.1219, batch_loss_c: 0.1340, batch_loss_s: 0.0938, time:5.8953, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:20:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2320/3125], step: 8570, 8.348 samples/sec, batch_loss: 0.1342, batch_loss_c: 0.1508, batch_loss_s: 0.0954, time:4.7914, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:00 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2330/3125], step: 8580, 7.459 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0688, batch_loss_s: 0.0763, time:5.3630, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:05 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2340/3125], step: 8590, 7.572 samples/sec, batch_loss: 0.2207, batch_loss_c: 0.2455, batch_loss_s: 0.1628, time:5.2829, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:10 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2350/3125], step: 8600, 7.772 samples/sec, batch_loss: 0.2939, batch_loss_c: 0.2847, batch_loss_s: 0.3153, time:5.1469, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2360/3125], step: 8610, 8.063 samples/sec, batch_loss: 0.4850, batch_loss_c: 0.4485, batch_loss_s: 0.5703, time:4.9611, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2370/3125], step: 8620, 7.886 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0743, batch_loss_s: 0.0793, time:5.0725, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2380/3125], step: 8630, 7.406 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0842, batch_loss_s: 0.0934, time:5.4009, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2390/3125], step: 8640, 8.344 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0742, batch_loss_s: 0.0963, time:4.7939, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2400/3125], step: 8650, 8.068 samples/sec, batch_loss: 0.1435, batch_loss_c: 0.1437, batch_loss_s: 0.1430, time:4.9580, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2410/3125], step: 8660, 7.874 samples/sec, batch_loss: 0.1851, batch_loss_c: 0.2044, batch_loss_s: 0.1402, time:5.0798, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2420/3125], step: 8670, 7.280 samples/sec, batch_loss: 0.6044, batch_loss_c: 0.5967, batch_loss_s: 0.6224, time:5.4949, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:52 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2430/3125], step: 8680, 7.301 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0869, batch_loss_s: 0.0717, time:5.4786, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:21:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2440/3125], step: 8690, 8.097 samples/sec, batch_loss: 0.3332, batch_loss_c: 0.3266, batch_loss_s: 0.3486, time:4.9400, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:01 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2450/3125], step: 8700, 9.053 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.1055, batch_loss_s: 0.0934, time:4.4183, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2460/3125], step: 8710, 7.993 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.0974, batch_loss_s: 0.0958, time:5.0045, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2470/3125], step: 8720, 8.031 samples/sec, batch_loss: 0.3222, batch_loss_c: 0.3265, batch_loss_s: 0.3122, time:4.9807, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2480/3125], step: 8730, 8.410 samples/sec, batch_loss: 0.2840, batch_loss_c: 0.3406, batch_loss_s: 0.1519, time:4.7561, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2490/3125], step: 8740, 8.288 samples/sec, batch_loss: 0.1592, batch_loss_c: 0.1904, batch_loss_s: 0.0863, time:4.8265, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2500/3125], step: 8750, 7.097 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0855, batch_loss_s: 0.0921, time:5.6366, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2510/3125], step: 8760, 8.883 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.1008, batch_loss_s: 0.0831, time:4.5029, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:36 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2520/3125], step: 8770, 7.408 samples/sec, batch_loss: 0.3636, batch_loss_c: 0.3761, batch_loss_s: 0.3343, time:5.3992, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2530/3125], step: 8780, 8.590 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0522, batch_loss_s: 0.0718, time:4.6564, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2540/3125], step: 8790, 8.397 samples/sec, batch_loss: 0.6215, batch_loss_c: 0.6125, batch_loss_s: 0.6426, time:4.7635, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:52 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2550/3125], step: 8800, 6.687 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0659, batch_loss_s: 0.0789, time:5.9821, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:22:57 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2560/3125], step: 8810, 7.542 samples/sec, batch_loss: 0.1062, batch_loss_c: 0.1054, batch_loss_s: 0.1082, time:5.3039, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:02 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2570/3125], step: 8820, 8.325 samples/sec, batch_loss: 0.2154, batch_loss_c: 0.2049, batch_loss_s: 0.2397, time:4.8049, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:07 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2580/3125], step: 8830, 7.427 samples/sec, batch_loss: 0.1802, batch_loss_c: 0.2169, batch_loss_s: 0.0946, time:5.3861, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:12 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2590/3125], step: 8840, 8.220 samples/sec, batch_loss: 0.4559, batch_loss_c: 0.4519, batch_loss_s: 0.4653, time:4.8659, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:17 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2600/3125], step: 8850, 7.748 samples/sec, batch_loss: 0.1858, batch_loss_c: 0.2306, batch_loss_s: 0.0813, time:5.1626, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:23 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2610/3125], step: 8860, 7.311 samples/sec, batch_loss: 0.3515, batch_loss_c: 0.3554, batch_loss_s: 0.3426, time:5.4714, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:28 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2620/3125], step: 8870, 7.760 samples/sec, batch_loss: 0.1655, batch_loss_c: 0.1803, batch_loss_s: 0.1312, time:5.1544, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:32 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2630/3125], step: 8880, 8.324 samples/sec, batch_loss: 0.2932, batch_loss_c: 0.2893, batch_loss_s: 0.3022, time:4.8051, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:37 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2640/3125], step: 8890, 8.668 samples/sec, batch_loss: 0.2771, batch_loss_c: 0.2607, batch_loss_s: 0.3154, time:4.6149, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:43 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2650/3125], step: 8900, 7.315 samples/sec, batch_loss: 0.1583, batch_loss_c: 0.1832, batch_loss_s: 0.1000, time:5.4682, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:48 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2660/3125], step: 8910, 7.515 samples/sec, batch_loss: 0.1411, batch_loss_c: 0.1461, batch_loss_s: 0.1295, time:5.3224, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:53 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2670/3125], step: 8920, 8.235 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0768, batch_loss_s: 0.1032, time:4.8576, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:23:58 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2680/3125], step: 8930, 7.270 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0985, batch_loss_s: 0.0895, time:5.5017, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:03 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2690/3125], step: 8940, 7.897 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0856, batch_loss_s: 0.0798, time:5.0650, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:10 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2700/3125], step: 8950, 6.093 samples/sec, batch_loss: 0.1759, batch_loss_c: 0.1900, batch_loss_s: 0.1430, time:6.5645, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:15 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2710/3125], step: 8960, 7.397 samples/sec, batch_loss: 0.1122, batch_loss_c: 0.1116, batch_loss_s: 0.1135, time:5.4076, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:20 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2720/3125], step: 8970, 7.769 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1569, batch_loss_s: 0.0924, time:5.1489, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2730/3125], step: 8980, 8.297 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0910, batch_loss_s: 0.0878, time:4.8210, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2740/3125], step: 8990, 8.735 samples/sec, batch_loss: 0.3040, batch_loss_c: 0.3013, batch_loss_s: 0.3103, time:4.5791, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2750/3125], step: 9000, 7.728 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0878, batch_loss_s: 0.0804, time:5.1763, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2760/3125], step: 9010, 8.817 samples/sec, batch_loss: 0.3331, batch_loss_c: 0.3342, batch_loss_s: 0.3304, time:4.5365, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:45 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2770/3125], step: 9020, 7.621 samples/sec, batch_loss: 0.5257, batch_loss_c: 0.5227, batch_loss_s: 0.5326, time:5.2487, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2780/3125], step: 9030, 7.918 samples/sec, batch_loss: 0.4353, batch_loss_c: 0.4677, batch_loss_s: 0.3596, time:5.0516, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:24:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2790/3125], step: 9040, 7.818 samples/sec, batch_loss: 0.1385, batch_loss_c: 0.1351, batch_loss_s: 0.1463, time:5.1163, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:01 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2800/3125], step: 9050, 7.249 samples/sec, batch_loss: 0.2663, batch_loss_c: 0.2767, batch_loss_s: 0.2419, time:5.5177, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2810/3125], step: 9060, 7.917 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.0969, batch_loss_s: 0.1119, time:5.0525, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2820/3125], step: 9070, 7.450 samples/sec, batch_loss: 0.3587, batch_loss_c: 0.3736, batch_loss_s: 0.3239, time:5.3691, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2830/3125], step: 9080, 8.700 samples/sec, batch_loss: 0.0546, batch_loss_c: 0.0499, batch_loss_s: 0.0656, time:4.5976, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2840/3125], step: 9090, 7.992 samples/sec, batch_loss: 0.3218, batch_loss_c: 0.3204, batch_loss_s: 0.3252, time:5.0047, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:25 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2850/3125], step: 9100, 8.738 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1097, batch_loss_s: 0.0895, time:4.5776, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:30 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2860/3125], step: 9110, 8.448 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1525, batch_loss_s: 0.1223, time:4.7348, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2870/3125], step: 9120, 8.172 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3100, batch_loss_s: 0.3188, time:4.8949, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2880/3125], step: 9130, 8.390 samples/sec, batch_loss: 0.4491, batch_loss_c: 0.4772, batch_loss_s: 0.3835, time:4.7678, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:44 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2890/3125], step: 9140, 8.305 samples/sec, batch_loss: 0.4554, batch_loss_c: 0.4524, batch_loss_s: 0.4624, time:4.8163, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:50 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2900/3125], step: 9150, 7.342 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0799, batch_loss_s: 0.0531, time:5.4480, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:25:55 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2910/3125], step: 9160, 7.697 samples/sec, batch_loss: 0.1911, batch_loss_c: 0.2197, batch_loss_s: 0.1244, time:5.1966, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:00 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2920/3125], step: 9170, 7.844 samples/sec, batch_loss: 0.3304, batch_loss_c: 0.3321, batch_loss_s: 0.3265, time:5.0998, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2930/3125], step: 9180, 6.526 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0793, batch_loss_s: 0.0789, time:6.1291, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2940/3125], step: 9190, 7.732 samples/sec, batch_loss: 0.4099, batch_loss_c: 0.4094, batch_loss_s: 0.4111, time:5.1733, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:17 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2950/3125], step: 9200, 7.529 samples/sec, batch_loss: 0.2367, batch_loss_c: 0.2610, batch_loss_s: 0.1802, time:5.3127, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2960/3125], step: 9210, 9.021 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.1021, batch_loss_s: 0.0917, time:4.4341, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2970/3125], step: 9220, 7.490 samples/sec, batch_loss: 0.1212, batch_loss_c: 0.1253, batch_loss_s: 0.1115, time:5.3408, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2980/3125], step: 9230, 8.057 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.0974, batch_loss_s: 0.1110, time:4.9645, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:37 \u001b[32mINFO     \u001b[0m train.py: [2/5], [2990/3125], step: 9240, 7.881 samples/sec, batch_loss: 0.3217, batch_loss_c: 0.3301, batch_loss_s: 0.3020, time:5.0755, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:41 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3000/3125], step: 9250, 8.715 samples/sec, batch_loss: 0.3610, batch_loss_c: 0.3735, batch_loss_s: 0.3318, time:4.5898, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:46 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3010/3125], step: 9260, 7.725 samples/sec, batch_loss: 0.1083, batch_loss_c: 0.1096, batch_loss_s: 0.1052, time:5.1777, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:51 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3020/3125], step: 9270, 7.683 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0918, batch_loss_s: 0.0912, time:5.2060, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:26:56 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3030/3125], step: 9280, 8.534 samples/sec, batch_loss: 0.3184, batch_loss_c: 0.3097, batch_loss_s: 0.3387, time:4.6869, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:01 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3040/3125], step: 9290, 8.439 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0858, batch_loss_s: 0.0982, time:4.7400, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:06 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3050/3125], step: 9300, 8.544 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1295, batch_loss_s: 0.1265, time:4.6816, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:11 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3060/3125], step: 9310, 7.600 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0815, batch_loss_s: 0.0969, time:5.2630, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:16 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3070/3125], step: 9320, 8.244 samples/sec, batch_loss: 0.4599, batch_loss_c: 0.4978, batch_loss_s: 0.3716, time:4.8521, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:21 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3080/3125], step: 9330, 8.064 samples/sec, batch_loss: 0.3477, batch_loss_c: 0.3408, batch_loss_s: 0.3637, time:4.9601, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:26 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3090/3125], step: 9340, 8.232 samples/sec, batch_loss: 0.3221, batch_loss_c: 0.3228, batch_loss_s: 0.3207, time:4.8593, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:31 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3100/3125], step: 9350, 7.781 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1076, batch_loss_s: 0.1017, time:5.1409, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:35 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3110/3125], step: 9360, 10.302 samples/sec, batch_loss: 0.1914, batch_loss_c: 0.2156, batch_loss_s: 0.1347, time:3.8828, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:39 \u001b[32mINFO     \u001b[0m train.py: [2/5], [3120/3125], step: 9370, 10.194 samples/sec, batch_loss: 0.2172, batch_loss_c: 0.2238, batch_loss_s: 0.2017, time:3.9239, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:40 \u001b[32mINFO     \u001b[0m train.py: [2/5], train_loss: 0.2002, time: 1578.7893, lr: 0.0001\u001b[0m\n",
            "2019-11-23 09:27:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [0/3125], step: 9375, 7.107 samples/sec, batch_loss: 0.1033, batch_loss_c: 0.1146, batch_loss_s: 0.0770, time:5.6282, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [10/3125], step: 9385, 8.141 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3059, batch_loss_s: 0.3282, time:4.9133, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:27:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [20/3125], step: 9395, 7.820 samples/sec, batch_loss: 0.1279, batch_loss_c: 0.1219, batch_loss_s: 0.1420, time:5.1150, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [30/3125], step: 9405, 8.670 samples/sec, batch_loss: 0.3026, batch_loss_c: 0.2972, batch_loss_s: 0.3150, time:4.6138, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [40/3125], step: 9415, 7.924 samples/sec, batch_loss: 0.3156, batch_loss_c: 0.3150, batch_loss_s: 0.3167, time:5.0480, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [50/3125], step: 9425, 7.942 samples/sec, batch_loss: 0.2898, batch_loss_c: 0.2903, batch_loss_s: 0.2887, time:5.0368, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [60/3125], step: 9435, 8.398 samples/sec, batch_loss: 0.6360, batch_loss_c: 0.6382, batch_loss_s: 0.6309, time:4.7631, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:20 \u001b[32mINFO     \u001b[0m train.py: [3/5], [70/3125], step: 9445, 8.931 samples/sec, batch_loss: 0.1617, batch_loss_c: 0.1786, batch_loss_s: 0.1221, time:4.4789, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:25 \u001b[32mINFO     \u001b[0m train.py: [3/5], [80/3125], step: 9455, 8.834 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0825, batch_loss_s: 0.0849, time:4.5280, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:29 \u001b[32mINFO     \u001b[0m train.py: [3/5], [90/3125], step: 9465, 8.632 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1230, batch_loss_s: 0.0947, time:4.6342, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:34 \u001b[32mINFO     \u001b[0m train.py: [3/5], [100/3125], step: 9475, 8.582 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0793, batch_loss_s: 0.0911, time:4.6607, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:39 \u001b[32mINFO     \u001b[0m train.py: [3/5], [110/3125], step: 9485, 8.272 samples/sec, batch_loss: 0.2235, batch_loss_c: 0.1863, batch_loss_s: 0.3103, time:4.8358, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:43 \u001b[32mINFO     \u001b[0m train.py: [3/5], [120/3125], step: 9495, 8.595 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0880, batch_loss_s: 0.0970, time:4.6540, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [130/3125], step: 9505, 8.736 samples/sec, batch_loss: 0.2897, batch_loss_c: 0.2795, batch_loss_s: 0.3136, time:4.5786, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:52 \u001b[32mINFO     \u001b[0m train.py: [3/5], [140/3125], step: 9515, 9.196 samples/sec, batch_loss: 0.1348, batch_loss_c: 0.1439, batch_loss_s: 0.1136, time:4.3495, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:28:57 \u001b[32mINFO     \u001b[0m train.py: [3/5], [150/3125], step: 9525, 8.484 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0935, batch_loss_s: 0.1013, time:4.7145, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [160/3125], step: 9535, 8.528 samples/sec, batch_loss: 0.3262, batch_loss_c: 0.3298, batch_loss_s: 0.3176, time:4.6902, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:07 \u001b[32mINFO     \u001b[0m train.py: [3/5], [170/3125], step: 9545, 8.384 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0727, batch_loss_s: 0.0745, time:4.7711, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [180/3125], step: 9555, 8.384 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1292, batch_loss_s: 0.1139, time:4.7708, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [190/3125], step: 9565, 8.278 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0776, batch_loss_s: 0.0968, time:4.8319, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [200/3125], step: 9575, 7.870 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0865, batch_loss_s: 0.1070, time:5.0829, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [210/3125], step: 9585, 7.931 samples/sec, batch_loss: 0.1379, batch_loss_c: 0.1367, batch_loss_s: 0.1408, time:5.0434, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [220/3125], step: 9595, 7.873 samples/sec, batch_loss: 0.3203, batch_loss_c: 0.3159, batch_loss_s: 0.3306, time:5.0810, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [230/3125], step: 9605, 8.093 samples/sec, batch_loss: 0.3460, batch_loss_c: 0.3416, batch_loss_s: 0.3563, time:4.9426, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [240/3125], step: 9615, 8.266 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3144, batch_loss_s: 0.3396, time:4.8392, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [250/3125], step: 9625, 8.509 samples/sec, batch_loss: 0.1968, batch_loss_c: 0.2014, batch_loss_s: 0.1861, time:4.7010, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [260/3125], step: 9635, 7.141 samples/sec, batch_loss: 0.3011, batch_loss_c: 0.2990, batch_loss_s: 0.3062, time:5.6011, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:29:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [270/3125], step: 9645, 8.856 samples/sec, batch_loss: 0.1257, batch_loss_c: 0.1240, batch_loss_s: 0.1297, time:4.5166, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [280/3125], step: 9655, 8.232 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0844, batch_loss_s: 0.0917, time:4.8589, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [290/3125], step: 9665, 8.382 samples/sec, batch_loss: 0.1266, batch_loss_c: 0.1312, batch_loss_s: 0.1158, time:4.7724, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [300/3125], step: 9675, 6.979 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0953, batch_loss_s: 0.0994, time:5.7319, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:17 \u001b[32mINFO     \u001b[0m train.py: [3/5], [310/3125], step: 9685, 7.608 samples/sec, batch_loss: 0.2942, batch_loss_c: 0.2900, batch_loss_s: 0.3042, time:5.2575, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [320/3125], step: 9695, 7.213 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0915, batch_loss_s: 0.0963, time:5.5455, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:28 \u001b[32mINFO     \u001b[0m train.py: [3/5], [330/3125], step: 9705, 7.217 samples/sec, batch_loss: 0.2609, batch_loss_c: 0.2373, batch_loss_s: 0.3160, time:5.5423, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:33 \u001b[32mINFO     \u001b[0m train.py: [3/5], [340/3125], step: 9715, 8.234 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1091, batch_loss_s: 0.1203, time:4.8581, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [350/3125], step: 9725, 8.123 samples/sec, batch_loss: 0.1282, batch_loss_c: 0.1259, batch_loss_s: 0.1336, time:4.9242, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [360/3125], step: 9735, 8.377 samples/sec, batch_loss: 0.2010, batch_loss_c: 0.2350, batch_loss_s: 0.1218, time:4.7748, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:47 \u001b[32mINFO     \u001b[0m train.py: [3/5], [370/3125], step: 9745, 8.677 samples/sec, batch_loss: 0.2777, batch_loss_c: 0.2687, batch_loss_s: 0.2988, time:4.6099, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:52 \u001b[32mINFO     \u001b[0m train.py: [3/5], [380/3125], step: 9755, 8.412 samples/sec, batch_loss: 0.0680, batch_loss_c: 0.0656, batch_loss_s: 0.0737, time:4.7553, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:30:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [390/3125], step: 9765, 8.671 samples/sec, batch_loss: 0.1383, batch_loss_c: 0.1332, batch_loss_s: 0.1502, time:4.6133, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [400/3125], step: 9775, 7.508 samples/sec, batch_loss: 0.1066, batch_loss_c: 0.1205, batch_loss_s: 0.0740, time:5.3279, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:07 \u001b[32mINFO     \u001b[0m train.py: [3/5], [410/3125], step: 9785, 6.927 samples/sec, batch_loss: 0.3699, batch_loss_c: 0.3909, batch_loss_s: 0.3208, time:5.7742, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:12 \u001b[32mINFO     \u001b[0m train.py: [3/5], [420/3125], step: 9795, 8.610 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1520, batch_loss_s: 0.1035, time:4.6456, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:17 \u001b[32mINFO     \u001b[0m train.py: [3/5], [430/3125], step: 9805, 7.418 samples/sec, batch_loss: 0.1680, batch_loss_c: 0.1985, batch_loss_s: 0.0970, time:5.3923, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:23 \u001b[32mINFO     \u001b[0m train.py: [3/5], [440/3125], step: 9815, 7.337 samples/sec, batch_loss: 0.3103, batch_loss_c: 0.3101, batch_loss_s: 0.3107, time:5.4520, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:28 \u001b[32mINFO     \u001b[0m train.py: [3/5], [450/3125], step: 9825, 7.060 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1059, batch_loss_s: 0.1089, time:5.6658, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:34 \u001b[32mINFO     \u001b[0m train.py: [3/5], [460/3125], step: 9835, 6.864 samples/sec, batch_loss: 0.4471, batch_loss_c: 0.4712, batch_loss_s: 0.3909, time:5.8275, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:39 \u001b[32mINFO     \u001b[0m train.py: [3/5], [470/3125], step: 9845, 7.884 samples/sec, batch_loss: 0.0780, batch_loss_c: 0.0815, batch_loss_s: 0.0699, time:5.0735, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [480/3125], step: 9855, 7.962 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1113, batch_loss_s: 0.0810, time:5.0242, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:50 \u001b[32mINFO     \u001b[0m train.py: [3/5], [490/3125], step: 9865, 7.526 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3255, batch_loss_s: 0.3086, time:5.3150, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:31:55 \u001b[32mINFO     \u001b[0m train.py: [3/5], [500/3125], step: 9875, 8.069 samples/sec, batch_loss: 0.1510, batch_loss_c: 0.1600, batch_loss_s: 0.1300, time:4.9575, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:00 \u001b[32mINFO     \u001b[0m train.py: [3/5], [510/3125], step: 9885, 8.075 samples/sec, batch_loss: 0.4026, batch_loss_c: 0.4094, batch_loss_s: 0.3868, time:4.9538, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [520/3125], step: 9895, 8.104 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1099, batch_loss_s: 0.1048, time:4.9359, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [530/3125], step: 9905, 7.964 samples/sec, batch_loss: 0.0851, batch_loss_c: 0.0791, batch_loss_s: 0.0990, time:5.0227, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [540/3125], step: 9915, 8.243 samples/sec, batch_loss: 0.0687, batch_loss_c: 0.0661, batch_loss_s: 0.0747, time:4.8528, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:19 \u001b[32mINFO     \u001b[0m train.py: [3/5], [550/3125], step: 9925, 9.176 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1409, batch_loss_s: 0.1261, time:4.3593, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:23 \u001b[32mINFO     \u001b[0m train.py: [3/5], [560/3125], step: 9935, 9.225 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0943, batch_loss_s: 0.0970, time:4.3358, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:28 \u001b[32mINFO     \u001b[0m train.py: [3/5], [570/3125], step: 9945, 8.456 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1180, batch_loss_s: 0.1172, time:4.7304, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:33 \u001b[32mINFO     \u001b[0m train.py: [3/5], [580/3125], step: 9955, 8.647 samples/sec, batch_loss: 0.2006, batch_loss_c: 0.2428, batch_loss_s: 0.1020, time:4.6258, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [590/3125], step: 9965, 8.280 samples/sec, batch_loss: 0.2048, batch_loss_c: 0.2094, batch_loss_s: 0.1943, time:4.8309, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [600/3125], step: 9975, 8.508 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0636, batch_loss_s: 0.0746, time:4.7013, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [610/3125], step: 9985, 7.287 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0886, batch_loss_s: 0.0947, time:5.4892, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:52 \u001b[32mINFO     \u001b[0m train.py: [3/5], [620/3125], step: 9995, 8.712 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0941, batch_loss_s: 0.1043, time:4.5912, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:32:57 \u001b[32mINFO     \u001b[0m train.py: [3/5], [630/3125], step: 10005, 8.659 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.2069, batch_loss_s: 0.1655, time:4.6196, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [640/3125], step: 10015, 7.930 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1171, batch_loss_s: 0.1187, time:5.0441, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [650/3125], step: 10025, 8.607 samples/sec, batch_loss: 0.1343, batch_loss_c: 0.1296, batch_loss_s: 0.1455, time:4.6472, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:12 \u001b[32mINFO     \u001b[0m train.py: [3/5], [660/3125], step: 10035, 6.935 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0714, batch_loss_s: 0.0865, time:5.7677, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:17 \u001b[32mINFO     \u001b[0m train.py: [3/5], [670/3125], step: 10045, 7.776 samples/sec, batch_loss: 0.0755, batch_loss_c: 0.0701, batch_loss_s: 0.0880, time:5.1441, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [680/3125], step: 10055, 8.402 samples/sec, batch_loss: 0.3003, batch_loss_c: 0.3037, batch_loss_s: 0.2922, time:4.7610, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [690/3125], step: 10065, 7.967 samples/sec, batch_loss: 0.1649, batch_loss_c: 0.1766, batch_loss_s: 0.1376, time:5.0204, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:32 \u001b[32mINFO     \u001b[0m train.py: [3/5], [700/3125], step: 10075, 7.760 samples/sec, batch_loss: 0.2880, batch_loss_c: 0.2855, batch_loss_s: 0.2941, time:5.1549, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [710/3125], step: 10085, 8.122 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3189, batch_loss_s: 0.3238, time:4.9251, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [720/3125], step: 10095, 8.553 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0843, batch_loss_s: 0.0791, time:4.6766, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:47 \u001b[32mINFO     \u001b[0m train.py: [3/5], [730/3125], step: 10105, 7.746 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0833, batch_loss_s: 0.0856, time:5.1641, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:52 \u001b[32mINFO     \u001b[0m train.py: [3/5], [740/3125], step: 10115, 8.092 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1088, batch_loss_s: 0.0933, time:4.9431, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:33:57 \u001b[32mINFO     \u001b[0m train.py: [3/5], [750/3125], step: 10125, 8.671 samples/sec, batch_loss: 0.2522, batch_loss_c: 0.2320, batch_loss_s: 0.2995, time:4.6132, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [760/3125], step: 10135, 7.390 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1262, batch_loss_s: 0.0876, time:5.4126, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:07 \u001b[32mINFO     \u001b[0m train.py: [3/5], [770/3125], step: 10145, 7.677 samples/sec, batch_loss: 0.3544, batch_loss_c: 0.3562, batch_loss_s: 0.3502, time:5.2102, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:13 \u001b[32mINFO     \u001b[0m train.py: [3/5], [780/3125], step: 10155, 7.165 samples/sec, batch_loss: 0.3069, batch_loss_c: 0.3097, batch_loss_s: 0.3003, time:5.5830, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:18 \u001b[32mINFO     \u001b[0m train.py: [3/5], [790/3125], step: 10165, 8.283 samples/sec, batch_loss: 0.3466, batch_loss_c: 0.3495, batch_loss_s: 0.3400, time:4.8292, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [800/3125], step: 10175, 8.521 samples/sec, batch_loss: 0.2036, batch_loss_c: 0.1981, batch_loss_s: 0.2162, time:4.6941, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [810/3125], step: 10185, 8.608 samples/sec, batch_loss: 0.2292, batch_loss_c: 0.1974, batch_loss_s: 0.3033, time:4.6470, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:32 \u001b[32mINFO     \u001b[0m train.py: [3/5], [820/3125], step: 10195, 8.887 samples/sec, batch_loss: 0.3571, batch_loss_c: 0.3751, batch_loss_s: 0.3150, time:4.5008, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [830/3125], step: 10205, 8.510 samples/sec, batch_loss: 0.0822, batch_loss_c: 0.0851, batch_loss_s: 0.0754, time:4.7001, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [840/3125], step: 10215, 9.000 samples/sec, batch_loss: 0.2566, batch_loss_c: 0.2415, batch_loss_s: 0.2919, time:4.4446, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [850/3125], step: 10225, 7.687 samples/sec, batch_loss: 0.3597, batch_loss_c: 0.3661, batch_loss_s: 0.3448, time:5.2037, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [860/3125], step: 10235, 7.779 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.0923, batch_loss_s: 0.1279, time:5.1424, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:34:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [870/3125], step: 10245, 8.461 samples/sec, batch_loss: 0.5452, batch_loss_c: 0.5368, batch_loss_s: 0.5650, time:4.7274, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [880/3125], step: 10255, 7.158 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1282, batch_loss_s: 0.1172, time:5.5882, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [890/3125], step: 10265, 8.108 samples/sec, batch_loss: 0.3410, batch_loss_c: 0.3472, batch_loss_s: 0.3267, time:4.9335, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [900/3125], step: 10275, 7.892 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1050, batch_loss_s: 0.1110, time:5.0687, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [910/3125], step: 10285, 7.849 samples/sec, batch_loss: 0.3032, batch_loss_c: 0.3050, batch_loss_s: 0.2991, time:5.0961, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [920/3125], step: 10295, 8.887 samples/sec, batch_loss: 0.1037, batch_loss_c: 0.1092, batch_loss_s: 0.0910, time:4.5010, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [930/3125], step: 10305, 8.126 samples/sec, batch_loss: 0.1572, batch_loss_c: 0.1713, batch_loss_s: 0.1242, time:4.9223, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [940/3125], step: 10315, 8.130 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1218, batch_loss_s: 0.1193, time:4.9201, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [950/3125], step: 10325, 7.331 samples/sec, batch_loss: 0.1376, batch_loss_c: 0.1241, batch_loss_s: 0.1692, time:5.4560, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [960/3125], step: 10335, 7.552 samples/sec, batch_loss: 0.0822, batch_loss_c: 0.0784, batch_loss_s: 0.0912, time:5.2965, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [970/3125], step: 10345, 8.734 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0804, batch_loss_s: 0.0867, time:4.5798, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [980/3125], step: 10355, 8.952 samples/sec, batch_loss: 0.1459, batch_loss_c: 0.1456, batch_loss_s: 0.1465, time:4.4681, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:35:55 \u001b[32mINFO     \u001b[0m train.py: [3/5], [990/3125], step: 10365, 8.705 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0827, batch_loss_s: 0.1016, time:4.5949, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:00 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1000/3125], step: 10375, 7.921 samples/sec, batch_loss: 0.1302, batch_loss_c: 0.1328, batch_loss_s: 0.1241, time:5.0497, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1010/3125], step: 10385, 7.939 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1734, batch_loss_s: 0.0851, time:5.0382, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1020/3125], step: 10395, 8.620 samples/sec, batch_loss: 0.1998, batch_loss_c: 0.2292, batch_loss_s: 0.1314, time:4.6404, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:15 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1030/3125], step: 10405, 7.726 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1326, batch_loss_s: 0.1543, time:5.1775, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:20 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1040/3125], step: 10415, 8.354 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1235, batch_loss_s: 0.0954, time:4.7883, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:25 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1050/3125], step: 10425, 7.631 samples/sec, batch_loss: 0.3355, batch_loss_c: 0.3316, batch_loss_s: 0.3446, time:5.2420, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1060/3125], step: 10435, 7.403 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0762, batch_loss_s: 0.1265, time:5.4032, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:35 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1070/3125], step: 10445, 8.091 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0870, batch_loss_s: 0.0899, time:4.9439, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:40 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1080/3125], step: 10455, 8.404 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.0999, batch_loss_s: 0.1129, time:4.7599, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:45 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1090/3125], step: 10465, 7.787 samples/sec, batch_loss: 0.3202, batch_loss_c: 0.3235, batch_loss_s: 0.3126, time:5.1365, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:50 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1100/3125], step: 10475, 8.856 samples/sec, batch_loss: 0.1733, batch_loss_c: 0.2030, batch_loss_s: 0.1039, time:4.5167, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:36:55 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1110/3125], step: 10485, 8.123 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1332, batch_loss_s: 0.0890, time:4.9243, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:00 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1120/3125], step: 10495, 8.002 samples/sec, batch_loss: 0.3056, batch_loss_c: 0.2873, batch_loss_s: 0.3483, time:4.9985, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1130/3125], step: 10505, 8.303 samples/sec, batch_loss: 0.3901, batch_loss_c: 0.3924, batch_loss_s: 0.3849, time:4.8178, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1140/3125], step: 10515, 8.006 samples/sec, batch_loss: 0.2190, batch_loss_c: 0.2523, batch_loss_s: 0.1416, time:4.9962, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1150/3125], step: 10525, 8.911 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0829, batch_loss_s: 0.0789, time:4.4889, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:19 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1160/3125], step: 10535, 8.222 samples/sec, batch_loss: 0.1221, batch_loss_c: 0.1299, batch_loss_s: 0.1038, time:4.8652, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1170/3125], step: 10545, 7.785 samples/sec, batch_loss: 0.1751, batch_loss_c: 0.1959, batch_loss_s: 0.1267, time:5.1379, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:30 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1180/3125], step: 10555, 7.251 samples/sec, batch_loss: 0.2996, batch_loss_c: 0.2796, batch_loss_s: 0.3462, time:5.5168, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:35 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1190/3125], step: 10565, 7.313 samples/sec, batch_loss: 0.1020, batch_loss_c: 0.1071, batch_loss_s: 0.0902, time:5.4695, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:40 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1200/3125], step: 10575, 8.101 samples/sec, batch_loss: 0.7284, batch_loss_c: 0.7033, batch_loss_s: 0.7869, time:4.9375, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:45 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1210/3125], step: 10585, 8.261 samples/sec, batch_loss: 0.3725, batch_loss_c: 0.3957, batch_loss_s: 0.3184, time:4.8420, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:50 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1220/3125], step: 10595, 7.348 samples/sec, batch_loss: 0.0922, batch_loss_c: 0.0896, batch_loss_s: 0.0984, time:5.4437, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:37:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1230/3125], step: 10605, 7.513 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1652, batch_loss_s: 0.1261, time:5.3238, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1240/3125], step: 10615, 8.220 samples/sec, batch_loss: 0.2130, batch_loss_c: 0.2400, batch_loss_s: 0.1501, time:4.8660, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1250/3125], step: 10625, 7.479 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1289, batch_loss_s: 0.1350, time:5.3482, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1260/3125], step: 10635, 8.510 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0756, batch_loss_s: 0.0952, time:4.7002, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1270/3125], step: 10645, 7.748 samples/sec, batch_loss: 0.5057, batch_loss_c: 0.4905, batch_loss_s: 0.5412, time:5.1625, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1280/3125], step: 10655, 7.637 samples/sec, batch_loss: 0.1815, batch_loss_c: 0.2083, batch_loss_s: 0.1191, time:5.2379, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1290/3125], step: 10665, 8.125 samples/sec, batch_loss: 0.0831, batch_loss_c: 0.0822, batch_loss_s: 0.0851, time:4.9230, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1300/3125], step: 10675, 8.134 samples/sec, batch_loss: 0.3397, batch_loss_c: 0.3462, batch_loss_s: 0.3247, time:4.9179, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1310/3125], step: 10685, 8.215 samples/sec, batch_loss: 0.1494, batch_loss_c: 0.1561, batch_loss_s: 0.1340, time:4.8691, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1320/3125], step: 10695, 8.004 samples/sec, batch_loss: 0.2062, batch_loss_c: 0.2467, batch_loss_s: 0.1115, time:4.9975, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:45 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1330/3125], step: 10705, 8.375 samples/sec, batch_loss: 0.1321, batch_loss_c: 0.1530, batch_loss_s: 0.0832, time:4.7760, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1340/3125], step: 10715, 6.794 samples/sec, batch_loss: 0.1522, batch_loss_c: 0.1745, batch_loss_s: 0.1003, time:5.8878, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:38:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1350/3125], step: 10725, 8.302 samples/sec, batch_loss: 0.5497, batch_loss_c: 0.5412, batch_loss_s: 0.5694, time:4.8179, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1360/3125], step: 10735, 7.271 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1018, batch_loss_s: 0.0895, time:5.5016, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1370/3125], step: 10745, 8.486 samples/sec, batch_loss: 0.1272, batch_loss_c: 0.1421, batch_loss_s: 0.0926, time:4.7138, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:12 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1380/3125], step: 10755, 7.770 samples/sec, batch_loss: 0.3599, batch_loss_c: 0.3586, batch_loss_s: 0.3629, time:5.1481, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1390/3125], step: 10765, 8.179 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0889, batch_loss_s: 0.0670, time:4.8905, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1400/3125], step: 10775, 7.490 samples/sec, batch_loss: 0.0852, batch_loss_c: 0.0868, batch_loss_s: 0.0815, time:5.3403, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1410/3125], step: 10785, 8.356 samples/sec, batch_loss: 0.1377, batch_loss_c: 0.1539, batch_loss_s: 0.0999, time:4.7869, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1420/3125], step: 10795, 8.773 samples/sec, batch_loss: 0.3004, batch_loss_c: 0.2985, batch_loss_s: 0.3049, time:4.5595, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1430/3125], step: 10805, 8.147 samples/sec, batch_loss: 0.5623, batch_loss_c: 0.5672, batch_loss_s: 0.5509, time:4.9097, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1440/3125], step: 10815, 8.680 samples/sec, batch_loss: 0.0550, batch_loss_c: 0.0511, batch_loss_s: 0.0642, time:4.6084, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:45 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1450/3125], step: 10825, 8.280 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1251, batch_loss_s: 0.1169, time:4.8310, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:50 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1460/3125], step: 10835, 8.095 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1102, batch_loss_s: 0.0857, time:4.9415, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:39:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1470/3125], step: 10845, 7.728 samples/sec, batch_loss: 0.1129, batch_loss_c: 0.1198, batch_loss_s: 0.0970, time:5.1757, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:00 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1480/3125], step: 10855, 8.499 samples/sec, batch_loss: 0.0610, batch_loss_c: 0.0564, batch_loss_s: 0.0716, time:4.7066, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1490/3125], step: 10865, 8.535 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1362, batch_loss_s: 0.1145, time:4.6868, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1500/3125], step: 10875, 7.814 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.0973, batch_loss_s: 0.1002, time:5.1189, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1510/3125], step: 10885, 7.375 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.0943, batch_loss_s: 0.0961, time:5.4240, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1520/3125], step: 10895, 6.773 samples/sec, batch_loss: 0.3621, batch_loss_c: 0.3516, batch_loss_s: 0.3866, time:5.9058, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1530/3125], step: 10905, 7.229 samples/sec, batch_loss: 0.1263, batch_loss_c: 0.1236, batch_loss_s: 0.1327, time:5.5336, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1540/3125], step: 10915, 8.998 samples/sec, batch_loss: 0.2418, batch_loss_c: 0.2574, batch_loss_s: 0.2054, time:4.4454, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1550/3125], step: 10925, 8.876 samples/sec, batch_loss: 0.1236, batch_loss_c: 0.1302, batch_loss_s: 0.1084, time:4.5067, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1560/3125], step: 10935, 8.453 samples/sec, batch_loss: 0.1532, batch_loss_c: 0.1734, batch_loss_s: 0.1062, time:4.7319, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1570/3125], step: 10945, 8.024 samples/sec, batch_loss: 0.3696, batch_loss_c: 0.3805, batch_loss_s: 0.3441, time:4.9850, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1580/3125], step: 10955, 7.975 samples/sec, batch_loss: 0.1335, batch_loss_c: 0.1344, batch_loss_s: 0.1313, time:5.0159, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:40:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1590/3125], step: 10965, 8.043 samples/sec, batch_loss: 0.3064, batch_loss_c: 0.2919, batch_loss_s: 0.3404, time:4.9732, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:00 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1600/3125], step: 10975, 9.245 samples/sec, batch_loss: 0.0855, batch_loss_c: 0.0811, batch_loss_s: 0.0957, time:4.3264, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1610/3125], step: 10985, 7.936 samples/sec, batch_loss: 0.3265, batch_loss_c: 0.3227, batch_loss_s: 0.3354, time:5.0405, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1620/3125], step: 10995, 8.703 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1108, batch_loss_s: 0.1122, time:4.5961, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1630/3125], step: 11005, 8.762 samples/sec, batch_loss: 0.1553, batch_loss_c: 0.1550, batch_loss_s: 0.1561, time:4.5653, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:19 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1640/3125], step: 11015, 8.561 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0874, batch_loss_s: 0.0901, time:4.6725, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1650/3125], step: 11025, 7.687 samples/sec, batch_loss: 0.1938, batch_loss_c: 0.2302, batch_loss_s: 0.1091, time:5.2036, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:29 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1660/3125], step: 11035, 7.734 samples/sec, batch_loss: 0.0599, batch_loss_c: 0.0576, batch_loss_s: 0.0653, time:5.1722, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:34 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1670/3125], step: 11045, 8.378 samples/sec, batch_loss: 0.1232, batch_loss_c: 0.1298, batch_loss_s: 0.1076, time:4.7743, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:39 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1680/3125], step: 11055, 7.714 samples/sec, batch_loss: 0.1947, batch_loss_c: 0.2196, batch_loss_s: 0.1367, time:5.1856, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1690/3125], step: 11065, 8.351 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1598, batch_loss_s: 0.1085, time:4.7896, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:49 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1700/3125], step: 11075, 7.721 samples/sec, batch_loss: 0.2723, batch_loss_c: 0.2523, batch_loss_s: 0.3191, time:5.1806, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:54 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1710/3125], step: 11085, 8.455 samples/sec, batch_loss: 0.3947, batch_loss_c: 0.4293, batch_loss_s: 0.3140, time:4.7308, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:41:59 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1720/3125], step: 11095, 8.337 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0924, batch_loss_s: 0.1120, time:4.7981, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:04 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1730/3125], step: 11105, 7.688 samples/sec, batch_loss: 0.0902, batch_loss_c: 0.0953, batch_loss_s: 0.0782, time:5.2031, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:09 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1740/3125], step: 11115, 7.730 samples/sec, batch_loss: 0.1721, batch_loss_c: 0.1867, batch_loss_s: 0.1382, time:5.1749, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1750/3125], step: 11125, 8.196 samples/sec, batch_loss: 0.1442, batch_loss_c: 0.1527, batch_loss_s: 0.1243, time:4.8802, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:20 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1760/3125], step: 11135, 7.047 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2845, batch_loss_s: 0.3110, time:5.6764, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1770/3125], step: 11145, 6.469 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0826, batch_loss_s: 0.0867, time:6.1835, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1780/3125], step: 11155, 8.082 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1230, batch_loss_s: 0.1005, time:4.9490, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:35 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1790/3125], step: 11165, 8.507 samples/sec, batch_loss: 0.3298, batch_loss_c: 0.2989, batch_loss_s: 0.4017, time:4.7020, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:41 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1800/3125], step: 11175, 7.602 samples/sec, batch_loss: 0.1295, batch_loss_c: 0.1446, batch_loss_s: 0.0945, time:5.2617, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1810/3125], step: 11185, 7.624 samples/sec, batch_loss: 0.1233, batch_loss_c: 0.1335, batch_loss_s: 0.0994, time:5.2463, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1820/3125], step: 11195, 7.656 samples/sec, batch_loss: 0.1547, batch_loss_c: 0.1832, batch_loss_s: 0.0881, time:5.2248, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:42:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1830/3125], step: 11205, 7.752 samples/sec, batch_loss: 0.2004, batch_loss_c: 0.2285, batch_loss_s: 0.1346, time:5.1602, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1840/3125], step: 11215, 8.917 samples/sec, batch_loss: 0.1826, batch_loss_c: 0.2246, batch_loss_s: 0.0844, time:4.4857, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1850/3125], step: 11225, 8.610 samples/sec, batch_loss: 0.3606, batch_loss_c: 0.3369, batch_loss_s: 0.4160, time:4.6459, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1860/3125], step: 11235, 8.212 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.1001, batch_loss_s: 0.1056, time:4.8710, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1870/3125], step: 11245, 7.445 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1234, batch_loss_s: 0.1173, time:5.3727, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1880/3125], step: 11255, 7.911 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1415, batch_loss_s: 0.1023, time:5.0565, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1890/3125], step: 11265, 8.011 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0906, batch_loss_s: 0.0797, time:4.9934, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1900/3125], step: 11275, 7.528 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1160, batch_loss_s: 0.0999, time:5.3136, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1910/3125], step: 11285, 7.746 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1139, batch_loss_s: 0.1481, time:5.1639, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1920/3125], step: 11295, 6.848 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0691, batch_loss_s: 0.0745, time:5.8411, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1930/3125], step: 11305, 7.110 samples/sec, batch_loss: 0.3287, batch_loss_c: 0.3243, batch_loss_s: 0.3391, time:5.6257, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:53 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1940/3125], step: 11315, 7.780 samples/sec, batch_loss: 0.1484, batch_loss_c: 0.1666, batch_loss_s: 0.1058, time:5.1416, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:43:59 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1950/3125], step: 11325, 7.110 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.1077, batch_loss_s: 0.0850, time:5.6260, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:04 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1960/3125], step: 11335, 7.697 samples/sec, batch_loss: 0.1971, batch_loss_c: 0.2295, batch_loss_s: 0.1213, time:5.1968, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:09 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1970/3125], step: 11345, 8.054 samples/sec, batch_loss: 0.5475, batch_loss_c: 0.5473, batch_loss_s: 0.5480, time:4.9662, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:13 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1980/3125], step: 11355, 8.540 samples/sec, batch_loss: 0.1548, batch_loss_c: 0.1684, batch_loss_s: 0.1231, time:4.6838, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:18 \u001b[32mINFO     \u001b[0m train.py: [3/5], [1990/3125], step: 11365, 8.077 samples/sec, batch_loss: 0.1976, batch_loss_c: 0.2082, batch_loss_s: 0.1730, time:4.9523, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2000/3125], step: 11375, 7.055 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0838, batch_loss_s: 0.0913, time:5.6701, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:29 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2010/3125], step: 11385, 8.610 samples/sec, batch_loss: 0.0844, batch_loss_c: 0.0794, batch_loss_s: 0.0959, time:4.6456, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:34 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2020/3125], step: 11395, 7.024 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0642, batch_loss_s: 0.0869, time:5.6944, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:39 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2030/3125], step: 11405, 8.573 samples/sec, batch_loss: 0.1119, batch_loss_c: 0.1143, batch_loss_s: 0.1064, time:4.6658, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2040/3125], step: 11415, 8.470 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1100, batch_loss_s: 0.0899, time:4.7224, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2050/3125], step: 11425, 8.576 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1091, batch_loss_s: 0.1239, time:4.6644, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:53 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2060/3125], step: 11435, 8.329 samples/sec, batch_loss: 0.3105, batch_loss_c: 0.3043, batch_loss_s: 0.3249, time:4.8027, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:44:58 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2070/3125], step: 11445, 8.662 samples/sec, batch_loss: 0.3118, batch_loss_c: 0.3087, batch_loss_s: 0.3189, time:4.6178, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:02 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2080/3125], step: 11455, 8.863 samples/sec, batch_loss: 0.2783, batch_loss_c: 0.2559, batch_loss_s: 0.3305, time:4.5133, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:07 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2090/3125], step: 11465, 8.085 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1079, batch_loss_s: 0.0986, time:4.9475, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:13 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2100/3125], step: 11475, 7.395 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1708, batch_loss_s: 0.1132, time:5.4088, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:18 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2110/3125], step: 11485, 8.111 samples/sec, batch_loss: 0.2749, batch_loss_c: 0.2614, batch_loss_s: 0.3063, time:4.9313, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2120/3125], step: 11495, 8.367 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0900, batch_loss_s: 0.0884, time:4.7806, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2130/3125], step: 11505, 7.876 samples/sec, batch_loss: 0.6047, batch_loss_c: 0.6258, batch_loss_s: 0.5554, time:5.0784, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:32 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2140/3125], step: 11515, 8.092 samples/sec, batch_loss: 0.1575, batch_loss_c: 0.1851, batch_loss_s: 0.0932, time:4.9434, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2150/3125], step: 11525, 8.322 samples/sec, batch_loss: 0.1896, batch_loss_c: 0.1913, batch_loss_s: 0.1857, time:4.8067, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:43 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2160/3125], step: 11535, 6.691 samples/sec, batch_loss: 0.3053, batch_loss_c: 0.2993, batch_loss_s: 0.3193, time:5.9779, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:49 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2170/3125], step: 11545, 7.275 samples/sec, batch_loss: 0.4360, batch_loss_c: 0.4467, batch_loss_s: 0.4112, time:5.4982, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:54 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2180/3125], step: 11555, 7.119 samples/sec, batch_loss: 0.2302, batch_loss_c: 0.2364, batch_loss_s: 0.2155, time:5.6188, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:45:59 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2190/3125], step: 11565, 8.203 samples/sec, batch_loss: 0.0715, batch_loss_c: 0.0593, batch_loss_s: 0.0999, time:4.8766, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:05 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2200/3125], step: 11575, 7.294 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1698, batch_loss_s: 0.1045, time:5.4837, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:10 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2210/3125], step: 11585, 7.894 samples/sec, batch_loss: 0.2429, batch_loss_c: 0.2487, batch_loss_s: 0.2292, time:5.0674, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:15 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2220/3125], step: 11595, 8.464 samples/sec, batch_loss: 0.3137, batch_loss_c: 0.3137, batch_loss_s: 0.3137, time:4.7260, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:20 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2230/3125], step: 11605, 7.750 samples/sec, batch_loss: 0.2229, batch_loss_c: 0.2528, batch_loss_s: 0.1531, time:5.1612, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:25 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2240/3125], step: 11615, 8.180 samples/sec, batch_loss: 0.3841, batch_loss_c: 0.3959, batch_loss_s: 0.3567, time:4.8901, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:29 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2250/3125], step: 11625, 8.298 samples/sec, batch_loss: 0.3084, batch_loss_c: 0.3068, batch_loss_s: 0.3122, time:4.8205, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:35 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2260/3125], step: 11635, 7.800 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3161, batch_loss_s: 0.3193, time:5.1285, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:40 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2270/3125], step: 11645, 7.755 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1546, batch_loss_s: 0.1249, time:5.1577, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2280/3125], step: 11655, 8.314 samples/sec, batch_loss: 0.1757, batch_loss_c: 0.1881, batch_loss_s: 0.1468, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:49 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2290/3125], step: 11665, 8.464 samples/sec, batch_loss: 0.3102, batch_loss_c: 0.3082, batch_loss_s: 0.3150, time:4.7257, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:54 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2300/3125], step: 11675, 8.433 samples/sec, batch_loss: 0.1319, batch_loss_c: 0.1537, batch_loss_s: 0.0810, time:4.7434, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:46:59 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2310/3125], step: 11685, 8.526 samples/sec, batch_loss: 0.2919, batch_loss_c: 0.2845, batch_loss_s: 0.3092, time:4.6916, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:03 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2320/3125], step: 11695, 8.500 samples/sec, batch_loss: 0.0688, batch_loss_c: 0.0723, batch_loss_s: 0.0608, time:4.7057, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:08 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2330/3125], step: 11705, 8.501 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0839, batch_loss_s: 0.1086, time:4.7055, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:13 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2340/3125], step: 11715, 8.556 samples/sec, batch_loss: 0.1331, batch_loss_c: 0.1476, batch_loss_s: 0.0993, time:4.6752, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:18 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2350/3125], step: 11725, 7.654 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.0970, batch_loss_s: 0.1127, time:5.2262, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2360/3125], step: 11735, 7.116 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3010, batch_loss_s: 0.3726, time:5.6215, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:28 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2370/3125], step: 11745, 8.195 samples/sec, batch_loss: 0.1450, batch_loss_c: 0.1638, batch_loss_s: 0.1013, time:4.8810, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:33 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2380/3125], step: 11755, 8.236 samples/sec, batch_loss: 0.1180, batch_loss_c: 0.1308, batch_loss_s: 0.0880, time:4.8568, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:38 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2390/3125], step: 11765, 8.666 samples/sec, batch_loss: 0.2591, batch_loss_c: 0.2375, batch_loss_s: 0.3095, time:4.6155, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:43 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2400/3125], step: 11775, 7.532 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3140, batch_loss_s: 0.3384, time:5.3105, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2410/3125], step: 11785, 7.783 samples/sec, batch_loss: 0.0604, batch_loss_c: 0.0601, batch_loss_s: 0.0610, time:5.1394, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:53 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2420/3125], step: 11795, 8.111 samples/sec, batch_loss: 0.1020, batch_loss_c: 0.0954, batch_loss_s: 0.1175, time:4.9318, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:47:58 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2430/3125], step: 11805, 8.552 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0803, batch_loss_s: 0.0935, time:4.6771, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:03 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2440/3125], step: 11815, 7.930 samples/sec, batch_loss: 0.3647, batch_loss_c: 0.3665, batch_loss_s: 0.3605, time:5.0441, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:08 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2450/3125], step: 11825, 8.180 samples/sec, batch_loss: 0.1355, batch_loss_c: 0.1295, batch_loss_s: 0.1495, time:4.8901, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2460/3125], step: 11835, 6.877 samples/sec, batch_loss: 0.1951, batch_loss_c: 0.2136, batch_loss_s: 0.1520, time:5.8161, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:19 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2470/3125], step: 11845, 8.238 samples/sec, batch_loss: 0.2882, batch_loss_c: 0.2769, batch_loss_s: 0.3146, time:4.8555, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2480/3125], step: 11855, 8.090 samples/sec, batch_loss: 0.3504, batch_loss_c: 0.3461, batch_loss_s: 0.3607, time:4.9445, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:29 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2490/3125], step: 11865, 7.973 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1285, batch_loss_s: 0.1328, time:5.0167, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:34 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2500/3125], step: 11875, 8.050 samples/sec, batch_loss: 0.2556, batch_loss_c: 0.2854, batch_loss_s: 0.1863, time:4.9688, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:39 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2510/3125], step: 11885, 7.865 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0685, batch_loss_s: 0.0713, time:5.0859, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2520/3125], step: 11895, 7.574 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1066, batch_loss_s: 0.1055, time:5.2815, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:49 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2530/3125], step: 11905, 8.389 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0792, batch_loss_s: 0.0714, time:4.7680, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:53 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2540/3125], step: 11915, 8.835 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1059, batch_loss_s: 0.0978, time:4.5274, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:48:58 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2550/3125], step: 11925, 8.381 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0806, batch_loss_s: 0.0882, time:4.7726, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:03 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2560/3125], step: 11935, 7.712 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1052, batch_loss_s: 0.0794, time:5.1865, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:08 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2570/3125], step: 11945, 8.339 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1533, batch_loss_s: 0.0974, time:4.7968, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:13 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2580/3125], step: 11955, 7.581 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0843, batch_loss_s: 0.1018, time:5.2761, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:18 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2590/3125], step: 11965, 8.238 samples/sec, batch_loss: 0.1826, batch_loss_c: 0.1946, batch_loss_s: 0.1547, time:4.8555, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:23 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2600/3125], step: 11975, 8.483 samples/sec, batch_loss: 0.1542, batch_loss_c: 0.1638, batch_loss_s: 0.1319, time:4.7154, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:28 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2610/3125], step: 11985, 7.989 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.0988, batch_loss_s: 0.1049, time:5.0069, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:32 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2620/3125], step: 11995, 8.803 samples/sec, batch_loss: 0.3052, batch_loss_c: 0.2983, batch_loss_s: 0.3212, time:4.5437, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:38 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2630/3125], step: 12005, 7.526 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.0995, batch_loss_s: 0.1098, time:5.3148, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:43 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2640/3125], step: 12015, 7.020 samples/sec, batch_loss: 0.2793, batch_loss_c: 0.2676, batch_loss_s: 0.3066, time:5.6980, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:48 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2650/3125], step: 12025, 8.654 samples/sec, batch_loss: 0.3633, batch_loss_c: 0.3715, batch_loss_s: 0.3444, time:4.6222, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:53 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2660/3125], step: 12035, 7.866 samples/sec, batch_loss: 0.1527, batch_loss_c: 0.1649, batch_loss_s: 0.1244, time:5.0849, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:49:59 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2670/3125], step: 12045, 7.270 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1170, batch_loss_s: 0.1026, time:5.5021, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:04 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2680/3125], step: 12055, 8.084 samples/sec, batch_loss: 0.1795, batch_loss_c: 0.1770, batch_loss_s: 0.1854, time:4.9482, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:09 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2690/3125], step: 12065, 7.629 samples/sec, batch_loss: 0.3155, batch_loss_c: 0.3145, batch_loss_s: 0.3180, time:5.2428, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:14 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2700/3125], step: 12075, 7.711 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0898, batch_loss_s: 0.1014, time:5.1876, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:19 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2710/3125], step: 12085, 7.535 samples/sec, batch_loss: 0.0941, batch_loss_c: 0.0943, batch_loss_s: 0.0937, time:5.3085, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:24 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2720/3125], step: 12095, 8.578 samples/sec, batch_loss: 0.2979, batch_loss_c: 0.2961, batch_loss_s: 0.3020, time:4.6630, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:30 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2730/3125], step: 12105, 6.700 samples/sec, batch_loss: 0.2099, batch_loss_c: 0.2367, batch_loss_s: 0.1475, time:5.9705, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:35 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2740/3125], step: 12115, 7.333 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0892, batch_loss_s: 0.0811, time:5.4545, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:40 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2750/3125], step: 12125, 7.958 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0826, batch_loss_s: 0.0947, time:5.0264, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2760/3125], step: 12135, 7.674 samples/sec, batch_loss: 0.1836, batch_loss_c: 0.2147, batch_loss_s: 0.1110, time:5.2122, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2770/3125], step: 12145, 8.100 samples/sec, batch_loss: 0.0586, batch_loss_c: 0.0572, batch_loss_s: 0.0619, time:4.9380, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:50:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2780/3125], step: 12155, 7.221 samples/sec, batch_loss: 0.2727, batch_loss_c: 0.2583, batch_loss_s: 0.3064, time:5.5392, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2790/3125], step: 12165, 8.281 samples/sec, batch_loss: 0.1486, batch_loss_c: 0.1585, batch_loss_s: 0.1256, time:4.8305, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2800/3125], step: 12175, 7.882 samples/sec, batch_loss: 0.1937, batch_loss_c: 0.2064, batch_loss_s: 0.1642, time:5.0747, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2810/3125], step: 12185, 8.276 samples/sec, batch_loss: 0.1637, batch_loss_c: 0.1889, batch_loss_s: 0.1048, time:4.8333, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2820/3125], step: 12195, 8.243 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0796, batch_loss_s: 0.0906, time:4.8527, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2830/3125], step: 12205, 6.888 samples/sec, batch_loss: 0.1534, batch_loss_c: 0.1599, batch_loss_s: 0.1382, time:5.8074, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2840/3125], step: 12215, 8.100 samples/sec, batch_loss: 0.1568, batch_loss_c: 0.1602, batch_loss_s: 0.1488, time:4.9386, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2850/3125], step: 12225, 8.148 samples/sec, batch_loss: 0.2478, batch_loss_c: 0.2984, batch_loss_s: 0.1296, time:4.9089, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2860/3125], step: 12235, 7.548 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1119, batch_loss_s: 0.0892, time:5.2991, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2870/3125], step: 12245, 7.938 samples/sec, batch_loss: 0.3366, batch_loss_c: 0.3306, batch_loss_s: 0.3508, time:5.0391, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:47 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2880/3125], step: 12255, 8.157 samples/sec, batch_loss: 0.3166, batch_loss_c: 0.3220, batch_loss_s: 0.3039, time:4.9038, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2890/3125], step: 12265, 8.354 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0630, batch_loss_s: 0.0775, time:4.7883, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:51:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2900/3125], step: 12275, 8.536 samples/sec, batch_loss: 0.3269, batch_loss_c: 0.3265, batch_loss_s: 0.3278, time:4.6858, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2910/3125], step: 12285, 7.631 samples/sec, batch_loss: 0.0594, batch_loss_c: 0.0533, batch_loss_s: 0.0736, time:5.2416, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2920/3125], step: 12295, 7.830 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0789, batch_loss_s: 0.0976, time:5.1084, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:12 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2930/3125], step: 12305, 7.244 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1265, batch_loss_s: 0.0661, time:5.5221, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:17 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2940/3125], step: 12315, 8.234 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0830, batch_loss_s: 0.0781, time:4.8580, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:22 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2950/3125], step: 12325, 8.347 samples/sec, batch_loss: 0.2142, batch_loss_c: 0.2667, batch_loss_s: 0.0917, time:4.7921, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:27 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2960/3125], step: 12335, 8.087 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0919, batch_loss_s: 0.0878, time:4.9462, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:32 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2970/3125], step: 12345, 7.640 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1368, batch_loss_s: 0.0701, time:5.2359, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:37 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2980/3125], step: 12355, 7.657 samples/sec, batch_loss: 0.2873, batch_loss_c: 0.2842, batch_loss_s: 0.2947, time:5.2238, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:42 \u001b[32mINFO     \u001b[0m train.py: [3/5], [2990/3125], step: 12365, 8.950 samples/sec, batch_loss: 0.7016, batch_loss_c: 0.6924, batch_loss_s: 0.7230, time:4.4692, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:47 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3000/3125], step: 12375, 7.842 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.0970, batch_loss_s: 0.1098, time:5.1010, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:51 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3010/3125], step: 12385, 8.573 samples/sec, batch_loss: 0.5577, batch_loss_c: 0.5573, batch_loss_s: 0.5586, time:4.6658, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:52:56 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3020/3125], step: 12395, 8.079 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0911, batch_loss_s: 0.1069, time:4.9514, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:01 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3030/3125], step: 12405, 8.475 samples/sec, batch_loss: 0.1349, batch_loss_c: 0.1343, batch_loss_s: 0.1362, time:4.7198, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:06 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3040/3125], step: 12415, 8.025 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0851, batch_loss_s: 0.0986, time:4.9847, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:11 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3050/3125], step: 12425, 8.182 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1819, batch_loss_s: 0.0652, time:4.8885, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:16 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3060/3125], step: 12435, 7.922 samples/sec, batch_loss: 0.5491, batch_loss_c: 0.5528, batch_loss_s: 0.5404, time:5.0492, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:21 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3070/3125], step: 12445, 8.024 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1079, batch_loss_s: 0.1097, time:4.9852, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:26 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3080/3125], step: 12455, 8.203 samples/sec, batch_loss: 0.0948, batch_loss_c: 0.0977, batch_loss_s: 0.0879, time:4.8761, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:31 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3090/3125], step: 12465, 8.037 samples/sec, batch_loss: 0.2859, batch_loss_c: 0.2667, batch_loss_s: 0.3305, time:4.9769, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:36 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3100/3125], step: 12475, 7.946 samples/sec, batch_loss: 0.3095, batch_loss_c: 0.3038, batch_loss_s: 0.3228, time:5.0338, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:40 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3110/3125], step: 12485, 10.133 samples/sec, batch_loss: 0.4263, batch_loss_c: 0.4039, batch_loss_s: 0.4785, time:3.9473, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:44 \u001b[32mINFO     \u001b[0m train.py: [3/5], [3120/3125], step: 12495, 10.094 samples/sec, batch_loss: 0.5071, batch_loss_c: 0.4883, batch_loss_s: 0.5511, time:3.9629, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:46 \u001b[32mINFO     \u001b[0m train.py: [3/5], train_loss: 0.2015, time: 1565.0247, lr: 0.0001\u001b[0m\n",
            "2019-11-23 09:53:51 \u001b[32mINFO     \u001b[0m train.py: [4/5], [0/3125], step: 12500, 7.663 samples/sec, batch_loss: 0.1836, batch_loss_c: 0.1784, batch_loss_s: 0.1955, time:5.2197, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:53:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [10/3125], step: 12510, 6.229 samples/sec, batch_loss: 0.1182, batch_loss_c: 0.1272, batch_loss_s: 0.0972, time:6.4216, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [20/3125], step: 12520, 8.857 samples/sec, batch_loss: 0.3303, batch_loss_c: 0.3317, batch_loss_s: 0.3270, time:4.5161, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [30/3125], step: 12530, 7.850 samples/sec, batch_loss: 0.1973, batch_loss_c: 0.2047, batch_loss_s: 0.1802, time:5.0952, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:12 \u001b[32mINFO     \u001b[0m train.py: [4/5], [40/3125], step: 12540, 8.442 samples/sec, batch_loss: 0.1384, batch_loss_c: 0.1361, batch_loss_s: 0.1436, time:4.7382, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:17 \u001b[32mINFO     \u001b[0m train.py: [4/5], [50/3125], step: 12550, 6.972 samples/sec, batch_loss: 0.3037, batch_loss_c: 0.2881, batch_loss_s: 0.3400, time:5.7369, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:22 \u001b[32mINFO     \u001b[0m train.py: [4/5], [60/3125], step: 12560, 8.169 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1128, batch_loss_s: 0.1263, time:4.8963, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [70/3125], step: 12570, 9.121 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1375, batch_loss_s: 0.1465, time:4.3854, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:32 \u001b[32mINFO     \u001b[0m train.py: [4/5], [80/3125], step: 12580, 8.232 samples/sec, batch_loss: 0.0828, batch_loss_c: 0.0818, batch_loss_s: 0.0852, time:4.8592, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [90/3125], step: 12590, 7.723 samples/sec, batch_loss: 0.3314, batch_loss_c: 0.3282, batch_loss_s: 0.3388, time:5.1795, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [100/3125], step: 12600, 7.792 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0892, batch_loss_s: 0.0716, time:5.1332, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [110/3125], step: 12610, 8.505 samples/sec, batch_loss: 0.1597, batch_loss_c: 0.1847, batch_loss_s: 0.1015, time:4.7032, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:51 \u001b[32mINFO     \u001b[0m train.py: [4/5], [120/3125], step: 12620, 9.094 samples/sec, batch_loss: 0.0986, batch_loss_c: 0.1067, batch_loss_s: 0.0796, time:4.3986, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:54:55 \u001b[32mINFO     \u001b[0m train.py: [4/5], [130/3125], step: 12630, 9.014 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.0941, batch_loss_s: 0.1026, time:4.4375, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:01 \u001b[32mINFO     \u001b[0m train.py: [4/5], [140/3125], step: 12640, 7.847 samples/sec, batch_loss: 0.0938, batch_loss_c: 0.0931, batch_loss_s: 0.0956, time:5.0977, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:06 \u001b[32mINFO     \u001b[0m train.py: [4/5], [150/3125], step: 12650, 8.040 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1052, batch_loss_s: 0.1157, time:4.9752, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [160/3125], step: 12660, 8.495 samples/sec, batch_loss: 0.1090, batch_loss_c: 0.1127, batch_loss_s: 0.1003, time:4.7085, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:15 \u001b[32mINFO     \u001b[0m train.py: [4/5], [170/3125], step: 12670, 8.328 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0733, batch_loss_s: 0.0830, time:4.8032, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [180/3125], step: 12680, 8.213 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0974, batch_loss_s: 0.0921, time:4.8702, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:25 \u001b[32mINFO     \u001b[0m train.py: [4/5], [190/3125], step: 12690, 7.716 samples/sec, batch_loss: 0.3172, batch_loss_c: 0.3154, batch_loss_s: 0.3214, time:5.1841, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:30 \u001b[32mINFO     \u001b[0m train.py: [4/5], [200/3125], step: 12700, 8.569 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0613, batch_loss_s: 0.0667, time:4.6681, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:35 \u001b[32mINFO     \u001b[0m train.py: [4/5], [210/3125], step: 12710, 8.307 samples/sec, batch_loss: 0.3326, batch_loss_c: 0.3346, batch_loss_s: 0.3281, time:4.8151, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [220/3125], step: 12720, 8.681 samples/sec, batch_loss: 0.2526, batch_loss_c: 0.2448, batch_loss_s: 0.2709, time:4.6078, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:44 \u001b[32mINFO     \u001b[0m train.py: [4/5], [230/3125], step: 12730, 8.530 samples/sec, batch_loss: 0.3121, batch_loss_c: 0.3151, batch_loss_s: 0.3052, time:4.6896, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:49 \u001b[32mINFO     \u001b[0m train.py: [4/5], [240/3125], step: 12740, 7.606 samples/sec, batch_loss: 0.3316, batch_loss_c: 0.3304, batch_loss_s: 0.3343, time:5.2594, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:55:55 \u001b[32mINFO     \u001b[0m train.py: [4/5], [250/3125], step: 12750, 7.145 samples/sec, batch_loss: 0.2997, batch_loss_c: 0.3019, batch_loss_s: 0.2945, time:5.5984, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:00 \u001b[32mINFO     \u001b[0m train.py: [4/5], [260/3125], step: 12760, 7.545 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0901, batch_loss_s: 0.0906, time:5.3012, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [270/3125], step: 12770, 7.941 samples/sec, batch_loss: 0.2276, batch_loss_c: 0.2684, batch_loss_s: 0.1326, time:5.0370, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [280/3125], step: 12780, 8.462 samples/sec, batch_loss: 0.3410, batch_loss_c: 0.3477, batch_loss_s: 0.3254, time:4.7270, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:15 \u001b[32mINFO     \u001b[0m train.py: [4/5], [290/3125], step: 12790, 8.560 samples/sec, batch_loss: 0.2584, batch_loss_c: 0.2292, batch_loss_s: 0.3266, time:4.6729, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [300/3125], step: 12800, 7.480 samples/sec, batch_loss: 0.4015, batch_loss_c: 0.4248, batch_loss_s: 0.3471, time:5.3477, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:25 \u001b[32mINFO     \u001b[0m train.py: [4/5], [310/3125], step: 12810, 8.259 samples/sec, batch_loss: 0.1130, batch_loss_c: 0.1152, batch_loss_s: 0.1080, time:4.8431, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:30 \u001b[32mINFO     \u001b[0m train.py: [4/5], [320/3125], step: 12820, 7.306 samples/sec, batch_loss: 0.5503, batch_loss_c: 0.5507, batch_loss_s: 0.5493, time:5.4752, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [330/3125], step: 12830, 7.495 samples/sec, batch_loss: 0.2123, batch_loss_c: 0.1751, batch_loss_s: 0.2991, time:5.3367, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [340/3125], step: 12840, 7.658 samples/sec, batch_loss: 0.1517, batch_loss_c: 0.1730, batch_loss_s: 0.1021, time:5.2234, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:46 \u001b[32mINFO     \u001b[0m train.py: [4/5], [350/3125], step: 12850, 8.171 samples/sec, batch_loss: 0.2132, batch_loss_c: 0.2373, batch_loss_s: 0.1571, time:4.8952, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:51 \u001b[32mINFO     \u001b[0m train.py: [4/5], [360/3125], step: 12860, 8.206 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0687, batch_loss_s: 0.0765, time:4.8747, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:56:55 \u001b[32mINFO     \u001b[0m train.py: [4/5], [370/3125], step: 12870, 8.541 samples/sec, batch_loss: 0.3081, batch_loss_c: 0.3084, batch_loss_s: 0.3075, time:4.6830, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:00 \u001b[32mINFO     \u001b[0m train.py: [4/5], [380/3125], step: 12880, 8.625 samples/sec, batch_loss: 0.0939, batch_loss_c: 0.1029, batch_loss_s: 0.0727, time:4.6377, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [390/3125], step: 12890, 8.493 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0771, batch_loss_s: 0.0827, time:4.7099, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [400/3125], step: 12900, 7.475 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1428, batch_loss_s: 0.1171, time:5.3512, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:15 \u001b[32mINFO     \u001b[0m train.py: [4/5], [410/3125], step: 12910, 7.768 samples/sec, batch_loss: 0.5416, batch_loss_c: 0.5437, batch_loss_s: 0.5368, time:5.1490, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [420/3125], step: 12920, 8.185 samples/sec, batch_loss: 0.3453, batch_loss_c: 0.3581, batch_loss_s: 0.3157, time:4.8872, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:25 \u001b[32mINFO     \u001b[0m train.py: [4/5], [430/3125], step: 12930, 7.227 samples/sec, batch_loss: 0.1586, batch_loss_c: 0.1602, batch_loss_s: 0.1547, time:5.5349, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:31 \u001b[32mINFO     \u001b[0m train.py: [4/5], [440/3125], step: 12940, 7.877 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1140, batch_loss_s: 0.1134, time:5.0780, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [450/3125], step: 12950, 8.091 samples/sec, batch_loss: 0.3275, batch_loss_c: 0.3217, batch_loss_s: 0.3411, time:4.9441, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [460/3125], step: 12960, 7.014 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.0949, batch_loss_s: 0.0966, time:5.7032, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [470/3125], step: 12970, 7.106 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0816, batch_loss_s: 0.0951, time:5.6293, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:53 \u001b[32mINFO     \u001b[0m train.py: [4/5], [480/3125], step: 12980, 6.939 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3366, batch_loss_s: 0.3381, time:5.7646, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:57:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [490/3125], step: 12990, 6.943 samples/sec, batch_loss: 0.1531, batch_loss_c: 0.1655, batch_loss_s: 0.1244, time:5.7610, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [500/3125], step: 13000, 8.410 samples/sec, batch_loss: 0.1135, batch_loss_c: 0.1224, batch_loss_s: 0.0928, time:4.7563, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:09 \u001b[32mINFO     \u001b[0m train.py: [4/5], [510/3125], step: 13010, 6.547 samples/sec, batch_loss: 0.1208, batch_loss_c: 0.1364, batch_loss_s: 0.0845, time:6.1100, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:14 \u001b[32mINFO     \u001b[0m train.py: [4/5], [520/3125], step: 13020, 8.255 samples/sec, batch_loss: 0.1295, batch_loss_c: 0.1491, batch_loss_s: 0.0838, time:4.8457, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:19 \u001b[32mINFO     \u001b[0m train.py: [4/5], [530/3125], step: 13030, 8.556 samples/sec, batch_loss: 0.3281, batch_loss_c: 0.3243, batch_loss_s: 0.3370, time:4.6750, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [540/3125], step: 13040, 9.227 samples/sec, batch_loss: 0.0600, batch_loss_c: 0.0542, batch_loss_s: 0.0733, time:4.3352, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:28 \u001b[32mINFO     \u001b[0m train.py: [4/5], [550/3125], step: 13050, 8.914 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0871, batch_loss_s: 0.0918, time:4.4871, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [560/3125], step: 13060, 7.797 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1077, batch_loss_s: 0.1198, time:5.1301, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:38 \u001b[32mINFO     \u001b[0m train.py: [4/5], [570/3125], step: 13070, 7.708 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0774, batch_loss_s: 0.0950, time:5.1895, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [580/3125], step: 13080, 8.330 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0785, batch_loss_s: 0.0806, time:4.8017, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [590/3125], step: 13090, 8.363 samples/sec, batch_loss: 0.1600, batch_loss_c: 0.1733, batch_loss_s: 0.1290, time:4.7828, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [600/3125], step: 13100, 8.215 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1173, batch_loss_s: 0.1059, time:4.8693, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:58:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [610/3125], step: 13110, 8.822 samples/sec, batch_loss: 0.0786, batch_loss_c: 0.0767, batch_loss_s: 0.0832, time:4.5342, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [620/3125], step: 13120, 7.088 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.1005, batch_loss_s: 0.0994, time:5.6435, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:08 \u001b[32mINFO     \u001b[0m train.py: [4/5], [630/3125], step: 13130, 7.323 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0814, batch_loss_s: 0.0992, time:5.4625, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [640/3125], step: 13140, 8.112 samples/sec, batch_loss: 0.1500, batch_loss_c: 0.1637, batch_loss_s: 0.1182, time:4.9310, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:19 \u001b[32mINFO     \u001b[0m train.py: [4/5], [650/3125], step: 13150, 6.953 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0787, batch_loss_s: 0.0702, time:5.7528, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:24 \u001b[32mINFO     \u001b[0m train.py: [4/5], [660/3125], step: 13160, 8.047 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0937, batch_loss_s: 0.1003, time:4.9711, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:28 \u001b[32mINFO     \u001b[0m train.py: [4/5], [670/3125], step: 13170, 8.445 samples/sec, batch_loss: 0.3788, batch_loss_c: 0.4104, batch_loss_s: 0.3051, time:4.7365, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:34 \u001b[32mINFO     \u001b[0m train.py: [4/5], [680/3125], step: 13180, 7.450 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1015, batch_loss_s: 0.1060, time:5.3689, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [690/3125], step: 13190, 7.791 samples/sec, batch_loss: 0.1093, batch_loss_c: 0.1103, batch_loss_s: 0.1071, time:5.1342, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:44 \u001b[32mINFO     \u001b[0m train.py: [4/5], [700/3125], step: 13200, 8.124 samples/sec, batch_loss: 0.2756, batch_loss_c: 0.2621, batch_loss_s: 0.3070, time:4.9236, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:49 \u001b[32mINFO     \u001b[0m train.py: [4/5], [710/3125], step: 13210, 7.699 samples/sec, batch_loss: 0.3199, batch_loss_c: 0.3144, batch_loss_s: 0.3329, time:5.1957, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:54 \u001b[32mINFO     \u001b[0m train.py: [4/5], [720/3125], step: 13220, 8.589 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.0946, batch_loss_s: 0.1114, time:4.6569, lr:0.0001\u001b[0m\n",
            "2019-11-23 09:59:59 \u001b[32mINFO     \u001b[0m train.py: [4/5], [730/3125], step: 13230, 7.379 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1254, batch_loss_s: 0.1247, time:5.4211, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:04 \u001b[32mINFO     \u001b[0m train.py: [4/5], [740/3125], step: 13240, 7.922 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.1007, batch_loss_s: 0.0953, time:5.0495, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [750/3125], step: 13250, 7.473 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1115, batch_loss_s: 0.1076, time:5.3528, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:14 \u001b[32mINFO     \u001b[0m train.py: [4/5], [760/3125], step: 13260, 8.283 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0777, batch_loss_s: 0.0974, time:4.8291, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [770/3125], step: 13270, 7.527 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1050, batch_loss_s: 0.1097, time:5.3144, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:25 \u001b[32mINFO     \u001b[0m train.py: [4/5], [780/3125], step: 13280, 7.703 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1231, batch_loss_s: 0.1018, time:5.1927, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:29 \u001b[32mINFO     \u001b[0m train.py: [4/5], [790/3125], step: 13290, 9.157 samples/sec, batch_loss: 0.2108, batch_loss_c: 0.2272, batch_loss_s: 0.1723, time:4.3682, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:34 \u001b[32mINFO     \u001b[0m train.py: [4/5], [800/3125], step: 13300, 9.242 samples/sec, batch_loss: 0.1223, batch_loss_c: 0.1283, batch_loss_s: 0.1083, time:4.3281, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:38 \u001b[32mINFO     \u001b[0m train.py: [4/5], [810/3125], step: 13310, 9.057 samples/sec, batch_loss: 0.0610, batch_loss_c: 0.0588, batch_loss_s: 0.0660, time:4.4165, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [820/3125], step: 13320, 8.616 samples/sec, batch_loss: 0.3067, batch_loss_c: 0.3048, batch_loss_s: 0.3111, time:4.6426, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [830/3125], step: 13330, 8.461 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0910, batch_loss_s: 0.0935, time:4.7275, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [840/3125], step: 13340, 7.896 samples/sec, batch_loss: 0.3094, batch_loss_c: 0.3022, batch_loss_s: 0.3260, time:5.0657, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:00:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [850/3125], step: 13350, 7.544 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1001, batch_loss_s: 0.1168, time:5.3021, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [860/3125], step: 13360, 8.094 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1533, batch_loss_s: 0.0976, time:4.9417, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [870/3125], step: 13370, 8.265 samples/sec, batch_loss: 0.0938, batch_loss_c: 0.0950, batch_loss_s: 0.0911, time:4.8398, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [880/3125], step: 13380, 6.993 samples/sec, batch_loss: 0.1078, batch_loss_c: 0.0999, batch_loss_s: 0.1261, time:5.7197, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:19 \u001b[32mINFO     \u001b[0m train.py: [4/5], [890/3125], step: 13390, 7.267 samples/sec, batch_loss: 0.1219, batch_loss_c: 0.1233, batch_loss_s: 0.1187, time:5.5042, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [900/3125], step: 13400, 8.630 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1255, batch_loss_s: 0.0767, time:4.6348, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:29 \u001b[32mINFO     \u001b[0m train.py: [4/5], [910/3125], step: 13410, 7.517 samples/sec, batch_loss: 0.4002, batch_loss_c: 0.3933, batch_loss_s: 0.4161, time:5.3214, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [920/3125], step: 13420, 8.773 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1136, batch_loss_s: 0.1196, time:4.5593, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:38 \u001b[32mINFO     \u001b[0m train.py: [4/5], [930/3125], step: 13430, 7.887 samples/sec, batch_loss: 0.0996, batch_loss_c: 0.0972, batch_loss_s: 0.1053, time:5.0719, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [940/3125], step: 13440, 8.657 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0703, batch_loss_s: 0.0829, time:4.6208, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:48 \u001b[32mINFO     \u001b[0m train.py: [4/5], [950/3125], step: 13450, 8.451 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0894, batch_loss_s: 0.0906, time:4.7330, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [960/3125], step: 13460, 8.976 samples/sec, batch_loss: 0.1659, batch_loss_c: 0.1702, batch_loss_s: 0.1560, time:4.4565, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:01:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [970/3125], step: 13470, 7.558 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1062, batch_loss_s: 0.0967, time:5.2925, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [980/3125], step: 13480, 8.245 samples/sec, batch_loss: 0.1046, batch_loss_c: 0.0996, batch_loss_s: 0.1164, time:4.8514, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [990/3125], step: 13490, 7.841 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.3172, batch_loss_s: 0.3184, time:5.1017, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:12 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1000/3125], step: 13500, 8.008 samples/sec, batch_loss: 0.2904, batch_loss_c: 0.2699, batch_loss_s: 0.3380, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:17 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1010/3125], step: 13510, 8.549 samples/sec, batch_loss: 0.3576, batch_loss_c: 0.3642, batch_loss_s: 0.3423, time:4.6791, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:22 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1020/3125], step: 13520, 8.180 samples/sec, batch_loss: 0.2266, batch_loss_c: 0.2486, batch_loss_s: 0.1754, time:4.8902, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1030/3125], step: 13530, 8.355 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0914, batch_loss_s: 0.0980, time:4.7873, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:32 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1040/3125], step: 13540, 7.902 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0574, batch_loss_s: 0.0717, time:5.0623, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1050/3125], step: 13550, 7.971 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1289, batch_loss_s: 0.1252, time:5.0183, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1060/3125], step: 13560, 8.195 samples/sec, batch_loss: 0.1604, batch_loss_c: 0.1895, batch_loss_s: 0.0926, time:4.8810, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1070/3125], step: 13570, 8.020 samples/sec, batch_loss: 0.3451, batch_loss_c: 0.3670, batch_loss_s: 0.2938, time:4.9878, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:51 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1080/3125], step: 13580, 8.710 samples/sec, batch_loss: 0.3317, batch_loss_c: 0.3361, batch_loss_s: 0.3213, time:4.5922, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:02:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1090/3125], step: 13590, 7.137 samples/sec, batch_loss: 0.0668, batch_loss_c: 0.0660, batch_loss_s: 0.0685, time:5.6046, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:01 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1100/3125], step: 13600, 8.714 samples/sec, batch_loss: 0.5269, batch_loss_c: 0.5200, batch_loss_s: 0.5432, time:4.5904, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:06 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1110/3125], step: 13610, 8.514 samples/sec, batch_loss: 0.3118, batch_loss_c: 0.3061, batch_loss_s: 0.3252, time:4.6979, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:11 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1120/3125], step: 13620, 8.543 samples/sec, batch_loss: 0.2115, batch_loss_c: 0.2521, batch_loss_s: 0.1169, time:4.6821, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:16 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1130/3125], step: 13630, 8.460 samples/sec, batch_loss: 0.3355, batch_loss_c: 0.3427, batch_loss_s: 0.3187, time:4.7282, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:21 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1140/3125], step: 13640, 7.754 samples/sec, batch_loss: 0.1846, batch_loss_c: 0.1914, batch_loss_s: 0.1688, time:5.1587, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:26 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1150/3125], step: 13650, 7.472 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0731, batch_loss_s: 0.0888, time:5.3535, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:31 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1160/3125], step: 13660, 7.773 samples/sec, batch_loss: 0.2870, batch_loss_c: 0.2773, batch_loss_s: 0.3097, time:5.1461, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1170/3125], step: 13670, 7.736 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1444, batch_loss_s: 0.1305, time:5.1707, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1180/3125], step: 13680, 8.254 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0567, batch_loss_s: 0.0644, time:4.8459, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:46 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1190/3125], step: 13690, 8.147 samples/sec, batch_loss: 0.3658, batch_loss_c: 0.3749, batch_loss_s: 0.3446, time:4.9098, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1200/3125], step: 13700, 6.954 samples/sec, batch_loss: 0.5411, batch_loss_c: 0.5425, batch_loss_s: 0.5377, time:5.7518, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:03:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1210/3125], step: 13710, 7.601 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1232, batch_loss_s: 0.1099, time:5.2624, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1220/3125], step: 13720, 8.006 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0910, batch_loss_s: 0.0732, time:4.9966, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1230/3125], step: 13730, 7.782 samples/sec, batch_loss: 0.0927, batch_loss_c: 0.0867, batch_loss_s: 0.1067, time:5.1401, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1240/3125], step: 13740, 7.118 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0618, batch_loss_s: 0.0751, time:5.6196, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1250/3125], step: 13750, 7.535 samples/sec, batch_loss: 0.1636, batch_loss_c: 0.1709, batch_loss_s: 0.1466, time:5.3082, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1260/3125], step: 13760, 8.349 samples/sec, batch_loss: 0.3608, batch_loss_c: 0.3687, batch_loss_s: 0.3424, time:4.7909, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:28 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1270/3125], step: 13770, 8.122 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0615, batch_loss_s: 0.0786, time:4.9247, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1280/3125], step: 13780, 7.264 samples/sec, batch_loss: 0.1027, batch_loss_c: 0.1032, batch_loss_s: 0.1015, time:5.5067, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1290/3125], step: 13790, 7.944 samples/sec, batch_loss: 0.5345, batch_loss_c: 0.5301, batch_loss_s: 0.5445, time:5.0350, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:44 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1300/3125], step: 13800, 7.880 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1032, batch_loss_s: 0.1073, time:5.0760, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:49 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1310/3125], step: 13810, 7.957 samples/sec, batch_loss: 0.3257, batch_loss_c: 0.3211, batch_loss_s: 0.3365, time:5.0270, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:54 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1320/3125], step: 13820, 8.071 samples/sec, batch_loss: 0.2941, batch_loss_c: 0.2840, batch_loss_s: 0.3178, time:4.9560, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:04:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1330/3125], step: 13830, 8.868 samples/sec, batch_loss: 0.0565, batch_loss_c: 0.0526, batch_loss_s: 0.0657, time:4.5105, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1340/3125], step: 13840, 8.477 samples/sec, batch_loss: 0.3594, batch_loss_c: 0.3741, batch_loss_s: 0.3249, time:4.7185, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:08 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1350/3125], step: 13850, 7.825 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0578, batch_loss_s: 0.0749, time:5.1118, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1360/3125], step: 13860, 8.323 samples/sec, batch_loss: 0.3022, batch_loss_c: 0.3001, batch_loss_s: 0.3072, time:4.8061, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:17 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1370/3125], step: 13870, 8.461 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0910, batch_loss_s: 0.0815, time:4.7276, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1380/3125], step: 13880, 7.308 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0981, batch_loss_s: 0.0787, time:5.4734, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:28 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1390/3125], step: 13890, 7.740 samples/sec, batch_loss: 0.3035, batch_loss_c: 0.3021, batch_loss_s: 0.3067, time:5.1676, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1400/3125], step: 13900, 7.704 samples/sec, batch_loss: 0.3209, batch_loss_c: 0.3201, batch_loss_s: 0.3228, time:5.1921, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1410/3125], step: 13910, 7.673 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2889, batch_loss_s: 0.3165, time:5.2129, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1420/3125], step: 13920, 8.158 samples/sec, batch_loss: 0.2260, batch_loss_c: 0.2642, batch_loss_s: 0.1368, time:4.9029, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:48 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1430/3125], step: 13930, 8.791 samples/sec, batch_loss: 0.3058, batch_loss_c: 0.3037, batch_loss_s: 0.3105, time:4.5503, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:53 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1440/3125], step: 13940, 7.388 samples/sec, batch_loss: 0.1333, batch_loss_c: 0.1394, batch_loss_s: 0.1193, time:5.4143, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:05:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1450/3125], step: 13950, 8.391 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.0963, batch_loss_s: 0.1106, time:4.7671, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1460/3125], step: 13960, 8.477 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0854, batch_loss_s: 0.0831, time:4.7187, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:08 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1470/3125], step: 13970, 7.545 samples/sec, batch_loss: 0.1348, batch_loss_c: 0.1424, batch_loss_s: 0.1172, time:5.3015, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1480/3125], step: 13980, 7.672 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0872, batch_loss_s: 0.0895, time:5.2137, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1490/3125], step: 13990, 8.338 samples/sec, batch_loss: 0.4286, batch_loss_c: 0.4405, batch_loss_s: 0.4009, time:4.7975, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:24 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1500/3125], step: 14000, 7.333 samples/sec, batch_loss: 0.1684, batch_loss_c: 0.1962, batch_loss_s: 0.1036, time:5.4552, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:29 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1510/3125], step: 14010, 7.601 samples/sec, batch_loss: 0.3367, batch_loss_c: 0.3462, batch_loss_s: 0.3144, time:5.2624, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1520/3125], step: 14020, 9.048 samples/sec, batch_loss: 0.1660, batch_loss_c: 0.1722, batch_loss_s: 0.1516, time:4.4210, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:38 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1530/3125], step: 14030, 8.558 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0809, batch_loss_s: 0.0989, time:4.6740, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1540/3125], step: 14040, 7.978 samples/sec, batch_loss: 0.0566, batch_loss_c: 0.0517, batch_loss_s: 0.0680, time:5.0141, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:48 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1550/3125], step: 14050, 8.715 samples/sec, batch_loss: 0.5992, batch_loss_c: 0.5711, batch_loss_s: 0.6648, time:4.5896, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1560/3125], step: 14060, 8.209 samples/sec, batch_loss: 0.4352, batch_loss_c: 0.4335, batch_loss_s: 0.4394, time:4.8726, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:06:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1570/3125], step: 14070, 7.440 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0790, batch_loss_s: 0.0902, time:5.3765, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1580/3125], step: 14080, 8.212 samples/sec, batch_loss: 0.2751, batch_loss_c: 0.3324, batch_loss_s: 0.1414, time:4.8712, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:08 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1590/3125], step: 14090, 7.675 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0857, batch_loss_s: 0.0937, time:5.2117, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1600/3125], step: 14100, 7.858 samples/sec, batch_loss: 0.1353, batch_loss_c: 0.1418, batch_loss_s: 0.1202, time:5.0903, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:17 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1610/3125], step: 14110, 9.121 samples/sec, batch_loss: 0.2620, batch_loss_c: 0.2653, batch_loss_s: 0.2545, time:4.3854, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:22 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1620/3125], step: 14120, 8.614 samples/sec, batch_loss: 0.3690, batch_loss_c: 0.3692, batch_loss_s: 0.3686, time:4.6438, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1630/3125], step: 14130, 7.436 samples/sec, batch_loss: 0.3337, batch_loss_c: 0.3321, batch_loss_s: 0.3375, time:5.3789, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:32 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1640/3125], step: 14140, 8.533 samples/sec, batch_loss: 0.2137, batch_loss_c: 0.2397, batch_loss_s: 0.1529, time:4.6877, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1650/3125], step: 14150, 7.771 samples/sec, batch_loss: 0.3384, batch_loss_c: 0.3430, batch_loss_s: 0.3278, time:5.1476, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1660/3125], step: 14160, 7.991 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1322, batch_loss_s: 0.1142, time:5.0054, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1670/3125], step: 14170, 8.185 samples/sec, batch_loss: 0.0736, batch_loss_c: 0.0713, batch_loss_s: 0.0789, time:4.8873, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1680/3125], step: 14180, 8.361 samples/sec, batch_loss: 0.2850, batch_loss_c: 0.2750, batch_loss_s: 0.3083, time:4.7843, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:07:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1690/3125], step: 14190, 7.800 samples/sec, batch_loss: 0.4977, batch_loss_c: 0.4755, batch_loss_s: 0.5493, time:5.1283, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1700/3125], step: 14200, 7.499 samples/sec, batch_loss: 0.5914, batch_loss_c: 0.6066, batch_loss_s: 0.5561, time:5.3337, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:08 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1710/3125], step: 14210, 7.509 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0818, batch_loss_s: 0.1013, time:5.3267, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1720/3125], step: 14220, 7.992 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0795, batch_loss_s: 0.0780, time:5.0053, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1730/3125], step: 14230, 7.383 samples/sec, batch_loss: 0.1624, batch_loss_c: 0.1741, batch_loss_s: 0.1350, time:5.4180, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:24 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1740/3125], step: 14240, 7.118 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1288, batch_loss_s: 0.0892, time:5.6196, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:29 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1750/3125], step: 14250, 7.273 samples/sec, batch_loss: 0.5171, batch_loss_c: 0.5104, batch_loss_s: 0.5326, time:5.5000, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:34 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1760/3125], step: 14260, 8.062 samples/sec, batch_loss: 0.1510, batch_loss_c: 0.1567, batch_loss_s: 0.1375, time:4.9618, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1770/3125], step: 14270, 7.795 samples/sec, batch_loss: 0.1707, batch_loss_c: 0.1929, batch_loss_s: 0.1188, time:5.1317, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:44 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1780/3125], step: 14280, 7.927 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0673, batch_loss_s: 0.1034, time:5.0462, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:50 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1790/3125], step: 14290, 7.649 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1205, batch_loss_s: 0.1237, time:5.2296, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:08:55 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1800/3125], step: 14300, 7.911 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1191, batch_loss_s: 0.1123, time:5.0563, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:00 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1810/3125], step: 14310, 7.539 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1002, batch_loss_s: 0.1667, time:5.3059, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1820/3125], step: 14320, 8.511 samples/sec, batch_loss: 0.2018, batch_loss_c: 0.2371, batch_loss_s: 0.1195, time:4.6999, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:09 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1830/3125], step: 14330, 8.567 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0901, batch_loss_s: 0.0886, time:4.6692, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:14 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1840/3125], step: 14340, 8.295 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1580, batch_loss_s: 0.1617, time:4.8222, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1850/3125], step: 14350, 7.502 samples/sec, batch_loss: 0.2730, batch_loss_c: 0.3181, batch_loss_s: 0.1678, time:5.3322, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:24 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1860/3125], step: 14360, 8.541 samples/sec, batch_loss: 0.0921, batch_loss_c: 0.0920, batch_loss_s: 0.0923, time:4.6835, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:30 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1870/3125], step: 14370, 7.554 samples/sec, batch_loss: 0.3380, batch_loss_c: 0.3440, batch_loss_s: 0.3239, time:5.2950, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:35 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1880/3125], step: 14380, 7.309 samples/sec, batch_loss: 0.0752, batch_loss_c: 0.0752, batch_loss_s: 0.0751, time:5.4729, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:40 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1890/3125], step: 14390, 7.518 samples/sec, batch_loss: 0.2165, batch_loss_c: 0.2456, batch_loss_s: 0.1486, time:5.3204, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:45 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1900/3125], step: 14400, 7.977 samples/sec, batch_loss: 0.3574, batch_loss_c: 0.3722, batch_loss_s: 0.3228, time:5.0142, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:50 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1910/3125], step: 14410, 8.137 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1370, batch_loss_s: 0.1127, time:4.9156, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:09:56 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1920/3125], step: 14420, 7.678 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.0776, batch_loss_s: 0.1553, time:5.2094, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:01 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1930/3125], step: 14430, 7.879 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1212, batch_loss_s: 0.1186, time:5.0766, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:06 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1940/3125], step: 14440, 7.373 samples/sec, batch_loss: 0.2462, batch_loss_c: 0.3000, batch_loss_s: 0.1207, time:5.4249, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:11 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1950/3125], step: 14450, 8.391 samples/sec, batch_loss: 0.3640, batch_loss_c: 0.4051, batch_loss_s: 0.2681, time:4.7672, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:16 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1960/3125], step: 14460, 8.454 samples/sec, batch_loss: 0.1394, batch_loss_c: 0.1404, batch_loss_s: 0.1372, time:4.7315, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:21 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1970/3125], step: 14470, 7.676 samples/sec, batch_loss: 0.3380, batch_loss_c: 0.3319, batch_loss_s: 0.3522, time:5.2111, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:26 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1980/3125], step: 14480, 8.055 samples/sec, batch_loss: 0.1728, batch_loss_c: 0.1600, batch_loss_s: 0.2026, time:4.9659, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:31 \u001b[32mINFO     \u001b[0m train.py: [4/5], [1990/3125], step: 14490, 7.247 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1252, batch_loss_s: 0.1366, time:5.5198, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2000/3125], step: 14500, 8.195 samples/sec, batch_loss: 0.3114, batch_loss_c: 0.3002, batch_loss_s: 0.3377, time:4.8811, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2010/3125], step: 14510, 7.814 samples/sec, batch_loss: 0.3410, batch_loss_c: 0.3463, batch_loss_s: 0.3286, time:5.1189, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:46 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2020/3125], step: 14520, 7.785 samples/sec, batch_loss: 0.3109, batch_loss_c: 0.3129, batch_loss_s: 0.3063, time:5.1382, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2030/3125], step: 14530, 7.553 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0844, batch_loss_s: 0.0780, time:5.2956, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:10:56 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2040/3125], step: 14540, 8.259 samples/sec, batch_loss: 0.1624, batch_loss_c: 0.1555, batch_loss_s: 0.1786, time:4.8429, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:01 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2050/3125], step: 14550, 8.061 samples/sec, batch_loss: 0.3321, batch_loss_c: 0.3407, batch_loss_s: 0.3120, time:4.9621, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2060/3125], step: 14560, 7.873 samples/sec, batch_loss: 0.1474, batch_loss_c: 0.1597, batch_loss_s: 0.1188, time:5.0806, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:11 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2070/3125], step: 14570, 8.468 samples/sec, batch_loss: 0.3693, batch_loss_c: 0.3550, batch_loss_s: 0.4028, time:4.7239, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:16 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2080/3125], step: 14580, 8.302 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0729, batch_loss_s: 0.0890, time:4.8179, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:21 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2090/3125], step: 14590, 7.812 samples/sec, batch_loss: 0.0614, batch_loss_c: 0.0586, batch_loss_s: 0.0679, time:5.1202, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:26 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2100/3125], step: 14600, 7.930 samples/sec, batch_loss: 0.1455, batch_loss_c: 0.0944, batch_loss_s: 0.2648, time:5.0443, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:31 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2110/3125], step: 14610, 8.585 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1144, batch_loss_s: 0.1077, time:4.6591, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2120/3125], step: 14620, 7.495 samples/sec, batch_loss: 0.1937, batch_loss_c: 0.1942, batch_loss_s: 0.1925, time:5.3368, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2130/3125], step: 14630, 7.307 samples/sec, batch_loss: 0.3235, batch_loss_c: 0.3328, batch_loss_s: 0.3018, time:5.4743, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2140/3125], step: 14640, 7.395 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.0906, batch_loss_s: 0.1114, time:5.4087, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2150/3125], step: 14650, 7.673 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.0897, batch_loss_s: 0.1104, time:5.2132, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:11:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2160/3125], step: 14660, 8.355 samples/sec, batch_loss: 0.2796, batch_loss_c: 0.2669, batch_loss_s: 0.3095, time:4.7875, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:03 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2170/3125], step: 14670, 7.270 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0758, batch_loss_s: 0.0751, time:5.5021, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2180/3125], step: 14680, 8.373 samples/sec, batch_loss: 0.5416, batch_loss_c: 0.5418, batch_loss_s: 0.5412, time:4.7771, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2190/3125], step: 14690, 7.736 samples/sec, batch_loss: 0.2681, batch_loss_c: 0.2558, batch_loss_s: 0.2970, time:5.1709, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2200/3125], step: 14700, 7.153 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1570, batch_loss_s: 0.1046, time:5.5923, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2210/3125], step: 14710, 9.146 samples/sec, batch_loss: 0.3398, batch_loss_c: 0.3428, batch_loss_s: 0.3327, time:4.3733, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2220/3125], step: 14720, 8.429 samples/sec, batch_loss: 0.1153, batch_loss_c: 0.1166, batch_loss_s: 0.1122, time:4.7454, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:32 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2230/3125], step: 14730, 7.882 samples/sec, batch_loss: 0.3579, batch_loss_c: 0.3803, batch_loss_s: 0.3054, time:5.0746, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2240/3125], step: 14740, 7.838 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.0988, batch_loss_s: 0.1000, time:5.1032, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2250/3125], step: 14750, 8.911 samples/sec, batch_loss: 0.5350, batch_loss_c: 0.5338, batch_loss_s: 0.5378, time:4.4887, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2260/3125], step: 14760, 7.305 samples/sec, batch_loss: 0.2872, batch_loss_c: 0.2796, batch_loss_s: 0.3048, time:5.4758, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:53 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2270/3125], step: 14770, 7.648 samples/sec, batch_loss: 0.1656, batch_loss_c: 0.2015, batch_loss_s: 0.0820, time:5.2303, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:12:57 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2280/3125], step: 14780, 8.332 samples/sec, batch_loss: 0.1003, batch_loss_c: 0.1033, batch_loss_s: 0.0933, time:4.8008, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2290/3125], step: 14790, 8.717 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0855, batch_loss_s: 0.1090, time:4.5885, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2300/3125], step: 14800, 7.958 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0775, batch_loss_s: 0.0920, time:5.0265, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:12 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2310/3125], step: 14810, 8.104 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1341, batch_loss_s: 0.0956, time:4.9356, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:17 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2320/3125], step: 14820, 8.341 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1480, batch_loss_s: 0.1205, time:4.7958, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:22 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2330/3125], step: 14830, 8.162 samples/sec, batch_loss: 0.5821, batch_loss_c: 0.5932, batch_loss_s: 0.5562, time:4.9006, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2340/3125], step: 14840, 7.853 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0696, batch_loss_s: 0.0766, time:5.0937, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:32 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2350/3125], step: 14850, 7.944 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0733, batch_loss_s: 0.0846, time:5.0355, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2360/3125], step: 14860, 8.401 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1234, batch_loss_s: 0.1020, time:4.7614, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2370/3125], step: 14870, 8.411 samples/sec, batch_loss: 0.3055, batch_loss_c: 0.3071, batch_loss_s: 0.3019, time:4.7559, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:46 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2380/3125], step: 14880, 8.079 samples/sec, batch_loss: 0.1187, batch_loss_c: 0.1329, batch_loss_s: 0.0854, time:4.9510, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2390/3125], step: 14890, 7.558 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.0978, batch_loss_s: 0.1157, time:5.2922, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:13:56 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2400/3125], step: 14900, 8.593 samples/sec, batch_loss: 0.3236, batch_loss_c: 0.3233, batch_loss_s: 0.3243, time:4.6552, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:01 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2410/3125], step: 14910, 8.294 samples/sec, batch_loss: 0.2717, batch_loss_c: 0.2558, batch_loss_s: 0.3087, time:4.8226, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:06 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2420/3125], step: 14920, 8.030 samples/sec, batch_loss: 0.4193, batch_loss_c: 0.4146, batch_loss_s: 0.4303, time:4.9813, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:11 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2430/3125], step: 14930, 7.718 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1159, batch_loss_s: 0.0942, time:5.1828, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:16 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2440/3125], step: 14940, 8.330 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0952, batch_loss_s: 0.1088, time:4.8019, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:21 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2450/3125], step: 14950, 8.253 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0696, batch_loss_s: 0.0798, time:4.8469, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:26 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2460/3125], step: 14960, 8.647 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1347, batch_loss_s: 0.1224, time:4.6257, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:30 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2470/3125], step: 14970, 8.747 samples/sec, batch_loss: 0.0813, batch_loss_c: 0.0785, batch_loss_s: 0.0878, time:4.5731, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:35 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2480/3125], step: 14980, 7.971 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0787, batch_loss_s: 0.0779, time:5.0179, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:40 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2490/3125], step: 14990, 7.589 samples/sec, batch_loss: 0.3448, batch_loss_c: 0.3573, batch_loss_s: 0.3156, time:5.2705, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:45 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2500/3125], step: 15000, 7.954 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0922, batch_loss_s: 0.1123, time:5.0287, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:50 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2510/3125], step: 15010, 8.778 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.0936, batch_loss_s: 0.1108, time:4.5569, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:14:55 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2520/3125], step: 15020, 8.489 samples/sec, batch_loss: 0.1004, batch_loss_c: 0.1053, batch_loss_s: 0.0891, time:4.7118, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:00 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2530/3125], step: 15030, 8.050 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1564, batch_loss_s: 0.1539, time:4.9692, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2540/3125], step: 15040, 7.869 samples/sec, batch_loss: 0.2107, batch_loss_c: 0.2640, batch_loss_s: 0.0862, time:5.0833, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2550/3125], step: 15050, 7.588 samples/sec, batch_loss: 0.3169, batch_loss_c: 0.3138, batch_loss_s: 0.3239, time:5.2715, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:15 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2560/3125], step: 15060, 8.009 samples/sec, batch_loss: 0.2506, batch_loss_c: 0.2477, batch_loss_s: 0.2575, time:4.9946, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2570/3125], step: 15070, 7.786 samples/sec, batch_loss: 0.2809, batch_loss_c: 0.2700, batch_loss_s: 0.3063, time:5.1375, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:25 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2580/3125], step: 15080, 7.729 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3199, batch_loss_s: 0.3130, time:5.1754, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:30 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2590/3125], step: 15090, 8.047 samples/sec, batch_loss: 0.3421, batch_loss_c: 0.3185, batch_loss_s: 0.3971, time:4.9706, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:36 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2600/3125], step: 15100, 7.364 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0776, batch_loss_s: 0.0874, time:5.4318, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:41 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2610/3125], step: 15110, 7.043 samples/sec, batch_loss: 0.3550, batch_loss_c: 0.3522, batch_loss_s: 0.3615, time:5.6792, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:46 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2620/3125], step: 15120, 8.220 samples/sec, batch_loss: 0.1575, batch_loss_c: 0.1760, batch_loss_s: 0.1143, time:4.8661, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:51 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2630/3125], step: 15130, 7.990 samples/sec, batch_loss: 0.2267, batch_loss_c: 0.2522, batch_loss_s: 0.1672, time:5.0063, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:15:56 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2640/3125], step: 15140, 7.830 samples/sec, batch_loss: 0.1745, batch_loss_c: 0.2045, batch_loss_s: 0.1047, time:5.1083, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2650/3125], step: 15150, 7.270 samples/sec, batch_loss: 0.5348, batch_loss_c: 0.5328, batch_loss_s: 0.5395, time:5.5020, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:07 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2660/3125], step: 15160, 7.829 samples/sec, batch_loss: 0.2755, batch_loss_c: 0.2504, batch_loss_s: 0.3339, time:5.1093, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:13 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2670/3125], step: 15170, 6.962 samples/sec, batch_loss: 0.0594, batch_loss_c: 0.0536, batch_loss_s: 0.0731, time:5.7453, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2680/3125], step: 15180, 7.320 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0605, batch_loss_s: 0.0638, time:5.4645, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2690/3125], step: 15190, 8.699 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0858, batch_loss_s: 0.1013, time:4.5983, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:27 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2700/3125], step: 15200, 8.679 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.0986, batch_loss_s: 0.1065, time:4.6088, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2710/3125], step: 15210, 7.507 samples/sec, batch_loss: 0.1234, batch_loss_c: 0.1247, batch_loss_s: 0.1205, time:5.3287, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:38 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2720/3125], step: 15220, 8.182 samples/sec, batch_loss: 0.1333, batch_loss_c: 0.1333, batch_loss_s: 0.1333, time:4.8885, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2730/3125], step: 15230, 7.427 samples/sec, batch_loss: 0.1308, batch_loss_c: 0.1433, batch_loss_s: 0.1015, time:5.3855, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:48 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2740/3125], step: 15240, 8.313 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1047, batch_loss_s: 0.1238, time:4.8115, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:54 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2750/3125], step: 15250, 7.099 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0712, batch_loss_s: 0.0746, time:5.6345, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:16:58 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2760/3125], step: 15260, 8.106 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0817, batch_loss_s: 0.0878, time:4.9344, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:04 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2770/3125], step: 15270, 7.843 samples/sec, batch_loss: 0.2400, batch_loss_c: 0.2824, batch_loss_s: 0.1411, time:5.1002, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:09 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2780/3125], step: 15280, 8.084 samples/sec, batch_loss: 0.2769, batch_loss_c: 0.2571, batch_loss_s: 0.3232, time:4.9483, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:14 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2790/3125], step: 15290, 8.038 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.1001, batch_loss_s: 0.1045, time:4.9766, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:18 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2800/3125], step: 15300, 8.636 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0766, batch_loss_s: 0.0818, time:4.6318, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:23 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2810/3125], step: 15310, 7.649 samples/sec, batch_loss: 0.3140, batch_loss_c: 0.2986, batch_loss_s: 0.3501, time:5.2294, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:28 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2820/3125], step: 15320, 8.530 samples/sec, batch_loss: 0.3095, batch_loss_c: 0.3041, batch_loss_s: 0.3221, time:4.6892, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:33 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2830/3125], step: 15330, 7.779 samples/sec, batch_loss: 0.3631, batch_loss_c: 0.3613, batch_loss_s: 0.3671, time:5.1423, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2840/3125], step: 15340, 7.560 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.0993, batch_loss_s: 0.1091, time:5.2913, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:43 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2850/3125], step: 15350, 8.366 samples/sec, batch_loss: 0.5538, batch_loss_c: 0.5592, batch_loss_s: 0.5411, time:4.7811, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:49 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2860/3125], step: 15360, 7.586 samples/sec, batch_loss: 0.2814, batch_loss_c: 0.2685, batch_loss_s: 0.3115, time:5.2732, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:54 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2870/3125], step: 15370, 7.454 samples/sec, batch_loss: 0.5605, batch_loss_c: 0.5580, batch_loss_s: 0.5661, time:5.3662, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:17:59 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2880/3125], step: 15380, 7.819 samples/sec, batch_loss: 0.2530, batch_loss_c: 0.3128, batch_loss_s: 0.1134, time:5.1158, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2890/3125], step: 15390, 7.235 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0877, batch_loss_s: 0.0968, time:5.5284, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:09 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2900/3125], step: 15400, 8.275 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1497, batch_loss_s: 0.1143, time:4.8341, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:14 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2910/3125], step: 15410, 8.459 samples/sec, batch_loss: 0.5721, batch_loss_c: 0.5693, batch_loss_s: 0.5785, time:4.7289, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:19 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2920/3125], step: 15420, 8.002 samples/sec, batch_loss: 0.1519, batch_loss_c: 0.1692, batch_loss_s: 0.1114, time:4.9985, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:24 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2930/3125], step: 15430, 7.488 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1208, batch_loss_s: 0.1171, time:5.3419, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:29 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2940/3125], step: 15440, 8.356 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0726, batch_loss_s: 0.0955, time:4.7871, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:35 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2950/3125], step: 15450, 7.659 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1225, batch_loss_s: 0.1067, time:5.2228, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:39 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2960/3125], step: 15460, 8.094 samples/sec, batch_loss: 0.2284, batch_loss_c: 0.2217, batch_loss_s: 0.2438, time:4.9418, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:44 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2970/3125], step: 15470, 8.613 samples/sec, batch_loss: 0.2940, batch_loss_c: 0.2930, batch_loss_s: 0.2966, time:4.6439, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:49 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2980/3125], step: 15480, 8.256 samples/sec, batch_loss: 0.1448, batch_loss_c: 0.1571, batch_loss_s: 0.1159, time:4.8450, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:54 \u001b[32mINFO     \u001b[0m train.py: [4/5], [2990/3125], step: 15490, 7.662 samples/sec, batch_loss: 0.1572, batch_loss_c: 0.1619, batch_loss_s: 0.1463, time:5.2206, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:18:59 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3000/3125], step: 15500, 7.507 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0821, batch_loss_s: 0.0918, time:5.3280, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:05 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3010/3125], step: 15510, 7.853 samples/sec, batch_loss: 0.1213, batch_loss_c: 0.1309, batch_loss_s: 0.0987, time:5.0935, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:10 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3020/3125], step: 15520, 7.705 samples/sec, batch_loss: 0.1322, batch_loss_c: 0.1313, batch_loss_s: 0.1340, time:5.1913, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:15 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3030/3125], step: 15530, 7.826 samples/sec, batch_loss: 0.3093, batch_loss_c: 0.3102, batch_loss_s: 0.3072, time:5.1110, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:20 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3040/3125], step: 15540, 7.863 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0955, batch_loss_s: 0.0838, time:5.0872, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:26 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3050/3125], step: 15550, 6.645 samples/sec, batch_loss: 0.2373, batch_loss_c: 0.2116, batch_loss_s: 0.2974, time:6.0193, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:31 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3060/3125], step: 15560, 7.422 samples/sec, batch_loss: 0.4114, batch_loss_c: 0.4452, batch_loss_s: 0.3328, time:5.3892, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:37 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3070/3125], step: 15570, 7.512 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0911, batch_loss_s: 0.0936, time:5.3252, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:42 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3080/3125], step: 15580, 8.171 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.1086, batch_loss_s: 0.0823, time:4.8953, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:47 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3090/3125], step: 15590, 7.283 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.0973, batch_loss_s: 0.1028, time:5.4922, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:52 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3100/3125], step: 15600, 8.082 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0897, batch_loss_s: 0.1020, time:4.9492, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:19:56 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3110/3125], step: 15610, 10.312 samples/sec, batch_loss: 0.5703, batch_loss_c: 0.5713, batch_loss_s: 0.5677, time:3.8789, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:20:00 \u001b[32mINFO     \u001b[0m train.py: [4/5], [3120/3125], step: 15620, 10.228 samples/sec, batch_loss: 0.1340, batch_loss_c: 0.1357, batch_loss_s: 0.1301, time:3.9110, lr:0.0001\u001b[0m\n",
            "2019-11-23 10:20:02 \u001b[32mINFO     \u001b[0m train.py: [4/5], train_loss: 0.1952, time: 1575.8856, lr: 0.0001\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}