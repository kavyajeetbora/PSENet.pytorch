{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSENet_trial_run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/PSENet.pytorch/blob/master/PSENet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UByxwp0F3QUp",
        "colab_type": "text"
      },
      "source": [
        "## Installing softwares and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSEHnmCxK_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99kqKlHoYkz",
        "colab_type": "code",
        "outputId": "5274be83-ea6e-4471-e252-69d65d60f518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pyclipper"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.6/dist-packages (1.1.0.post1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoynOlfnIW1",
        "colab_type": "code",
        "outputId": "7fc8d474-c330-4cfd-9bbb-97f64b7b34f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhJ-6yyXcnRx",
        "colab_type": "code",
        "outputId": "da3522a6-6b3d-4714-c9c0-eaa6b122ef43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import shutil, os\n",
        "os.chdir('/content')\n",
        "directory = '/content/cloned-repo'\n",
        "if os.path.exists(directory):\n",
        "  shutil.rmtree(directory)\n",
        "\n",
        "!git clone https://github.com/kavyajeetbora/PSENet.pytorch.git /content/cloned-repo\n",
        "print(\"Cloned the repository\")\n",
        "os.chdir('/content/cloned-repo')\n",
        "!ls"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/cloned-repo'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/24)\u001b[K\rremote: Counting objects:   8% (2/24)\u001b[K\rremote: Counting objects:  12% (3/24)\u001b[K\rremote: Counting objects:  16% (4/24)\u001b[K\rremote: Counting objects:  20% (5/24)\u001b[K\rremote: Counting objects:  25% (6/24)\u001b[K\rremote: Counting objects:  29% (7/24)\u001b[K\rremote: Counting objects:  33% (8/24)\u001b[K\rremote: Counting objects:  37% (9/24)\u001b[K\rremote: Counting objects:  41% (10/24)\u001b[K\rremote: Counting objects:  45% (11/24)\u001b[K\rremote: Counting objects:  50% (12/24)\u001b[K\rremote: Counting objects:  54% (13/24)\u001b[K\rremote: Counting objects:  58% (14/24)\u001b[K\rremote: Counting objects:  62% (15/24)\u001b[K\rremote: Counting objects:  66% (16/24)\u001b[K\rremote: Counting objects:  70% (17/24)\u001b[K\rremote: Counting objects:  75% (18/24)\u001b[K\rremote: Counting objects:  79% (19/24)\u001b[K\rremote: Counting objects:  83% (20/24)\u001b[K\rremote: Counting objects:  87% (21/24)\u001b[K\rremote: Counting objects:  91% (22/24)\u001b[K\rremote: Counting objects:  95% (23/24)\u001b[K\rremote: Counting objects: 100% (24/24)\u001b[K\rremote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 424 (delta 12), reused 0 (delta 0), pack-reused 400\u001b[K\n",
            "Receiving objects: 100% (424/424), 8.19 MiB | 10.83 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n",
            "Cloned the repository\n",
            "cal_recall\t\t LICENSE\t\tPSENet_trial_run.ipynb\n",
            "config.py\t\t models\t\t\tREADME.md\n",
            "dataset\t\t\t predict.py\t\ttrain.py\n",
            "eval.py\t\t\t pse\t\t\tutils\n",
            "imgs\t\t\t PSENet.ipynb\n",
            "install_dependencies.sh  PSENet_training.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrOmfo6_3X2I",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the data and setting up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLMxTujlm0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping the files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def unzip_files(file,output_dir):\n",
        "  with ZipFile(file, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall(output_dir)\n",
        "  print('Extracted to',output_dir)\n",
        "\n",
        "def make_directory(directory):\n",
        "  if os.path.isdir(directory):\n",
        "    shutil.rmtree(directory)\n",
        "  \n",
        "  os.mkdir(directory)\n",
        "  print('Created a new directory')\n",
        "\n",
        "training_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Training Set/Random 5000.zip'\n",
        "test_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Test Set/real_Image_dataset_Detection.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJ6xb5u2dgg",
        "colab_type": "code",
        "outputId": "31db6dbe-cec4-4f6d-9917-9da4d58a1a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# make directories\n",
        "make_directory('Training Set')\n",
        "make_directory('Test Set')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created a new directory\n",
            "Created a new directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSaSXr-m-K4",
        "colab_type": "code",
        "outputId": "caf00058-5599-48af-ba71-917e6f7c1002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(training_data_zip,'Training Set')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Training Set\n",
            "CPU times: user 3.44 s, sys: 1.22 s, total: 4.66 s\n",
            "Wall time: 5.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPn5aW9nSxu",
        "colab_type": "code",
        "outputId": "e38382f6-7009-4d62-9d24-183d62f60e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(test_data_zip,'Test Set')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Test Set\n",
            "CPU times: user 473 ms, sys: 122 ms, total: 595 ms\n",
            "Wall time: 639 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSeyluknVH4",
        "colab_type": "code",
        "outputId": "c9b4b5e5-39ed-4de8-f9d0-9aa78a69311e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Images')))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOp4JsZ6nXvn",
        "colab_type": "code",
        "outputId": "35322c9f-fd8f-44d4-b8e5-6ab8ad5a5948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Annotations')))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvg89mXn8zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset.data_utils import *\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JeHTz3G6Lyj",
        "colab_type": "code",
        "outputId": "0b108b3c-d55a-4c00-c192-3f45a051a43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = MyDataset('Training Set',transform=transforms.ToTensor())\n",
        "len(train_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLKMn-5SBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9a9PsyF3dqo",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9x221Ya0RBGO",
        "outputId": "c0f4f39a-3f18-4ac1-da6b-7ed9bbdfbf6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!chmod +x install_dependencies.sh # make shell script executable\n",
        "!./install_dependencies.sh # run the shell script"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.6/dist-packages (1.1.0.post1)\n",
            "Requirement already satisfied: Polygon3 in /usr/local/lib/python3.6/dist-packages (3.0.8)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (4.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD4GuTKC3wXY",
        "colab_type": "code",
        "outputId": "3d6ac82d-fd7c-49cb-dc6b-b15db3ffe842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make: Entering directory '/content/cloned-repo/pse'\n",
            "make: 'pse.so' is up to date.\n",
            "make: Leaving directory '/content/cloned-repo/pse'\n",
            "2019-11-23 11:07:37 \u001b[32mINFO     \u001b[0m utils.py: logger init finished\u001b[0m\n",
            "2019-11-23 11:07:37 \u001b[32mINFO     \u001b[0m train.py: {'Lambda': 0.7,\n",
            " 'OHEM_ratio': 3,\n",
            " 'backbone': 'resnet18',\n",
            " 'checkpoint': '',\n",
            " 'data_shape': 640,\n",
            " 'display_input_images': False,\n",
            " 'display_interval': 10,\n",
            " 'display_output_images': False,\n",
            " 'end_lr': 1e-07,\n",
            " 'epochs': 10,\n",
            " 'gpu_id': '0',\n",
            " 'lr': 0.0001,\n",
            " 'lr_decay_step': [200, 400],\n",
            " 'lr_gamma': 0.1,\n",
            " 'm': 0.5,\n",
            " 'n': 6,\n",
            " 'output_dir': '/content/drive/My Drive/PSENet',\n",
            " 'pretrained': False,\n",
            " 'pretrained_path': '/content/drive/My Drive/PSENet/PSENet_resnet18.pth',\n",
            " 'restart_training': False,\n",
            " 'scale': 1,\n",
            " 'seed': 2,\n",
            " 'show_images_interval': 50,\n",
            " 'start_epoch': 0,\n",
            " 'testroot': 'Test Set',\n",
            " 'train_batch_size': 4,\n",
            " 'trainroot': 'Training Set',\n",
            " 'warm_up_epoch': 6,\n",
            " 'warm_up_lr': 1e-05,\n",
            " 'weight_decay': 0.0005,\n",
            " 'workers': 12}\u001b[0m\n",
            "2019-11-23 11:07:37 \u001b[32mINFO     \u001b[0m train.py: train with gpu 0 and pytorch 1.3.1\u001b[0m\n",
            "2019-11-23 11:07:43 \u001b[32mINFO     \u001b[0m train.py: train dataset has 12500 samples,3125 in dataloader\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "2019-11-23 11:07:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [0/3125], step: 0, 3.028 samples/sec, batch_loss: 0.1251, batch_loss_c: 0.1366, batch_loss_s: 0.0983, time:13.2122, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [10/3125], step: 10, 8.307 samples/sec, batch_loss: 0.2708, batch_loss_c: 0.2486, batch_loss_s: 0.3225, time:4.8152, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [20/3125], step: 20, 7.332 samples/sec, batch_loss: 0.1529, batch_loss_c: 0.1682, batch_loss_s: 0.1172, time:5.4555, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [30/3125], step: 30, 7.448 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1128, batch_loss_s: 0.1003, time:5.3704, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [40/3125], step: 40, 7.046 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1091, batch_loss_s: 0.0924, time:5.6773, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [50/3125], step: 50, 7.581 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0760, batch_loss_s: 0.0882, time:5.2766, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [60/3125], step: 60, 6.929 samples/sec, batch_loss: 0.3133, batch_loss_c: 0.3061, batch_loss_s: 0.3304, time:5.7729, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [70/3125], step: 70, 7.310 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1158, batch_loss_s: 0.1049, time:5.4717, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [80/3125], step: 80, 8.773 samples/sec, batch_loss: 0.2879, batch_loss_c: 0.3543, batch_loss_s: 0.1328, time:4.5592, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [90/3125], step: 90, 6.936 samples/sec, batch_loss: 0.5103, batch_loss_c: 0.4948, batch_loss_s: 0.5462, time:5.7667, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [100/3125], step: 100, 7.461 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0736, batch_loss_s: 0.0778, time:5.3615, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:08:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [110/3125], step: 110, 7.215 samples/sec, batch_loss: 0.1904, batch_loss_c: 0.1874, batch_loss_s: 0.1975, time:5.5444, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [120/3125], step: 120, 7.848 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1128, batch_loss_s: 0.0814, time:5.0968, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [130/3125], step: 130, 6.959 samples/sec, batch_loss: 0.1490, batch_loss_c: 0.1710, batch_loss_s: 0.0976, time:5.7476, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [140/3125], step: 140, 7.663 samples/sec, batch_loss: 0.3641, batch_loss_c: 0.3784, batch_loss_s: 0.3308, time:5.2201, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [150/3125], step: 150, 7.420 samples/sec, batch_loss: 0.1846, batch_loss_c: 0.1964, batch_loss_s: 0.1572, time:5.3905, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [160/3125], step: 160, 8.030 samples/sec, batch_loss: 0.1207, batch_loss_c: 0.1394, batch_loss_s: 0.0769, time:4.9811, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [170/3125], step: 170, 8.184 samples/sec, batch_loss: 0.3278, batch_loss_c: 0.3233, batch_loss_s: 0.3382, time:4.8877, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [180/3125], step: 180, 8.258 samples/sec, batch_loss: 0.1293, batch_loss_c: 0.1425, batch_loss_s: 0.0985, time:4.8439, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [190/3125], step: 190, 6.867 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0759, batch_loss_s: 0.0832, time:5.8253, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [200/3125], step: 200, 7.445 samples/sec, batch_loss: 0.3293, batch_loss_c: 0.3357, batch_loss_s: 0.3142, time:5.3730, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [210/3125], step: 210, 7.218 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.1020, batch_loss_s: 0.1053, time:5.5415, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:09:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [220/3125], step: 220, 6.949 samples/sec, batch_loss: 0.5331, batch_loss_c: 0.5326, batch_loss_s: 0.5343, time:5.7560, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [230/3125], step: 230, 7.831 samples/sec, batch_loss: 0.3339, batch_loss_c: 0.3311, batch_loss_s: 0.3404, time:5.1080, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [240/3125], step: 240, 8.217 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1326, batch_loss_s: 0.1036, time:4.8680, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [250/3125], step: 250, 7.845 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0582, batch_loss_s: 0.0821, time:5.0986, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [260/3125], step: 260, 8.107 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1095, batch_loss_s: 0.0916, time:4.9343, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [270/3125], step: 270, 7.884 samples/sec, batch_loss: 0.4543, batch_loss_c: 0.4650, batch_loss_s: 0.4295, time:5.0732, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [280/3125], step: 280, 8.375 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0894, batch_loss_s: 0.0933, time:4.7762, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [290/3125], step: 290, 7.642 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0861, batch_loss_s: 0.1008, time:5.2343, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [300/3125], step: 300, 7.706 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.0973, batch_loss_s: 0.1105, time:5.1907, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [310/3125], step: 310, 6.842 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0907, batch_loss_s: 0.1067, time:5.8460, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [320/3125], step: 320, 7.473 samples/sec, batch_loss: 0.2330, batch_loss_c: 0.1999, batch_loss_s: 0.3103, time:5.3522, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [330/3125], step: 330, 7.096 samples/sec, batch_loss: 0.5313, batch_loss_c: 0.5231, batch_loss_s: 0.5502, time:5.6371, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:10:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [340/3125], step: 340, 7.695 samples/sec, batch_loss: 0.1052, batch_loss_c: 0.0986, batch_loss_s: 0.1206, time:5.1983, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [350/3125], step: 350, 7.942 samples/sec, batch_loss: 0.1824, batch_loss_c: 0.2057, batch_loss_s: 0.1281, time:5.0364, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [360/3125], step: 360, 7.483 samples/sec, batch_loss: 0.1430, batch_loss_c: 0.1420, batch_loss_s: 0.1454, time:5.3454, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [370/3125], step: 370, 7.797 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1126, batch_loss_s: 0.1252, time:5.1302, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [380/3125], step: 380, 7.528 samples/sec, batch_loss: 0.3020, batch_loss_c: 0.2965, batch_loss_s: 0.3149, time:5.3135, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [390/3125], step: 390, 6.213 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.1129, batch_loss_s: 0.0551, time:6.4378, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [400/3125], step: 400, 7.795 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0978, batch_loss_s: 0.0761, time:5.1317, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [410/3125], step: 410, 8.402 samples/sec, batch_loss: 0.3476, batch_loss_c: 0.3546, batch_loss_s: 0.3313, time:4.7608, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [420/3125], step: 420, 8.309 samples/sec, batch_loss: 0.1635, batch_loss_c: 0.1969, batch_loss_s: 0.0856, time:4.8139, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [430/3125], step: 430, 7.489 samples/sec, batch_loss: 0.1150, batch_loss_c: 0.1294, batch_loss_s: 0.0814, time:5.3415, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [440/3125], step: 440, 7.609 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1322, batch_loss_s: 0.0988, time:5.2567, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:11:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [450/3125], step: 450, 7.649 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0837, batch_loss_s: 0.0980, time:5.2296, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [460/3125], step: 460, 7.903 samples/sec, batch_loss: 0.1356, batch_loss_c: 0.1390, batch_loss_s: 0.1277, time:5.0611, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [470/3125], step: 470, 7.988 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1064, batch_loss_s: 0.0795, time:5.0077, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [480/3125], step: 480, 7.815 samples/sec, batch_loss: 0.2959, batch_loss_c: 0.2883, batch_loss_s: 0.3138, time:5.1186, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [490/3125], step: 490, 7.707 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1109, batch_loss_s: 0.1048, time:5.1900, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [500/3125], step: 500, 8.504 samples/sec, batch_loss: 0.1828, batch_loss_c: 0.2269, batch_loss_s: 0.0801, time:4.7036, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [510/3125], step: 510, 7.819 samples/sec, batch_loss: 0.1534, batch_loss_c: 0.1556, batch_loss_s: 0.1483, time:5.1156, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [520/3125], step: 520, 7.907 samples/sec, batch_loss: 0.2935, batch_loss_c: 0.2718, batch_loss_s: 0.3439, time:5.0585, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [530/3125], step: 530, 8.325 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1059, batch_loss_s: 0.1064, time:4.8046, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [540/3125], step: 540, 7.980 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1243, batch_loss_s: 0.0850, time:5.0124, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [550/3125], step: 550, 7.713 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1143, batch_loss_s: 0.0893, time:5.1860, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [560/3125], step: 560, 7.620 samples/sec, batch_loss: 0.4390, batch_loss_c: 0.4477, batch_loss_s: 0.4186, time:5.2497, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:12:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [570/3125], step: 570, 7.065 samples/sec, batch_loss: 0.2225, batch_loss_c: 0.2320, batch_loss_s: 0.2005, time:5.6615, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [580/3125], step: 580, 8.023 samples/sec, batch_loss: 0.2953, batch_loss_c: 0.2948, batch_loss_s: 0.2964, time:4.9858, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [590/3125], step: 590, 7.599 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0760, batch_loss_s: 0.1010, time:5.2641, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [600/3125], step: 600, 7.832 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1214, batch_loss_s: 0.0948, time:5.1074, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [610/3125], step: 610, 7.848 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0768, batch_loss_s: 0.0910, time:5.0965, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [620/3125], step: 620, 8.068 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0875, batch_loss_s: 0.1011, time:4.9580, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [630/3125], step: 630, 8.169 samples/sec, batch_loss: 0.1234, batch_loss_c: 0.1255, batch_loss_s: 0.1184, time:4.8965, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [640/3125], step: 640, 8.188 samples/sec, batch_loss: 0.3230, batch_loss_c: 0.3053, batch_loss_s: 0.3643, time:4.8854, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [650/3125], step: 650, 7.138 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1342, batch_loss_s: 0.1008, time:5.6040, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [660/3125], step: 660, 8.422 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1615, batch_loss_s: 0.0803, time:4.7492, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [670/3125], step: 670, 7.820 samples/sec, batch_loss: 0.1153, batch_loss_c: 0.1118, batch_loss_s: 0.1233, time:5.1148, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [680/3125], step: 680, 8.063 samples/sec, batch_loss: 0.3146, batch_loss_c: 0.3205, batch_loss_s: 0.3009, time:4.9612, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:13:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [690/3125], step: 690, 7.489 samples/sec, batch_loss: 0.3052, batch_loss_c: 0.3048, batch_loss_s: 0.3060, time:5.3415, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [700/3125], step: 700, 7.489 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1179, batch_loss_s: 0.1163, time:5.3411, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [710/3125], step: 710, 7.914 samples/sec, batch_loss: 0.0623, batch_loss_c: 0.0577, batch_loss_s: 0.0729, time:5.0541, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [720/3125], step: 720, 7.584 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.0794, batch_loss_s: 0.1840, time:5.2746, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [730/3125], step: 730, 7.649 samples/sec, batch_loss: 0.1326, batch_loss_c: 0.1441, batch_loss_s: 0.1056, time:5.2295, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [740/3125], step: 740, 7.918 samples/sec, batch_loss: 0.2228, batch_loss_c: 0.2169, batch_loss_s: 0.2366, time:5.0517, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [750/3125], step: 750, 7.276 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0878, batch_loss_s: 0.1103, time:5.4975, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [760/3125], step: 760, 7.003 samples/sec, batch_loss: 0.5610, batch_loss_c: 0.5696, batch_loss_s: 0.5410, time:5.7120, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [770/3125], step: 770, 7.021 samples/sec, batch_loss: 0.2294, batch_loss_c: 0.2769, batch_loss_s: 0.1188, time:5.6970, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [780/3125], step: 780, 7.683 samples/sec, batch_loss: 0.3468, batch_loss_c: 0.3416, batch_loss_s: 0.3589, time:5.2063, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [790/3125], step: 790, 7.267 samples/sec, batch_loss: 0.2261, batch_loss_c: 0.2228, batch_loss_s: 0.2338, time:5.5041, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:14:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [800/3125], step: 800, 8.101 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1211, batch_loss_s: 0.1179, time:4.9378, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [810/3125], step: 810, 6.839 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1070, batch_loss_s: 0.1083, time:5.8487, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [820/3125], step: 820, 7.906 samples/sec, batch_loss: 0.1989, batch_loss_c: 0.2251, batch_loss_s: 0.1377, time:5.0595, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [830/3125], step: 830, 6.904 samples/sec, batch_loss: 0.1152, batch_loss_c: 0.1219, batch_loss_s: 0.0996, time:5.7937, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [840/3125], step: 840, 8.273 samples/sec, batch_loss: 0.1295, batch_loss_c: 0.1331, batch_loss_s: 0.1211, time:4.8353, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [850/3125], step: 850, 7.875 samples/sec, batch_loss: 0.1384, batch_loss_c: 0.1419, batch_loss_s: 0.1301, time:5.0791, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [860/3125], step: 860, 7.143 samples/sec, batch_loss: 0.3556, batch_loss_c: 0.3634, batch_loss_s: 0.3372, time:5.5998, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [870/3125], step: 870, 7.194 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0927, batch_loss_s: 0.0811, time:5.5602, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [880/3125], step: 880, 8.093 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1422, batch_loss_s: 0.0831, time:4.9425, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [890/3125], step: 890, 8.082 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.0789, batch_loss_s: 0.1406, time:4.9490, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [900/3125], step: 900, 8.258 samples/sec, batch_loss: 0.2840, batch_loss_c: 0.2699, batch_loss_s: 0.3167, time:4.8436, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [910/3125], step: 910, 8.285 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1472, batch_loss_s: 0.1387, time:4.8280, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:15:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [920/3125], step: 920, 8.024 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1336, batch_loss_s: 0.0955, time:4.9850, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [930/3125], step: 930, 8.623 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1295, batch_loss_s: 0.1150, time:4.6386, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [940/3125], step: 940, 8.291 samples/sec, batch_loss: 0.3773, batch_loss_c: 0.3864, batch_loss_s: 0.3560, time:4.8244, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [950/3125], step: 950, 8.024 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.0981, batch_loss_s: 0.0924, time:4.9853, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [960/3125], step: 960, 7.948 samples/sec, batch_loss: 0.3186, batch_loss_c: 0.3193, batch_loss_s: 0.3170, time:5.0329, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [970/3125], step: 970, 7.628 samples/sec, batch_loss: 0.3507, batch_loss_c: 0.3574, batch_loss_s: 0.3351, time:5.2438, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [980/3125], step: 980, 6.830 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0887, batch_loss_s: 0.0753, time:5.8567, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [990/3125], step: 990, 7.026 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1201, batch_loss_s: 0.1260, time:5.6934, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1000/3125], step: 1000, 7.780 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1614, batch_loss_s: 0.1047, time:5.1414, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1010/3125], step: 1010, 7.902 samples/sec, batch_loss: 0.5823, batch_loss_c: 0.5795, batch_loss_s: 0.5890, time:5.0618, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1020/3125], step: 1020, 7.087 samples/sec, batch_loss: 0.3820, batch_loss_c: 0.3871, batch_loss_s: 0.3701, time:5.6440, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:16:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1030/3125], step: 1030, 7.675 samples/sec, batch_loss: 0.1496, batch_loss_c: 0.1595, batch_loss_s: 0.1264, time:5.2119, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1040/3125], step: 1040, 8.124 samples/sec, batch_loss: 0.3304, batch_loss_c: 0.3265, batch_loss_s: 0.3394, time:4.9238, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1050/3125], step: 1050, 7.564 samples/sec, batch_loss: 0.3605, batch_loss_c: 0.3481, batch_loss_s: 0.3894, time:5.2880, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1060/3125], step: 1060, 8.592 samples/sec, batch_loss: 0.4892, batch_loss_c: 0.4677, batch_loss_s: 0.5394, time:4.6553, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1070/3125], step: 1070, 8.403 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1154, batch_loss_s: 0.1178, time:4.7604, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1080/3125], step: 1080, 8.050 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0828, batch_loss_s: 0.0953, time:4.9692, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1090/3125], step: 1090, 7.607 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.0960, batch_loss_s: 0.0962, time:5.2585, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1100/3125], step: 1100, 8.088 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.0902, batch_loss_s: 0.1015, time:4.9456, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1110/3125], step: 1110, 7.481 samples/sec, batch_loss: 0.1703, batch_loss_c: 0.1741, batch_loss_s: 0.1615, time:5.3469, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1120/3125], step: 1120, 8.299 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.1037, batch_loss_s: 0.0872, time:4.8198, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1130/3125], step: 1130, 8.285 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1037, batch_loss_s: 0.0989, time:4.8281, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1140/3125], step: 1140, 7.414 samples/sec, batch_loss: 0.2112, batch_loss_c: 0.2268, batch_loss_s: 0.1748, time:5.3953, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:17:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1150/3125], step: 1150, 7.634 samples/sec, batch_loss: 0.3451, batch_loss_c: 0.3432, batch_loss_s: 0.3497, time:5.2398, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1160/3125], step: 1160, 7.530 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1290, batch_loss_s: 0.1215, time:5.3124, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1170/3125], step: 1170, 7.574 samples/sec, batch_loss: 0.3033, batch_loss_c: 0.3003, batch_loss_s: 0.3105, time:5.2811, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1180/3125], step: 1180, 6.676 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.1093, batch_loss_s: 0.0835, time:5.9916, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1190/3125], step: 1190, 6.846 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0835, batch_loss_s: 0.0910, time:5.8432, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1200/3125], step: 1200, 7.673 samples/sec, batch_loss: 0.1691, batch_loss_c: 0.1991, batch_loss_s: 0.0991, time:5.2130, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1210/3125], step: 1210, 8.062 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1147, batch_loss_s: 0.1463, time:4.9614, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1220/3125], step: 1220, 8.333 samples/sec, batch_loss: 0.0854, batch_loss_c: 0.0847, batch_loss_s: 0.0871, time:4.8004, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1230/3125], step: 1230, 8.099 samples/sec, batch_loss: 0.2138, batch_loss_c: 0.2345, batch_loss_s: 0.1654, time:4.9391, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1240/3125], step: 1240, 8.052 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0720, batch_loss_s: 0.0853, time:4.9674, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1250/3125], step: 1250, 6.988 samples/sec, batch_loss: 0.1119, batch_loss_c: 0.1169, batch_loss_s: 0.1004, time:5.7243, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1260/3125], step: 1260, 7.610 samples/sec, batch_loss: 0.1419, batch_loss_c: 0.1619, batch_loss_s: 0.0953, time:5.2565, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:18:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1270/3125], step: 1270, 7.086 samples/sec, batch_loss: 0.1949, batch_loss_c: 0.2216, batch_loss_s: 0.1325, time:5.6453, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1280/3125], step: 1280, 7.950 samples/sec, batch_loss: 0.1316, batch_loss_c: 0.1381, batch_loss_s: 0.1164, time:5.0315, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1290/3125], step: 1290, 7.575 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1139, batch_loss_s: 0.1052, time:5.2802, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1300/3125], step: 1300, 7.526 samples/sec, batch_loss: 0.1071, batch_loss_c: 0.0987, batch_loss_s: 0.1268, time:5.3151, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1310/3125], step: 1310, 7.061 samples/sec, batch_loss: 0.5104, batch_loss_c: 0.4836, batch_loss_s: 0.5730, time:5.6653, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1320/3125], step: 1320, 7.363 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1058, batch_loss_s: 0.0808, time:5.4329, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1330/3125], step: 1330, 7.732 samples/sec, batch_loss: 0.3124, batch_loss_c: 0.3138, batch_loss_s: 0.3091, time:5.1731, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1340/3125], step: 1340, 8.000 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.0969, batch_loss_s: 0.1123, time:4.9999, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1350/3125], step: 1350, 7.750 samples/sec, batch_loss: 0.3149, batch_loss_c: 0.3106, batch_loss_s: 0.3249, time:5.1614, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1360/3125], step: 1360, 8.224 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1330, batch_loss_s: 0.1529, time:4.8641, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1370/3125], step: 1370, 8.175 samples/sec, batch_loss: 0.3648, batch_loss_c: 0.3686, batch_loss_s: 0.3559, time:4.8930, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:19:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1380/3125], step: 1380, 7.457 samples/sec, batch_loss: 0.2015, batch_loss_c: 0.2001, batch_loss_s: 0.2047, time:5.3641, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1390/3125], step: 1390, 8.074 samples/sec, batch_loss: 0.1082, batch_loss_c: 0.1083, batch_loss_s: 0.1079, time:4.9544, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1400/3125], step: 1400, 7.898 samples/sec, batch_loss: 0.2883, batch_loss_c: 0.2798, batch_loss_s: 0.3081, time:5.0648, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1410/3125], step: 1410, 7.236 samples/sec, batch_loss: 0.2568, batch_loss_c: 0.2327, batch_loss_s: 0.3131, time:5.5277, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1420/3125], step: 1420, 6.826 samples/sec, batch_loss: 0.1525, batch_loss_c: 0.1615, batch_loss_s: 0.1316, time:5.8603, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1430/3125], step: 1430, 6.985 samples/sec, batch_loss: 0.3066, batch_loss_c: 0.3034, batch_loss_s: 0.3141, time:5.7268, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1440/3125], step: 1440, 7.498 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1034, batch_loss_s: 0.1040, time:5.3346, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1450/3125], step: 1450, 7.680 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1549, batch_loss_s: 0.1633, time:5.2085, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1460/3125], step: 1460, 8.122 samples/sec, batch_loss: 0.0939, batch_loss_c: 0.0906, batch_loss_s: 0.1016, time:4.9250, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1470/3125], step: 1470, 9.000 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0810, batch_loss_s: 0.1013, time:4.4443, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1480/3125], step: 1480, 8.378 samples/sec, batch_loss: 0.5787, batch_loss_c: 0.5842, batch_loss_s: 0.5658, time:4.7742, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1490/3125], step: 1490, 7.503 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0901, batch_loss_s: 0.0916, time:5.3314, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:20:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1500/3125], step: 1500, 7.856 samples/sec, batch_loss: 0.4794, batch_loss_c: 0.4532, batch_loss_s: 0.5407, time:5.0918, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1510/3125], step: 1510, 7.994 samples/sec, batch_loss: 0.3084, batch_loss_c: 0.3111, batch_loss_s: 0.3020, time:5.0036, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1520/3125], step: 1520, 8.544 samples/sec, batch_loss: 0.3243, batch_loss_c: 0.3248, batch_loss_s: 0.3234, time:4.6819, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1530/3125], step: 1530, 8.492 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1208, batch_loss_s: 0.0827, time:4.7101, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1540/3125], step: 1540, 7.997 samples/sec, batch_loss: 0.0828, batch_loss_c: 0.0759, batch_loss_s: 0.0989, time:5.0016, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1550/3125], step: 1550, 7.541 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.1065, batch_loss_s: 0.0818, time:5.3046, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1560/3125], step: 1560, 8.823 samples/sec, batch_loss: 0.1101, batch_loss_c: 0.1120, batch_loss_s: 0.1056, time:4.5336, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1570/3125], step: 1570, 7.265 samples/sec, batch_loss: 0.1106, batch_loss_c: 0.1285, batch_loss_s: 0.0688, time:5.5062, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1580/3125], step: 1580, 8.019 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0734, batch_loss_s: 0.0785, time:4.9879, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1590/3125], step: 1590, 8.128 samples/sec, batch_loss: 0.4200, batch_loss_c: 0.4343, batch_loss_s: 0.3866, time:4.9213, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1600/3125], step: 1600, 7.752 samples/sec, batch_loss: 0.1633, batch_loss_c: 0.1780, batch_loss_s: 0.1289, time:5.1603, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1610/3125], step: 1610, 7.982 samples/sec, batch_loss: 0.3147, batch_loss_c: 0.3013, batch_loss_s: 0.3459, time:5.0110, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:21:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1620/3125], step: 1620, 8.401 samples/sec, batch_loss: 0.1640, batch_loss_c: 0.1752, batch_loss_s: 0.1378, time:4.7613, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1630/3125], step: 1630, 7.781 samples/sec, batch_loss: 0.2057, batch_loss_c: 0.2587, batch_loss_s: 0.0821, time:5.1410, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1640/3125], step: 1640, 7.768 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0871, batch_loss_s: 0.0858, time:5.1495, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1650/3125], step: 1650, 8.067 samples/sec, batch_loss: 0.5406, batch_loss_c: 0.5352, batch_loss_s: 0.5534, time:4.9584, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1660/3125], step: 1660, 8.110 samples/sec, batch_loss: 0.3428, batch_loss_c: 0.3482, batch_loss_s: 0.3303, time:4.9325, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1670/3125], step: 1670, 7.411 samples/sec, batch_loss: 0.1291, batch_loss_c: 0.1494, batch_loss_s: 0.0820, time:5.3973, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1680/3125], step: 1680, 8.260 samples/sec, batch_loss: 0.3745, batch_loss_c: 0.3759, batch_loss_s: 0.3713, time:4.8429, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1690/3125], step: 1690, 6.999 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1115, batch_loss_s: 0.0919, time:5.7151, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1700/3125], step: 1700, 6.635 samples/sec, batch_loss: 0.1764, batch_loss_c: 0.1896, batch_loss_s: 0.1456, time:6.0290, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1710/3125], step: 1710, 6.624 samples/sec, batch_loss: 0.2765, batch_loss_c: 0.2590, batch_loss_s: 0.3172, time:6.0389, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1720/3125], step: 1720, 6.998 samples/sec, batch_loss: 0.2256, batch_loss_c: 0.2616, batch_loss_s: 0.1415, time:5.7158, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:22:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1730/3125], step: 1730, 7.057 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3185, batch_loss_s: 0.3281, time:5.6685, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1740/3125], step: 1740, 7.695 samples/sec, batch_loss: 0.3237, batch_loss_c: 0.3242, batch_loss_s: 0.3225, time:5.1980, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1750/3125], step: 1750, 7.696 samples/sec, batch_loss: 0.1836, batch_loss_c: 0.2023, batch_loss_s: 0.1398, time:5.1978, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1760/3125], step: 1760, 7.019 samples/sec, batch_loss: 0.1208, batch_loss_c: 0.1233, batch_loss_s: 0.1148, time:5.6984, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1770/3125], step: 1770, 7.161 samples/sec, batch_loss: 0.2835, batch_loss_c: 0.2752, batch_loss_s: 0.3030, time:5.5860, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1780/3125], step: 1780, 7.391 samples/sec, batch_loss: 0.5749, batch_loss_c: 0.5942, batch_loss_s: 0.5301, time:5.4122, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1790/3125], step: 1790, 7.773 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.1090, batch_loss_s: 0.0748, time:5.1460, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1800/3125], step: 1800, 7.942 samples/sec, batch_loss: 0.3550, batch_loss_c: 0.3614, batch_loss_s: 0.3401, time:5.0367, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1810/3125], step: 1810, 7.651 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1223, batch_loss_s: 0.1032, time:5.2279, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1820/3125], step: 1820, 8.264 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0631, batch_loss_s: 0.0720, time:4.8405, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1830/3125], step: 1830, 7.816 samples/sec, batch_loss: 0.3729, batch_loss_c: 0.3906, batch_loss_s: 0.3316, time:5.1174, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:23:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1840/3125], step: 1840, 7.729 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1183, batch_loss_s: 0.1086, time:5.1754, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1850/3125], step: 1850, 7.169 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.0982, batch_loss_s: 0.0956, time:5.5800, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1860/3125], step: 1860, 7.619 samples/sec, batch_loss: 0.1478, batch_loss_c: 0.1725, batch_loss_s: 0.0903, time:5.2500, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1870/3125], step: 1870, 8.198 samples/sec, batch_loss: 0.1536, batch_loss_c: 0.1638, batch_loss_s: 0.1297, time:4.8794, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1880/3125], step: 1880, 8.971 samples/sec, batch_loss: 0.1667, batch_loss_c: 0.1634, batch_loss_s: 0.1744, time:4.4590, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1890/3125], step: 1890, 8.153 samples/sec, batch_loss: 0.0859, batch_loss_c: 0.0877, batch_loss_s: 0.0817, time:4.9064, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1900/3125], step: 1900, 8.342 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0939, batch_loss_s: 0.0788, time:4.7951, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1910/3125], step: 1910, 7.557 samples/sec, batch_loss: 0.2979, batch_loss_c: 0.2949, batch_loss_s: 0.3050, time:5.2929, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1920/3125], step: 1920, 8.081 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1033, batch_loss_s: 0.0997, time:4.9496, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1930/3125], step: 1930, 7.821 samples/sec, batch_loss: 0.3495, batch_loss_c: 0.3316, batch_loss_s: 0.3913, time:5.1147, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1940/3125], step: 1940, 7.214 samples/sec, batch_loss: 0.1450, batch_loss_c: 0.1534, batch_loss_s: 0.1253, time:5.5447, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1950/3125], step: 1950, 7.798 samples/sec, batch_loss: 0.1160, batch_loss_c: 0.1262, batch_loss_s: 0.0924, time:5.1298, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:24:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1960/3125], step: 1960, 7.731 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1095, batch_loss_s: 0.0935, time:5.1738, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1970/3125], step: 1970, 8.570 samples/sec, batch_loss: 0.3038, batch_loss_c: 0.3002, batch_loss_s: 0.3121, time:4.6673, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1980/3125], step: 1980, 7.702 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1084, batch_loss_s: 0.1245, time:5.1935, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1990/3125], step: 1990, 8.273 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1291, batch_loss_s: 0.0995, time:4.8350, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2000/3125], step: 2000, 7.264 samples/sec, batch_loss: 0.1790, batch_loss_c: 0.1977, batch_loss_s: 0.1353, time:5.5066, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2010/3125], step: 2010, 8.030 samples/sec, batch_loss: 0.1503, batch_loss_c: 0.1594, batch_loss_s: 0.1289, time:4.9814, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2020/3125], step: 2020, 8.246 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1376, batch_loss_s: 0.0921, time:4.8509, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2030/3125], step: 2030, 8.167 samples/sec, batch_loss: 0.0721, batch_loss_c: 0.0731, batch_loss_s: 0.0697, time:4.8980, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2040/3125], step: 2040, 7.250 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0749, batch_loss_s: 0.0831, time:5.5173, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2050/3125], step: 2050, 7.508 samples/sec, batch_loss: 0.3086, batch_loss_c: 0.3057, batch_loss_s: 0.3154, time:5.3275, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2060/3125], step: 2060, 8.092 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0847, batch_loss_s: 0.1027, time:4.9430, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2070/3125], step: 2070, 7.771 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1094, batch_loss_s: 0.1065, time:5.1477, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:25:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2080/3125], step: 2080, 7.814 samples/sec, batch_loss: 0.1027, batch_loss_c: 0.0894, batch_loss_s: 0.1337, time:5.1189, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2090/3125], step: 2090, 8.295 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0570, batch_loss_s: 0.0637, time:4.8220, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2100/3125], step: 2100, 8.371 samples/sec, batch_loss: 0.1410, batch_loss_c: 0.1591, batch_loss_s: 0.0986, time:4.7787, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2110/3125], step: 2110, 7.882 samples/sec, batch_loss: 0.0678, batch_loss_c: 0.0625, batch_loss_s: 0.0800, time:5.0752, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2120/3125], step: 2120, 7.490 samples/sec, batch_loss: 0.3102, batch_loss_c: 0.3062, batch_loss_s: 0.3195, time:5.3405, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2130/3125], step: 2130, 8.438 samples/sec, batch_loss: 0.0624, batch_loss_c: 0.0567, batch_loss_s: 0.0757, time:4.7403, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2140/3125], step: 2140, 7.726 samples/sec, batch_loss: 0.1667, batch_loss_c: 0.1958, batch_loss_s: 0.0987, time:5.1775, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2150/3125], step: 2150, 7.875 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0755, batch_loss_s: 0.0920, time:5.0795, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2160/3125], step: 2160, 7.993 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0662, batch_loss_s: 0.0851, time:5.0042, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2170/3125], step: 2170, 7.474 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1011, batch_loss_s: 0.1228, time:5.3519, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2180/3125], step: 2180, 8.674 samples/sec, batch_loss: 0.1493, batch_loss_c: 0.1594, batch_loss_s: 0.1258, time:4.6112, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2190/3125], step: 2190, 7.853 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1691, batch_loss_s: 0.1077, time:5.0933, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:26:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2200/3125], step: 2200, 7.673 samples/sec, batch_loss: 0.3017, batch_loss_c: 0.2977, batch_loss_s: 0.3111, time:5.2132, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2210/3125], step: 2210, 7.747 samples/sec, batch_loss: 0.1662, batch_loss_c: 0.1318, batch_loss_s: 0.2464, time:5.1634, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2220/3125], step: 2220, 8.437 samples/sec, batch_loss: 0.0711, batch_loss_c: 0.0685, batch_loss_s: 0.0772, time:4.7408, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2230/3125], step: 2230, 7.867 samples/sec, batch_loss: 0.2204, batch_loss_c: 0.2709, batch_loss_s: 0.1025, time:5.0844, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2240/3125], step: 2240, 7.486 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0753, batch_loss_s: 0.0904, time:5.3436, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2250/3125], step: 2250, 7.748 samples/sec, batch_loss: 0.1552, batch_loss_c: 0.1489, batch_loss_s: 0.1697, time:5.1627, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2260/3125], step: 2260, 7.442 samples/sec, batch_loss: 0.3097, batch_loss_c: 0.3042, batch_loss_s: 0.3227, time:5.3746, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2270/3125], step: 2270, 8.008 samples/sec, batch_loss: 0.3097, batch_loss_c: 0.3007, batch_loss_s: 0.3309, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2280/3125], step: 2280, 7.672 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0888, batch_loss_s: 0.0763, time:5.2135, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2290/3125], step: 2290, 7.778 samples/sec, batch_loss: 0.5320, batch_loss_c: 0.5125, batch_loss_s: 0.5775, time:5.1427, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2300/3125], step: 2300, 8.179 samples/sec, batch_loss: 0.3331, batch_loss_c: 0.3335, batch_loss_s: 0.3321, time:4.8903, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2310/3125], step: 2310, 8.263 samples/sec, batch_loss: 0.1695, batch_loss_c: 0.1858, batch_loss_s: 0.1316, time:4.8409, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:27:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2320/3125], step: 2320, 7.813 samples/sec, batch_loss: 0.1128, batch_loss_c: 0.1147, batch_loss_s: 0.1085, time:5.1195, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2330/3125], step: 2330, 7.938 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3155, batch_loss_s: 0.3037, time:5.0393, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2340/3125], step: 2340, 8.444 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1213, batch_loss_s: 0.1321, time:4.7370, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2350/3125], step: 2350, 8.369 samples/sec, batch_loss: 0.0696, batch_loss_c: 0.0639, batch_loss_s: 0.0828, time:4.7797, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2360/3125], step: 2360, 7.581 samples/sec, batch_loss: 0.5413, batch_loss_c: 0.5349, batch_loss_s: 0.5562, time:5.2761, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2370/3125], step: 2370, 8.203 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0864, batch_loss_s: 0.0856, time:4.8763, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2380/3125], step: 2380, 7.675 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1289, batch_loss_s: 0.1245, time:5.2117, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2390/3125], step: 2390, 8.300 samples/sec, batch_loss: 0.1625, batch_loss_c: 0.1839, batch_loss_s: 0.1127, time:4.8191, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2400/3125], step: 2400, 8.074 samples/sec, batch_loss: 0.4492, batch_loss_c: 0.4342, batch_loss_s: 0.4843, time:4.9540, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2410/3125], step: 2410, 7.292 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0895, batch_loss_s: 0.0617, time:5.4857, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2420/3125], step: 2420, 7.750 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.3054, batch_loss_s: 0.3011, time:5.1613, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2430/3125], step: 2430, 8.828 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1121, batch_loss_s: 0.1094, time:4.5312, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:28:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2440/3125], step: 2440, 8.474 samples/sec, batch_loss: 0.3299, batch_loss_c: 0.3290, batch_loss_s: 0.3322, time:4.7204, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2450/3125], step: 2450, 8.072 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1020, batch_loss_s: 0.1068, time:4.9551, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2460/3125], step: 2460, 7.658 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0808, batch_loss_s: 0.0845, time:5.2231, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2470/3125], step: 2470, 8.818 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3046, batch_loss_s: 0.3330, time:4.5362, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2480/3125], step: 2480, 8.216 samples/sec, batch_loss: 0.2953, batch_loss_c: 0.2926, batch_loss_s: 0.3015, time:4.8688, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2490/3125], step: 2490, 8.524 samples/sec, batch_loss: 0.0656, batch_loss_c: 0.0616, batch_loss_s: 0.0750, time:4.6929, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2500/3125], step: 2500, 7.592 samples/sec, batch_loss: 0.1212, batch_loss_c: 0.1365, batch_loss_s: 0.0857, time:5.2686, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2510/3125], step: 2510, 8.222 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.0917, batch_loss_s: 0.1040, time:4.8653, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2520/3125], step: 2520, 7.700 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0757, batch_loss_s: 0.0851, time:5.1951, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2530/3125], step: 2530, 8.229 samples/sec, batch_loss: 0.1518, batch_loss_c: 0.1772, batch_loss_s: 0.0925, time:4.8608, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2540/3125], step: 2540, 8.110 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1452, batch_loss_s: 0.0748, time:4.9319, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2550/3125], step: 2550, 8.219 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0826, batch_loss_s: 0.0991, time:4.8667, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:29:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2560/3125], step: 2560, 7.712 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1001, batch_loss_s: 0.1029, time:5.1864, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2570/3125], step: 2570, 8.071 samples/sec, batch_loss: 0.5268, batch_loss_c: 0.5182, batch_loss_s: 0.5467, time:4.9562, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2580/3125], step: 2580, 7.993 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1505, batch_loss_s: 0.0854, time:5.0043, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2590/3125], step: 2590, 7.170 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0988, batch_loss_s: 0.0902, time:5.5785, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2600/3125], step: 2600, 7.992 samples/sec, batch_loss: 0.1829, batch_loss_c: 0.1881, batch_loss_s: 0.1708, time:5.0048, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2610/3125], step: 2610, 7.614 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0860, batch_loss_s: 0.0949, time:5.2535, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2620/3125], step: 2620, 7.666 samples/sec, batch_loss: 0.5367, batch_loss_c: 0.5389, batch_loss_s: 0.5317, time:5.2180, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2630/3125], step: 2630, 8.384 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0801, batch_loss_s: 0.0879, time:4.7710, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2640/3125], step: 2640, 8.511 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0949, batch_loss_s: 0.0812, time:4.6996, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2650/3125], step: 2650, 7.815 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1415, batch_loss_s: 0.0823, time:5.1183, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2660/3125], step: 2660, 6.620 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0784, batch_loss_s: 0.0945, time:6.0422, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:30:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2670/3125], step: 2670, 7.992 samples/sec, batch_loss: 0.1472, batch_loss_c: 0.1713, batch_loss_s: 0.0909, time:5.0048, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2680/3125], step: 2680, 8.246 samples/sec, batch_loss: 0.0888, batch_loss_c: 0.0857, batch_loss_s: 0.0960, time:4.8508, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2690/3125], step: 2690, 8.194 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0712, batch_loss_s: 0.0871, time:4.8817, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2700/3125], step: 2700, 7.300 samples/sec, batch_loss: 0.2765, batch_loss_c: 0.2618, batch_loss_s: 0.3109, time:5.4797, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2710/3125], step: 2710, 8.607 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0876, batch_loss_s: 0.0947, time:4.6476, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2720/3125], step: 2720, 8.280 samples/sec, batch_loss: 0.0755, batch_loss_c: 0.0829, batch_loss_s: 0.0584, time:4.8311, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2730/3125], step: 2730, 8.720 samples/sec, batch_loss: 0.2451, batch_loss_c: 0.2996, batch_loss_s: 0.1180, time:4.5871, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2740/3125], step: 2740, 8.890 samples/sec, batch_loss: 0.0770, batch_loss_c: 0.0744, batch_loss_s: 0.0831, time:4.4992, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2750/3125], step: 2750, 7.624 samples/sec, batch_loss: 0.1137, batch_loss_c: 0.1175, batch_loss_s: 0.1048, time:5.2465, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2760/3125], step: 2760, 7.821 samples/sec, batch_loss: 0.1681, batch_loss_c: 0.1672, batch_loss_s: 0.1703, time:5.1142, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2770/3125], step: 2770, 7.954 samples/sec, batch_loss: 0.3414, batch_loss_c: 0.3513, batch_loss_s: 0.3183, time:5.0290, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2780/3125], step: 2780, 7.865 samples/sec, batch_loss: 0.2494, batch_loss_c: 0.2143, batch_loss_s: 0.3312, time:5.0861, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2790/3125], step: 2790, 7.746 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1491, batch_loss_s: 0.1001, time:5.1637, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:31:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2800/3125], step: 2800, 8.610 samples/sec, batch_loss: 0.1466, batch_loss_c: 0.1557, batch_loss_s: 0.1254, time:4.6456, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2810/3125], step: 2810, 7.309 samples/sec, batch_loss: 0.1191, batch_loss_c: 0.1275, batch_loss_s: 0.0996, time:5.4730, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2820/3125], step: 2820, 8.603 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1105, batch_loss_s: 0.1158, time:4.6496, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2830/3125], step: 2830, 7.352 samples/sec, batch_loss: 0.1526, batch_loss_c: 0.1686, batch_loss_s: 0.1151, time:5.4407, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2840/3125], step: 2840, 6.482 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0767, batch_loss_s: 0.0888, time:6.1706, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2850/3125], step: 2850, 7.850 samples/sec, batch_loss: 0.3020, batch_loss_c: 0.2992, batch_loss_s: 0.3086, time:5.0957, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2860/3125], step: 2860, 7.935 samples/sec, batch_loss: 0.2877, batch_loss_c: 0.2857, batch_loss_s: 0.2923, time:5.0407, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2870/3125], step: 2870, 7.682 samples/sec, batch_loss: 0.1106, batch_loss_c: 0.1239, batch_loss_s: 0.0793, time:5.2071, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2880/3125], step: 2880, 7.368 samples/sec, batch_loss: 0.0963, batch_loss_c: 0.0776, batch_loss_s: 0.1400, time:5.4292, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2890/3125], step: 2890, 7.175 samples/sec, batch_loss: 0.1714, batch_loss_c: 0.1788, batch_loss_s: 0.1543, time:5.5747, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2900/3125], step: 2900, 8.449 samples/sec, batch_loss: 0.5138, batch_loss_c: 0.5007, batch_loss_s: 0.5443, time:4.7343, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:32:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2910/3125], step: 2910, 8.514 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.0899, batch_loss_s: 0.1023, time:4.6983, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2920/3125], step: 2920, 7.468 samples/sec, batch_loss: 0.3423, batch_loss_c: 0.3341, batch_loss_s: 0.3615, time:5.3563, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2930/3125], step: 2930, 7.844 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1514, batch_loss_s: 0.1279, time:5.0996, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2940/3125], step: 2940, 7.337 samples/sec, batch_loss: 0.1554, batch_loss_c: 0.1615, batch_loss_s: 0.1411, time:5.4515, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2950/3125], step: 2950, 7.597 samples/sec, batch_loss: 0.1334, batch_loss_c: 0.1335, batch_loss_s: 0.1330, time:5.2649, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2960/3125], step: 2960, 8.507 samples/sec, batch_loss: 0.1362, batch_loss_c: 0.1524, batch_loss_s: 0.0984, time:4.7021, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2970/3125], step: 2970, 7.176 samples/sec, batch_loss: 0.3850, batch_loss_c: 0.3963, batch_loss_s: 0.3584, time:5.5744, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2980/3125], step: 2980, 6.825 samples/sec, batch_loss: 0.2917, batch_loss_c: 0.2710, batch_loss_s: 0.3399, time:5.8606, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2990/3125], step: 2990, 8.352 samples/sec, batch_loss: 0.5227, batch_loss_c: 0.5099, batch_loss_s: 0.5526, time:4.7895, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3000/3125], step: 3000, 7.360 samples/sec, batch_loss: 0.3992, batch_loss_c: 0.4196, batch_loss_s: 0.3516, time:5.4347, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3010/3125], step: 3010, 7.138 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0842, batch_loss_s: 0.0952, time:5.6038, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:33:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3020/3125], step: 3020, 6.889 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1051, batch_loss_s: 0.1016, time:5.8060, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3030/3125], step: 3030, 6.826 samples/sec, batch_loss: 0.3231, batch_loss_c: 0.3200, batch_loss_s: 0.3303, time:5.8602, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3040/3125], step: 3040, 7.392 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0802, batch_loss_s: 0.0745, time:5.4113, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3050/3125], step: 3050, 6.374 samples/sec, batch_loss: 0.3300, batch_loss_c: 0.3199, batch_loss_s: 0.3536, time:6.2754, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3060/3125], step: 3060, 6.938 samples/sec, batch_loss: 0.1385, batch_loss_c: 0.1535, batch_loss_s: 0.1037, time:5.7657, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3070/3125], step: 3070, 7.341 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3195, batch_loss_s: 0.3114, time:5.4491, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3080/3125], step: 3080, 7.821 samples/sec, batch_loss: 0.2603, batch_loss_c: 0.2479, batch_loss_s: 0.2892, time:5.1145, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3090/3125], step: 3090, 7.924 samples/sec, batch_loss: 0.1185, batch_loss_c: 0.1142, batch_loss_s: 0.1286, time:5.0480, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3100/3125], step: 3100, 7.655 samples/sec, batch_loss: 0.3828, batch_loss_c: 0.3897, batch_loss_s: 0.3666, time:5.2254, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3110/3125], step: 3110, 10.100 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1062, batch_loss_s: 0.1216, time:3.9602, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3120/3125], step: 3120, 10.114 samples/sec, batch_loss: 0.1611, batch_loss_c: 0.1901, batch_loss_s: 0.0934, time:3.9551, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:34:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], train_loss: 0.1913, time: 1625.9922, lr: 0.0001\u001b[0m\n",
            "2019-11-23 11:34:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [0/3125], step: 3125, 7.561 samples/sec, batch_loss: 0.2424, batch_loss_c: 0.2141, batch_loss_s: 0.3083, time:5.2903, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [10/3125], step: 3135, 4.784 samples/sec, batch_loss: 0.1157, batch_loss_c: 0.1183, batch_loss_s: 0.1095, time:8.3617, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [20/3125], step: 3145, 8.469 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0883, batch_loss_s: 0.0872, time:4.7234, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [30/3125], step: 3155, 7.343 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1661, batch_loss_s: 0.1126, time:5.4472, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [40/3125], step: 3165, 8.164 samples/sec, batch_loss: 0.1079, batch_loss_c: 0.1061, batch_loss_s: 0.1122, time:4.8997, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [50/3125], step: 3175, 8.402 samples/sec, batch_loss: 0.5777, batch_loss_c: 0.5839, batch_loss_s: 0.5633, time:4.7608, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [60/3125], step: 3185, 7.564 samples/sec, batch_loss: 0.4037, batch_loss_c: 0.4073, batch_loss_s: 0.3952, time:5.2883, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [70/3125], step: 3195, 7.107 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1078, batch_loss_s: 0.0848, time:5.6282, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [80/3125], step: 3205, 7.824 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0778, batch_loss_s: 0.0827, time:5.1126, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [90/3125], step: 3215, 7.942 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0855, batch_loss_s: 0.0932, time:5.0366, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [100/3125], step: 3225, 7.715 samples/sec, batch_loss: 0.7162, batch_loss_c: 0.6810, batch_loss_s: 0.7983, time:5.1846, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:35:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [110/3125], step: 3235, 7.400 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1101, batch_loss_s: 0.0932, time:5.4053, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [120/3125], step: 3245, 6.588 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.1013, batch_loss_s: 0.0870, time:6.0716, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [130/3125], step: 3255, 7.424 samples/sec, batch_loss: 0.3578, batch_loss_c: 0.3568, batch_loss_s: 0.3600, time:5.3878, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [140/3125], step: 3265, 7.276 samples/sec, batch_loss: 0.3305, batch_loss_c: 0.3466, batch_loss_s: 0.2929, time:5.4972, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [150/3125], step: 3275, 7.368 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1072, batch_loss_s: 0.0919, time:5.4289, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [160/3125], step: 3285, 7.963 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1556, batch_loss_s: 0.0871, time:5.0232, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [170/3125], step: 3295, 8.069 samples/sec, batch_loss: 0.0649, batch_loss_c: 0.0597, batch_loss_s: 0.0769, time:4.9573, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [180/3125], step: 3305, 6.738 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1222, batch_loss_s: 0.1070, time:5.9366, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [190/3125], step: 3315, 7.090 samples/sec, batch_loss: 0.3269, batch_loss_c: 0.3271, batch_loss_s: 0.3263, time:5.6419, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [200/3125], step: 3325, 7.430 samples/sec, batch_loss: 0.2800, batch_loss_c: 0.3260, batch_loss_s: 0.1727, time:5.3834, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [210/3125], step: 3335, 7.427 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0693, batch_loss_s: 0.0771, time:5.3856, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:36:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [220/3125], step: 3345, 7.517 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3504, batch_loss_s: 0.2306, time:5.3214, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [230/3125], step: 3355, 7.509 samples/sec, batch_loss: 0.2814, batch_loss_c: 0.2699, batch_loss_s: 0.3081, time:5.3271, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [240/3125], step: 3365, 8.154 samples/sec, batch_loss: 0.3951, batch_loss_c: 0.3906, batch_loss_s: 0.4058, time:4.9057, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [250/3125], step: 3375, 8.513 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0861, batch_loss_s: 0.0850, time:4.6990, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [260/3125], step: 3385, 7.906 samples/sec, batch_loss: 0.3336, batch_loss_c: 0.3307, batch_loss_s: 0.3405, time:5.0593, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [270/3125], step: 3395, 7.568 samples/sec, batch_loss: 0.3152, batch_loss_c: 0.3149, batch_loss_s: 0.3161, time:5.2855, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [280/3125], step: 3405, 7.598 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1312, batch_loss_s: 0.1304, time:5.2646, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [290/3125], step: 3415, 7.750 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1268, batch_loss_s: 0.0779, time:5.1614, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [300/3125], step: 3425, 7.499 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0754, batch_loss_s: 0.0629, time:5.3341, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [310/3125], step: 3435, 7.824 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0950, batch_loss_s: 0.0984, time:5.1123, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [320/3125], step: 3445, 6.906 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0866, batch_loss_s: 0.0940, time:5.7919, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [330/3125], step: 3455, 7.648 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0892, batch_loss_s: 0.1031, time:5.2298, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:37:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [340/3125], step: 3465, 7.818 samples/sec, batch_loss: 0.3550, batch_loss_c: 0.3632, batch_loss_s: 0.3359, time:5.1167, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [350/3125], step: 3475, 8.139 samples/sec, batch_loss: 0.2964, batch_loss_c: 0.2932, batch_loss_s: 0.3040, time:4.9146, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [360/3125], step: 3485, 7.946 samples/sec, batch_loss: 0.0937, batch_loss_c: 0.0935, batch_loss_s: 0.0942, time:5.0338, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [370/3125], step: 3495, 8.167 samples/sec, batch_loss: 0.3525, batch_loss_c: 0.3537, batch_loss_s: 0.3497, time:4.8976, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [380/3125], step: 3505, 6.819 samples/sec, batch_loss: 0.3830, batch_loss_c: 0.3997, batch_loss_s: 0.3443, time:5.8658, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [390/3125], step: 3515, 7.128 samples/sec, batch_loss: 0.0813, batch_loss_c: 0.0789, batch_loss_s: 0.0871, time:5.6120, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [400/3125], step: 3525, 7.657 samples/sec, batch_loss: 0.1615, batch_loss_c: 0.1689, batch_loss_s: 0.1444, time:5.2242, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [410/3125], step: 3535, 8.490 samples/sec, batch_loss: 0.0773, batch_loss_c: 0.0754, batch_loss_s: 0.0817, time:4.7114, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [420/3125], step: 3545, 7.647 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0836, batch_loss_s: 0.1071, time:5.2306, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [430/3125], step: 3555, 7.873 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.0941, batch_loss_s: 0.0926, time:5.0809, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [440/3125], step: 3565, 8.545 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.2978, batch_loss_s: 0.3187, time:4.6813, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [450/3125], step: 3575, 7.490 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0984, batch_loss_s: 0.0946, time:5.3406, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:38:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [460/3125], step: 3585, 7.406 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0958, batch_loss_s: 0.1042, time:5.4007, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [470/3125], step: 3595, 8.169 samples/sec, batch_loss: 0.1293, batch_loss_c: 0.1476, batch_loss_s: 0.0867, time:4.8965, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [480/3125], step: 3605, 7.931 samples/sec, batch_loss: 0.2900, batch_loss_c: 0.2779, batch_loss_s: 0.3184, time:5.0437, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [490/3125], step: 3615, 7.356 samples/sec, batch_loss: 0.1407, batch_loss_c: 0.1371, batch_loss_s: 0.1489, time:5.4375, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [500/3125], step: 3625, 7.437 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1222, batch_loss_s: 0.1198, time:5.3786, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [510/3125], step: 3635, 7.397 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1060, batch_loss_s: 0.0958, time:5.4075, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [520/3125], step: 3645, 7.689 samples/sec, batch_loss: 0.3040, batch_loss_c: 0.2935, batch_loss_s: 0.3286, time:5.2023, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [530/3125], step: 3655, 7.060 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1223, batch_loss_s: 0.1064, time:5.6657, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [540/3125], step: 3665, 8.074 samples/sec, batch_loss: 0.3058, batch_loss_c: 0.2947, batch_loss_s: 0.3317, time:4.9541, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [550/3125], step: 3675, 7.249 samples/sec, batch_loss: 0.2112, batch_loss_c: 0.2391, batch_loss_s: 0.1462, time:5.5176, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [560/3125], step: 3685, 7.956 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0698, batch_loss_s: 0.0835, time:5.0277, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:39:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [570/3125], step: 3695, 7.848 samples/sec, batch_loss: 0.1562, batch_loss_c: 0.1795, batch_loss_s: 0.1017, time:5.0971, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [580/3125], step: 3705, 8.150 samples/sec, batch_loss: 0.1081, batch_loss_c: 0.1086, batch_loss_s: 0.1070, time:4.9081, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [590/3125], step: 3715, 8.361 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0711, batch_loss_s: 0.0873, time:4.7842, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [600/3125], step: 3725, 7.119 samples/sec, batch_loss: 0.3779, batch_loss_c: 0.3983, batch_loss_s: 0.3303, time:5.6186, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [610/3125], step: 3735, 8.325 samples/sec, batch_loss: 0.1506, batch_loss_c: 0.1693, batch_loss_s: 0.1072, time:4.8049, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [620/3125], step: 3745, 7.981 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1175, batch_loss_s: 0.1356, time:5.0122, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [630/3125], step: 3755, 7.822 samples/sec, batch_loss: 0.2325, batch_loss_c: 0.2528, batch_loss_s: 0.1853, time:5.1136, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [640/3125], step: 3765, 8.279 samples/sec, batch_loss: 0.0586, batch_loss_c: 0.0530, batch_loss_s: 0.0718, time:4.8318, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [650/3125], step: 3775, 8.317 samples/sec, batch_loss: 0.3722, batch_loss_c: 0.3755, batch_loss_s: 0.3645, time:4.8095, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [660/3125], step: 3785, 7.525 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1248, batch_loss_s: 0.0700, time:5.3155, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [670/3125], step: 3795, 8.179 samples/sec, batch_loss: 0.3105, batch_loss_c: 0.3043, batch_loss_s: 0.3249, time:4.8908, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [680/3125], step: 3805, 7.155 samples/sec, batch_loss: 0.4065, batch_loss_c: 0.4266, batch_loss_s: 0.3598, time:5.5902, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:40:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [690/3125], step: 3815, 7.208 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3278, batch_loss_s: 0.3101, time:5.5494, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [700/3125], step: 3825, 7.615 samples/sec, batch_loss: 0.1527, batch_loss_c: 0.1581, batch_loss_s: 0.1402, time:5.2527, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [710/3125], step: 3835, 8.780 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.0990, batch_loss_s: 0.0985, time:4.5557, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [720/3125], step: 3845, 8.358 samples/sec, batch_loss: 0.3149, batch_loss_c: 0.3164, batch_loss_s: 0.3116, time:4.7856, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [730/3125], step: 3855, 6.930 samples/sec, batch_loss: 0.1792, batch_loss_c: 0.1779, batch_loss_s: 0.1821, time:5.7717, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [740/3125], step: 3865, 8.373 samples/sec, batch_loss: 0.1582, batch_loss_c: 0.1746, batch_loss_s: 0.1200, time:4.7772, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [750/3125], step: 3875, 7.616 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0911, batch_loss_s: 0.0760, time:5.2523, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [760/3125], step: 3885, 7.793 samples/sec, batch_loss: 0.0589, batch_loss_c: 0.0524, batch_loss_s: 0.0743, time:5.1329, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [770/3125], step: 3895, 7.336 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0703, batch_loss_s: 0.0733, time:5.4528, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [780/3125], step: 3905, 7.743 samples/sec, batch_loss: 0.3660, batch_loss_c: 0.3733, batch_loss_s: 0.3489, time:5.1658, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [790/3125], step: 3915, 7.399 samples/sec, batch_loss: 0.5991, batch_loss_c: 0.5902, batch_loss_s: 0.6197, time:5.4060, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:41:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [800/3125], step: 3925, 7.508 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1069, batch_loss_s: 0.1211, time:5.3274, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [810/3125], step: 3935, 7.922 samples/sec, batch_loss: 0.3579, batch_loss_c: 0.3572, batch_loss_s: 0.3596, time:5.0493, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [820/3125], step: 3945, 7.600 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1015, batch_loss_s: 0.1036, time:5.2633, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [830/3125], step: 3955, 7.574 samples/sec, batch_loss: 0.3536, batch_loss_c: 0.3712, batch_loss_s: 0.3125, time:5.2810, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [840/3125], step: 3965, 7.658 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1222, batch_loss_s: 0.0985, time:5.2236, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [850/3125], step: 3975, 7.457 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0818, batch_loss_s: 0.0885, time:5.3642, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [860/3125], step: 3985, 7.589 samples/sec, batch_loss: 0.2267, batch_loss_c: 0.2791, batch_loss_s: 0.1043, time:5.2710, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [870/3125], step: 3995, 7.398 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0719, batch_loss_s: 0.0875, time:5.4068, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [880/3125], step: 4005, 8.226 samples/sec, batch_loss: 0.1681, batch_loss_c: 0.1872, batch_loss_s: 0.1235, time:4.8627, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [890/3125], step: 4015, 8.199 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0786, batch_loss_s: 0.0805, time:4.8788, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [900/3125], step: 4025, 7.872 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1220, batch_loss_s: 0.1042, time:5.0810, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [910/3125], step: 4035, 8.786 samples/sec, batch_loss: 0.3342, batch_loss_c: 0.3338, batch_loss_s: 0.3352, time:4.5529, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:42:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [920/3125], step: 4045, 7.788 samples/sec, batch_loss: 0.3525, batch_loss_c: 0.3564, batch_loss_s: 0.3433, time:5.1363, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [930/3125], step: 4055, 7.832 samples/sec, batch_loss: 0.5030, batch_loss_c: 0.4866, batch_loss_s: 0.5411, time:5.1073, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [940/3125], step: 4065, 7.428 samples/sec, batch_loss: 0.1582, batch_loss_c: 0.1657, batch_loss_s: 0.1408, time:5.3850, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [950/3125], step: 4075, 7.594 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1235, batch_loss_s: 0.0896, time:5.2671, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [960/3125], step: 4085, 8.463 samples/sec, batch_loss: 0.3577, batch_loss_c: 0.3270, batch_loss_s: 0.4295, time:4.7264, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [970/3125], step: 4095, 8.116 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1067, batch_loss_s: 0.1090, time:4.9288, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [980/3125], step: 4105, 7.785 samples/sec, batch_loss: 0.1540, batch_loss_c: 0.1571, batch_loss_s: 0.1468, time:5.1379, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [990/3125], step: 4115, 6.310 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0791, batch_loss_s: 0.0810, time:6.3394, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1000/3125], step: 4125, 8.454 samples/sec, batch_loss: 0.1573, batch_loss_c: 0.1595, batch_loss_s: 0.1524, time:4.7315, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1010/3125], step: 4135, 8.439 samples/sec, batch_loss: 0.5714, batch_loss_c: 0.5721, batch_loss_s: 0.5699, time:4.7398, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1020/3125], step: 4145, 8.254 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1082, batch_loss_s: 0.1051, time:4.8464, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1030/3125], step: 4155, 7.315 samples/sec, batch_loss: 0.1335, batch_loss_c: 0.1627, batch_loss_s: 0.0656, time:5.4683, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:43:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1040/3125], step: 4165, 7.470 samples/sec, batch_loss: 0.1829, batch_loss_c: 0.1960, batch_loss_s: 0.1525, time:5.3548, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1050/3125], step: 4175, 8.443 samples/sec, batch_loss: 0.1731, batch_loss_c: 0.1690, batch_loss_s: 0.1826, time:4.7378, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1060/3125], step: 4185, 7.379 samples/sec, batch_loss: 0.3493, batch_loss_c: 0.3561, batch_loss_s: 0.3333, time:5.4208, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1070/3125], step: 4195, 8.431 samples/sec, batch_loss: 0.0580, batch_loss_c: 0.0551, batch_loss_s: 0.0648, time:4.7446, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1080/3125], step: 4205, 8.151 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1177, batch_loss_s: 0.0878, time:4.9075, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1090/3125], step: 4215, 7.530 samples/sec, batch_loss: 0.3485, batch_loss_c: 0.3542, batch_loss_s: 0.3353, time:5.3123, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1100/3125], step: 4225, 7.679 samples/sec, batch_loss: 0.1333, batch_loss_c: 0.1419, batch_loss_s: 0.1134, time:5.2093, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1110/3125], step: 4235, 7.821 samples/sec, batch_loss: 0.1269, batch_loss_c: 0.1317, batch_loss_s: 0.1158, time:5.1147, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1120/3125], step: 4245, 8.434 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1419, batch_loss_s: 0.1513, time:4.7427, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1130/3125], step: 4255, 8.046 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0697, batch_loss_s: 0.0786, time:4.9714, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1140/3125], step: 4265, 7.023 samples/sec, batch_loss: 0.2998, batch_loss_c: 0.3014, batch_loss_s: 0.2960, time:5.6954, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:44:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1150/3125], step: 4275, 7.805 samples/sec, batch_loss: 0.3075, batch_loss_c: 0.3009, batch_loss_s: 0.3230, time:5.1250, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1160/3125], step: 4285, 7.555 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1061, batch_loss_s: 0.0979, time:5.2948, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1170/3125], step: 4295, 7.059 samples/sec, batch_loss: 0.0948, batch_loss_c: 0.1009, batch_loss_s: 0.0804, time:5.6668, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1180/3125], step: 4305, 7.380 samples/sec, batch_loss: 0.1458, batch_loss_c: 0.1484, batch_loss_s: 0.1397, time:5.4203, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1190/3125], step: 4315, 7.013 samples/sec, batch_loss: 0.1605, batch_loss_c: 0.1664, batch_loss_s: 0.1469, time:5.7034, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1200/3125], step: 4325, 7.291 samples/sec, batch_loss: 0.1316, batch_loss_c: 0.1305, batch_loss_s: 0.1344, time:5.4866, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1210/3125], step: 4335, 7.632 samples/sec, batch_loss: 0.2314, batch_loss_c: 0.2864, batch_loss_s: 0.1030, time:5.2411, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1220/3125], step: 4345, 8.017 samples/sec, batch_loss: 0.1272, batch_loss_c: 0.1390, batch_loss_s: 0.0998, time:4.9895, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1230/3125], step: 4355, 8.568 samples/sec, batch_loss: 0.3701, batch_loss_c: 0.3778, batch_loss_s: 0.3522, time:4.6684, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1240/3125], step: 4365, 8.058 samples/sec, batch_loss: 0.2487, batch_loss_c: 0.2378, batch_loss_s: 0.2741, time:4.9640, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1250/3125], step: 4375, 8.043 samples/sec, batch_loss: 0.3251, batch_loss_c: 0.3235, batch_loss_s: 0.3290, time:4.9732, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1260/3125], step: 4385, 7.178 samples/sec, batch_loss: 0.2161, batch_loss_c: 0.2540, batch_loss_s: 0.1277, time:5.5724, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:45:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1270/3125], step: 4395, 7.063 samples/sec, batch_loss: 0.1431, batch_loss_c: 0.1571, batch_loss_s: 0.1105, time:5.6634, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1280/3125], step: 4405, 8.588 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0672, batch_loss_s: 0.0857, time:4.6578, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1290/3125], step: 4415, 6.873 samples/sec, batch_loss: 0.0734, batch_loss_c: 0.0734, batch_loss_s: 0.0735, time:5.8195, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1300/3125], step: 4425, 8.016 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.1019, batch_loss_s: 0.0800, time:4.9899, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1310/3125], step: 4435, 7.733 samples/sec, batch_loss: 0.1340, batch_loss_c: 0.1341, batch_loss_s: 0.1335, time:5.1727, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1320/3125], step: 4445, 7.907 samples/sec, batch_loss: 0.3246, batch_loss_c: 0.3170, batch_loss_s: 0.3423, time:5.0588, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1330/3125], step: 4455, 8.097 samples/sec, batch_loss: 0.0579, batch_loss_c: 0.0575, batch_loss_s: 0.0587, time:4.9404, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1340/3125], step: 4465, 7.828 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0861, batch_loss_s: 0.0936, time:5.1096, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1350/3125], step: 4475, 7.577 samples/sec, batch_loss: 0.2294, batch_loss_c: 0.2022, batch_loss_s: 0.2928, time:5.2790, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1360/3125], step: 4485, 7.425 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1232, batch_loss_s: 0.1226, time:5.3869, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1370/3125], step: 4495, 6.957 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0810, batch_loss_s: 0.0916, time:5.7497, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:46:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1380/3125], step: 4505, 8.711 samples/sec, batch_loss: 0.2191, batch_loss_c: 0.2132, batch_loss_s: 0.2330, time:4.5919, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1390/3125], step: 4515, 6.707 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0960, batch_loss_s: 0.0820, time:5.9641, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1400/3125], step: 4525, 7.322 samples/sec, batch_loss: 0.3881, batch_loss_c: 0.3961, batch_loss_s: 0.3694, time:5.4632, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1410/3125], step: 4535, 7.444 samples/sec, batch_loss: 0.0641, batch_loss_c: 0.0624, batch_loss_s: 0.0682, time:5.3737, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1420/3125], step: 4545, 7.086 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.1015, batch_loss_s: 0.0898, time:5.6448, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1430/3125], step: 4555, 7.741 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.0949, batch_loss_s: 0.1156, time:5.1676, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1440/3125], step: 4565, 7.389 samples/sec, batch_loss: 0.2834, batch_loss_c: 0.2610, batch_loss_s: 0.3355, time:5.4135, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1450/3125], step: 4575, 7.648 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.0864, batch_loss_s: 0.1163, time:5.2298, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1460/3125], step: 4585, 7.569 samples/sec, batch_loss: 0.1857, batch_loss_c: 0.2052, batch_loss_s: 0.1403, time:5.2847, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1470/3125], step: 4595, 7.449 samples/sec, batch_loss: 0.3542, batch_loss_c: 0.3518, batch_loss_s: 0.3600, time:5.3699, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1480/3125], step: 4605, 7.945 samples/sec, batch_loss: 0.3098, batch_loss_c: 0.3309, batch_loss_s: 0.2606, time:5.0345, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1490/3125], step: 4615, 8.024 samples/sec, batch_loss: 0.3407, batch_loss_c: 0.3295, batch_loss_s: 0.3667, time:4.9851, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:47:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1500/3125], step: 4625, 8.897 samples/sec, batch_loss: 0.3589, batch_loss_c: 0.3673, batch_loss_s: 0.3393, time:4.4960, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1510/3125], step: 4635, 7.845 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0696, batch_loss_s: 0.0868, time:5.0986, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1520/3125], step: 4645, 8.592 samples/sec, batch_loss: 0.0921, batch_loss_c: 0.0912, batch_loss_s: 0.0942, time:4.6553, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1530/3125], step: 4655, 7.845 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1139, batch_loss_s: 0.1053, time:5.0987, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1540/3125], step: 4665, 7.721 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1024, batch_loss_s: 0.1129, time:5.1805, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1550/3125], step: 4675, 8.115 samples/sec, batch_loss: 0.1223, batch_loss_c: 0.1258, batch_loss_s: 0.1144, time:4.9291, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1560/3125], step: 4685, 8.595 samples/sec, batch_loss: 0.3741, batch_loss_c: 0.3723, batch_loss_s: 0.3782, time:4.6541, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1570/3125], step: 4695, 8.179 samples/sec, batch_loss: 0.1065, batch_loss_c: 0.1066, batch_loss_s: 0.1063, time:4.8904, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1580/3125], step: 4705, 8.033 samples/sec, batch_loss: 0.1428, batch_loss_c: 0.1355, batch_loss_s: 0.1598, time:4.9793, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1590/3125], step: 4715, 7.368 samples/sec, batch_loss: 0.1360, batch_loss_c: 0.1351, batch_loss_s: 0.1381, time:5.4288, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1600/3125], step: 4725, 8.053 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1498, batch_loss_s: 0.1058, time:4.9671, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1610/3125], step: 4735, 8.292 samples/sec, batch_loss: 0.1870, batch_loss_c: 0.1917, batch_loss_s: 0.1763, time:4.8242, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:48:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1620/3125], step: 4745, 7.591 samples/sec, batch_loss: 0.1638, batch_loss_c: 0.1669, batch_loss_s: 0.1564, time:5.2695, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1630/3125], step: 4755, 8.361 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0777, batch_loss_s: 0.1071, time:4.7840, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1640/3125], step: 4765, 7.408 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0779, batch_loss_s: 0.0778, time:5.3997, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1650/3125], step: 4775, 7.146 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0831, batch_loss_s: 0.0856, time:5.5972, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1660/3125], step: 4785, 7.003 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0707, batch_loss_s: 0.0847, time:5.7119, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1670/3125], step: 4795, 7.195 samples/sec, batch_loss: 0.3551, batch_loss_c: 0.3570, batch_loss_s: 0.3507, time:5.5591, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1680/3125], step: 4805, 7.240 samples/sec, batch_loss: 0.3567, batch_loss_c: 0.3600, batch_loss_s: 0.3491, time:5.5250, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1690/3125], step: 4815, 6.895 samples/sec, batch_loss: 0.1685, batch_loss_c: 0.2033, batch_loss_s: 0.0874, time:5.8015, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1700/3125], step: 4825, 7.227 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0727, batch_loss_s: 0.0939, time:5.5350, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1710/3125], step: 4835, 7.598 samples/sec, batch_loss: 0.0623, batch_loss_c: 0.0574, batch_loss_s: 0.0737, time:5.2649, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1720/3125], step: 4845, 7.982 samples/sec, batch_loss: 0.2989, batch_loss_c: 0.2946, batch_loss_s: 0.3089, time:5.0112, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:49:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1730/3125], step: 4855, 6.013 samples/sec, batch_loss: 0.1902, batch_loss_c: 0.2177, batch_loss_s: 0.1261, time:6.6520, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1740/3125], step: 4865, 8.047 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1021, batch_loss_s: 0.1057, time:4.9706, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1750/3125], step: 4875, 6.632 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0749, batch_loss_s: 0.1040, time:6.0316, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1760/3125], step: 4885, 7.992 samples/sec, batch_loss: 0.1330, batch_loss_c: 0.1430, batch_loss_s: 0.1097, time:5.0051, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1770/3125], step: 4895, 6.601 samples/sec, batch_loss: 0.3509, batch_loss_c: 0.3568, batch_loss_s: 0.3374, time:6.0593, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1780/3125], step: 4905, 7.991 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.0996, batch_loss_s: 0.1085, time:5.0056, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1790/3125], step: 4915, 7.434 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.1113, batch_loss_s: 0.0801, time:5.3808, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1800/3125], step: 4925, 7.568 samples/sec, batch_loss: 0.2529, batch_loss_c: 0.2844, batch_loss_s: 0.1795, time:5.2855, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1810/3125], step: 4935, 8.082 samples/sec, batch_loss: 0.5049, batch_loss_c: 0.4860, batch_loss_s: 0.5488, time:4.9491, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1820/3125], step: 4945, 8.713 samples/sec, batch_loss: 0.0768, batch_loss_c: 0.0770, batch_loss_s: 0.0763, time:4.5908, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1830/3125], step: 4955, 8.269 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0826, batch_loss_s: 0.1015, time:4.8376, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:50:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1840/3125], step: 4965, 8.424 samples/sec, batch_loss: 0.3422, batch_loss_c: 0.3491, batch_loss_s: 0.3260, time:4.7485, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1850/3125], step: 4975, 8.440 samples/sec, batch_loss: 0.2681, batch_loss_c: 0.2505, batch_loss_s: 0.3092, time:4.7392, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1860/3125], step: 4985, 8.777 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0813, batch_loss_s: 0.0869, time:4.5572, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1870/3125], step: 4995, 8.058 samples/sec, batch_loss: 0.1339, batch_loss_c: 0.1527, batch_loss_s: 0.0901, time:4.9639, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1880/3125], step: 5005, 8.269 samples/sec, batch_loss: 0.3053, batch_loss_c: 0.3040, batch_loss_s: 0.3084, time:4.8371, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1890/3125], step: 5015, 7.004 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0708, batch_loss_s: 0.0748, time:5.7110, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1900/3125], step: 5025, 8.370 samples/sec, batch_loss: 0.0770, batch_loss_c: 0.0732, batch_loss_s: 0.0859, time:4.7790, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1910/3125], step: 5035, 8.105 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0621, batch_loss_s: 0.0863, time:4.9351, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1920/3125], step: 5045, 7.564 samples/sec, batch_loss: 0.2993, batch_loss_c: 0.2965, batch_loss_s: 0.3057, time:5.2882, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1930/3125], step: 5055, 7.230 samples/sec, batch_loss: 0.2487, batch_loss_c: 0.2457, batch_loss_s: 0.2558, time:5.5323, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1940/3125], step: 5065, 6.984 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0670, batch_loss_s: 0.0829, time:5.7277, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1950/3125], step: 5075, 8.088 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1046, batch_loss_s: 0.1106, time:4.9456, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:51:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1960/3125], step: 5085, 8.168 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0660, batch_loss_s: 0.0937, time:4.8969, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1970/3125], step: 5095, 6.710 samples/sec, batch_loss: 0.4651, batch_loss_c: 0.5013, batch_loss_s: 0.3807, time:5.9611, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1980/3125], step: 5105, 7.833 samples/sec, batch_loss: 0.1518, batch_loss_c: 0.1744, batch_loss_s: 0.0992, time:5.1065, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1990/3125], step: 5115, 6.284 samples/sec, batch_loss: 0.1100, batch_loss_c: 0.1087, batch_loss_s: 0.1132, time:6.3658, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2000/3125], step: 5125, 7.966 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2783, batch_loss_s: 0.3253, time:5.0215, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2010/3125], step: 5135, 8.167 samples/sec, batch_loss: 0.3654, batch_loss_c: 0.3684, batch_loss_s: 0.3585, time:4.8977, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2020/3125], step: 5145, 7.891 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1132, batch_loss_s: 0.0860, time:5.0691, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2030/3125], step: 5155, 7.499 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1314, batch_loss_s: 0.1064, time:5.3341, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2040/3125], step: 5165, 6.636 samples/sec, batch_loss: 0.1860, batch_loss_c: 0.2302, batch_loss_s: 0.0830, time:6.0279, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2050/3125], step: 5175, 8.097 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.3042, batch_loss_s: 0.3059, time:4.9399, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2060/3125], step: 5185, 8.778 samples/sec, batch_loss: 0.1188, batch_loss_c: 0.1097, batch_loss_s: 0.1400, time:4.5570, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:52:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2070/3125], step: 5195, 8.102 samples/sec, batch_loss: 0.1214, batch_loss_c: 0.1264, batch_loss_s: 0.1097, time:4.9369, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2080/3125], step: 5205, 7.778 samples/sec, batch_loss: 0.2969, batch_loss_c: 0.2926, batch_loss_s: 0.3069, time:5.1424, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2090/3125], step: 5215, 7.790 samples/sec, batch_loss: 0.1187, batch_loss_c: 0.1190, batch_loss_s: 0.1180, time:5.1350, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2100/3125], step: 5225, 7.899 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0863, batch_loss_s: 0.1103, time:5.0638, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2110/3125], step: 5235, 8.469 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1075, batch_loss_s: 0.1314, time:4.7231, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2120/3125], step: 5245, 8.271 samples/sec, batch_loss: 0.2497, batch_loss_c: 0.2741, batch_loss_s: 0.1927, time:4.8362, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2130/3125], step: 5255, 7.138 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0981, batch_loss_s: 0.0778, time:5.6036, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2140/3125], step: 5265, 7.761 samples/sec, batch_loss: 0.3417, batch_loss_c: 0.3542, batch_loss_s: 0.3126, time:5.1543, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2150/3125], step: 5275, 8.917 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1179, batch_loss_s: 0.0774, time:4.4856, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2160/3125], step: 5285, 8.007 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1138, batch_loss_s: 0.1297, time:4.9958, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2170/3125], step: 5295, 7.843 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0731, batch_loss_s: 0.0885, time:5.1000, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2180/3125], step: 5305, 7.951 samples/sec, batch_loss: 0.3483, batch_loss_c: 0.3526, batch_loss_s: 0.3383, time:5.0305, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:53:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2190/3125], step: 5315, 8.263 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0762, batch_loss_s: 0.0877, time:4.8408, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2200/3125], step: 5325, 8.249 samples/sec, batch_loss: 0.1927, batch_loss_c: 0.2268, batch_loss_s: 0.1133, time:4.8490, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2210/3125], step: 5335, 8.045 samples/sec, batch_loss: 0.3537, batch_loss_c: 0.3560, batch_loss_s: 0.3482, time:4.9722, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2220/3125], step: 5345, 8.303 samples/sec, batch_loss: 0.2671, batch_loss_c: 0.2563, batch_loss_s: 0.2923, time:4.8178, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2230/3125], step: 5355, 7.755 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1108, batch_loss_s: 0.1108, time:5.1581, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2240/3125], step: 5365, 8.052 samples/sec, batch_loss: 0.1901, batch_loss_c: 0.2051, batch_loss_s: 0.1550, time:4.9680, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2250/3125], step: 5375, 7.297 samples/sec, batch_loss: 0.1511, batch_loss_c: 0.1616, batch_loss_s: 0.1267, time:5.4814, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2260/3125], step: 5385, 7.998 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.1014, batch_loss_s: 0.0855, time:5.0010, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2270/3125], step: 5395, 6.900 samples/sec, batch_loss: 0.3143, batch_loss_c: 0.3124, batch_loss_s: 0.3188, time:5.7970, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2280/3125], step: 5405, 8.151 samples/sec, batch_loss: 0.1377, batch_loss_c: 0.1217, batch_loss_s: 0.1753, time:4.9071, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2290/3125], step: 5415, 7.596 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1100, batch_loss_s: 0.0960, time:5.2661, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2300/3125], step: 5425, 7.963 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0957, batch_loss_s: 0.0819, time:5.0234, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:54:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2310/3125], step: 5435, 7.818 samples/sec, batch_loss: 0.0513, batch_loss_c: 0.0480, batch_loss_s: 0.0590, time:5.1162, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2320/3125], step: 5445, 8.111 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1551, batch_loss_s: 0.1191, time:4.9314, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2330/3125], step: 5455, 7.095 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.3030, batch_loss_s: 0.3041, time:5.6378, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2340/3125], step: 5465, 7.970 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1237, batch_loss_s: 0.1019, time:5.0190, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2350/3125], step: 5475, 8.613 samples/sec, batch_loss: 0.2846, batch_loss_c: 0.2775, batch_loss_s: 0.3013, time:4.6442, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2360/3125], step: 5485, 8.627 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1533, batch_loss_s: 0.0721, time:4.6366, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2370/3125], step: 5495, 7.717 samples/sec, batch_loss: 0.2848, batch_loss_c: 0.2716, batch_loss_s: 0.3157, time:5.1835, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2380/3125], step: 5505, 8.079 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3410, batch_loss_s: 0.3281, time:4.9510, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2390/3125], step: 5515, 8.044 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3113, batch_loss_s: 0.3332, time:4.9729, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2400/3125], step: 5525, 7.349 samples/sec, batch_loss: 0.3559, batch_loss_c: 0.3588, batch_loss_s: 0.3491, time:5.4432, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2410/3125], step: 5535, 7.948 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0953, batch_loss_s: 0.0798, time:5.0326, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2420/3125], step: 5545, 8.013 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0754, batch_loss_s: 0.0945, time:4.9916, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:55:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2430/3125], step: 5555, 7.612 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0563, batch_loss_s: 0.0782, time:5.2551, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2440/3125], step: 5565, 8.314 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0754, batch_loss_s: 0.0948, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2450/3125], step: 5575, 8.425 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0817, batch_loss_s: 0.0880, time:4.7479, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2460/3125], step: 5585, 7.426 samples/sec, batch_loss: 0.0687, batch_loss_c: 0.0631, batch_loss_s: 0.0818, time:5.3863, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2470/3125], step: 5595, 8.069 samples/sec, batch_loss: 0.3038, batch_loss_c: 0.3004, batch_loss_s: 0.3119, time:4.9571, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2480/3125], step: 5605, 8.857 samples/sec, batch_loss: 0.0597, batch_loss_c: 0.0561, batch_loss_s: 0.0682, time:4.5160, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2490/3125], step: 5615, 7.492 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0723, batch_loss_s: 0.0867, time:5.3389, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2500/3125], step: 5625, 8.896 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1785, batch_loss_s: 0.1140, time:4.4962, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2510/3125], step: 5635, 8.226 samples/sec, batch_loss: 0.3190, batch_loss_c: 0.3129, batch_loss_s: 0.3334, time:4.8626, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2520/3125], step: 5645, 7.347 samples/sec, batch_loss: 0.1477, batch_loss_c: 0.1483, batch_loss_s: 0.1464, time:5.4446, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2530/3125], step: 5655, 7.002 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1250, batch_loss_s: 0.1117, time:5.7123, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2540/3125], step: 5665, 8.568 samples/sec, batch_loss: 0.0588, batch_loss_c: 0.0525, batch_loss_s: 0.0737, time:4.6686, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:56:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2550/3125], step: 5675, 8.100 samples/sec, batch_loss: 0.0822, batch_loss_c: 0.0755, batch_loss_s: 0.0978, time:4.9384, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2560/3125], step: 5685, 7.566 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0866, batch_loss_s: 0.1016, time:5.2869, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2570/3125], step: 5695, 7.182 samples/sec, batch_loss: 0.1325, batch_loss_c: 0.1425, batch_loss_s: 0.1091, time:5.5696, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2580/3125], step: 5705, 8.004 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0740, batch_loss_s: 0.0792, time:4.9976, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2590/3125], step: 5715, 7.796 samples/sec, batch_loss: 0.1109, batch_loss_c: 0.1193, batch_loss_s: 0.0913, time:5.1306, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2600/3125], step: 5725, 7.743 samples/sec, batch_loss: 0.1490, batch_loss_c: 0.1634, batch_loss_s: 0.1155, time:5.1661, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2610/3125], step: 5735, 8.249 samples/sec, batch_loss: 0.1644, batch_loss_c: 0.1779, batch_loss_s: 0.1331, time:4.8492, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2620/3125], step: 5745, 7.232 samples/sec, batch_loss: 0.0976, batch_loss_c: 0.1033, batch_loss_s: 0.0843, time:5.5310, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2630/3125], step: 5755, 7.146 samples/sec, batch_loss: 0.3666, batch_loss_c: 0.3766, batch_loss_s: 0.3432, time:5.5972, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2640/3125], step: 5765, 7.467 samples/sec, batch_loss: 0.3697, batch_loss_c: 0.4004, batch_loss_s: 0.2980, time:5.3570, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2650/3125], step: 5775, 7.531 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1384, batch_loss_s: 0.1068, time:5.3115, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:57:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2660/3125], step: 5785, 8.052 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3117, batch_loss_s: 0.3190, time:4.9675, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2670/3125], step: 5795, 8.238 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.1124, batch_loss_s: 0.0888, time:4.8554, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2680/3125], step: 5805, 8.438 samples/sec, batch_loss: 0.1389, batch_loss_c: 0.1460, batch_loss_s: 0.1223, time:4.7406, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2690/3125], step: 5815, 7.783 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.1556, batch_loss_s: 0.1792, time:5.1394, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2700/3125], step: 5825, 8.822 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1264, batch_loss_s: 0.0950, time:4.5342, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2710/3125], step: 5835, 8.773 samples/sec, batch_loss: 0.5225, batch_loss_c: 0.5138, batch_loss_s: 0.5426, time:4.5595, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2720/3125], step: 5845, 8.687 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0776, batch_loss_s: 0.1031, time:4.6046, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2730/3125], step: 5855, 7.583 samples/sec, batch_loss: 0.3245, batch_loss_c: 0.3279, batch_loss_s: 0.3166, time:5.2752, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2740/3125], step: 5865, 8.125 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0714, batch_loss_s: 0.0694, time:4.9231, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2750/3125], step: 5875, 8.027 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0628, batch_loss_s: 0.0787, time:4.9829, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2760/3125], step: 5885, 7.863 samples/sec, batch_loss: 0.1756, batch_loss_c: 0.1991, batch_loss_s: 0.1208, time:5.0871, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2770/3125], step: 5895, 8.269 samples/sec, batch_loss: 0.1843, batch_loss_c: 0.1924, batch_loss_s: 0.1654, time:4.8373, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2780/3125], step: 5905, 7.787 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1292, batch_loss_s: 0.1194, time:5.1370, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:58:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2790/3125], step: 5915, 7.617 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0867, batch_loss_s: 0.0900, time:5.2516, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2800/3125], step: 5925, 8.237 samples/sec, batch_loss: 0.2913, batch_loss_c: 0.2885, batch_loss_s: 0.2976, time:4.8562, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2810/3125], step: 5935, 7.215 samples/sec, batch_loss: 0.3313, batch_loss_c: 0.3346, batch_loss_s: 0.3237, time:5.5441, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2820/3125], step: 5945, 7.495 samples/sec, batch_loss: 0.2964, batch_loss_c: 0.2875, batch_loss_s: 0.3172, time:5.3368, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2830/3125], step: 5955, 6.982 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1217, batch_loss_s: 0.1170, time:5.7291, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2840/3125], step: 5965, 7.071 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1299, batch_loss_s: 0.1023, time:5.6566, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2850/3125], step: 5975, 8.014 samples/sec, batch_loss: 0.1971, batch_loss_c: 0.1896, batch_loss_s: 0.2145, time:4.9910, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2860/3125], step: 5985, 7.409 samples/sec, batch_loss: 0.3415, batch_loss_c: 0.3395, batch_loss_s: 0.3462, time:5.3992, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2870/3125], step: 5995, 7.248 samples/sec, batch_loss: 0.3631, batch_loss_c: 0.3822, batch_loss_s: 0.3184, time:5.5186, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2880/3125], step: 6005, 8.138 samples/sec, batch_loss: 0.1527, batch_loss_c: 0.1651, batch_loss_s: 0.1237, time:4.9153, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2890/3125], step: 6015, 7.287 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0816, batch_loss_s: 0.0965, time:5.4891, lr:0.0001\u001b[0m\n",
            "2019-11-23 11:59:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2900/3125], step: 6025, 7.776 samples/sec, batch_loss: 0.2142, batch_loss_c: 0.2217, batch_loss_s: 0.1967, time:5.1439, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2910/3125], step: 6035, 7.519 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1014, batch_loss_s: 0.0882, time:5.3198, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2920/3125], step: 6045, 8.078 samples/sec, batch_loss: 0.5369, batch_loss_c: 0.5370, batch_loss_s: 0.5367, time:4.9517, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2930/3125], step: 6055, 7.606 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1180, batch_loss_s: 0.1199, time:5.2587, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2940/3125], step: 6065, 6.377 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.0937, batch_loss_s: 0.1106, time:6.2728, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2950/3125], step: 6075, 7.604 samples/sec, batch_loss: 0.3856, batch_loss_c: 0.4002, batch_loss_s: 0.3514, time:5.2605, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2960/3125], step: 6085, 7.339 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0733, batch_loss_s: 0.0787, time:5.4503, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2970/3125], step: 6095, 7.417 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1184, batch_loss_s: 0.1271, time:5.3931, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2980/3125], step: 6105, 6.992 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0708, batch_loss_s: 0.0755, time:5.7206, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2990/3125], step: 6115, 7.531 samples/sec, batch_loss: 0.0607, batch_loss_c: 0.0523, batch_loss_s: 0.0804, time:5.3114, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3000/3125], step: 6125, 7.570 samples/sec, batch_loss: 0.3737, batch_loss_c: 0.3779, batch_loss_s: 0.3640, time:5.2843, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:00:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3010/3125], step: 6135, 6.559 samples/sec, batch_loss: 0.2335, batch_loss_c: 0.2328, batch_loss_s: 0.2350, time:6.0981, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3020/3125], step: 6145, 7.538 samples/sec, batch_loss: 0.1656, batch_loss_c: 0.2002, batch_loss_s: 0.0850, time:5.3067, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3030/3125], step: 6155, 7.216 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.1068, batch_loss_s: 0.0906, time:5.5432, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3040/3125], step: 6165, 7.760 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0627, batch_loss_s: 0.0748, time:5.1546, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3050/3125], step: 6175, 7.854 samples/sec, batch_loss: 0.4524, batch_loss_c: 0.4157, batch_loss_s: 0.5379, time:5.0928, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3060/3125], step: 6185, 7.039 samples/sec, batch_loss: 0.0730, batch_loss_c: 0.0777, batch_loss_s: 0.0621, time:5.6824, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3070/3125], step: 6195, 7.779 samples/sec, batch_loss: 0.1080, batch_loss_c: 0.1244, batch_loss_s: 0.0698, time:5.1423, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3080/3125], step: 6205, 6.655 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.0946, batch_loss_s: 0.1030, time:6.0104, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3090/3125], step: 6215, 7.562 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1143, batch_loss_s: 0.0608, time:5.2894, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3100/3125], step: 6225, 7.663 samples/sec, batch_loss: 0.1103, batch_loss_c: 0.1083, batch_loss_s: 0.1152, time:5.2196, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3110/3125], step: 6235, 10.056 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0866, batch_loss_s: 0.0998, time:3.9778, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3120/3125], step: 6245, 10.199 samples/sec, batch_loss: 0.1536, batch_loss_c: 0.1762, batch_loss_s: 0.1011, time:3.9221, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:01:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], train_loss: 0.1906, time: 1626.5395, lr: 0.0001\u001b[0m\n",
            "2019-11-23 12:02:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [0/3125], step: 6250, 7.655 samples/sec, batch_loss: 0.1696, batch_loss_c: 0.1997, batch_loss_s: 0.0992, time:5.2253, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [10/3125], step: 6260, 5.632 samples/sec, batch_loss: 0.1995, batch_loss_c: 0.2488, batch_loss_s: 0.0846, time:7.1026, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [20/3125], step: 6270, 8.779 samples/sec, batch_loss: 0.1102, batch_loss_c: 0.1082, batch_loss_s: 0.1147, time:4.5562, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [30/3125], step: 6280, 8.297 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1219, batch_loss_s: 0.1124, time:4.8209, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [40/3125], step: 6290, 7.466 samples/sec, batch_loss: 0.2590, batch_loss_c: 0.2325, batch_loss_s: 0.3208, time:5.3579, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [50/3125], step: 6300, 8.677 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1610, batch_loss_s: 0.1036, time:4.6099, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [60/3125], step: 6310, 7.419 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0757, batch_loss_s: 0.0829, time:5.3919, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [70/3125], step: 6320, 7.435 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1018, batch_loss_s: 0.1183, time:5.3798, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [80/3125], step: 6330, 7.556 samples/sec, batch_loss: 0.0975, batch_loss_c: 0.1026, batch_loss_s: 0.0857, time:5.2935, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [90/3125], step: 6340, 8.225 samples/sec, batch_loss: 0.1968, batch_loss_c: 0.2329, batch_loss_s: 0.1123, time:4.8630, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:02:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [100/3125], step: 6350, 7.449 samples/sec, batch_loss: 0.3304, batch_loss_c: 0.3672, batch_loss_s: 0.2444, time:5.3700, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [110/3125], step: 6360, 7.328 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1522, batch_loss_s: 0.1451, time:5.4582, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [120/3125], step: 6370, 6.605 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1470, batch_loss_s: 0.1226, time:6.0562, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [130/3125], step: 6380, 7.222 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0897, batch_loss_s: 0.0918, time:5.5385, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [140/3125], step: 6390, 8.044 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1113, batch_loss_s: 0.1339, time:4.9728, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [150/3125], step: 6400, 7.533 samples/sec, batch_loss: 0.3486, batch_loss_c: 0.3523, batch_loss_s: 0.3401, time:5.3103, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [160/3125], step: 6410, 7.652 samples/sec, batch_loss: 0.1359, batch_loss_c: 0.1532, batch_loss_s: 0.0958, time:5.2275, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [170/3125], step: 6420, 8.127 samples/sec, batch_loss: 0.3570, batch_loss_c: 0.3558, batch_loss_s: 0.3596, time:4.9219, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [180/3125], step: 6430, 7.941 samples/sec, batch_loss: 0.5137, batch_loss_c: 0.5009, batch_loss_s: 0.5435, time:5.0369, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [190/3125], step: 6440, 7.876 samples/sec, batch_loss: 0.3398, batch_loss_c: 0.3463, batch_loss_s: 0.3246, time:5.0786, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [200/3125], step: 6450, 8.095 samples/sec, batch_loss: 0.4672, batch_loss_c: 0.4699, batch_loss_s: 0.4610, time:4.9414, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [210/3125], step: 6460, 7.447 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.0989, batch_loss_s: 0.1087, time:5.3716, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:03:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [220/3125], step: 6470, 7.568 samples/sec, batch_loss: 0.1720, batch_loss_c: 0.1951, batch_loss_s: 0.1180, time:5.2857, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [230/3125], step: 6480, 7.400 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1087, batch_loss_s: 0.1099, time:5.4056, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [240/3125], step: 6490, 8.410 samples/sec, batch_loss: 0.1067, batch_loss_c: 0.1103, batch_loss_s: 0.0983, time:4.7560, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [250/3125], step: 6500, 7.822 samples/sec, batch_loss: 0.0810, batch_loss_c: 0.0783, batch_loss_s: 0.0874, time:5.1141, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [260/3125], step: 6510, 7.779 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.1029, batch_loss_s: 0.0782, time:5.1420, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [270/3125], step: 6520, 7.964 samples/sec, batch_loss: 0.2991, batch_loss_c: 0.2950, batch_loss_s: 0.3085, time:5.0224, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [280/3125], step: 6530, 8.442 samples/sec, batch_loss: 0.1430, batch_loss_c: 0.1476, batch_loss_s: 0.1324, time:4.7384, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [290/3125], step: 6540, 8.287 samples/sec, batch_loss: 0.2472, batch_loss_c: 0.2446, batch_loss_s: 0.2534, time:4.8268, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [300/3125], step: 6550, 7.683 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1340, batch_loss_s: 0.1002, time:5.2065, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [310/3125], step: 6560, 7.258 samples/sec, batch_loss: 0.1322, batch_loss_c: 0.1423, batch_loss_s: 0.1084, time:5.5109, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [320/3125], step: 6570, 7.967 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0795, batch_loss_s: 0.0839, time:5.0205, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [330/3125], step: 6580, 7.997 samples/sec, batch_loss: 0.2976, batch_loss_c: 0.2942, batch_loss_s: 0.3055, time:5.0020, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:04:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [340/3125], step: 6590, 7.997 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0651, batch_loss_s: 0.0837, time:5.0022, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [350/3125], step: 6600, 7.583 samples/sec, batch_loss: 0.2604, batch_loss_c: 0.2440, batch_loss_s: 0.2988, time:5.2751, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [360/3125], step: 6610, 7.830 samples/sec, batch_loss: 0.2799, batch_loss_c: 0.2644, batch_loss_s: 0.3161, time:5.1085, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [370/3125], step: 6620, 7.226 samples/sec, batch_loss: 0.1067, batch_loss_c: 0.1040, batch_loss_s: 0.1130, time:5.5354, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [380/3125], step: 6630, 6.885 samples/sec, batch_loss: 0.1260, batch_loss_c: 0.1285, batch_loss_s: 0.1201, time:5.8100, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [390/3125], step: 6640, 6.781 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1156, batch_loss_s: 0.0821, time:5.8985, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [400/3125], step: 6650, 8.842 samples/sec, batch_loss: 0.0642, batch_loss_c: 0.0627, batch_loss_s: 0.0676, time:4.5239, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [410/3125], step: 6660, 7.612 samples/sec, batch_loss: 0.3490, batch_loss_c: 0.3526, batch_loss_s: 0.3406, time:5.2547, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [420/3125], step: 6670, 7.582 samples/sec, batch_loss: 0.2904, batch_loss_c: 0.3111, batch_loss_s: 0.2421, time:5.2755, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [430/3125], step: 6680, 7.793 samples/sec, batch_loss: 0.3198, batch_loss_c: 0.3164, batch_loss_s: 0.3276, time:5.1326, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [440/3125], step: 6690, 7.737 samples/sec, batch_loss: 0.0987, batch_loss_c: 0.0991, batch_loss_s: 0.0978, time:5.1702, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:05:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [450/3125], step: 6700, 8.908 samples/sec, batch_loss: 0.2880, batch_loss_c: 0.2798, batch_loss_s: 0.3071, time:4.4905, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [460/3125], step: 6710, 7.369 samples/sec, batch_loss: 0.2780, batch_loss_c: 0.2704, batch_loss_s: 0.2956, time:5.4283, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [470/3125], step: 6720, 8.721 samples/sec, batch_loss: 0.3834, batch_loss_c: 0.4068, batch_loss_s: 0.3285, time:4.5867, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [480/3125], step: 6730, 7.459 samples/sec, batch_loss: 0.0854, batch_loss_c: 0.0865, batch_loss_s: 0.0826, time:5.3625, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [490/3125], step: 6740, 7.393 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1024, batch_loss_s: 0.0881, time:5.4108, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [500/3125], step: 6750, 8.472 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3284, batch_loss_s: 0.3197, time:4.7216, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [510/3125], step: 6760, 7.893 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.1074, batch_loss_s: 0.0724, time:5.0675, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [520/3125], step: 6770, 7.948 samples/sec, batch_loss: 0.0814, batch_loss_c: 0.0784, batch_loss_s: 0.0883, time:5.0327, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [530/3125], step: 6780, 8.302 samples/sec, batch_loss: 0.0645, batch_loss_c: 0.0559, batch_loss_s: 0.0845, time:4.8184, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [540/3125], step: 6790, 7.320 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.0993, batch_loss_s: 0.1054, time:5.4648, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [550/3125], step: 6800, 8.099 samples/sec, batch_loss: 0.0551, batch_loss_c: 0.0519, batch_loss_s: 0.0628, time:4.9391, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [560/3125], step: 6810, 7.551 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.1072, batch_loss_s: 0.0810, time:5.2970, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:06:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [570/3125], step: 6820, 8.252 samples/sec, batch_loss: 0.1330, batch_loss_c: 0.1349, batch_loss_s: 0.1287, time:4.8472, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [580/3125], step: 6830, 8.696 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1202, batch_loss_s: 0.0889, time:4.5999, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [590/3125], step: 6840, 8.102 samples/sec, batch_loss: 0.2416, batch_loss_c: 0.2450, batch_loss_s: 0.2337, time:4.9373, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [600/3125], step: 6850, 6.950 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.0979, batch_loss_s: 0.1044, time:5.7556, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [610/3125], step: 6860, 8.342 samples/sec, batch_loss: 0.3275, batch_loss_c: 0.3291, batch_loss_s: 0.3239, time:4.7949, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [620/3125], step: 6870, 7.675 samples/sec, batch_loss: 0.2994, batch_loss_c: 0.3293, batch_loss_s: 0.2294, time:5.2119, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [630/3125], step: 6880, 8.278 samples/sec, batch_loss: 0.1354, batch_loss_c: 0.1432, batch_loss_s: 0.1171, time:4.8321, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [640/3125], step: 6890, 8.325 samples/sec, batch_loss: 0.1964, batch_loss_c: 0.2340, batch_loss_s: 0.1089, time:4.8048, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [650/3125], step: 6900, 8.376 samples/sec, batch_loss: 0.2967, batch_loss_c: 0.2915, batch_loss_s: 0.3087, time:4.7756, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [660/3125], step: 6910, 7.272 samples/sec, batch_loss: 0.0571, batch_loss_c: 0.0498, batch_loss_s: 0.0741, time:5.5002, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [670/3125], step: 6920, 8.404 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1311, batch_loss_s: 0.0789, time:4.7597, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [680/3125], step: 6930, 8.772 samples/sec, batch_loss: 0.1236, batch_loss_c: 0.1252, batch_loss_s: 0.1199, time:4.5602, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:07:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [690/3125], step: 6940, 7.562 samples/sec, batch_loss: 0.6861, batch_loss_c: 0.6482, batch_loss_s: 0.7746, time:5.2896, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [700/3125], step: 6950, 7.738 samples/sec, batch_loss: 0.1269, batch_loss_c: 0.1430, batch_loss_s: 0.0891, time:5.1692, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [710/3125], step: 6960, 7.707 samples/sec, batch_loss: 0.3362, batch_loss_c: 0.3406, batch_loss_s: 0.3261, time:5.1903, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [720/3125], step: 6970, 7.871 samples/sec, batch_loss: 0.0605, batch_loss_c: 0.0614, batch_loss_s: 0.0584, time:5.0820, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [730/3125], step: 6980, 7.466 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1052, batch_loss_s: 0.1089, time:5.3578, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [740/3125], step: 6990, 7.045 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1018, batch_loss_s: 0.1207, time:5.6781, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [750/3125], step: 7000, 8.111 samples/sec, batch_loss: 0.2191, batch_loss_c: 0.2358, batch_loss_s: 0.1802, time:4.9316, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [760/3125], step: 7010, 6.669 samples/sec, batch_loss: 0.1976, batch_loss_c: 0.2012, batch_loss_s: 0.1894, time:5.9975, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [770/3125], step: 7020, 7.962 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0846, batch_loss_s: 0.0730, time:5.0237, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [780/3125], step: 7030, 7.556 samples/sec, batch_loss: 0.2016, batch_loss_c: 0.1886, batch_loss_s: 0.2319, time:5.2937, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [790/3125], step: 7040, 7.803 samples/sec, batch_loss: 0.3365, batch_loss_c: 0.3320, batch_loss_s: 0.3471, time:5.1261, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:08:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [800/3125], step: 7050, 6.974 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.0970, batch_loss_s: 0.1033, time:5.7354, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [810/3125], step: 7060, 6.969 samples/sec, batch_loss: 0.3333, batch_loss_c: 0.3409, batch_loss_s: 0.3158, time:5.7397, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [820/3125], step: 7070, 8.137 samples/sec, batch_loss: 0.3254, batch_loss_c: 0.3318, batch_loss_s: 0.3103, time:4.9160, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [830/3125], step: 7080, 8.618 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1487, batch_loss_s: 0.1080, time:4.6416, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [840/3125], step: 7090, 8.275 samples/sec, batch_loss: 0.3987, batch_loss_c: 0.4268, batch_loss_s: 0.3334, time:4.8340, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [850/3125], step: 7100, 7.092 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.2982, batch_loss_s: 0.3284, time:5.6400, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [860/3125], step: 7110, 8.482 samples/sec, batch_loss: 0.4013, batch_loss_c: 0.4144, batch_loss_s: 0.3709, time:4.7161, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [870/3125], step: 7120, 7.221 samples/sec, batch_loss: 0.0876, batch_loss_c: 0.0798, batch_loss_s: 0.1056, time:5.5391, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [880/3125], step: 7130, 7.863 samples/sec, batch_loss: 0.0509, batch_loss_c: 0.0466, batch_loss_s: 0.0612, time:5.0874, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [890/3125], step: 7140, 8.128 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3160, batch_loss_s: 0.3340, time:4.9210, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [900/3125], step: 7150, 7.629 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0960, batch_loss_s: 0.1006, time:5.2429, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [910/3125], step: 7160, 8.282 samples/sec, batch_loss: 0.1452, batch_loss_c: 0.1704, batch_loss_s: 0.0863, time:4.8297, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:09:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [920/3125], step: 7170, 8.430 samples/sec, batch_loss: 0.3479, batch_loss_c: 0.3507, batch_loss_s: 0.3411, time:4.7448, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [930/3125], step: 7180, 8.001 samples/sec, batch_loss: 0.2010, batch_loss_c: 0.2380, batch_loss_s: 0.1149, time:4.9996, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [940/3125], step: 7190, 8.095 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0796, batch_loss_s: 0.0783, time:4.9411, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [950/3125], step: 7200, 7.785 samples/sec, batch_loss: 0.1468, batch_loss_c: 0.1442, batch_loss_s: 0.1526, time:5.1381, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [960/3125], step: 7210, 7.323 samples/sec, batch_loss: 0.1688, batch_loss_c: 0.1845, batch_loss_s: 0.1321, time:5.4620, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [970/3125], step: 7220, 7.465 samples/sec, batch_loss: 0.3177, batch_loss_c: 0.3173, batch_loss_s: 0.3185, time:5.3581, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [980/3125], step: 7230, 7.709 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0850, batch_loss_s: 0.1070, time:5.1890, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [990/3125], step: 7240, 7.928 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0954, batch_loss_s: 0.0966, time:5.0452, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1000/3125], step: 7250, 7.393 samples/sec, batch_loss: 0.3015, batch_loss_c: 0.2940, batch_loss_s: 0.3189, time:5.4103, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1010/3125], step: 7260, 7.639 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1463, batch_loss_s: 0.1517, time:5.2362, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1020/3125], step: 7270, 8.101 samples/sec, batch_loss: 0.2877, batch_loss_c: 0.2815, batch_loss_s: 0.3023, time:4.9375, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1030/3125], step: 7280, 7.593 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.2941, batch_loss_s: 0.3006, time:5.2683, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:10:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1040/3125], step: 7290, 8.050 samples/sec, batch_loss: 0.3170, batch_loss_c: 0.3245, batch_loss_s: 0.2995, time:4.9688, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1050/3125], step: 7300, 7.520 samples/sec, batch_loss: 0.4214, batch_loss_c: 0.4604, batch_loss_s: 0.3302, time:5.3189, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1060/3125], step: 7310, 7.766 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0745, batch_loss_s: 0.0897, time:5.1508, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1070/3125], step: 7320, 8.141 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0741, batch_loss_s: 0.1291, time:4.9132, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1080/3125], step: 7330, 7.836 samples/sec, batch_loss: 0.1699, batch_loss_c: 0.1863, batch_loss_s: 0.1315, time:5.1048, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1090/3125], step: 7340, 7.925 samples/sec, batch_loss: 0.3056, batch_loss_c: 0.3037, batch_loss_s: 0.3102, time:5.0475, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1100/3125], step: 7350, 8.141 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0848, batch_loss_s: 0.0946, time:4.9132, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1110/3125], step: 7360, 8.042 samples/sec, batch_loss: 0.2325, batch_loss_c: 0.2502, batch_loss_s: 0.1913, time:4.9740, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1120/3125], step: 7370, 7.579 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0742, batch_loss_s: 0.0733, time:5.2774, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1130/3125], step: 7380, 7.439 samples/sec, batch_loss: 0.3341, batch_loss_c: 0.3434, batch_loss_s: 0.3124, time:5.3768, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1140/3125], step: 7390, 7.606 samples/sec, batch_loss: 0.1584, batch_loss_c: 0.1847, batch_loss_s: 0.0969, time:5.2590, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:11:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1150/3125], step: 7400, 7.455 samples/sec, batch_loss: 0.2538, batch_loss_c: 0.2493, batch_loss_s: 0.2642, time:5.3653, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1160/3125], step: 7410, 8.044 samples/sec, batch_loss: 0.1132, batch_loss_c: 0.1195, batch_loss_s: 0.0986, time:4.9725, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1170/3125], step: 7420, 6.687 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0715, batch_loss_s: 0.0804, time:5.9819, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1180/3125], step: 7430, 6.725 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0831, batch_loss_s: 0.0646, time:5.9477, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1190/3125], step: 7440, 7.612 samples/sec, batch_loss: 0.1054, batch_loss_c: 0.1075, batch_loss_s: 0.1005, time:5.2550, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1200/3125], step: 7450, 6.817 samples/sec, batch_loss: 0.2568, batch_loss_c: 0.2567, batch_loss_s: 0.2570, time:5.8680, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1210/3125], step: 7460, 8.265 samples/sec, batch_loss: 0.1657, batch_loss_c: 0.1823, batch_loss_s: 0.1268, time:4.8396, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1220/3125], step: 7470, 7.696 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0932, batch_loss_s: 0.0903, time:5.1977, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1230/3125], step: 7480, 7.093 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1094, batch_loss_s: 0.0929, time:5.6391, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1240/3125], step: 7490, 8.805 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1087, batch_loss_s: 0.1147, time:4.5427, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1250/3125], step: 7500, 8.004 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3050, batch_loss_s: 0.3319, time:4.9977, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1260/3125], step: 7510, 8.787 samples/sec, batch_loss: 0.5585, batch_loss_c: 0.5629, batch_loss_s: 0.5482, time:4.5523, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:12:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1270/3125], step: 7520, 8.158 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1026, batch_loss_s: 0.1138, time:4.9031, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1280/3125], step: 7530, 7.907 samples/sec, batch_loss: 0.2943, batch_loss_c: 0.2893, batch_loss_s: 0.3059, time:5.0589, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1290/3125], step: 7540, 7.746 samples/sec, batch_loss: 0.3213, batch_loss_c: 0.3196, batch_loss_s: 0.3253, time:5.1642, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1300/3125], step: 7550, 7.013 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1210, batch_loss_s: 0.1113, time:5.7038, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1310/3125], step: 7560, 7.642 samples/sec, batch_loss: 0.1248, batch_loss_c: 0.1355, batch_loss_s: 0.0998, time:5.2345, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1320/3125], step: 7570, 7.184 samples/sec, batch_loss: 0.5183, batch_loss_c: 0.5057, batch_loss_s: 0.5477, time:5.5680, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1330/3125], step: 7580, 6.672 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0659, batch_loss_s: 0.0860, time:5.9953, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1340/3125], step: 7590, 7.252 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0803, batch_loss_s: 0.0983, time:5.5158, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1350/3125], step: 7600, 7.348 samples/sec, batch_loss: 0.2928, batch_loss_c: 0.2801, batch_loss_s: 0.3224, time:5.4439, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1360/3125], step: 7610, 7.893 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0936, batch_loss_s: 0.1018, time:5.0676, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1370/3125], step: 7620, 8.183 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0635, batch_loss_s: 0.0625, time:4.8884, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:13:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1380/3125], step: 7630, 8.450 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0746, batch_loss_s: 0.0828, time:4.7335, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1390/3125], step: 7640, 7.872 samples/sec, batch_loss: 0.1020, batch_loss_c: 0.1011, batch_loss_s: 0.1041, time:5.0816, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1400/3125], step: 7650, 7.306 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3251, batch_loss_s: 0.3274, time:5.4749, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1410/3125], step: 7660, 7.939 samples/sec, batch_loss: 0.0950, batch_loss_c: 0.0905, batch_loss_s: 0.1053, time:5.0382, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1420/3125], step: 7670, 8.333 samples/sec, batch_loss: 0.0984, batch_loss_c: 0.1028, batch_loss_s: 0.0880, time:4.8000, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1430/3125], step: 7680, 7.339 samples/sec, batch_loss: 0.3328, batch_loss_c: 0.3318, batch_loss_s: 0.3353, time:5.4500, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1440/3125], step: 7690, 8.058 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0984, batch_loss_s: 0.0981, time:4.9641, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1450/3125], step: 7700, 8.102 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0967, batch_loss_s: 0.1080, time:4.9369, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1460/3125], step: 7710, 7.755 samples/sec, batch_loss: 0.1358, batch_loss_c: 0.1353, batch_loss_s: 0.1367, time:5.1583, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1470/3125], step: 7720, 7.492 samples/sec, batch_loss: 0.5662, batch_loss_c: 0.5671, batch_loss_s: 0.5643, time:5.3392, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1480/3125], step: 7730, 6.970 samples/sec, batch_loss: 0.1258, batch_loss_c: 0.1293, batch_loss_s: 0.1177, time:5.7385, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1490/3125], step: 7740, 8.713 samples/sec, batch_loss: 0.3780, batch_loss_c: 0.4006, batch_loss_s: 0.3251, time:4.5909, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:14:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1500/3125], step: 7750, 7.552 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1102, batch_loss_s: 0.1008, time:5.2964, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1510/3125], step: 7760, 8.077 samples/sec, batch_loss: 0.0662, batch_loss_c: 0.0601, batch_loss_s: 0.0802, time:4.9521, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1520/3125], step: 7770, 7.861 samples/sec, batch_loss: 0.2899, batch_loss_c: 0.2842, batch_loss_s: 0.3030, time:5.0887, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1530/3125], step: 7780, 7.917 samples/sec, batch_loss: 0.3048, batch_loss_c: 0.3015, batch_loss_s: 0.3125, time:5.0524, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1540/3125], step: 7790, 8.604 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0616, batch_loss_s: 0.0796, time:4.6489, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1550/3125], step: 7800, 7.784 samples/sec, batch_loss: 0.1261, batch_loss_c: 0.1318, batch_loss_s: 0.1127, time:5.1387, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1560/3125], step: 7810, 7.786 samples/sec, batch_loss: 0.1213, batch_loss_c: 0.1223, batch_loss_s: 0.1188, time:5.1371, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1570/3125], step: 7820, 6.842 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1080, batch_loss_s: 0.1001, time:5.8460, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1580/3125], step: 7830, 7.273 samples/sec, batch_loss: 0.3200, batch_loss_c: 0.3188, batch_loss_s: 0.3230, time:5.4998, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1590/3125], step: 7840, 8.626 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0898, batch_loss_s: 0.0861, time:4.6371, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1600/3125], step: 7850, 7.861 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1050, batch_loss_s: 0.1029, time:5.0885, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:15:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1610/3125], step: 7860, 7.470 samples/sec, batch_loss: 0.1432, batch_loss_c: 0.1513, batch_loss_s: 0.1245, time:5.3551, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1620/3125], step: 7870, 7.611 samples/sec, batch_loss: 0.1878, batch_loss_c: 0.1835, batch_loss_s: 0.1978, time:5.2556, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1630/3125], step: 7880, 8.037 samples/sec, batch_loss: 0.0497, batch_loss_c: 0.0454, batch_loss_s: 0.0597, time:4.9768, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1640/3125], step: 7890, 7.718 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1289, batch_loss_s: 0.1174, time:5.1830, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1650/3125], step: 7900, 8.174 samples/sec, batch_loss: 0.1926, batch_loss_c: 0.2223, batch_loss_s: 0.1232, time:4.8933, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1660/3125], step: 7910, 6.700 samples/sec, batch_loss: 0.3449, batch_loss_c: 0.3640, batch_loss_s: 0.3006, time:5.9703, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1670/3125], step: 7920, 7.556 samples/sec, batch_loss: 0.3375, batch_loss_c: 0.3392, batch_loss_s: 0.3336, time:5.2936, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1680/3125], step: 7930, 7.024 samples/sec, batch_loss: 0.1741, batch_loss_c: 0.1980, batch_loss_s: 0.1183, time:5.6949, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1690/3125], step: 7940, 7.064 samples/sec, batch_loss: 0.3662, batch_loss_c: 0.3721, batch_loss_s: 0.3523, time:5.6621, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1700/3125], step: 7950, 7.293 samples/sec, batch_loss: 0.1521, batch_loss_c: 0.1530, batch_loss_s: 0.1501, time:5.4847, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1710/3125], step: 7960, 7.848 samples/sec, batch_loss: 0.2344, batch_loss_c: 0.1978, batch_loss_s: 0.3199, time:5.0967, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1720/3125], step: 7970, 7.757 samples/sec, batch_loss: 0.3062, batch_loss_c: 0.3044, batch_loss_s: 0.3103, time:5.1568, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:16:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1730/3125], step: 7980, 7.364 samples/sec, batch_loss: 0.1905, batch_loss_c: 0.1893, batch_loss_s: 0.1933, time:5.4320, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1740/3125], step: 7990, 7.006 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1325, batch_loss_s: 0.1227, time:5.7090, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1750/3125], step: 8000, 6.824 samples/sec, batch_loss: 0.3014, batch_loss_c: 0.2899, batch_loss_s: 0.3281, time:5.8618, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1760/3125], step: 8010, 6.860 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.3081, batch_loss_s: 0.3085, time:5.8308, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1770/3125], step: 8020, 6.820 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0876, batch_loss_s: 0.0753, time:5.8649, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1780/3125], step: 8030, 7.896 samples/sec, batch_loss: 0.2894, batch_loss_c: 0.2857, batch_loss_s: 0.2980, time:5.0661, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1790/3125], step: 8040, 8.634 samples/sec, batch_loss: 0.1380, batch_loss_c: 0.1553, batch_loss_s: 0.0977, time:4.6326, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1800/3125], step: 8050, 7.940 samples/sec, batch_loss: 0.2785, batch_loss_c: 0.2608, batch_loss_s: 0.3199, time:5.0378, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1810/3125], step: 8060, 8.209 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1027, batch_loss_s: 0.1163, time:4.8725, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1820/3125], step: 8070, 6.990 samples/sec, batch_loss: 0.5600, batch_loss_c: 0.5519, batch_loss_s: 0.5791, time:5.7221, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1830/3125], step: 8080, 8.340 samples/sec, batch_loss: 0.3118, batch_loss_c: 0.3113, batch_loss_s: 0.3130, time:4.7965, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:17:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1840/3125], step: 8090, 8.114 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.0904, batch_loss_s: 0.1070, time:4.9300, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1850/3125], step: 8100, 7.456 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1101, batch_loss_s: 0.1006, time:5.3647, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1860/3125], step: 8110, 8.425 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0827, batch_loss_s: 0.0950, time:4.7477, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1870/3125], step: 8120, 8.186 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2792, batch_loss_s: 0.3392, time:4.8861, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1880/3125], step: 8130, 8.313 samples/sec, batch_loss: 0.0489, batch_loss_c: 0.0456, batch_loss_s: 0.0565, time:4.8119, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1890/3125], step: 8140, 8.171 samples/sec, batch_loss: 0.3001, batch_loss_c: 0.2950, batch_loss_s: 0.3120, time:4.8955, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1900/3125], step: 8150, 7.221 samples/sec, batch_loss: 0.1899, batch_loss_c: 0.2231, batch_loss_s: 0.1124, time:5.5394, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1910/3125], step: 8160, 8.144 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0897, batch_loss_s: 0.0895, time:4.9115, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1920/3125], step: 8170, 8.238 samples/sec, batch_loss: 0.2966, batch_loss_c: 0.2915, batch_loss_s: 0.3087, time:4.8554, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1930/3125], step: 8180, 7.754 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0687, batch_loss_s: 0.0817, time:5.1583, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1940/3125], step: 8190, 7.539 samples/sec, batch_loss: 0.3775, batch_loss_c: 0.3809, batch_loss_s: 0.3697, time:5.3056, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1950/3125], step: 8200, 8.719 samples/sec, batch_loss: 0.0858, batch_loss_c: 0.0837, batch_loss_s: 0.0906, time:4.5878, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:18:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1960/3125], step: 8210, 7.989 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0876, batch_loss_s: 0.0914, time:5.0066, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1970/3125], step: 8220, 7.825 samples/sec, batch_loss: 0.2672, batch_loss_c: 0.2744, batch_loss_s: 0.2502, time:5.1116, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1980/3125], step: 8230, 7.842 samples/sec, batch_loss: 0.1747, batch_loss_c: 0.1912, batch_loss_s: 0.1363, time:5.1006, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1990/3125], step: 8240, 7.614 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.0944, batch_loss_s: 0.1095, time:5.2536, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2000/3125], step: 8250, 7.786 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1137, batch_loss_s: 0.1219, time:5.1371, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2010/3125], step: 8260, 8.088 samples/sec, batch_loss: 0.0650, batch_loss_c: 0.0616, batch_loss_s: 0.0729, time:4.9459, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2020/3125], step: 8270, 7.542 samples/sec, batch_loss: 0.1759, batch_loss_c: 0.1844, batch_loss_s: 0.1562, time:5.3036, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2030/3125], step: 8280, 7.381 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3606, batch_loss_s: 0.3200, time:5.4191, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2040/3125], step: 8290, 7.874 samples/sec, batch_loss: 0.2938, batch_loss_c: 0.2879, batch_loss_s: 0.3075, time:5.0798, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2050/3125], step: 8300, 7.848 samples/sec, batch_loss: 0.1477, batch_loss_c: 0.1708, batch_loss_s: 0.0939, time:5.0970, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2060/3125], step: 8310, 8.120 samples/sec, batch_loss: 0.1175, batch_loss_c: 0.1165, batch_loss_s: 0.1199, time:4.9263, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2070/3125], step: 8320, 8.204 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1312, batch_loss_s: 0.0814, time:4.8759, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:19:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2080/3125], step: 8330, 7.600 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.0979, batch_loss_s: 0.0987, time:5.2631, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2090/3125], step: 8340, 8.587 samples/sec, batch_loss: 0.1250, batch_loss_c: 0.1353, batch_loss_s: 0.1010, time:4.6580, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2100/3125], step: 8350, 8.674 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.3059, batch_loss_s: 0.3103, time:4.6117, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2110/3125], step: 8360, 7.914 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0956, batch_loss_s: 0.0856, time:5.0541, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2120/3125], step: 8370, 8.076 samples/sec, batch_loss: 0.3230, batch_loss_c: 0.2991, batch_loss_s: 0.3789, time:4.9529, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2130/3125], step: 8380, 8.384 samples/sec, batch_loss: 0.2656, batch_loss_c: 0.2670, batch_loss_s: 0.2622, time:4.7711, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2140/3125], step: 8390, 8.928 samples/sec, batch_loss: 0.1700, batch_loss_c: 0.1748, batch_loss_s: 0.1589, time:4.4801, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2150/3125], step: 8400, 8.857 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0623, batch_loss_s: 0.0640, time:4.5163, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2160/3125], step: 8410, 8.030 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0852, batch_loss_s: 0.0794, time:4.9812, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2170/3125], step: 8420, 8.371 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1196, batch_loss_s: 0.1004, time:4.7781, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2180/3125], step: 8430, 8.321 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0861, batch_loss_s: 0.0677, time:4.8069, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2190/3125], step: 8440, 7.778 samples/sec, batch_loss: 0.3400, batch_loss_c: 0.3390, batch_loss_s: 0.3423, time:5.1427, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:20:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2200/3125], step: 8450, 8.527 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2069, batch_loss_s: 0.1946, time:4.6908, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2210/3125], step: 8460, 8.532 samples/sec, batch_loss: 0.3425, batch_loss_c: 0.3508, batch_loss_s: 0.3232, time:4.6880, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2220/3125], step: 8470, 8.832 samples/sec, batch_loss: 0.3217, batch_loss_c: 0.3316, batch_loss_s: 0.2985, time:4.5291, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2230/3125], step: 8480, 8.772 samples/sec, batch_loss: 0.3092, batch_loss_c: 0.3040, batch_loss_s: 0.3215, time:4.5600, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2240/3125], step: 8490, 7.913 samples/sec, batch_loss: 0.2463, batch_loss_c: 0.2754, batch_loss_s: 0.1783, time:5.0549, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2250/3125], step: 8500, 7.194 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1008, batch_loss_s: 0.1219, time:5.5603, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2260/3125], step: 8510, 8.699 samples/sec, batch_loss: 0.1325, batch_loss_c: 0.1405, batch_loss_s: 0.1137, time:4.5980, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2270/3125], step: 8520, 8.098 samples/sec, batch_loss: 0.0902, batch_loss_c: 0.0883, batch_loss_s: 0.0948, time:4.9398, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2280/3125], step: 8530, 7.231 samples/sec, batch_loss: 0.5440, batch_loss_c: 0.5474, batch_loss_s: 0.5361, time:5.5317, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2290/3125], step: 8540, 7.503 samples/sec, batch_loss: 0.0977, batch_loss_c: 0.0961, batch_loss_s: 0.1015, time:5.3314, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2300/3125], step: 8550, 8.034 samples/sec, batch_loss: 0.2955, batch_loss_c: 0.2874, batch_loss_s: 0.3144, time:4.9789, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2310/3125], step: 8560, 8.197 samples/sec, batch_loss: 0.1270, batch_loss_c: 0.1385, batch_loss_s: 0.1001, time:4.8797, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:21:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2320/3125], step: 8570, 8.282 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1318, batch_loss_s: 0.0745, time:4.8297, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2330/3125], step: 8580, 9.016 samples/sec, batch_loss: 0.3018, batch_loss_c: 0.3050, batch_loss_s: 0.2944, time:4.4366, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2340/3125], step: 8590, 7.551 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1011, batch_loss_s: 0.1294, time:5.2975, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2350/3125], step: 8600, 8.008 samples/sec, batch_loss: 0.3100, batch_loss_c: 0.3024, batch_loss_s: 0.3278, time:4.9947, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2360/3125], step: 8610, 8.176 samples/sec, batch_loss: 0.2724, batch_loss_c: 0.2511, batch_loss_s: 0.3222, time:4.8921, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2370/3125], step: 8620, 7.882 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0889, batch_loss_s: 0.0924, time:5.0746, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2380/3125], step: 8630, 8.241 samples/sec, batch_loss: 0.0659, batch_loss_c: 0.0623, batch_loss_s: 0.0743, time:4.8539, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2390/3125], step: 8640, 7.686 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0744, batch_loss_s: 0.0904, time:5.2042, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2400/3125], step: 8650, 7.693 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1341, batch_loss_s: 0.1351, time:5.1995, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2410/3125], step: 8660, 8.139 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1016, batch_loss_s: 0.0876, time:4.9144, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2420/3125], step: 8670, 8.376 samples/sec, batch_loss: 0.4121, batch_loss_c: 0.4371, batch_loss_s: 0.3536, time:4.7754, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2430/3125], step: 8680, 8.110 samples/sec, batch_loss: 0.0690, batch_loss_c: 0.0670, batch_loss_s: 0.0737, time:4.9322, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:22:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2440/3125], step: 8690, 7.452 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1200, batch_loss_s: 0.1286, time:5.3678, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2450/3125], step: 8700, 7.422 samples/sec, batch_loss: 0.0858, batch_loss_c: 0.0820, batch_loss_s: 0.0948, time:5.3894, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2460/3125], step: 8710, 8.048 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0851, batch_loss_s: 0.1003, time:4.9703, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2470/3125], step: 8720, 8.918 samples/sec, batch_loss: 0.2585, batch_loss_c: 0.2406, batch_loss_s: 0.3003, time:4.4852, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2480/3125], step: 8730, 8.153 samples/sec, batch_loss: 0.3643, batch_loss_c: 0.3669, batch_loss_s: 0.3581, time:4.9060, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2490/3125], step: 8740, 8.439 samples/sec, batch_loss: 0.0858, batch_loss_c: 0.0815, batch_loss_s: 0.0959, time:4.7398, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2500/3125], step: 8750, 7.843 samples/sec, batch_loss: 0.1139, batch_loss_c: 0.1167, batch_loss_s: 0.1073, time:5.1001, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2510/3125], step: 8760, 7.956 samples/sec, batch_loss: 0.0937, batch_loss_c: 0.0966, batch_loss_s: 0.0869, time:5.0278, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2520/3125], step: 8770, 8.958 samples/sec, batch_loss: 0.3754, batch_loss_c: 0.3869, batch_loss_s: 0.3485, time:4.4651, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2530/3125], step: 8780, 8.840 samples/sec, batch_loss: 0.3116, batch_loss_c: 0.3095, batch_loss_s: 0.3165, time:4.5250, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2540/3125], step: 8790, 8.678 samples/sec, batch_loss: 0.1878, batch_loss_c: 0.2293, batch_loss_s: 0.0911, time:4.6094, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2550/3125], step: 8800, 7.079 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0835, batch_loss_s: 0.0777, time:5.6508, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:23:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2560/3125], step: 8810, 8.053 samples/sec, batch_loss: 0.2021, batch_loss_c: 0.2027, batch_loss_s: 0.2008, time:4.9673, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2570/3125], step: 8820, 7.254 samples/sec, batch_loss: 0.2632, batch_loss_c: 0.3178, batch_loss_s: 0.1356, time:5.5138, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2580/3125], step: 8830, 8.691 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0713, batch_loss_s: 0.0757, time:4.6024, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2590/3125], step: 8840, 7.831 samples/sec, batch_loss: 0.1227, batch_loss_c: 0.1214, batch_loss_s: 0.1258, time:5.1077, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2600/3125], step: 8850, 7.122 samples/sec, batch_loss: 0.1408, batch_loss_c: 0.1601, batch_loss_s: 0.0959, time:5.6164, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2610/3125], step: 8860, 8.138 samples/sec, batch_loss: 0.3180, batch_loss_c: 0.3175, batch_loss_s: 0.3191, time:4.9154, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2620/3125], step: 8870, 6.984 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0774, batch_loss_s: 0.0693, time:5.7276, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2630/3125], step: 8880, 9.188 samples/sec, batch_loss: 0.7277, batch_loss_c: 0.7109, batch_loss_s: 0.7668, time:4.3537, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2640/3125], step: 8890, 8.218 samples/sec, batch_loss: 0.1640, batch_loss_c: 0.1970, batch_loss_s: 0.0869, time:4.8675, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2650/3125], step: 8900, 8.512 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1163, batch_loss_s: 0.0979, time:4.6994, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2660/3125], step: 8910, 8.246 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0739, batch_loss_s: 0.0931, time:4.8506, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2670/3125], step: 8920, 8.132 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0741, batch_loss_s: 0.0708, time:4.9189, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2680/3125], step: 8930, 8.740 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0870, batch_loss_s: 0.0919, time:4.5767, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:24:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2690/3125], step: 8940, 7.373 samples/sec, batch_loss: 0.0768, batch_loss_c: 0.0779, batch_loss_s: 0.0741, time:5.4255, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2700/3125], step: 8950, 8.296 samples/sec, batch_loss: 0.2067, batch_loss_c: 0.2260, batch_loss_s: 0.1616, time:4.8219, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2710/3125], step: 8960, 9.060 samples/sec, batch_loss: 0.0968, batch_loss_c: 0.1014, batch_loss_s: 0.0861, time:4.4149, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2720/3125], step: 8970, 7.887 samples/sec, batch_loss: 0.1149, batch_loss_c: 0.0913, batch_loss_s: 0.1700, time:5.0717, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2730/3125], step: 8980, 7.868 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0848, batch_loss_s: 0.0805, time:5.0836, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2740/3125], step: 8990, 8.510 samples/sec, batch_loss: 0.1421, batch_loss_c: 0.1578, batch_loss_s: 0.1055, time:4.7005, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2750/3125], step: 9000, 8.443 samples/sec, batch_loss: 0.2877, batch_loss_c: 0.2746, batch_loss_s: 0.3184, time:4.7377, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2760/3125], step: 9010, 7.953 samples/sec, batch_loss: 0.3959, batch_loss_c: 0.3978, batch_loss_s: 0.3914, time:5.0298, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2770/3125], step: 9020, 8.650 samples/sec, batch_loss: 0.2770, batch_loss_c: 0.2600, batch_loss_s: 0.3164, time:4.6242, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2780/3125], step: 9030, 7.771 samples/sec, batch_loss: 0.1836, batch_loss_c: 0.2148, batch_loss_s: 0.1106, time:5.1474, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2790/3125], step: 9040, 8.678 samples/sec, batch_loss: 0.1334, batch_loss_c: 0.1253, batch_loss_s: 0.1522, time:4.6095, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2800/3125], step: 9050, 7.635 samples/sec, batch_loss: 0.1667, batch_loss_c: 0.2005, batch_loss_s: 0.0879, time:5.2393, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:25:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2810/3125], step: 9060, 8.160 samples/sec, batch_loss: 0.1183, batch_loss_c: 0.1083, batch_loss_s: 0.1414, time:4.9020, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2820/3125], step: 9070, 7.586 samples/sec, batch_loss: 0.1700, batch_loss_c: 0.1986, batch_loss_s: 0.1035, time:5.2730, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2830/3125], step: 9080, 8.234 samples/sec, batch_loss: 0.0685, batch_loss_c: 0.0659, batch_loss_s: 0.0744, time:4.8579, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2840/3125], step: 9090, 8.234 samples/sec, batch_loss: 0.1649, batch_loss_c: 0.1560, batch_loss_s: 0.1856, time:4.8582, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2850/3125], step: 9100, 8.363 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0908, batch_loss_s: 0.0811, time:4.7827, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2860/3125], step: 9110, 9.106 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0994, batch_loss_s: 0.0832, time:4.3927, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2870/3125], step: 9120, 7.600 samples/sec, batch_loss: 0.0623, batch_loss_c: 0.0564, batch_loss_s: 0.0761, time:5.2633, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2880/3125], step: 9130, 7.545 samples/sec, batch_loss: 0.3611, batch_loss_c: 0.3603, batch_loss_s: 0.3630, time:5.3015, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2890/3125], step: 9140, 7.972 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1185, batch_loss_s: 0.1128, time:5.0174, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2900/3125], step: 9150, 8.481 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0722, batch_loss_s: 0.0737, time:4.7167, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2910/3125], step: 9160, 6.567 samples/sec, batch_loss: 0.1369, batch_loss_c: 0.1513, batch_loss_s: 0.1032, time:6.0913, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2920/3125], step: 9170, 7.330 samples/sec, batch_loss: 0.3711, batch_loss_c: 0.3848, batch_loss_s: 0.3393, time:5.4570, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:26:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2930/3125], step: 9180, 8.443 samples/sec, batch_loss: 0.1027, batch_loss_c: 0.1014, batch_loss_s: 0.1057, time:4.7379, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2940/3125], step: 9190, 8.015 samples/sec, batch_loss: 0.5630, batch_loss_c: 0.5617, batch_loss_s: 0.5660, time:4.9908, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2950/3125], step: 9200, 6.651 samples/sec, batch_loss: 0.2345, batch_loss_c: 0.2748, batch_loss_s: 0.1407, time:6.0143, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2960/3125], step: 9210, 8.200 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0937, batch_loss_s: 0.0898, time:4.8781, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2970/3125], step: 9220, 7.494 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1200, batch_loss_s: 0.1006, time:5.3373, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2980/3125], step: 9230, 8.712 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1004, batch_loss_s: 0.1107, time:4.5913, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2990/3125], step: 9240, 8.056 samples/sec, batch_loss: 0.3540, batch_loss_c: 0.3599, batch_loss_s: 0.3402, time:4.9652, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3000/3125], step: 9250, 7.614 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1122, batch_loss_s: 0.1119, time:5.2534, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3010/3125], step: 9260, 7.156 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1036, batch_loss_s: 0.1261, time:5.5895, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3020/3125], step: 9270, 6.997 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0709, batch_loss_s: 0.1023, time:5.7169, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3030/3125], step: 9280, 8.147 samples/sec, batch_loss: 0.1209, batch_loss_c: 0.1251, batch_loss_s: 0.1113, time:4.9095, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:27:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3040/3125], step: 9290, 7.414 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0971, batch_loss_s: 0.0923, time:5.3953, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3050/3125], step: 9300, 7.068 samples/sec, batch_loss: 0.0576, batch_loss_c: 0.0546, batch_loss_s: 0.0646, time:5.6597, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3060/3125], step: 9310, 7.707 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1139, batch_loss_s: 0.1144, time:5.1901, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3070/3125], step: 9320, 7.261 samples/sec, batch_loss: 0.3497, batch_loss_c: 0.3605, batch_loss_s: 0.3244, time:5.5092, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3080/3125], step: 9330, 7.652 samples/sec, batch_loss: 0.3283, batch_loss_c: 0.3216, batch_loss_s: 0.3441, time:5.2275, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3090/3125], step: 9340, 7.567 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1275, batch_loss_s: 0.0950, time:5.2864, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3100/3125], step: 9350, 7.282 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1079, batch_loss_s: 0.1073, time:5.4934, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3110/3125], step: 9360, 10.107 samples/sec, batch_loss: 0.1492, batch_loss_c: 0.1331, batch_loss_s: 0.1866, time:3.9575, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3120/3125], step: 9370, 10.131 samples/sec, batch_loss: 0.1516, batch_loss_c: 0.1567, batch_loss_s: 0.1395, time:3.9483, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], train_loss: 0.1885, time: 1601.9419, lr: 0.0001\u001b[0m\n",
            "2019-11-23 12:28:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [0/3125], step: 9375, 6.399 samples/sec, batch_loss: 0.1033, batch_loss_c: 0.1153, batch_loss_s: 0.0753, time:6.2513, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [10/3125], step: 9385, 7.975 samples/sec, batch_loss: 0.1686, batch_loss_c: 0.1974, batch_loss_s: 0.1015, time:5.0155, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:28:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [20/3125], step: 9395, 8.188 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.1041, batch_loss_s: 0.0804, time:4.8852, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [30/3125], step: 9405, 8.244 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1513, batch_loss_s: 0.1285, time:4.8519, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [40/3125], step: 9415, 8.157 samples/sec, batch_loss: 0.1371, batch_loss_c: 0.1163, batch_loss_s: 0.1854, time:4.9039, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [50/3125], step: 9425, 8.075 samples/sec, batch_loss: 0.0603, batch_loss_c: 0.0515, batch_loss_s: 0.0808, time:4.9534, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [60/3125], step: 9435, 7.852 samples/sec, batch_loss: 0.3752, batch_loss_c: 0.3808, batch_loss_s: 0.3619, time:5.0943, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [70/3125], step: 9445, 7.989 samples/sec, batch_loss: 0.1274, batch_loss_c: 0.1449, batch_loss_s: 0.0864, time:5.0071, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [80/3125], step: 9455, 7.133 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0635, batch_loss_s: 0.0734, time:5.6080, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [90/3125], step: 9465, 8.580 samples/sec, batch_loss: 0.2981, batch_loss_c: 0.2962, batch_loss_s: 0.3023, time:4.6620, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [100/3125], step: 9475, 8.106 samples/sec, batch_loss: 0.3054, batch_loss_c: 0.3011, batch_loss_s: 0.3154, time:4.9344, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [110/3125], step: 9485, 7.064 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0895, batch_loss_s: 0.1023, time:5.6624, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [120/3125], step: 9495, 7.796 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0740, batch_loss_s: 0.0825, time:5.1310, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [130/3125], step: 9505, 6.878 samples/sec, batch_loss: 0.2594, batch_loss_c: 0.2555, batch_loss_s: 0.2684, time:5.8155, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:29:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [140/3125], step: 9515, 8.288 samples/sec, batch_loss: 0.1609, batch_loss_c: 0.1773, batch_loss_s: 0.1224, time:4.8262, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [150/3125], step: 9525, 7.844 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1188, batch_loss_s: 0.1053, time:5.0994, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [160/3125], step: 9535, 7.923 samples/sec, batch_loss: 0.5752, batch_loss_c: 0.5759, batch_loss_s: 0.5735, time:5.0483, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [170/3125], step: 9545, 8.349 samples/sec, batch_loss: 0.0735, batch_loss_c: 0.0733, batch_loss_s: 0.0741, time:4.7911, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [180/3125], step: 9555, 7.990 samples/sec, batch_loss: 0.3467, batch_loss_c: 0.3533, batch_loss_s: 0.3314, time:5.0060, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [190/3125], step: 9565, 8.117 samples/sec, batch_loss: 0.2862, batch_loss_c: 0.2727, batch_loss_s: 0.3178, time:4.9277, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [200/3125], step: 9575, 7.156 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0967, batch_loss_s: 0.0947, time:5.5900, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [210/3125], step: 9585, 6.622 samples/sec, batch_loss: 0.0963, batch_loss_c: 0.0959, batch_loss_s: 0.0972, time:6.0401, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [220/3125], step: 9595, 6.867 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0964, batch_loss_s: 0.0893, time:5.8248, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [230/3125], step: 9605, 8.011 samples/sec, batch_loss: 0.2148, batch_loss_c: 0.2119, batch_loss_s: 0.2215, time:4.9930, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [240/3125], step: 9615, 8.673 samples/sec, batch_loss: 0.0914, batch_loss_c: 0.0934, batch_loss_s: 0.0867, time:4.6119, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [250/3125], step: 9625, 8.708 samples/sec, batch_loss: 0.5386, batch_loss_c: 0.5369, batch_loss_s: 0.5427, time:4.5936, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:30:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [260/3125], step: 9635, 8.532 samples/sec, batch_loss: 0.3329, batch_loss_c: 0.3375, batch_loss_s: 0.3220, time:4.6885, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [270/3125], step: 9645, 8.762 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1248, batch_loss_s: 0.1076, time:4.5653, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [280/3125], step: 9655, 8.410 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1128, batch_loss_s: 0.1304, time:4.7560, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [290/3125], step: 9665, 7.684 samples/sec, batch_loss: 0.3711, batch_loss_c: 0.3783, batch_loss_s: 0.3541, time:5.2057, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [300/3125], step: 9675, 7.713 samples/sec, batch_loss: 0.0633, batch_loss_c: 0.0610, batch_loss_s: 0.0685, time:5.1860, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [310/3125], step: 9685, 7.570 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0665, batch_loss_s: 0.0682, time:5.2841, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [320/3125], step: 9695, 8.852 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0906, batch_loss_s: 0.0981, time:4.5187, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [330/3125], step: 9705, 8.482 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0679, batch_loss_s: 0.0795, time:4.7157, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [340/3125], step: 9715, 7.960 samples/sec, batch_loss: 0.0714, batch_loss_c: 0.0650, batch_loss_s: 0.0864, time:5.0253, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [350/3125], step: 9725, 8.340 samples/sec, batch_loss: 0.1418, batch_loss_c: 0.1473, batch_loss_s: 0.1289, time:4.7959, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [360/3125], step: 9735, 7.350 samples/sec, batch_loss: 0.1726, batch_loss_c: 0.2019, batch_loss_s: 0.1042, time:5.4423, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [370/3125], step: 9745, 7.878 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0714, batch_loss_s: 0.0563, time:5.0776, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:31:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [380/3125], step: 9755, 7.718 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0808, batch_loss_s: 0.0800, time:5.1827, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [390/3125], step: 9765, 7.387 samples/sec, batch_loss: 0.3189, batch_loss_c: 0.3139, batch_loss_s: 0.3306, time:5.4153, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [400/3125], step: 9775, 7.835 samples/sec, batch_loss: 0.3193, batch_loss_c: 0.3243, batch_loss_s: 0.3077, time:5.1051, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [410/3125], step: 9785, 8.893 samples/sec, batch_loss: 0.3798, batch_loss_c: 0.3841, batch_loss_s: 0.3696, time:4.4980, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [420/3125], step: 9795, 8.252 samples/sec, batch_loss: 0.1817, batch_loss_c: 0.2076, batch_loss_s: 0.1212, time:4.8470, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [430/3125], step: 9805, 8.436 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0986, batch_loss_s: 0.0905, time:4.7415, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [440/3125], step: 9815, 8.360 samples/sec, batch_loss: 0.1274, batch_loss_c: 0.1333, batch_loss_s: 0.1135, time:4.7845, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [450/3125], step: 9825, 8.775 samples/sec, batch_loss: 0.1370, batch_loss_c: 0.1470, batch_loss_s: 0.1138, time:4.5585, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [460/3125], step: 9835, 8.559 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1348, batch_loss_s: 0.1155, time:4.6733, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [470/3125], step: 9845, 8.911 samples/sec, batch_loss: 0.0620, batch_loss_c: 0.0608, batch_loss_s: 0.0647, time:4.4886, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [480/3125], step: 9855, 8.509 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.1025, batch_loss_s: 0.0905, time:4.7007, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [490/3125], step: 9865, 8.663 samples/sec, batch_loss: 0.3356, batch_loss_c: 0.3418, batch_loss_s: 0.3211, time:4.6176, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [500/3125], step: 9875, 8.223 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0797, batch_loss_s: 0.0803, time:4.8642, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:32:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [510/3125], step: 9885, 8.152 samples/sec, batch_loss: 0.1778, batch_loss_c: 0.2039, batch_loss_s: 0.1168, time:4.9065, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [520/3125], step: 9895, 7.866 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1188, batch_loss_s: 0.1056, time:5.0854, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [530/3125], step: 9905, 8.971 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0766, batch_loss_s: 0.0855, time:4.4589, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [540/3125], step: 9915, 8.130 samples/sec, batch_loss: 0.0704, batch_loss_c: 0.0685, batch_loss_s: 0.0747, time:4.9201, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [550/3125], step: 9925, 8.124 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0939, batch_loss_s: 0.0835, time:4.9236, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [560/3125], step: 9935, 7.293 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.1092, batch_loss_s: 0.0887, time:5.4848, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [570/3125], step: 9945, 8.192 samples/sec, batch_loss: 0.5421, batch_loss_c: 0.5355, batch_loss_s: 0.5576, time:4.8825, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [580/3125], step: 9955, 8.255 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0601, batch_loss_s: 0.0831, time:4.8453, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [590/3125], step: 9965, 7.534 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1539, batch_loss_s: 0.1528, time:5.3096, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [600/3125], step: 9975, 7.080 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0543, batch_loss_s: 0.0670, time:5.6495, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [610/3125], step: 9985, 7.870 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0742, batch_loss_s: 0.0663, time:5.0829, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [620/3125], step: 9995, 8.625 samples/sec, batch_loss: 0.5339, batch_loss_c: 0.5330, batch_loss_s: 0.5361, time:4.6378, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:33:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [630/3125], step: 10005, 8.381 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1104, batch_loss_s: 0.0853, time:4.7724, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [640/3125], step: 10015, 8.120 samples/sec, batch_loss: 0.1110, batch_loss_c: 0.1168, batch_loss_s: 0.0973, time:4.9262, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [650/3125], step: 10025, 8.149 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0927, batch_loss_s: 0.1021, time:4.9088, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [660/3125], step: 10035, 7.923 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0746, batch_loss_s: 0.0761, time:5.0484, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [670/3125], step: 10045, 8.603 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1023, batch_loss_s: 0.0941, time:4.6496, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [680/3125], step: 10055, 7.345 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0922, batch_loss_s: 0.0833, time:5.4460, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [690/3125], step: 10065, 7.496 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1068, batch_loss_s: 0.1046, time:5.3364, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [700/3125], step: 10075, 7.542 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0588, batch_loss_s: 0.0721, time:5.3034, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [710/3125], step: 10085, 8.113 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0825, batch_loss_s: 0.0860, time:4.9301, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [720/3125], step: 10095, 7.656 samples/sec, batch_loss: 0.0721, batch_loss_c: 0.0654, batch_loss_s: 0.0876, time:5.2244, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [730/3125], step: 10105, 8.120 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.3056, batch_loss_s: 0.3111, time:4.9261, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:34:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [740/3125], step: 10115, 7.007 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1285, batch_loss_s: 0.1180, time:5.7083, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [750/3125], step: 10125, 7.498 samples/sec, batch_loss: 0.2182, batch_loss_c: 0.1775, batch_loss_s: 0.3131, time:5.3351, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [760/3125], step: 10135, 8.012 samples/sec, batch_loss: 0.3284, batch_loss_c: 0.3323, batch_loss_s: 0.3194, time:4.9924, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [770/3125], step: 10145, 7.223 samples/sec, batch_loss: 0.2787, batch_loss_c: 0.3038, batch_loss_s: 0.2202, time:5.5380, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [780/3125], step: 10155, 7.691 samples/sec, batch_loss: 0.1357, batch_loss_c: 0.1394, batch_loss_s: 0.1271, time:5.2012, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [790/3125], step: 10165, 8.720 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0832, batch_loss_s: 0.1046, time:4.5872, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [800/3125], step: 10175, 8.311 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1255, batch_loss_s: 0.0992, time:4.8128, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [810/3125], step: 10185, 8.674 samples/sec, batch_loss: 0.3363, batch_loss_c: 0.3358, batch_loss_s: 0.3376, time:4.6114, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [820/3125], step: 10195, 8.199 samples/sec, batch_loss: 0.2338, batch_loss_c: 0.2158, batch_loss_s: 0.2757, time:4.8786, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [830/3125], step: 10205, 8.166 samples/sec, batch_loss: 0.2462, batch_loss_c: 0.2546, batch_loss_s: 0.2267, time:4.8982, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [840/3125], step: 10215, 8.322 samples/sec, batch_loss: 0.2659, batch_loss_c: 0.2443, batch_loss_s: 0.3162, time:4.8065, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [850/3125], step: 10225, 7.044 samples/sec, batch_loss: 0.1504, batch_loss_c: 0.1732, batch_loss_s: 0.0972, time:5.6783, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:35:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [860/3125], step: 10235, 7.513 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0825, batch_loss_s: 0.0893, time:5.3240, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [870/3125], step: 10245, 8.411 samples/sec, batch_loss: 0.5517, batch_loss_c: 0.5448, batch_loss_s: 0.5677, time:4.7559, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [880/3125], step: 10255, 7.834 samples/sec, batch_loss: 0.3602, batch_loss_c: 0.3629, batch_loss_s: 0.3541, time:5.1059, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [890/3125], step: 10265, 7.147 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0972, batch_loss_s: 0.0800, time:5.5968, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [900/3125], step: 10275, 7.601 samples/sec, batch_loss: 0.0931, batch_loss_c: 0.0935, batch_loss_s: 0.0920, time:5.2623, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [910/3125], step: 10285, 8.284 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1159, batch_loss_s: 0.1099, time:4.8284, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [920/3125], step: 10295, 8.475 samples/sec, batch_loss: 0.0616, batch_loss_c: 0.0621, batch_loss_s: 0.0605, time:4.7199, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [930/3125], step: 10305, 8.148 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1358, batch_loss_s: 0.0931, time:4.9090, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [940/3125], step: 10315, 8.852 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0938, batch_loss_s: 0.0889, time:4.5187, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [950/3125], step: 10325, 8.922 samples/sec, batch_loss: 0.1100, batch_loss_c: 0.1079, batch_loss_s: 0.1150, time:4.4834, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [960/3125], step: 10335, 6.946 samples/sec, batch_loss: 0.3247, batch_loss_c: 0.3354, batch_loss_s: 0.2998, time:5.7588, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [970/3125], step: 10345, 8.084 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1053, batch_loss_s: 0.0951, time:4.9479, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:36:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [980/3125], step: 10355, 6.982 samples/sec, batch_loss: 0.3700, batch_loss_c: 0.3920, batch_loss_s: 0.3187, time:5.7292, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [990/3125], step: 10365, 7.824 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0741, batch_loss_s: 0.0922, time:5.1122, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1000/3125], step: 10375, 7.466 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1159, batch_loss_s: 0.1193, time:5.3576, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1010/3125], step: 10385, 8.053 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.1139, batch_loss_s: 0.0695, time:4.9669, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1020/3125], step: 10395, 7.431 samples/sec, batch_loss: 0.2625, batch_loss_c: 0.2874, batch_loss_s: 0.2045, time:5.3831, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1030/3125], step: 10405, 7.628 samples/sec, batch_loss: 0.2987, batch_loss_c: 0.2937, batch_loss_s: 0.3102, time:5.2437, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1040/3125], step: 10415, 8.194 samples/sec, batch_loss: 0.0730, batch_loss_c: 0.0748, batch_loss_s: 0.0687, time:4.8814, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1050/3125], step: 10425, 7.349 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0913, batch_loss_s: 0.0969, time:5.4427, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1060/3125], step: 10435, 8.356 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0771, batch_loss_s: 0.0764, time:4.7869, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1070/3125], step: 10445, 8.379 samples/sec, batch_loss: 0.0700, batch_loss_c: 0.0694, batch_loss_s: 0.0714, time:4.7736, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1080/3125], step: 10455, 8.328 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0800, batch_loss_s: 0.1117, time:4.8028, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1090/3125], step: 10465, 8.226 samples/sec, batch_loss: 0.3477, batch_loss_c: 0.3591, batch_loss_s: 0.3210, time:4.8626, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:37:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1100/3125], step: 10475, 9.060 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0762, batch_loss_s: 0.0814, time:4.4151, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1110/3125], step: 10485, 8.208 samples/sec, batch_loss: 0.1301, batch_loss_c: 0.1290, batch_loss_s: 0.1326, time:4.8735, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1120/3125], step: 10495, 7.990 samples/sec, batch_loss: 0.3145, batch_loss_c: 0.2968, batch_loss_s: 0.3556, time:5.0063, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1130/3125], step: 10505, 7.169 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0782, batch_loss_s: 0.0812, time:5.5797, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1140/3125], step: 10515, 7.928 samples/sec, batch_loss: 0.1978, batch_loss_c: 0.2431, batch_loss_s: 0.0919, time:5.0455, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1150/3125], step: 10525, 8.023 samples/sec, batch_loss: 0.3306, batch_loss_c: 0.3336, batch_loss_s: 0.3236, time:4.9854, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1160/3125], step: 10535, 7.148 samples/sec, batch_loss: 0.3051, batch_loss_c: 0.3060, batch_loss_s: 0.3028, time:5.5956, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1170/3125], step: 10545, 6.962 samples/sec, batch_loss: 0.1144, batch_loss_c: 0.1214, batch_loss_s: 0.0983, time:5.7455, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1180/3125], step: 10555, 8.814 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1267, batch_loss_s: 0.1503, time:4.5380, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1190/3125], step: 10565, 7.166 samples/sec, batch_loss: 0.3098, batch_loss_c: 0.3099, batch_loss_s: 0.3097, time:5.5823, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1200/3125], step: 10575, 7.363 samples/sec, batch_loss: 0.1801, batch_loss_c: 0.1498, batch_loss_s: 0.2507, time:5.4324, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1210/3125], step: 10585, 8.375 samples/sec, batch_loss: 0.2306, batch_loss_c: 0.2307, batch_loss_s: 0.2304, time:4.7762, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:38:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1220/3125], step: 10595, 7.896 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0795, batch_loss_s: 0.0968, time:5.0658, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1230/3125], step: 10605, 7.899 samples/sec, batch_loss: 0.5162, batch_loss_c: 0.4997, batch_loss_s: 0.5544, time:5.0636, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1240/3125], step: 10615, 7.798 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.0989, batch_loss_s: 0.1006, time:5.1294, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1250/3125], step: 10625, 7.505 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1213, batch_loss_s: 0.1068, time:5.3294, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1260/3125], step: 10635, 7.804 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0734, batch_loss_s: 0.0730, time:5.1258, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1270/3125], step: 10645, 7.788 samples/sec, batch_loss: 0.3486, batch_loss_c: 0.3520, batch_loss_s: 0.3406, time:5.1359, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1280/3125], step: 10655, 7.365 samples/sec, batch_loss: 0.3527, batch_loss_c: 0.3637, batch_loss_s: 0.3270, time:5.4309, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1290/3125], step: 10665, 8.396 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1806, batch_loss_s: 0.0793, time:4.7641, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1300/3125], step: 10675, 8.239 samples/sec, batch_loss: 0.1978, batch_loss_c: 0.2473, batch_loss_s: 0.0826, time:4.8548, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1310/3125], step: 10685, 7.347 samples/sec, batch_loss: 0.0660, batch_loss_c: 0.0643, batch_loss_s: 0.0699, time:5.4441, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1320/3125], step: 10695, 7.785 samples/sec, batch_loss: 0.2043, batch_loss_c: 0.2479, batch_loss_s: 0.1024, time:5.1383, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:39:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1330/3125], step: 10705, 8.087 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1595, batch_loss_s: 0.0913, time:4.9462, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1340/3125], step: 10715, 7.424 samples/sec, batch_loss: 0.1926, batch_loss_c: 0.2238, batch_loss_s: 0.1196, time:5.3882, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1350/3125], step: 10725, 8.194 samples/sec, batch_loss: 0.1377, batch_loss_c: 0.1452, batch_loss_s: 0.1201, time:4.8815, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1360/3125], step: 10735, 7.753 samples/sec, batch_loss: 0.1431, batch_loss_c: 0.1469, batch_loss_s: 0.1341, time:5.1591, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1370/3125], step: 10745, 8.675 samples/sec, batch_loss: 0.3108, batch_loss_c: 0.3026, batch_loss_s: 0.3300, time:4.6108, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1380/3125], step: 10755, 8.635 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1253, batch_loss_s: 0.1050, time:4.6322, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1390/3125], step: 10765, 7.932 samples/sec, batch_loss: 0.1060, batch_loss_c: 0.1034, batch_loss_s: 0.1121, time:5.0428, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1400/3125], step: 10775, 7.754 samples/sec, batch_loss: 0.0751, batch_loss_c: 0.0748, batch_loss_s: 0.0757, time:5.1585, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1410/3125], step: 10785, 7.897 samples/sec, batch_loss: 0.5444, batch_loss_c: 0.5447, batch_loss_s: 0.5435, time:5.0650, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1420/3125], step: 10795, 7.693 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0912, batch_loss_s: 0.0763, time:5.1999, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1430/3125], step: 10805, 6.704 samples/sec, batch_loss: 0.4671, batch_loss_c: 0.4885, batch_loss_s: 0.4171, time:5.9664, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1440/3125], step: 10815, 7.839 samples/sec, batch_loss: 0.0605, batch_loss_c: 0.0528, batch_loss_s: 0.0784, time:5.1024, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:40:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1450/3125], step: 10825, 7.999 samples/sec, batch_loss: 0.1130, batch_loss_c: 0.1137, batch_loss_s: 0.1114, time:5.0009, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1460/3125], step: 10835, 8.054 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0929, batch_loss_s: 0.0871, time:4.9663, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1470/3125], step: 10845, 8.015 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0833, batch_loss_s: 0.0981, time:4.9907, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1480/3125], step: 10855, 8.733 samples/sec, batch_loss: 0.2939, batch_loss_c: 0.2914, batch_loss_s: 0.2996, time:4.5806, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1490/3125], step: 10865, 9.108 samples/sec, batch_loss: 0.1393, batch_loss_c: 0.1389, batch_loss_s: 0.1404, time:4.3918, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1500/3125], step: 10875, 7.857 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0766, batch_loss_s: 0.0886, time:5.0909, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1510/3125], step: 10885, 8.844 samples/sec, batch_loss: 0.0794, batch_loss_c: 0.0805, batch_loss_s: 0.0770, time:4.5229, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1520/3125], step: 10895, 8.617 samples/sec, batch_loss: 0.1703, batch_loss_c: 0.1799, batch_loss_s: 0.1479, time:4.6422, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1530/3125], step: 10905, 8.523 samples/sec, batch_loss: 0.3202, batch_loss_c: 0.3161, batch_loss_s: 0.3299, time:4.6934, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1540/3125], step: 10915, 8.489 samples/sec, batch_loss: 0.5589, batch_loss_c: 0.5589, batch_loss_s: 0.5588, time:4.7118, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1550/3125], step: 10925, 7.429 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1382, batch_loss_s: 0.1068, time:5.3846, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1560/3125], step: 10935, 8.423 samples/sec, batch_loss: 0.1581, batch_loss_c: 0.1857, batch_loss_s: 0.0935, time:4.7491, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:41:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1570/3125], step: 10945, 8.230 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1028, batch_loss_s: 0.0879, time:4.8601, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1580/3125], step: 10955, 7.684 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1043, batch_loss_s: 0.1097, time:5.2054, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1590/3125], step: 10965, 8.388 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0855, batch_loss_s: 0.0753, time:4.7687, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1600/3125], step: 10975, 7.273 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0786, batch_loss_s: 0.0913, time:5.4995, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1610/3125], step: 10985, 8.318 samples/sec, batch_loss: 0.5210, batch_loss_c: 0.5128, batch_loss_s: 0.5402, time:4.8090, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1620/3125], step: 10995, 7.703 samples/sec, batch_loss: 0.5578, batch_loss_c: 0.5588, batch_loss_s: 0.5555, time:5.1930, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1630/3125], step: 11005, 7.918 samples/sec, batch_loss: 0.2794, batch_loss_c: 0.2591, batch_loss_s: 0.3266, time:5.0519, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1640/3125], step: 11015, 7.544 samples/sec, batch_loss: 0.0932, batch_loss_c: 0.0951, batch_loss_s: 0.0890, time:5.3022, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1650/3125], step: 11025, 8.384 samples/sec, batch_loss: 0.1825, batch_loss_c: 0.1717, batch_loss_s: 0.2078, time:4.7711, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1660/3125], step: 11035, 7.204 samples/sec, batch_loss: 0.0655, batch_loss_c: 0.0665, batch_loss_s: 0.0633, time:5.5528, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1670/3125], step: 11045, 6.770 samples/sec, batch_loss: 0.1000, batch_loss_c: 0.1046, batch_loss_s: 0.0894, time:5.9088, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1680/3125], step: 11055, 8.133 samples/sec, batch_loss: 0.1483, batch_loss_c: 0.1605, batch_loss_s: 0.1200, time:4.9182, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:42:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1690/3125], step: 11065, 7.344 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1167, batch_loss_s: 0.1140, time:5.4469, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1700/3125], step: 11075, 6.473 samples/sec, batch_loss: 0.3795, batch_loss_c: 0.3702, batch_loss_s: 0.4011, time:6.1799, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1710/3125], step: 11085, 7.392 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0829, batch_loss_s: 0.0884, time:5.4111, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1720/3125], step: 11095, 9.016 samples/sec, batch_loss: 0.3103, batch_loss_c: 0.3089, batch_loss_s: 0.3134, time:4.4366, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1730/3125], step: 11105, 7.220 samples/sec, batch_loss: 0.3153, batch_loss_c: 0.3151, batch_loss_s: 0.3158, time:5.5402, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1740/3125], step: 11115, 7.684 samples/sec, batch_loss: 0.1883, batch_loss_c: 0.2119, batch_loss_s: 0.1331, time:5.2059, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1750/3125], step: 11125, 7.213 samples/sec, batch_loss: 0.1369, batch_loss_c: 0.1409, batch_loss_s: 0.1277, time:5.5459, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1760/3125], step: 11135, 7.662 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3228, batch_loss_s: 0.3181, time:5.2205, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1770/3125], step: 11145, 7.939 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0889, batch_loss_s: 0.1004, time:5.0383, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1780/3125], step: 11155, 7.558 samples/sec, batch_loss: 0.2998, batch_loss_c: 0.2879, batch_loss_s: 0.3276, time:5.2924, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1790/3125], step: 11165, 7.787 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0650, batch_loss_s: 0.0843, time:5.1369, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:43:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1800/3125], step: 11175, 8.029 samples/sec, batch_loss: 0.1129, batch_loss_c: 0.1182, batch_loss_s: 0.1004, time:4.9816, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1810/3125], step: 11185, 7.659 samples/sec, batch_loss: 0.0917, batch_loss_c: 0.1005, batch_loss_s: 0.0712, time:5.2226, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1820/3125], step: 11195, 9.106 samples/sec, batch_loss: 0.1648, batch_loss_c: 0.1623, batch_loss_s: 0.1706, time:4.3929, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1830/3125], step: 11205, 8.086 samples/sec, batch_loss: 0.1198, batch_loss_c: 0.1312, batch_loss_s: 0.0932, time:4.9466, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1840/3125], step: 11215, 7.935 samples/sec, batch_loss: 0.4331, batch_loss_c: 0.4243, batch_loss_s: 0.4536, time:5.0407, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1850/3125], step: 11225, 9.065 samples/sec, batch_loss: 0.3508, batch_loss_c: 0.3473, batch_loss_s: 0.3591, time:4.4126, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1860/3125], step: 11235, 8.131 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0911, batch_loss_s: 0.0940, time:4.9196, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1870/3125], step: 11245, 8.342 samples/sec, batch_loss: 0.3001, batch_loss_c: 0.2884, batch_loss_s: 0.3273, time:4.7950, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1880/3125], step: 11255, 8.453 samples/sec, batch_loss: 0.1417, batch_loss_c: 0.1546, batch_loss_s: 0.1115, time:4.7318, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1890/3125], step: 11265, 7.276 samples/sec, batch_loss: 0.0744, batch_loss_c: 0.0758, batch_loss_s: 0.0711, time:5.4978, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1900/3125], step: 11275, 7.538 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1090, batch_loss_s: 0.1029, time:5.3065, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1910/3125], step: 11285, 8.476 samples/sec, batch_loss: 0.4388, batch_loss_c: 0.4131, batch_loss_s: 0.4986, time:4.7193, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1920/3125], step: 11295, 8.294 samples/sec, batch_loss: 0.0575, batch_loss_c: 0.0501, batch_loss_s: 0.0750, time:4.8226, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:44:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1930/3125], step: 11305, 8.168 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1181, batch_loss_s: 0.0996, time:4.8970, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1940/3125], step: 11315, 8.220 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1273, batch_loss_s: 0.0836, time:4.8661, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1950/3125], step: 11325, 7.330 samples/sec, batch_loss: 0.0939, batch_loss_c: 0.0927, batch_loss_s: 0.0967, time:5.4572, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1960/3125], step: 11335, 6.917 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1202, batch_loss_s: 0.1099, time:5.7832, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1970/3125], step: 11345, 8.214 samples/sec, batch_loss: 0.3714, batch_loss_c: 0.3678, batch_loss_s: 0.3799, time:4.8697, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1980/3125], step: 11355, 7.092 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.1113, batch_loss_s: 0.0796, time:5.6400, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1990/3125], step: 11365, 8.125 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0977, batch_loss_s: 0.0742, time:4.9231, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2000/3125], step: 11375, 7.178 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1022, batch_loss_s: 0.1745, time:5.5725, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2010/3125], step: 11385, 8.716 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3214, batch_loss_s: 0.3214, time:4.5892, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2020/3125], step: 11395, 8.073 samples/sec, batch_loss: 0.1191, batch_loss_c: 0.0932, batch_loss_s: 0.1794, time:4.9547, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2030/3125], step: 11405, 7.497 samples/sec, batch_loss: 0.2040, batch_loss_c: 0.1862, batch_loss_s: 0.2455, time:5.3354, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:45:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2040/3125], step: 11415, 8.055 samples/sec, batch_loss: 0.5517, batch_loss_c: 0.5528, batch_loss_s: 0.5493, time:4.9661, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2050/3125], step: 11425, 7.574 samples/sec, batch_loss: 0.1086, batch_loss_c: 0.1079, batch_loss_s: 0.1101, time:5.2810, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2060/3125], step: 11435, 8.256 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1162, batch_loss_s: 0.0942, time:4.8452, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2070/3125], step: 11445, 7.923 samples/sec, batch_loss: 0.3103, batch_loss_c: 0.3132, batch_loss_s: 0.3036, time:5.0488, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2080/3125], step: 11455, 8.538 samples/sec, batch_loss: 0.1422, batch_loss_c: 0.1398, batch_loss_s: 0.1478, time:4.6849, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2090/3125], step: 11465, 7.969 samples/sec, batch_loss: 0.1711, batch_loss_c: 0.1781, batch_loss_s: 0.1546, time:5.0194, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2100/3125], step: 11475, 8.213 samples/sec, batch_loss: 0.3233, batch_loss_c: 0.3315, batch_loss_s: 0.3041, time:4.8706, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2110/3125], step: 11485, 8.493 samples/sec, batch_loss: 0.1903, batch_loss_c: 0.1489, batch_loss_s: 0.2870, time:4.7097, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2120/3125], step: 11495, 7.383 samples/sec, batch_loss: 0.0588, batch_loss_c: 0.0534, batch_loss_s: 0.0715, time:5.4178, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2130/3125], step: 11505, 7.726 samples/sec, batch_loss: 0.3514, batch_loss_c: 0.3552, batch_loss_s: 0.3426, time:5.1770, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2140/3125], step: 11515, 8.095 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0971, batch_loss_s: 0.0925, time:4.9412, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2150/3125], step: 11525, 8.415 samples/sec, batch_loss: 0.3198, batch_loss_c: 0.3227, batch_loss_s: 0.3130, time:4.7536, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:46:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2160/3125], step: 11535, 8.802 samples/sec, batch_loss: 0.3660, batch_loss_c: 0.3896, batch_loss_s: 0.3112, time:4.5445, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2170/3125], step: 11545, 8.457 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3056, batch_loss_s: 0.3618, time:4.7300, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2180/3125], step: 11555, 6.718 samples/sec, batch_loss: 0.1875, batch_loss_c: 0.1896, batch_loss_s: 0.1827, time:5.9539, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2190/3125], step: 11565, 7.817 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0942, batch_loss_s: 0.0830, time:5.1170, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2200/3125], step: 11575, 7.587 samples/sec, batch_loss: 0.1442, batch_loss_c: 0.1512, batch_loss_s: 0.1278, time:5.2724, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2210/3125], step: 11585, 8.894 samples/sec, batch_loss: 0.3168, batch_loss_c: 0.3083, batch_loss_s: 0.3366, time:4.4976, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2220/3125], step: 11595, 7.635 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.1020, batch_loss_s: 0.0818, time:5.2388, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2230/3125], step: 11605, 7.758 samples/sec, batch_loss: 0.3196, batch_loss_c: 0.3180, batch_loss_s: 0.3233, time:5.1562, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2240/3125], step: 11615, 8.032 samples/sec, batch_loss: 0.3339, batch_loss_c: 0.3379, batch_loss_s: 0.3246, time:4.9798, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2250/3125], step: 11625, 7.689 samples/sec, batch_loss: 0.3270, batch_loss_c: 0.3207, batch_loss_s: 0.3419, time:5.2025, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2260/3125], step: 11635, 8.144 samples/sec, batch_loss: 0.3172, batch_loss_c: 0.3050, batch_loss_s: 0.3457, time:4.9114, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2270/3125], step: 11645, 7.294 samples/sec, batch_loss: 0.3784, batch_loss_c: 0.3960, batch_loss_s: 0.3375, time:5.4837, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:47:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2280/3125], step: 11655, 8.335 samples/sec, batch_loss: 0.0631, batch_loss_c: 0.0573, batch_loss_s: 0.0765, time:4.7989, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2290/3125], step: 11665, 8.713 samples/sec, batch_loss: 0.1292, batch_loss_c: 0.1278, batch_loss_s: 0.1326, time:4.5908, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2300/3125], step: 11675, 8.841 samples/sec, batch_loss: 0.2138, batch_loss_c: 0.2391, batch_loss_s: 0.1548, time:4.5245, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2310/3125], step: 11685, 7.377 samples/sec, batch_loss: 0.2993, batch_loss_c: 0.2983, batch_loss_s: 0.3017, time:5.4224, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2320/3125], step: 11695, 9.279 samples/sec, batch_loss: 0.3315, batch_loss_c: 0.3351, batch_loss_s: 0.3232, time:4.3108, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2330/3125], step: 11705, 8.008 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1149, batch_loss_s: 0.1403, time:4.9950, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2340/3125], step: 11715, 8.013 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1000, batch_loss_s: 0.1092, time:4.9918, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2350/3125], step: 11725, 8.415 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0915, batch_loss_s: 0.1085, time:4.7536, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2360/3125], step: 11735, 8.612 samples/sec, batch_loss: 0.3230, batch_loss_c: 0.3218, batch_loss_s: 0.3258, time:4.6447, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2370/3125], step: 11745, 7.529 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.0997, batch_loss_s: 0.1078, time:5.3131, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2380/3125], step: 11755, 8.647 samples/sec, batch_loss: 0.3315, batch_loss_c: 0.3347, batch_loss_s: 0.3242, time:4.6259, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2390/3125], step: 11765, 8.526 samples/sec, batch_loss: 0.0641, batch_loss_c: 0.0623, batch_loss_s: 0.0683, time:4.6916, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2400/3125], step: 11775, 7.965 samples/sec, batch_loss: 0.1137, batch_loss_c: 0.1151, batch_loss_s: 0.1104, time:5.0219, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:48:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2410/3125], step: 11785, 8.196 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0821, batch_loss_s: 0.0891, time:4.8807, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2420/3125], step: 11795, 8.093 samples/sec, batch_loss: 0.3434, batch_loss_c: 0.3440, batch_loss_s: 0.3420, time:4.9423, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2430/3125], step: 11805, 8.078 samples/sec, batch_loss: 0.0770, batch_loss_c: 0.0731, batch_loss_s: 0.0859, time:4.9516, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2440/3125], step: 11815, 7.774 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1311, batch_loss_s: 0.1114, time:5.1451, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2450/3125], step: 11825, 8.353 samples/sec, batch_loss: 0.1315, batch_loss_c: 0.1317, batch_loss_s: 0.1310, time:4.7885, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2460/3125], step: 11835, 8.119 samples/sec, batch_loss: 0.1509, batch_loss_c: 0.1610, batch_loss_s: 0.1273, time:4.9267, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2470/3125], step: 11845, 9.045 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0824, batch_loss_s: 0.0877, time:4.4224, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2480/3125], step: 11855, 8.409 samples/sec, batch_loss: 0.1205, batch_loss_c: 0.1142, batch_loss_s: 0.1352, time:4.7566, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2490/3125], step: 11865, 8.745 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1066, batch_loss_s: 0.1097, time:4.5740, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2500/3125], step: 11875, 8.846 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0865, batch_loss_s: 0.0635, time:4.5218, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2510/3125], step: 11885, 8.048 samples/sec, batch_loss: 0.2042, batch_loss_c: 0.1647, batch_loss_s: 0.2964, time:4.9700, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2520/3125], step: 11895, 7.932 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0688, batch_loss_s: 0.0816, time:5.0430, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:49:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2530/3125], step: 11905, 8.346 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0872, batch_loss_s: 0.0774, time:4.7927, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2540/3125], step: 11915, 8.877 samples/sec, batch_loss: 0.3669, batch_loss_c: 0.3662, batch_loss_s: 0.3684, time:4.5059, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2550/3125], step: 11925, 8.668 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0642, batch_loss_s: 0.0789, time:4.6147, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2560/3125], step: 11935, 8.493 samples/sec, batch_loss: 0.0709, batch_loss_c: 0.0632, batch_loss_s: 0.0891, time:4.7096, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2570/3125], step: 11945, 8.187 samples/sec, batch_loss: 0.1250, batch_loss_c: 0.1451, batch_loss_s: 0.0782, time:4.8860, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2580/3125], step: 11955, 8.539 samples/sec, batch_loss: 0.1495, batch_loss_c: 0.1584, batch_loss_s: 0.1290, time:4.6843, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2590/3125], step: 11965, 8.000 samples/sec, batch_loss: 0.3470, batch_loss_c: 0.3493, batch_loss_s: 0.3418, time:4.9998, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2600/3125], step: 11975, 7.863 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1034, batch_loss_s: 0.1065, time:5.0870, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2610/3125], step: 11985, 8.261 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1095, batch_loss_s: 0.1091, time:4.8419, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2620/3125], step: 11995, 8.266 samples/sec, batch_loss: 0.1824, batch_loss_c: 0.2054, batch_loss_s: 0.1288, time:4.8392, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2630/3125], step: 12005, 7.413 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0747, batch_loss_s: 0.0921, time:5.3960, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2640/3125], step: 12015, 8.395 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0966, batch_loss_s: 0.0965, time:4.7647, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:50:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2650/3125], step: 12025, 8.479 samples/sec, batch_loss: 0.1322, batch_loss_c: 0.1408, batch_loss_s: 0.1120, time:4.7173, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2660/3125], step: 12035, 7.937 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.1019, batch_loss_s: 0.1006, time:5.0394, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2670/3125], step: 12045, 8.321 samples/sec, batch_loss: 0.3775, batch_loss_c: 0.3732, batch_loss_s: 0.3875, time:4.8073, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2680/3125], step: 12055, 8.740 samples/sec, batch_loss: 0.0902, batch_loss_c: 0.0944, batch_loss_s: 0.0803, time:4.5766, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2690/3125], step: 12065, 7.995 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0820, batch_loss_s: 0.0837, time:5.0034, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2700/3125], step: 12075, 8.363 samples/sec, batch_loss: 0.3172, batch_loss_c: 0.3215, batch_loss_s: 0.3071, time:4.7832, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2710/3125], step: 12085, 7.339 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1279, batch_loss_s: 0.1014, time:5.4505, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2720/3125], step: 12095, 8.411 samples/sec, batch_loss: 0.3032, batch_loss_c: 0.3013, batch_loss_s: 0.3077, time:4.7559, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2730/3125], step: 12105, 8.662 samples/sec, batch_loss: 0.4724, batch_loss_c: 0.5072, batch_loss_s: 0.3913, time:4.6178, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2740/3125], step: 12115, 8.283 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1183, batch_loss_s: 0.0714, time:4.8292, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2750/3125], step: 12125, 8.992 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0781, batch_loss_s: 0.0885, time:4.4482, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2760/3125], step: 12135, 8.196 samples/sec, batch_loss: 0.3320, batch_loss_c: 0.3384, batch_loss_s: 0.3171, time:4.8806, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2770/3125], step: 12145, 8.265 samples/sec, batch_loss: 0.0583, batch_loss_c: 0.0563, batch_loss_s: 0.0629, time:4.8398, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:51:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2780/3125], step: 12155, 8.099 samples/sec, batch_loss: 0.3063, batch_loss_c: 0.3002, batch_loss_s: 0.3204, time:4.9389, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2790/3125], step: 12165, 8.008 samples/sec, batch_loss: 0.3428, batch_loss_c: 0.3460, batch_loss_s: 0.3352, time:4.9953, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2800/3125], step: 12175, 7.613 samples/sec, batch_loss: 0.1950, batch_loss_c: 0.2229, batch_loss_s: 0.1299, time:5.2539, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2810/3125], step: 12185, 8.041 samples/sec, batch_loss: 0.3062, batch_loss_c: 0.3057, batch_loss_s: 0.3076, time:4.9745, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2820/3125], step: 12195, 8.115 samples/sec, batch_loss: 0.1393, batch_loss_c: 0.1177, batch_loss_s: 0.1899, time:4.9294, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2830/3125], step: 12205, 8.324 samples/sec, batch_loss: 0.1315, batch_loss_c: 0.1322, batch_loss_s: 0.1298, time:4.8054, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2840/3125], step: 12215, 7.365 samples/sec, batch_loss: 0.5423, batch_loss_c: 0.5393, batch_loss_s: 0.5494, time:5.4312, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2850/3125], step: 12225, 7.605 samples/sec, batch_loss: 0.2524, batch_loss_c: 0.2564, batch_loss_s: 0.2430, time:5.2598, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2860/3125], step: 12235, 8.445 samples/sec, batch_loss: 0.0831, batch_loss_c: 0.0836, batch_loss_s: 0.0820, time:4.7368, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2870/3125], step: 12245, 7.814 samples/sec, batch_loss: 0.5134, batch_loss_c: 0.5049, batch_loss_s: 0.5332, time:5.1193, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2880/3125], step: 12255, 7.516 samples/sec, batch_loss: 0.3052, batch_loss_c: 0.3051, batch_loss_s: 0.3053, time:5.3221, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2890/3125], step: 12265, 7.828 samples/sec, batch_loss: 0.0810, batch_loss_c: 0.0812, batch_loss_s: 0.0803, time:5.1100, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:52:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2900/3125], step: 12275, 9.100 samples/sec, batch_loss: 0.1380, batch_loss_c: 0.1567, batch_loss_s: 0.0942, time:4.3956, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2910/3125], step: 12285, 8.765 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1029, batch_loss_s: 0.0966, time:4.5634, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2920/3125], step: 12295, 8.095 samples/sec, batch_loss: 0.3381, batch_loss_c: 0.3405, batch_loss_s: 0.3328, time:4.9415, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2930/3125], step: 12305, 7.788 samples/sec, batch_loss: 0.5572, batch_loss_c: 0.5615, batch_loss_s: 0.5472, time:5.1361, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2940/3125], step: 12315, 8.280 samples/sec, batch_loss: 0.4948, batch_loss_c: 0.4725, batch_loss_s: 0.5468, time:4.8307, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2950/3125], step: 12325, 7.763 samples/sec, batch_loss: 0.1065, batch_loss_c: 0.1174, batch_loss_s: 0.0811, time:5.1523, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2960/3125], step: 12335, 7.622 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1128, batch_loss_s: 0.1083, time:5.2482, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2970/3125], step: 12345, 7.641 samples/sec, batch_loss: 0.2954, batch_loss_c: 0.2884, batch_loss_s: 0.3116, time:5.2348, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2980/3125], step: 12355, 6.188 samples/sec, batch_loss: 0.3306, batch_loss_c: 0.3316, batch_loss_s: 0.3284, time:6.4642, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2990/3125], step: 12365, 7.589 samples/sec, batch_loss: 0.2933, batch_loss_c: 0.2732, batch_loss_s: 0.3404, time:5.2711, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3000/3125], step: 12375, 7.872 samples/sec, batch_loss: 0.2656, batch_loss_c: 0.2500, batch_loss_s: 0.3020, time:5.0816, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:53:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3010/3125], step: 12385, 7.317 samples/sec, batch_loss: 0.3426, batch_loss_c: 0.3440, batch_loss_s: 0.3391, time:5.4665, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3020/3125], step: 12395, 8.217 samples/sec, batch_loss: 0.3086, batch_loss_c: 0.3015, batch_loss_s: 0.3251, time:4.8678, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3030/3125], step: 12405, 7.999 samples/sec, batch_loss: 0.4585, batch_loss_c: 0.4584, batch_loss_s: 0.4589, time:5.0007, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3040/3125], step: 12415, 7.496 samples/sec, batch_loss: 0.1311, batch_loss_c: 0.1310, batch_loss_s: 0.1315, time:5.3361, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3050/3125], step: 12425, 7.707 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1792, batch_loss_s: 0.0628, time:5.1901, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3060/3125], step: 12435, 7.922 samples/sec, batch_loss: 0.4706, batch_loss_c: 0.5144, batch_loss_s: 0.3682, time:5.0491, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3070/3125], step: 12445, 8.471 samples/sec, batch_loss: 0.3276, batch_loss_c: 0.3223, batch_loss_s: 0.3400, time:4.7219, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3080/3125], step: 12455, 7.188 samples/sec, batch_loss: 0.1541, batch_loss_c: 0.1520, batch_loss_s: 0.1589, time:5.5651, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3090/3125], step: 12465, 7.633 samples/sec, batch_loss: 0.1282, batch_loss_c: 0.1219, batch_loss_s: 0.1428, time:5.2401, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3100/3125], step: 12475, 7.783 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0717, batch_loss_s: 0.0798, time:5.1395, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3110/3125], step: 12485, 10.364 samples/sec, batch_loss: 0.0919, batch_loss_c: 0.1007, batch_loss_s: 0.0712, time:3.8594, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3120/3125], step: 12495, 10.235 samples/sec, batch_loss: 0.1079, batch_loss_c: 0.1060, batch_loss_s: 0.1123, time:3.9080, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:54:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], train_loss: 0.1885, time: 1573.1688, lr: 0.0001\u001b[0m\n",
            "2019-11-23 12:54:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [0/3125], step: 12500, 7.468 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0809, batch_loss_s: 0.1178, time:5.3559, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [10/3125], step: 12510, 5.337 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1186, batch_loss_s: 0.0886, time:7.4953, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [20/3125], step: 12520, 8.455 samples/sec, batch_loss: 0.2880, batch_loss_c: 0.2740, batch_loss_s: 0.3207, time:4.7311, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [30/3125], step: 12530, 8.363 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1178, batch_loss_s: 0.0914, time:4.7832, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [40/3125], step: 12540, 8.461 samples/sec, batch_loss: 0.3111, batch_loss_c: 0.3104, batch_loss_s: 0.3127, time:4.7276, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [50/3125], step: 12550, 7.494 samples/sec, batch_loss: 0.1209, batch_loss_c: 0.1313, batch_loss_s: 0.0967, time:5.3375, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [60/3125], step: 12560, 7.642 samples/sec, batch_loss: 0.1052, batch_loss_c: 0.1043, batch_loss_s: 0.1072, time:5.2344, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [70/3125], step: 12570, 7.524 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0759, batch_loss_s: 0.0910, time:5.3162, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [80/3125], step: 12580, 8.042 samples/sec, batch_loss: 0.1794, batch_loss_c: 0.1804, batch_loss_s: 0.1770, time:4.9740, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [90/3125], step: 12590, 7.832 samples/sec, batch_loss: 0.2310, batch_loss_c: 0.2450, batch_loss_s: 0.1982, time:5.1070, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [100/3125], step: 12600, 6.893 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0920, batch_loss_s: 0.0782, time:5.8026, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:55:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [110/3125], step: 12610, 6.836 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.1108, batch_loss_s: 0.1135, time:5.8516, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [120/3125], step: 12620, 7.585 samples/sec, batch_loss: 0.1368, batch_loss_c: 0.1188, batch_loss_s: 0.1787, time:5.2735, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [130/3125], step: 12630, 8.020 samples/sec, batch_loss: 0.1234, batch_loss_c: 0.1216, batch_loss_s: 0.1277, time:4.9876, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [140/3125], step: 12640, 8.550 samples/sec, batch_loss: 0.3470, batch_loss_c: 0.3587, batch_loss_s: 0.3196, time:4.6785, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [150/3125], step: 12650, 7.339 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0725, batch_loss_s: 0.0844, time:5.4505, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [160/3125], step: 12660, 8.297 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1174, batch_loss_s: 0.1276, time:4.8211, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [170/3125], step: 12670, 8.074 samples/sec, batch_loss: 0.2855, batch_loss_c: 0.2708, batch_loss_s: 0.3196, time:4.9541, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [180/3125], step: 12680, 8.748 samples/sec, batch_loss: 0.3029, batch_loss_c: 0.2999, batch_loss_s: 0.3099, time:4.5724, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [190/3125], step: 12690, 8.136 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0740, batch_loss_s: 0.0827, time:4.9164, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [200/3125], step: 12700, 7.932 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3130, batch_loss_s: 0.3118, time:5.0428, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [210/3125], step: 12710, 7.977 samples/sec, batch_loss: 0.1081, batch_loss_c: 0.1185, batch_loss_s: 0.0837, time:5.0146, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [220/3125], step: 12720, 7.523 samples/sec, batch_loss: 0.1614, batch_loss_c: 0.1898, batch_loss_s: 0.0952, time:5.3169, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:56:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [230/3125], step: 12730, 8.535 samples/sec, batch_loss: 0.1122, batch_loss_c: 0.1197, batch_loss_s: 0.0948, time:4.6865, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [240/3125], step: 12740, 8.274 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0782, batch_loss_s: 0.0892, time:4.8346, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [250/3125], step: 12750, 8.393 samples/sec, batch_loss: 0.1656, batch_loss_c: 0.1699, batch_loss_s: 0.1553, time:4.7661, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [260/3125], step: 12760, 8.966 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0739, batch_loss_s: 0.0870, time:4.4615, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [270/3125], step: 12770, 8.505 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0937, batch_loss_s: 0.0800, time:4.7034, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [280/3125], step: 12780, 7.917 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0933, batch_loss_s: 0.0777, time:5.0522, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [290/3125], step: 12790, 9.036 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1304, batch_loss_s: 0.1094, time:4.4269, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [300/3125], step: 12800, 8.425 samples/sec, batch_loss: 0.3697, batch_loss_c: 0.3912, batch_loss_s: 0.3197, time:4.7480, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [310/3125], step: 12810, 7.859 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.0959, batch_loss_s: 0.1159, time:5.0898, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [320/3125], step: 12820, 8.537 samples/sec, batch_loss: 0.1179, batch_loss_c: 0.1113, batch_loss_s: 0.1334, time:4.6856, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [330/3125], step: 12830, 8.371 samples/sec, batch_loss: 0.3138, batch_loss_c: 0.3134, batch_loss_s: 0.3148, time:4.7782, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [340/3125], step: 12840, 8.631 samples/sec, batch_loss: 0.5753, batch_loss_c: 0.5863, batch_loss_s: 0.5496, time:4.6343, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [350/3125], step: 12850, 7.959 samples/sec, batch_loss: 0.3320, batch_loss_c: 0.3336, batch_loss_s: 0.3281, time:5.0259, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:57:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [360/3125], step: 12860, 8.037 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.0970, batch_loss_s: 0.1038, time:4.9771, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [370/3125], step: 12870, 7.948 samples/sec, batch_loss: 0.2881, batch_loss_c: 0.2857, batch_loss_s: 0.2936, time:5.0327, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [380/3125], step: 12880, 7.445 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0737, batch_loss_s: 0.0753, time:5.3730, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [390/3125], step: 12890, 8.045 samples/sec, batch_loss: 0.1685, batch_loss_c: 0.1814, batch_loss_s: 0.1384, time:4.9722, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [400/3125], step: 12900, 7.447 samples/sec, batch_loss: 0.1617, batch_loss_c: 0.1661, batch_loss_s: 0.1517, time:5.3714, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [410/3125], step: 12910, 8.575 samples/sec, batch_loss: 0.1271, batch_loss_c: 0.1280, batch_loss_s: 0.1251, time:4.6647, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [420/3125], step: 12920, 8.255 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0619, batch_loss_s: 0.0711, time:4.8454, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [430/3125], step: 12930, 7.434 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.1927, batch_loss_s: 0.1989, time:5.3810, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [440/3125], step: 12940, 8.087 samples/sec, batch_loss: 0.0745, batch_loss_c: 0.0692, batch_loss_s: 0.0869, time:4.9463, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [450/3125], step: 12950, 8.698 samples/sec, batch_loss: 0.2219, batch_loss_c: 0.1874, batch_loss_s: 0.3022, time:4.5989, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [460/3125], step: 12960, 8.406 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0905, batch_loss_s: 0.0931, time:4.7584, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [470/3125], step: 12970, 8.054 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0949, batch_loss_s: 0.0796, time:4.9665, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:58:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [480/3125], step: 12980, 8.093 samples/sec, batch_loss: 0.0630, batch_loss_c: 0.0588, batch_loss_s: 0.0726, time:4.9428, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [490/3125], step: 12990, 8.900 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1592, batch_loss_s: 0.1293, time:4.4942, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [500/3125], step: 13000, 7.949 samples/sec, batch_loss: 0.2330, batch_loss_c: 0.2344, batch_loss_s: 0.2297, time:5.0322, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [510/3125], step: 13010, 7.697 samples/sec, batch_loss: 0.2817, batch_loss_c: 0.2673, batch_loss_s: 0.3152, time:5.1968, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [520/3125], step: 13020, 7.995 samples/sec, batch_loss: 0.2038, batch_loss_c: 0.2502, batch_loss_s: 0.0957, time:5.0033, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [530/3125], step: 13030, 7.955 samples/sec, batch_loss: 0.0650, batch_loss_c: 0.0578, batch_loss_s: 0.0817, time:5.0282, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [540/3125], step: 13040, 7.752 samples/sec, batch_loss: 0.0810, batch_loss_c: 0.0865, batch_loss_s: 0.0681, time:5.1601, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [550/3125], step: 13050, 8.042 samples/sec, batch_loss: 0.2670, batch_loss_c: 0.2928, batch_loss_s: 0.2070, time:4.9740, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [560/3125], step: 13060, 8.576 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1125, batch_loss_s: 0.1129, time:4.6641, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [570/3125], step: 13070, 6.936 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0929, batch_loss_s: 0.1021, time:5.7674, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [580/3125], step: 13080, 8.027 samples/sec, batch_loss: 0.0773, batch_loss_c: 0.0798, batch_loss_s: 0.0714, time:4.9832, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [590/3125], step: 13090, 8.622 samples/sec, batch_loss: 0.3090, batch_loss_c: 0.3120, batch_loss_s: 0.3019, time:4.6392, lr:0.0001\u001b[0m\n",
            "2019-11-23 12:59:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [600/3125], step: 13100, 7.825 samples/sec, batch_loss: 0.1387, batch_loss_c: 0.1538, batch_loss_s: 0.1034, time:5.1117, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [610/3125], step: 13110, 8.633 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.0945, batch_loss_s: 0.1516, time:4.6334, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [620/3125], step: 13120, 8.507 samples/sec, batch_loss: 0.3717, batch_loss_c: 0.3606, batch_loss_s: 0.3975, time:4.7019, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [630/3125], step: 13130, 8.487 samples/sec, batch_loss: 0.3164, batch_loss_c: 0.3165, batch_loss_s: 0.3162, time:4.7129, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [640/3125], step: 13140, 7.497 samples/sec, batch_loss: 0.1534, batch_loss_c: 0.1667, batch_loss_s: 0.1222, time:5.3357, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [650/3125], step: 13150, 7.979 samples/sec, batch_loss: 0.0770, batch_loss_c: 0.0748, batch_loss_s: 0.0821, time:5.0132, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [660/3125], step: 13160, 8.996 samples/sec, batch_loss: 0.2810, batch_loss_c: 0.2709, batch_loss_s: 0.3043, time:4.4464, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [670/3125], step: 13170, 8.171 samples/sec, batch_loss: 0.2072, batch_loss_c: 0.1672, batch_loss_s: 0.3005, time:4.8954, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [680/3125], step: 13180, 8.479 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1008, batch_loss_s: 0.1075, time:4.7177, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [690/3125], step: 13190, 8.681 samples/sec, batch_loss: 0.1195, batch_loss_c: 0.1268, batch_loss_s: 0.1027, time:4.6078, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [700/3125], step: 13200, 7.859 samples/sec, batch_loss: 0.2772, batch_loss_c: 0.2620, batch_loss_s: 0.3127, time:5.0896, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [710/3125], step: 13210, 7.947 samples/sec, batch_loss: 0.0831, batch_loss_c: 0.0817, batch_loss_s: 0.0864, time:5.0332, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:00:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [720/3125], step: 13220, 7.828 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3082, batch_loss_s: 0.3230, time:5.1099, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [730/3125], step: 13230, 6.982 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0806, batch_loss_s: 0.0896, time:5.7292, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [740/3125], step: 13240, 7.681 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1436, batch_loss_s: 0.0983, time:5.2078, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [750/3125], step: 13250, 7.006 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1199, batch_loss_s: 0.0995, time:5.7091, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [760/3125], step: 13260, 7.625 samples/sec, batch_loss: 0.2649, batch_loss_c: 0.2507, batch_loss_s: 0.2980, time:5.2462, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [770/3125], step: 13270, 7.795 samples/sec, batch_loss: 0.1173, batch_loss_c: 0.1169, batch_loss_s: 0.1182, time:5.1315, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [780/3125], step: 13280, 6.793 samples/sec, batch_loss: 0.1100, batch_loss_c: 0.1165, batch_loss_s: 0.0950, time:5.8885, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [790/3125], step: 13290, 7.917 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1099, batch_loss_s: 0.1144, time:5.0525, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [800/3125], step: 13300, 7.791 samples/sec, batch_loss: 0.0736, batch_loss_c: 0.0735, batch_loss_s: 0.0741, time:5.1338, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [810/3125], step: 13310, 8.182 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0673, batch_loss_s: 0.0610, time:4.8890, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [820/3125], step: 13320, 7.864 samples/sec, batch_loss: 0.3549, batch_loss_c: 0.3489, batch_loss_s: 0.3689, time:5.0864, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:01:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [830/3125], step: 13330, 7.629 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.1057, batch_loss_s: 0.0835, time:5.2434, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [840/3125], step: 13340, 8.334 samples/sec, batch_loss: 0.3163, batch_loss_c: 0.3076, batch_loss_s: 0.3367, time:4.7999, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [850/3125], step: 13350, 7.143 samples/sec, batch_loss: 0.1926, batch_loss_c: 0.2330, batch_loss_s: 0.0983, time:5.5999, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [860/3125], step: 13360, 7.851 samples/sec, batch_loss: 0.1774, batch_loss_c: 0.1759, batch_loss_s: 0.1811, time:5.0950, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [870/3125], step: 13370, 7.945 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.1028, batch_loss_s: 0.0817, time:5.0344, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [880/3125], step: 13380, 8.243 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1202, batch_loss_s: 0.0944, time:4.8527, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [890/3125], step: 13390, 8.272 samples/sec, batch_loss: 0.1083, batch_loss_c: 0.1144, batch_loss_s: 0.0943, time:4.8356, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [900/3125], step: 13400, 8.277 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1425, batch_loss_s: 0.1177, time:4.8325, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [910/3125], step: 13410, 8.386 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3138, batch_loss_s: 0.3077, time:4.7701, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [920/3125], step: 13420, 8.741 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.0965, batch_loss_s: 0.1052, time:4.5760, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [930/3125], step: 13430, 8.438 samples/sec, batch_loss: 0.1505, batch_loss_c: 0.1726, batch_loss_s: 0.0990, time:4.7405, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [940/3125], step: 13440, 8.125 samples/sec, batch_loss: 0.1354, batch_loss_c: 0.1342, batch_loss_s: 0.1381, time:4.9231, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:02:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [950/3125], step: 13450, 7.823 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.1804, batch_loss_s: 0.1213, time:5.1131, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [960/3125], step: 13460, 7.734 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1184, batch_loss_s: 0.0764, time:5.1722, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [970/3125], step: 13470, 7.639 samples/sec, batch_loss: 0.5211, batch_loss_c: 0.5175, batch_loss_s: 0.5295, time:5.2360, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [980/3125], step: 13480, 7.684 samples/sec, batch_loss: 0.1595, batch_loss_c: 0.1757, batch_loss_s: 0.1218, time:5.2057, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [990/3125], step: 13490, 8.217 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0779, batch_loss_s: 0.0673, time:4.8678, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1000/3125], step: 13500, 7.952 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1297, batch_loss_s: 0.0772, time:5.0303, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1010/3125], step: 13510, 7.599 samples/sec, batch_loss: 0.2033, batch_loss_c: 0.2080, batch_loss_s: 0.1923, time:5.2641, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1020/3125], step: 13520, 8.021 samples/sec, batch_loss: 0.1765, batch_loss_c: 0.2021, batch_loss_s: 0.1169, time:4.9870, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1030/3125], step: 13530, 8.810 samples/sec, batch_loss: 0.0592, batch_loss_c: 0.0565, batch_loss_s: 0.0654, time:4.5404, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1040/3125], step: 13540, 7.470 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0825, batch_loss_s: 0.0694, time:5.3545, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1050/3125], step: 13550, 7.633 samples/sec, batch_loss: 0.4666, batch_loss_c: 0.4468, batch_loss_s: 0.5130, time:5.2405, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1060/3125], step: 13560, 8.270 samples/sec, batch_loss: 0.3631, batch_loss_c: 0.3897, batch_loss_s: 0.3009, time:4.8365, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1070/3125], step: 13570, 8.671 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1406, batch_loss_s: 0.1294, time:4.6131, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:03:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1080/3125], step: 13580, 8.501 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1360, batch_loss_s: 0.1314, time:4.7055, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1090/3125], step: 13590, 8.513 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0672, batch_loss_s: 0.0671, time:4.6990, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1100/3125], step: 13600, 7.981 samples/sec, batch_loss: 0.3445, batch_loss_c: 0.3495, batch_loss_s: 0.3327, time:5.0121, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1110/3125], step: 13610, 8.127 samples/sec, batch_loss: 0.3054, batch_loss_c: 0.2992, batch_loss_s: 0.3197, time:4.9219, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1120/3125], step: 13620, 7.033 samples/sec, batch_loss: 0.2129, batch_loss_c: 0.2314, batch_loss_s: 0.1699, time:5.6879, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1130/3125], step: 13630, 7.992 samples/sec, batch_loss: 0.3181, batch_loss_c: 0.3137, batch_loss_s: 0.3285, time:5.0050, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1140/3125], step: 13640, 7.816 samples/sec, batch_loss: 0.5396, batch_loss_c: 0.5361, batch_loss_s: 0.5479, time:5.1175, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1150/3125], step: 13650, 7.543 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.0749, batch_loss_s: 0.1932, time:5.3030, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1160/3125], step: 13660, 7.079 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0697, batch_loss_s: 0.0860, time:5.6507, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1170/3125], step: 13670, 7.264 samples/sec, batch_loss: 0.3285, batch_loss_c: 0.3252, batch_loss_s: 0.3362, time:5.5064, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1180/3125], step: 13680, 8.214 samples/sec, batch_loss: 0.2663, batch_loss_c: 0.2503, batch_loss_s: 0.3036, time:4.8700, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:04:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1190/3125], step: 13690, 7.454 samples/sec, batch_loss: 0.2861, batch_loss_c: 0.2714, batch_loss_s: 0.3204, time:5.3664, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1200/3125], step: 13700, 7.567 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0821, batch_loss_s: 0.0711, time:5.2864, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1210/3125], step: 13710, 7.810 samples/sec, batch_loss: 0.1515, batch_loss_c: 0.1694, batch_loss_s: 0.1097, time:5.1214, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1220/3125], step: 13720, 7.992 samples/sec, batch_loss: 0.0523, batch_loss_c: 0.0501, batch_loss_s: 0.0573, time:5.0049, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1230/3125], step: 13730, 7.769 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.1010, batch_loss_s: 0.1036, time:5.1484, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1240/3125], step: 13740, 8.100 samples/sec, batch_loss: 0.0558, batch_loss_c: 0.0511, batch_loss_s: 0.0668, time:4.9381, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1250/3125], step: 13750, 7.526 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1214, batch_loss_s: 0.1082, time:5.3150, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1260/3125], step: 13760, 7.144 samples/sec, batch_loss: 0.1512, batch_loss_c: 0.1516, batch_loss_s: 0.1504, time:5.5988, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1270/3125], step: 13770, 8.616 samples/sec, batch_loss: 0.0723, batch_loss_c: 0.0700, batch_loss_s: 0.0778, time:4.6425, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1280/3125], step: 13780, 7.548 samples/sec, batch_loss: 0.4369, batch_loss_c: 0.4723, batch_loss_s: 0.3544, time:5.2997, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1290/3125], step: 13790, 8.867 samples/sec, batch_loss: 0.2080, batch_loss_c: 0.2275, batch_loss_s: 0.1626, time:4.5113, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1300/3125], step: 13800, 8.673 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0878, batch_loss_s: 0.0821, time:4.6122, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:05:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1310/3125], step: 13810, 7.467 samples/sec, batch_loss: 0.3159, batch_loss_c: 0.3156, batch_loss_s: 0.3165, time:5.3566, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1320/3125], step: 13820, 8.210 samples/sec, batch_loss: 0.1532, batch_loss_c: 0.1703, batch_loss_s: 0.1132, time:4.8722, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1330/3125], step: 13830, 8.869 samples/sec, batch_loss: 0.0634, batch_loss_c: 0.0580, batch_loss_s: 0.0759, time:4.5101, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1340/3125], step: 13840, 7.864 samples/sec, batch_loss: 0.1727, batch_loss_c: 0.1808, batch_loss_s: 0.1538, time:5.0865, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1350/3125], step: 13850, 7.642 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1440, batch_loss_s: 0.1313, time:5.2340, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1360/3125], step: 13860, 7.703 samples/sec, batch_loss: 0.4680, batch_loss_c: 0.4837, batch_loss_s: 0.4312, time:5.1926, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1370/3125], step: 13870, 7.901 samples/sec, batch_loss: 0.2772, batch_loss_c: 0.3266, batch_loss_s: 0.1619, time:5.0626, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1380/3125], step: 13880, 7.855 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1203, batch_loss_s: 0.1081, time:5.0921, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1390/3125], step: 13890, 7.454 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1431, batch_loss_s: 0.1333, time:5.3660, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1400/3125], step: 13900, 7.183 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0748, batch_loss_s: 0.0935, time:5.5687, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1410/3125], step: 13910, 6.974 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0603, batch_loss_s: 0.0806, time:5.7353, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:06:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1420/3125], step: 13920, 8.058 samples/sec, batch_loss: 0.4317, batch_loss_c: 0.4566, batch_loss_s: 0.3736, time:4.9642, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1430/3125], step: 13930, 7.260 samples/sec, batch_loss: 0.3110, batch_loss_c: 0.2837, batch_loss_s: 0.3748, time:5.5098, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1440/3125], step: 13940, 8.445 samples/sec, batch_loss: 0.2514, batch_loss_c: 0.2442, batch_loss_s: 0.2681, time:4.7368, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1450/3125], step: 13950, 8.243 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0735, batch_loss_s: 0.0899, time:4.8528, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1460/3125], step: 13960, 7.904 samples/sec, batch_loss: 0.1259, batch_loss_c: 0.1163, batch_loss_s: 0.1484, time:5.0610, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1470/3125], step: 13970, 7.846 samples/sec, batch_loss: 0.1620, batch_loss_c: 0.1927, batch_loss_s: 0.0903, time:5.0985, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1480/3125], step: 13980, 9.057 samples/sec, batch_loss: 0.0662, batch_loss_c: 0.0647, batch_loss_s: 0.0696, time:4.4163, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1490/3125], step: 13990, 8.549 samples/sec, batch_loss: 0.3279, batch_loss_c: 0.3238, batch_loss_s: 0.3373, time:4.6788, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1500/3125], step: 14000, 8.055 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0903, batch_loss_s: 0.0747, time:4.9657, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1510/3125], step: 14010, 8.255 samples/sec, batch_loss: 0.3868, batch_loss_c: 0.4114, batch_loss_s: 0.3295, time:4.8456, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1520/3125], step: 14020, 7.791 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0809, batch_loss_s: 0.0795, time:5.1344, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1530/3125], step: 14030, 7.901 samples/sec, batch_loss: 0.2894, batch_loss_c: 0.2837, batch_loss_s: 0.3028, time:5.0624, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1540/3125], step: 14040, 8.051 samples/sec, batch_loss: 0.0711, batch_loss_c: 0.0649, batch_loss_s: 0.0856, time:4.9684, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:07:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1550/3125], step: 14050, 8.838 samples/sec, batch_loss: 0.5240, batch_loss_c: 0.5090, batch_loss_s: 0.5592, time:4.5257, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1560/3125], step: 14060, 7.979 samples/sec, batch_loss: 0.1513, batch_loss_c: 0.1609, batch_loss_s: 0.1287, time:5.0133, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1570/3125], step: 14070, 8.375 samples/sec, batch_loss: 0.1066, batch_loss_c: 0.1140, batch_loss_s: 0.0893, time:4.7759, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1580/3125], step: 14080, 8.104 samples/sec, batch_loss: 0.4110, batch_loss_c: 0.4306, batch_loss_s: 0.3652, time:4.9359, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1590/3125], step: 14090, 7.586 samples/sec, batch_loss: 0.0875, batch_loss_c: 0.0874, batch_loss_s: 0.0879, time:5.2730, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1600/3125], step: 14100, 8.022 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.0964, batch_loss_s: 0.1024, time:4.9864, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1610/3125], step: 14110, 8.107 samples/sec, batch_loss: 0.1275, batch_loss_c: 0.1257, batch_loss_s: 0.1317, time:4.9338, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1620/3125], step: 14120, 8.634 samples/sec, batch_loss: 0.1373, batch_loss_c: 0.1293, batch_loss_s: 0.1559, time:4.6329, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1630/3125], step: 14130, 7.572 samples/sec, batch_loss: 0.1377, batch_loss_c: 0.1538, batch_loss_s: 0.1003, time:5.2828, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1640/3125], step: 14140, 8.216 samples/sec, batch_loss: 0.2546, batch_loss_c: 0.2949, batch_loss_s: 0.1608, time:4.8688, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1650/3125], step: 14150, 8.236 samples/sec, batch_loss: 0.1261, batch_loss_c: 0.1176, batch_loss_s: 0.1459, time:4.8568, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1660/3125], step: 14160, 7.914 samples/sec, batch_loss: 0.1657, batch_loss_c: 0.1685, batch_loss_s: 0.1592, time:5.0546, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:08:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1670/3125], step: 14170, 7.911 samples/sec, batch_loss: 0.0752, batch_loss_c: 0.0706, batch_loss_s: 0.0858, time:5.0565, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1680/3125], step: 14180, 7.358 samples/sec, batch_loss: 0.3681, batch_loss_c: 0.3565, batch_loss_s: 0.3952, time:5.4366, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1690/3125], step: 14190, 7.706 samples/sec, batch_loss: 0.2564, batch_loss_c: 0.2973, batch_loss_s: 0.1610, time:5.1904, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1700/3125], step: 14200, 8.060 samples/sec, batch_loss: 0.2326, batch_loss_c: 0.2658, batch_loss_s: 0.1551, time:4.9630, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1710/3125], step: 14210, 7.631 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.1166, batch_loss_s: 0.0674, time:5.2416, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1720/3125], step: 14220, 7.757 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0747, batch_loss_s: 0.0632, time:5.1565, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1730/3125], step: 14230, 7.369 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1292, batch_loss_s: 0.0855, time:5.4282, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1740/3125], step: 14240, 7.054 samples/sec, batch_loss: 0.1748, batch_loss_c: 0.1894, batch_loss_s: 0.1409, time:5.6704, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1750/3125], step: 14250, 7.743 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0671, batch_loss_s: 0.0863, time:5.1661, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1760/3125], step: 14260, 7.392 samples/sec, batch_loss: 0.2985, batch_loss_c: 0.2987, batch_loss_s: 0.2983, time:5.4116, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1770/3125], step: 14270, 6.915 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1275, batch_loss_s: 0.0943, time:5.7845, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:09:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1780/3125], step: 14280, 7.586 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0691, batch_loss_s: 0.0829, time:5.2731, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1790/3125], step: 14290, 7.425 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0689, batch_loss_s: 0.0807, time:5.3871, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1800/3125], step: 14300, 9.214 samples/sec, batch_loss: 0.1805, batch_loss_c: 0.2052, batch_loss_s: 0.1227, time:4.3412, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1810/3125], step: 14310, 7.591 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0815, batch_loss_s: 0.0991, time:5.2692, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1820/3125], step: 14320, 8.245 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1003, batch_loss_s: 0.1088, time:4.8513, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1830/3125], step: 14330, 7.928 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0806, batch_loss_s: 0.0935, time:5.0454, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1840/3125], step: 14340, 7.855 samples/sec, batch_loss: 0.2255, batch_loss_c: 0.2236, batch_loss_s: 0.2299, time:5.0926, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1850/3125], step: 14350, 9.128 samples/sec, batch_loss: 0.3319, batch_loss_c: 0.3342, batch_loss_s: 0.3265, time:4.3823, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1860/3125], step: 14360, 7.610 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0937, batch_loss_s: 0.0747, time:5.2561, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1870/3125], step: 14370, 8.664 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2057, batch_loss_s: 0.1976, time:4.6168, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1880/3125], step: 14380, 8.878 samples/sec, batch_loss: 0.1333, batch_loss_c: 0.1405, batch_loss_s: 0.1167, time:4.5053, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1890/3125], step: 14390, 8.941 samples/sec, batch_loss: 0.1253, batch_loss_c: 0.1292, batch_loss_s: 0.1163, time:4.4739, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:10:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1900/3125], step: 14400, 7.771 samples/sec, batch_loss: 0.2058, batch_loss_c: 0.2466, batch_loss_s: 0.1106, time:5.1476, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1910/3125], step: 14410, 7.520 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0776, batch_loss_s: 0.0936, time:5.3191, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1920/3125], step: 14420, 8.503 samples/sec, batch_loss: 0.1549, batch_loss_c: 0.1605, batch_loss_s: 0.1419, time:4.7041, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1930/3125], step: 14430, 8.166 samples/sec, batch_loss: 0.1351, batch_loss_c: 0.1286, batch_loss_s: 0.1501, time:4.8982, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1940/3125], step: 14440, 8.007 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1631, batch_loss_s: 0.1089, time:4.9959, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1950/3125], step: 14450, 7.298 samples/sec, batch_loss: 0.3409, batch_loss_c: 0.3509, batch_loss_s: 0.3175, time:5.4812, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1960/3125], step: 14460, 7.528 samples/sec, batch_loss: 0.1065, batch_loss_c: 0.1031, batch_loss_s: 0.1145, time:5.3132, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1970/3125], step: 14470, 7.955 samples/sec, batch_loss: 0.3027, batch_loss_c: 0.3161, batch_loss_s: 0.2714, time:5.0281, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1980/3125], step: 14480, 8.318 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.0968, batch_loss_s: 0.1168, time:4.8089, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1990/3125], step: 14490, 8.032 samples/sec, batch_loss: 0.3245, batch_loss_c: 0.3253, batch_loss_s: 0.3226, time:4.9799, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2000/3125], step: 14500, 7.368 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3141, batch_loss_s: 0.3198, time:5.4285, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2010/3125], step: 14510, 7.950 samples/sec, batch_loss: 0.2809, batch_loss_c: 0.2550, batch_loss_s: 0.3412, time:5.0312, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:11:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2020/3125], step: 14520, 8.039 samples/sec, batch_loss: 0.3220, batch_loss_c: 0.3060, batch_loss_s: 0.3593, time:4.9755, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2030/3125], step: 14530, 7.505 samples/sec, batch_loss: 0.0744, batch_loss_c: 0.0775, batch_loss_s: 0.0671, time:5.3297, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2040/3125], step: 14540, 7.853 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0719, batch_loss_s: 0.0857, time:5.0935, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2050/3125], step: 14550, 7.786 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0763, batch_loss_s: 0.0899, time:5.1374, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2060/3125], step: 14560, 7.985 samples/sec, batch_loss: 0.1784, batch_loss_c: 0.2030, batch_loss_s: 0.1210, time:5.0096, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2070/3125], step: 14570, 7.914 samples/sec, batch_loss: 0.2915, batch_loss_c: 0.2904, batch_loss_s: 0.2940, time:5.0544, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2080/3125], step: 14580, 8.164 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0924, batch_loss_s: 0.1020, time:4.8993, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2090/3125], step: 14590, 7.986 samples/sec, batch_loss: 0.0473, batch_loss_c: 0.0425, batch_loss_s: 0.0584, time:5.0086, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2100/3125], step: 14600, 8.689 samples/sec, batch_loss: 0.1724, batch_loss_c: 0.2048, batch_loss_s: 0.0966, time:4.6034, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2110/3125], step: 14610, 8.181 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1135, batch_loss_s: 0.0941, time:4.8894, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2120/3125], step: 14620, 7.584 samples/sec, batch_loss: 0.1597, batch_loss_c: 0.1626, batch_loss_s: 0.1528, time:5.2743, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2130/3125], step: 14630, 8.070 samples/sec, batch_loss: 0.3983, batch_loss_c: 0.4259, batch_loss_s: 0.3340, time:4.9566, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:12:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2140/3125], step: 14640, 8.211 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0779, batch_loss_s: 0.0910, time:4.8716, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2150/3125], step: 14650, 8.482 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0844, batch_loss_s: 0.1052, time:4.7159, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2160/3125], step: 14660, 7.933 samples/sec, batch_loss: 0.2604, batch_loss_c: 0.2385, batch_loss_s: 0.3112, time:5.0419, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2170/3125], step: 14670, 7.772 samples/sec, batch_loss: 0.0737, batch_loss_c: 0.0758, batch_loss_s: 0.0688, time:5.1469, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2180/3125], step: 14680, 8.174 samples/sec, batch_loss: 0.0525, batch_loss_c: 0.0458, batch_loss_s: 0.0681, time:4.8934, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2190/3125], step: 14690, 8.107 samples/sec, batch_loss: 0.0691, batch_loss_c: 0.0673, batch_loss_s: 0.0733, time:4.9341, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2200/3125], step: 14700, 8.233 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1285, batch_loss_s: 0.1063, time:4.8585, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2210/3125], step: 14710, 8.164 samples/sec, batch_loss: 0.3974, batch_loss_c: 0.4226, batch_loss_s: 0.3387, time:4.8994, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2220/3125], step: 14720, 7.349 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0640, batch_loss_s: 0.0687, time:5.4430, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2230/3125], step: 14730, 8.131 samples/sec, batch_loss: 0.3557, batch_loss_c: 0.3499, batch_loss_s: 0.3691, time:4.9194, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2240/3125], step: 14740, 8.015 samples/sec, batch_loss: 0.3043, batch_loss_c: 0.2942, batch_loss_s: 0.3278, time:4.9909, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2250/3125], step: 14750, 7.870 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1260, batch_loss_s: 0.1240, time:5.0824, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:13:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2260/3125], step: 14760, 7.586 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0703, batch_loss_s: 0.0782, time:5.2732, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2270/3125], step: 14770, 8.314 samples/sec, batch_loss: 0.1613, batch_loss_c: 0.1799, batch_loss_s: 0.1179, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2280/3125], step: 14780, 8.414 samples/sec, batch_loss: 0.1816, batch_loss_c: 0.2077, batch_loss_s: 0.1206, time:4.7538, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2290/3125], step: 14790, 7.755 samples/sec, batch_loss: 0.1962, batch_loss_c: 0.1811, batch_loss_s: 0.2316, time:5.1583, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2300/3125], step: 14800, 8.028 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1333, batch_loss_s: 0.0737, time:4.9827, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2310/3125], step: 14810, 8.462 samples/sec, batch_loss: 0.1877, batch_loss_c: 0.2026, batch_loss_s: 0.1530, time:4.7269, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2320/3125], step: 14820, 8.718 samples/sec, batch_loss: 0.3612, batch_loss_c: 0.3816, batch_loss_s: 0.3134, time:4.5884, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2330/3125], step: 14830, 8.376 samples/sec, batch_loss: 0.3324, batch_loss_c: 0.3363, batch_loss_s: 0.3235, time:4.7757, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2340/3125], step: 14840, 8.123 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1105, batch_loss_s: 0.0921, time:4.9243, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2350/3125], step: 14850, 7.623 samples/sec, batch_loss: 0.0714, batch_loss_c: 0.0678, batch_loss_s: 0.0797, time:5.2474, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2360/3125], step: 14860, 8.586 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1140, batch_loss_s: 0.0915, time:4.6585, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2370/3125], step: 14870, 8.211 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0657, batch_loss_s: 0.0785, time:4.8713, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2380/3125], step: 14880, 8.433 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1047, batch_loss_s: 0.1315, time:4.7433, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:14:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2390/3125], step: 14890, 8.049 samples/sec, batch_loss: 0.3012, batch_loss_c: 0.2910, batch_loss_s: 0.3249, time:4.9698, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2400/3125], step: 14900, 8.623 samples/sec, batch_loss: 0.3573, batch_loss_c: 0.3568, batch_loss_s: 0.3586, time:4.6387, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2410/3125], step: 14910, 8.426 samples/sec, batch_loss: 0.2747, batch_loss_c: 0.2639, batch_loss_s: 0.2998, time:4.7470, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2420/3125], step: 14920, 7.811 samples/sec, batch_loss: 0.3314, batch_loss_c: 0.3344, batch_loss_s: 0.3245, time:5.1207, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2430/3125], step: 14930, 8.828 samples/sec, batch_loss: 0.3174, batch_loss_c: 0.3227, batch_loss_s: 0.3049, time:4.5310, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2440/3125], step: 14940, 8.967 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0717, batch_loss_s: 0.0828, time:4.4606, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2450/3125], step: 14950, 8.679 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0637, batch_loss_s: 0.0658, time:4.6086, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2460/3125], step: 14960, 8.345 samples/sec, batch_loss: 0.1399, batch_loss_c: 0.1517, batch_loss_s: 0.1124, time:4.7935, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2470/3125], step: 14970, 8.553 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0673, batch_loss_s: 0.0841, time:4.6765, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2480/3125], step: 14980, 8.602 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1395, batch_loss_s: 0.0952, time:4.6500, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2490/3125], step: 14990, 8.296 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1439, batch_loss_s: 0.0935, time:4.8217, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2500/3125], step: 15000, 7.983 samples/sec, batch_loss: 0.1052, batch_loss_c: 0.0955, batch_loss_s: 0.1278, time:5.0104, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:15:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2510/3125], step: 15010, 8.198 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0748, batch_loss_s: 0.0939, time:4.8792, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2520/3125], step: 15020, 8.415 samples/sec, batch_loss: 0.1886, batch_loss_c: 0.1940, batch_loss_s: 0.1760, time:4.7534, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2530/3125], step: 15030, 8.249 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0953, batch_loss_s: 0.0919, time:4.8489, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2540/3125], step: 15040, 7.623 samples/sec, batch_loss: 0.3676, batch_loss_c: 0.3871, batch_loss_s: 0.3219, time:5.2471, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2550/3125], step: 15050, 7.207 samples/sec, batch_loss: 0.3312, batch_loss_c: 0.3348, batch_loss_s: 0.3228, time:5.5504, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2560/3125], step: 15060, 7.834 samples/sec, batch_loss: 0.1394, batch_loss_c: 0.1560, batch_loss_s: 0.1005, time:5.1061, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2570/3125], step: 15070, 7.977 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0880, batch_loss_s: 0.0753, time:5.0147, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2580/3125], step: 15080, 7.857 samples/sec, batch_loss: 0.1744, batch_loss_c: 0.1926, batch_loss_s: 0.1320, time:5.0910, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2590/3125], step: 15090, 8.092 samples/sec, batch_loss: 0.3732, batch_loss_c: 0.3720, batch_loss_s: 0.3758, time:4.9431, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2600/3125], step: 15100, 8.806 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.0958, batch_loss_s: 0.1091, time:4.5425, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2610/3125], step: 15110, 7.660 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0756, batch_loss_s: 0.0806, time:5.2220, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2620/3125], step: 15120, 7.633 samples/sec, batch_loss: 0.1787, batch_loss_c: 0.1882, batch_loss_s: 0.1565, time:5.2407, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:16:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2630/3125], step: 15130, 8.754 samples/sec, batch_loss: 0.1504, batch_loss_c: 0.1534, batch_loss_s: 0.1433, time:4.5695, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2640/3125], step: 15140, 7.520 samples/sec, batch_loss: 0.2919, batch_loss_c: 0.2770, batch_loss_s: 0.3268, time:5.3189, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2650/3125], step: 15150, 7.708 samples/sec, batch_loss: 0.3274, batch_loss_c: 0.3311, batch_loss_s: 0.3188, time:5.1896, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2660/3125], step: 15160, 8.283 samples/sec, batch_loss: 0.1259, batch_loss_c: 0.1151, batch_loss_s: 0.1512, time:4.8289, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2670/3125], step: 15170, 7.788 samples/sec, batch_loss: 0.0591, batch_loss_c: 0.0539, batch_loss_s: 0.0712, time:5.1362, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2680/3125], step: 15180, 7.808 samples/sec, batch_loss: 0.2883, batch_loss_c: 0.2901, batch_loss_s: 0.2839, time:5.1231, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2690/3125], step: 15190, 8.195 samples/sec, batch_loss: 0.2803, batch_loss_c: 0.2658, batch_loss_s: 0.3141, time:4.8812, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2700/3125], step: 15200, 8.091 samples/sec, batch_loss: 0.1057, batch_loss_c: 0.0982, batch_loss_s: 0.1233, time:4.9437, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2710/3125], step: 15210, 7.836 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0803, batch_loss_s: 0.0892, time:5.1048, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2720/3125], step: 15220, 8.054 samples/sec, batch_loss: 0.0849, batch_loss_c: 0.0771, batch_loss_s: 0.1029, time:4.9666, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2730/3125], step: 15230, 7.517 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0827, batch_loss_s: 0.1009, time:5.3210, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2740/3125], step: 15240, 7.747 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1543, batch_loss_s: 0.1589, time:5.1631, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:17:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2750/3125], step: 15250, 8.005 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0704, batch_loss_s: 0.0831, time:4.9967, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2760/3125], step: 15260, 8.605 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0975, batch_loss_s: 0.0803, time:4.6485, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2770/3125], step: 15270, 8.008 samples/sec, batch_loss: 0.1228, batch_loss_c: 0.1323, batch_loss_s: 0.1005, time:4.9950, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2780/3125], step: 15280, 7.757 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0895, batch_loss_s: 0.0920, time:5.1565, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2790/3125], step: 15290, 7.736 samples/sec, batch_loss: 0.3125, batch_loss_c: 0.2991, batch_loss_s: 0.3436, time:5.1706, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2800/3125], step: 15300, 8.071 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0701, batch_loss_s: 0.0573, time:4.9560, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2810/3125], step: 15310, 8.878 samples/sec, batch_loss: 0.1325, batch_loss_c: 0.1307, batch_loss_s: 0.1366, time:4.5057, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2820/3125], step: 15320, 7.722 samples/sec, batch_loss: 0.3069, batch_loss_c: 0.3045, batch_loss_s: 0.3127, time:5.1800, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2830/3125], step: 15330, 8.247 samples/sec, batch_loss: 0.3412, batch_loss_c: 0.3401, batch_loss_s: 0.3438, time:4.8503, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2840/3125], step: 15340, 8.139 samples/sec, batch_loss: 0.1517, batch_loss_c: 0.1624, batch_loss_s: 0.1268, time:4.9143, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2850/3125], step: 15350, 7.378 samples/sec, batch_loss: 0.1490, batch_loss_c: 0.1505, batch_loss_s: 0.1457, time:5.4217, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2860/3125], step: 15360, 8.014 samples/sec, batch_loss: 0.1626, batch_loss_c: 0.1857, batch_loss_s: 0.1088, time:4.9913, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:18:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2870/3125], step: 15370, 8.650 samples/sec, batch_loss: 0.1533, batch_loss_c: 0.1842, batch_loss_s: 0.0811, time:4.6242, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2880/3125], step: 15380, 7.759 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1175, batch_loss_s: 0.0991, time:5.1556, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2890/3125], step: 15390, 7.451 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0855, batch_loss_s: 0.0872, time:5.3684, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2900/3125], step: 15400, 7.719 samples/sec, batch_loss: 0.2929, batch_loss_c: 0.2848, batch_loss_s: 0.3118, time:5.1821, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2910/3125], step: 15410, 8.063 samples/sec, batch_loss: 0.5617, batch_loss_c: 0.5655, batch_loss_s: 0.5528, time:4.9610, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2920/3125], step: 15420, 8.531 samples/sec, batch_loss: 0.3236, batch_loss_c: 0.3197, batch_loss_s: 0.3327, time:4.6886, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2930/3125], step: 15430, 8.557 samples/sec, batch_loss: 0.1710, batch_loss_c: 0.2022, batch_loss_s: 0.0982, time:4.6747, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2940/3125], step: 15440, 7.068 samples/sec, batch_loss: 0.0557, batch_loss_c: 0.0504, batch_loss_s: 0.0679, time:5.6596, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2950/3125], step: 15450, 7.581 samples/sec, batch_loss: 0.1157, batch_loss_c: 0.1215, batch_loss_s: 0.1022, time:5.2765, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2960/3125], step: 15460, 7.470 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.1053, batch_loss_s: 0.0750, time:5.3546, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2970/3125], step: 15470, 7.596 samples/sec, batch_loss: 0.2410, batch_loss_c: 0.2192, batch_loss_s: 0.2918, time:5.2657, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2980/3125], step: 15480, 8.271 samples/sec, batch_loss: 0.3466, batch_loss_c: 0.3572, batch_loss_s: 0.3218, time:4.8364, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:19:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2990/3125], step: 15490, 7.994 samples/sec, batch_loss: 0.2413, batch_loss_c: 0.2384, batch_loss_s: 0.2480, time:5.0040, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3000/3125], step: 15500, 7.174 samples/sec, batch_loss: 0.3165, batch_loss_c: 0.3165, batch_loss_s: 0.3164, time:5.5758, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3010/3125], step: 15510, 7.563 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.0987, batch_loss_s: 0.1208, time:5.2889, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3020/3125], step: 15520, 7.581 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.1019, batch_loss_s: 0.0885, time:5.2763, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3030/3125], step: 15530, 7.852 samples/sec, batch_loss: 0.0697, batch_loss_c: 0.0624, batch_loss_s: 0.0868, time:5.0942, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3040/3125], step: 15540, 7.363 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0663, batch_loss_s: 0.0896, time:5.4323, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3050/3125], step: 15550, 7.059 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0833, batch_loss_s: 0.0831, time:5.6667, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3060/3125], step: 15560, 7.333 samples/sec, batch_loss: 0.4477, batch_loss_c: 0.4626, batch_loss_s: 0.4130, time:5.4551, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3070/3125], step: 15570, 8.141 samples/sec, batch_loss: 0.1256, batch_loss_c: 0.1295, batch_loss_s: 0.1165, time:4.9132, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3080/3125], step: 15580, 8.050 samples/sec, batch_loss: 0.3700, batch_loss_c: 0.3855, batch_loss_s: 0.3339, time:4.9691, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3090/3125], step: 15590, 7.405 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0874, batch_loss_s: 0.0886, time:5.4016, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:20:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3100/3125], step: 15600, 7.705 samples/sec, batch_loss: 0.5476, batch_loss_c: 0.5454, batch_loss_s: 0.5528, time:5.1915, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3110/3125], step: 15610, 10.248 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.1118, batch_loss_s: 0.0900, time:3.9031, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3120/3125], step: 15620, 10.226 samples/sec, batch_loss: 0.1703, batch_loss_c: 0.1954, batch_loss_s: 0.1118, time:3.9117, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], train_loss: 0.1806, time: 1574.3473, lr: 0.0001\u001b[0m\n",
            "2019-11-23 13:21:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [0/3125], step: 15625, 6.314 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1038, batch_loss_s: 0.1025, time:6.3353, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [10/3125], step: 15635, 5.667 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1285, batch_loss_s: 0.0955, time:7.0587, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [20/3125], step: 15645, 8.491 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.1077, batch_loss_s: 0.0812, time:4.7106, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [30/3125], step: 15655, 8.460 samples/sec, batch_loss: 0.3128, batch_loss_c: 0.3120, batch_loss_s: 0.3147, time:4.7284, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [40/3125], step: 15665, 8.450 samples/sec, batch_loss: 0.3274, batch_loss_c: 0.3251, batch_loss_s: 0.3326, time:4.7339, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [50/3125], step: 15675, 8.123 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1469, batch_loss_s: 0.1502, time:4.9241, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [60/3125], step: 15685, 7.588 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0836, batch_loss_s: 0.1090, time:5.2714, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [70/3125], step: 15695, 8.288 samples/sec, batch_loss: 0.3768, batch_loss_c: 0.3851, batch_loss_s: 0.3575, time:4.8261, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [80/3125], step: 15705, 7.557 samples/sec, batch_loss: 0.3246, batch_loss_c: 0.3205, batch_loss_s: 0.3343, time:5.2928, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:21:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [90/3125], step: 15715, 8.376 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0822, batch_loss_s: 0.0888, time:4.7756, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [100/3125], step: 15725, 8.009 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0865, batch_loss_s: 0.0766, time:4.9942, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [110/3125], step: 15735, 7.799 samples/sec, batch_loss: 0.3060, batch_loss_c: 0.3551, batch_loss_s: 0.1914, time:5.1289, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [120/3125], step: 15745, 8.301 samples/sec, batch_loss: 0.1524, batch_loss_c: 0.1735, batch_loss_s: 0.1034, time:4.8188, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [130/3125], step: 15755, 8.118 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0763, batch_loss_s: 0.0789, time:4.9273, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [140/3125], step: 15765, 7.501 samples/sec, batch_loss: 0.4491, batch_loss_c: 0.4669, batch_loss_s: 0.4073, time:5.3323, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [150/3125], step: 15775, 7.450 samples/sec, batch_loss: 0.1314, batch_loss_c: 0.1362, batch_loss_s: 0.1201, time:5.3689, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [160/3125], step: 15785, 6.998 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1250, batch_loss_s: 0.1004, time:5.7160, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [170/3125], step: 15795, 8.544 samples/sec, batch_loss: 0.1452, batch_loss_c: 0.1522, batch_loss_s: 0.1289, time:4.6818, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [180/3125], step: 15805, 8.579 samples/sec, batch_loss: 0.0963, batch_loss_c: 0.1092, batch_loss_s: 0.0662, time:4.6623, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [190/3125], step: 15815, 8.215 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0838, batch_loss_s: 0.1047, time:4.8692, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:22:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [200/3125], step: 15825, 7.504 samples/sec, batch_loss: 0.2974, batch_loss_c: 0.2952, batch_loss_s: 0.3027, time:5.3308, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [210/3125], step: 15835, 7.231 samples/sec, batch_loss: 0.1490, batch_loss_c: 0.1463, batch_loss_s: 0.1552, time:5.5318, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [220/3125], step: 15845, 8.389 samples/sec, batch_loss: 0.3836, batch_loss_c: 0.3816, batch_loss_s: 0.3883, time:4.7681, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [230/3125], step: 15855, 8.404 samples/sec, batch_loss: 0.3451, batch_loss_c: 0.3329, batch_loss_s: 0.3734, time:4.7595, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [240/3125], step: 15865, 8.121 samples/sec, batch_loss: 0.3607, batch_loss_c: 0.3695, batch_loss_s: 0.3402, time:4.9257, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [250/3125], step: 15875, 7.939 samples/sec, batch_loss: 0.3243, batch_loss_c: 0.3260, batch_loss_s: 0.3203, time:5.0382, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [260/3125], step: 15885, 8.325 samples/sec, batch_loss: 0.0607, batch_loss_c: 0.0568, batch_loss_s: 0.0698, time:4.8051, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [270/3125], step: 15895, 8.324 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1177, batch_loss_s: 0.1114, time:4.8056, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [280/3125], step: 15905, 8.302 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1314, batch_loss_s: 0.0986, time:4.8182, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [290/3125], step: 15915, 7.783 samples/sec, batch_loss: 0.1940, batch_loss_c: 0.2358, batch_loss_s: 0.0964, time:5.1391, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [300/3125], step: 15925, 8.704 samples/sec, batch_loss: 0.0688, batch_loss_c: 0.0657, batch_loss_s: 0.0762, time:4.5957, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [310/3125], step: 15935, 8.389 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0809, batch_loss_s: 0.0901, time:4.7682, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [320/3125], step: 15945, 7.979 samples/sec, batch_loss: 0.1165, batch_loss_c: 0.1155, batch_loss_s: 0.1187, time:5.0134, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:23:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [330/3125], step: 15955, 8.032 samples/sec, batch_loss: 0.2514, batch_loss_c: 0.2410, batch_loss_s: 0.2758, time:4.9801, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [340/3125], step: 15965, 8.438 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0819, batch_loss_s: 0.1061, time:4.7407, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [350/3125], step: 15975, 7.461 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0916, batch_loss_s: 0.1034, time:5.3615, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [360/3125], step: 15985, 7.980 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.2362, batch_loss_s: 0.0971, time:5.0127, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [370/3125], step: 15995, 8.319 samples/sec, batch_loss: 0.3192, batch_loss_c: 0.3178, batch_loss_s: 0.3224, time:4.8084, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [380/3125], step: 16005, 7.272 samples/sec, batch_loss: 0.1327, batch_loss_c: 0.1524, batch_loss_s: 0.0869, time:5.5006, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [390/3125], step: 16015, 7.878 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0874, batch_loss_s: 0.0908, time:5.0777, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [400/3125], step: 16025, 7.709 samples/sec, batch_loss: 0.1960, batch_loss_c: 0.1948, batch_loss_s: 0.1990, time:5.1890, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [410/3125], step: 16035, 7.886 samples/sec, batch_loss: 0.1341, batch_loss_c: 0.1407, batch_loss_s: 0.1187, time:5.0725, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [420/3125], step: 16045, 7.702 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0825, batch_loss_s: 0.0818, time:5.1932, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [430/3125], step: 16055, 8.280 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0728, batch_loss_s: 0.1210, time:4.8310, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [440/3125], step: 16065, 9.228 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0692, batch_loss_s: 0.0704, time:4.3344, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:24:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [450/3125], step: 16075, 8.468 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0895, batch_loss_s: 0.0907, time:4.7239, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [460/3125], step: 16085, 8.350 samples/sec, batch_loss: 0.3221, batch_loss_c: 0.3226, batch_loss_s: 0.3209, time:4.7903, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [470/3125], step: 16095, 8.824 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.0992, batch_loss_s: 0.1000, time:4.5332, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [480/3125], step: 16105, 9.188 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1327, batch_loss_s: 0.1163, time:4.3536, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [490/3125], step: 16115, 8.363 samples/sec, batch_loss: 0.1659, batch_loss_c: 0.1953, batch_loss_s: 0.0974, time:4.7831, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [500/3125], step: 16125, 7.841 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.1095, batch_loss_s: 0.0804, time:5.1015, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [510/3125], step: 16135, 8.194 samples/sec, batch_loss: 0.3005, batch_loss_c: 0.3329, batch_loss_s: 0.2248, time:4.8814, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [520/3125], step: 16145, 8.424 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0778, batch_loss_s: 0.0722, time:4.7481, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [530/3125], step: 16155, 8.625 samples/sec, batch_loss: 0.5034, batch_loss_c: 0.4912, batch_loss_s: 0.5320, time:4.6375, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [540/3125], step: 16165, 8.419 samples/sec, batch_loss: 0.2005, batch_loss_c: 0.2417, batch_loss_s: 0.1046, time:4.7511, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [550/3125], step: 16175, 7.570 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1180, batch_loss_s: 0.1162, time:5.2840, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [560/3125], step: 16185, 7.489 samples/sec, batch_loss: 0.3328, batch_loss_c: 0.3312, batch_loss_s: 0.3363, time:5.3415, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:25:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [570/3125], step: 16195, 7.710 samples/sec, batch_loss: 0.1117, batch_loss_c: 0.1187, batch_loss_s: 0.0952, time:5.1878, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [580/3125], step: 16205, 8.664 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1236, batch_loss_s: 0.0934, time:4.6170, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [590/3125], step: 16215, 7.840 samples/sec, batch_loss: 0.1149, batch_loss_c: 0.1292, batch_loss_s: 0.0815, time:5.1023, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [600/3125], step: 16225, 7.928 samples/sec, batch_loss: 0.1662, batch_loss_c: 0.1895, batch_loss_s: 0.1116, time:5.0451, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [610/3125], step: 16235, 8.473 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1367, batch_loss_s: 0.1384, time:4.7211, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [620/3125], step: 16245, 8.316 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0862, batch_loss_s: 0.0762, time:4.8100, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [630/3125], step: 16255, 8.814 samples/sec, batch_loss: 0.1691, batch_loss_c: 0.1390, batch_loss_s: 0.2393, time:4.5381, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [640/3125], step: 16265, 8.408 samples/sec, batch_loss: 0.3415, batch_loss_c: 0.3450, batch_loss_s: 0.3334, time:4.7571, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [650/3125], step: 16275, 8.253 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0894, batch_loss_s: 0.0955, time:4.8469, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [660/3125], step: 16285, 8.236 samples/sec, batch_loss: 0.1680, batch_loss_c: 0.1466, batch_loss_s: 0.2180, time:4.8567, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [670/3125], step: 16295, 7.699 samples/sec, batch_loss: 0.1020, batch_loss_c: 0.1037, batch_loss_s: 0.0981, time:5.1955, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [680/3125], step: 16305, 8.882 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.0973, batch_loss_s: 0.1320, time:4.5037, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:26:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [690/3125], step: 16315, 8.591 samples/sec, batch_loss: 0.1388, batch_loss_c: 0.1639, batch_loss_s: 0.0803, time:4.6558, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [700/3125], step: 16325, 7.302 samples/sec, batch_loss: 0.1663, batch_loss_c: 0.1901, batch_loss_s: 0.1106, time:5.4781, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [710/3125], step: 16335, 7.604 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0663, batch_loss_s: 0.0778, time:5.2602, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [720/3125], step: 16345, 7.331 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0581, batch_loss_s: 0.0838, time:5.4565, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [730/3125], step: 16355, 7.522 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0948, batch_loss_s: 0.0966, time:5.3177, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [740/3125], step: 16365, 8.304 samples/sec, batch_loss: 0.1548, batch_loss_c: 0.1855, batch_loss_s: 0.0830, time:4.8168, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [750/3125], step: 16375, 8.162 samples/sec, batch_loss: 0.0690, batch_loss_c: 0.0685, batch_loss_s: 0.0701, time:4.9007, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [760/3125], step: 16385, 7.673 samples/sec, batch_loss: 0.3379, batch_loss_c: 0.3429, batch_loss_s: 0.3264, time:5.2128, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [770/3125], step: 16395, 8.012 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0941, batch_loss_s: 0.0963, time:4.9924, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [780/3125], step: 16405, 8.369 samples/sec, batch_loss: 0.0671, batch_loss_c: 0.0589, batch_loss_s: 0.0862, time:4.7795, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [790/3125], step: 16415, 8.414 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3099, batch_loss_s: 0.3170, time:4.7542, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [800/3125], step: 16425, 8.063 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.1012, batch_loss_s: 0.0811, time:4.9607, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:27:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [810/3125], step: 16435, 7.525 samples/sec, batch_loss: 0.3049, batch_loss_c: 0.3015, batch_loss_s: 0.3130, time:5.3158, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [820/3125], step: 16445, 7.704 samples/sec, batch_loss: 0.1228, batch_loss_c: 0.1368, batch_loss_s: 0.0900, time:5.1922, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [830/3125], step: 16455, 9.141 samples/sec, batch_loss: 0.4291, batch_loss_c: 0.4233, batch_loss_s: 0.4424, time:4.3757, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [840/3125], step: 16465, 8.016 samples/sec, batch_loss: 0.1292, batch_loss_c: 0.1408, batch_loss_s: 0.1020, time:4.9901, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [850/3125], step: 16475, 7.521 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1418, batch_loss_s: 0.0948, time:5.3185, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [860/3125], step: 16485, 7.413 samples/sec, batch_loss: 0.0667, batch_loss_c: 0.0532, batch_loss_s: 0.0980, time:5.3960, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [870/3125], step: 16495, 8.550 samples/sec, batch_loss: 0.2994, batch_loss_c: 0.2965, batch_loss_s: 0.3063, time:4.6782, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [880/3125], step: 16505, 7.454 samples/sec, batch_loss: 0.1079, batch_loss_c: 0.1104, batch_loss_s: 0.1021, time:5.3664, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [890/3125], step: 16515, 7.524 samples/sec, batch_loss: 0.1910, batch_loss_c: 0.2258, batch_loss_s: 0.1098, time:5.3161, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [900/3125], step: 16525, 7.655 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.0999, batch_loss_s: 0.1078, time:5.2256, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [910/3125], step: 16535, 9.102 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0870, batch_loss_s: 0.0667, time:4.3947, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [920/3125], step: 16545, 8.502 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0869, batch_loss_s: 0.0582, time:4.7048, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:28:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [930/3125], step: 16555, 8.105 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0966, batch_loss_s: 0.0954, time:4.9355, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [940/3125], step: 16565, 7.871 samples/sec, batch_loss: 0.1212, batch_loss_c: 0.1153, batch_loss_s: 0.1349, time:5.0817, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [950/3125], step: 16575, 8.128 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0721, batch_loss_s: 0.0776, time:4.9210, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [960/3125], step: 16585, 8.407 samples/sec, batch_loss: 0.1584, batch_loss_c: 0.1776, batch_loss_s: 0.1137, time:4.7579, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [970/3125], step: 16595, 8.381 samples/sec, batch_loss: 0.1735, batch_loss_c: 0.2053, batch_loss_s: 0.0993, time:4.7729, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [980/3125], step: 16605, 7.817 samples/sec, batch_loss: 0.3720, batch_loss_c: 0.3742, batch_loss_s: 0.3668, time:5.1172, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [990/3125], step: 16615, 7.409 samples/sec, batch_loss: 0.1498, batch_loss_c: 0.1562, batch_loss_s: 0.1348, time:5.3985, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1000/3125], step: 16625, 7.725 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0713, batch_loss_s: 0.0832, time:5.1782, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1010/3125], step: 16635, 7.766 samples/sec, batch_loss: 0.2798, batch_loss_c: 0.2548, batch_loss_s: 0.3380, time:5.1509, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1020/3125], step: 16645, 7.759 samples/sec, batch_loss: 0.5460, batch_loss_c: 0.5483, batch_loss_s: 0.5404, time:5.1550, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1030/3125], step: 16655, 7.929 samples/sec, batch_loss: 0.1359, batch_loss_c: 0.1517, batch_loss_s: 0.0989, time:5.0448, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1040/3125], step: 16665, 7.174 samples/sec, batch_loss: 0.3200, batch_loss_c: 0.3170, batch_loss_s: 0.3271, time:5.5753, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:29:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1050/3125], step: 16675, 8.634 samples/sec, batch_loss: 0.0640, batch_loss_c: 0.0602, batch_loss_s: 0.0730, time:4.6330, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1060/3125], step: 16685, 8.158 samples/sec, batch_loss: 0.0752, batch_loss_c: 0.0718, batch_loss_s: 0.0833, time:4.9033, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1070/3125], step: 16695, 8.665 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0673, batch_loss_s: 0.0774, time:4.6161, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1080/3125], step: 16705, 7.625 samples/sec, batch_loss: 0.0557, batch_loss_c: 0.0510, batch_loss_s: 0.0667, time:5.2462, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1090/3125], step: 16715, 8.197 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.1079, batch_loss_s: 0.0868, time:4.8798, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1100/3125], step: 16725, 8.860 samples/sec, batch_loss: 0.5336, batch_loss_c: 0.5302, batch_loss_s: 0.5416, time:4.5145, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1110/3125], step: 16735, 8.448 samples/sec, batch_loss: 0.3443, batch_loss_c: 0.3521, batch_loss_s: 0.3260, time:4.7348, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1120/3125], step: 16745, 7.241 samples/sec, batch_loss: 0.0690, batch_loss_c: 0.0732, batch_loss_s: 0.0592, time:5.5241, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1130/3125], step: 16755, 8.583 samples/sec, batch_loss: 0.3279, batch_loss_c: 0.3280, batch_loss_s: 0.3276, time:4.6603, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1140/3125], step: 16765, 7.230 samples/sec, batch_loss: 0.3813, batch_loss_c: 0.3725, batch_loss_s: 0.4017, time:5.5325, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1150/3125], step: 16775, 8.354 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1348, batch_loss_s: 0.1012, time:4.7879, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1160/3125], step: 16785, 8.226 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1030, batch_loss_s: 0.1332, time:4.8629, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:30:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1170/3125], step: 16795, 7.827 samples/sec, batch_loss: 0.1550, batch_loss_c: 0.1649, batch_loss_s: 0.1317, time:5.1108, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1180/3125], step: 16805, 6.742 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0669, batch_loss_s: 0.0883, time:5.9328, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1190/3125], step: 16815, 8.299 samples/sec, batch_loss: 0.1747, batch_loss_c: 0.1699, batch_loss_s: 0.1861, time:4.8200, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1200/3125], step: 16825, 8.707 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0841, batch_loss_s: 0.0905, time:4.5937, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1210/3125], step: 16835, 7.677 samples/sec, batch_loss: 0.2992, batch_loss_c: 0.3013, batch_loss_s: 0.2943, time:5.2107, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1220/3125], step: 16845, 8.409 samples/sec, batch_loss: 0.0987, batch_loss_c: 0.1025, batch_loss_s: 0.0897, time:4.7568, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1230/3125], step: 16855, 8.770 samples/sec, batch_loss: 0.3235, batch_loss_c: 0.3192, batch_loss_s: 0.3335, time:4.5608, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1240/3125], step: 16865, 8.246 samples/sec, batch_loss: 0.3372, batch_loss_c: 0.3341, batch_loss_s: 0.3444, time:4.8508, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1250/3125], step: 16875, 7.704 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0892, batch_loss_s: 0.1074, time:5.1919, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1260/3125], step: 16885, 8.522 samples/sec, batch_loss: 0.0576, batch_loss_c: 0.0537, batch_loss_s: 0.0667, time:4.6936, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1270/3125], step: 16895, 7.353 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1329, batch_loss_s: 0.0728, time:5.4400, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1280/3125], step: 16905, 7.999 samples/sec, batch_loss: 0.3812, batch_loss_c: 0.3781, batch_loss_s: 0.3883, time:5.0006, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:31:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1290/3125], step: 16915, 8.200 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1239, batch_loss_s: 0.1096, time:4.8782, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1300/3125], step: 16925, 7.593 samples/sec, batch_loss: 0.0627, batch_loss_c: 0.0573, batch_loss_s: 0.0754, time:5.2683, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1310/3125], step: 16935, 7.886 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3192, batch_loss_s: 0.3077, time:5.0725, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1320/3125], step: 16945, 7.952 samples/sec, batch_loss: 0.2925, batch_loss_c: 0.2807, batch_loss_s: 0.3202, time:5.0302, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1330/3125], step: 16955, 8.803 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1145, batch_loss_s: 0.1153, time:4.5438, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1340/3125], step: 16965, 7.522 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0726, batch_loss_s: 0.0856, time:5.3176, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1350/3125], step: 16975, 8.030 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1544, batch_loss_s: 0.0652, time:4.9810, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1360/3125], step: 16985, 8.645 samples/sec, batch_loss: 0.1594, batch_loss_c: 0.1907, batch_loss_s: 0.0864, time:4.6270, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1370/3125], step: 16995, 8.391 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0838, batch_loss_s: 0.1226, time:4.7672, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1380/3125], step: 17005, 8.744 samples/sec, batch_loss: 0.5464, batch_loss_c: 0.5425, batch_loss_s: 0.5556, time:4.5747, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1390/3125], step: 17015, 7.148 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.1017, batch_loss_s: 0.0949, time:5.5957, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1400/3125], step: 17025, 8.037 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.3094, batch_loss_s: 0.3021, time:4.9770, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:32:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1410/3125], step: 17035, 7.867 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0847, batch_loss_s: 0.0914, time:5.0847, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1420/3125], step: 17045, 7.580 samples/sec, batch_loss: 0.0917, batch_loss_c: 0.0971, batch_loss_s: 0.0790, time:5.2770, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1430/3125], step: 17055, 7.448 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1045, batch_loss_s: 0.0952, time:5.3704, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1440/3125], step: 17065, 8.276 samples/sec, batch_loss: 0.1302, batch_loss_c: 0.1380, batch_loss_s: 0.1120, time:4.8330, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1450/3125], step: 17075, 7.839 samples/sec, batch_loss: 0.1744, batch_loss_c: 0.1895, batch_loss_s: 0.1393, time:5.1029, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1460/3125], step: 17085, 7.512 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0782, batch_loss_s: 0.0872, time:5.3245, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1470/3125], step: 17095, 7.977 samples/sec, batch_loss: 0.1725, batch_loss_c: 0.1881, batch_loss_s: 0.1361, time:5.0145, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1480/3125], step: 17105, 8.294 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0660, batch_loss_s: 0.0817, time:4.8228, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1490/3125], step: 17115, 8.803 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1249, batch_loss_s: 0.0965, time:4.5441, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1500/3125], step: 17125, 7.291 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0806, batch_loss_s: 0.0938, time:5.4862, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1510/3125], step: 17135, 7.780 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0819, batch_loss_s: 0.0866, time:5.1413, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1520/3125], step: 17145, 8.795 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.0963, batch_loss_s: 0.1075, time:4.5482, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:33:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1530/3125], step: 17155, 7.705 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1288, batch_loss_s: 0.0969, time:5.1911, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1540/3125], step: 17165, 7.386 samples/sec, batch_loss: 0.1193, batch_loss_c: 0.1243, batch_loss_s: 0.1077, time:5.4155, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1550/3125], step: 17175, 7.666 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1223, batch_loss_s: 0.1115, time:5.2177, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1560/3125], step: 17185, 8.053 samples/sec, batch_loss: 0.2723, batch_loss_c: 0.2515, batch_loss_s: 0.3207, time:4.9674, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1570/3125], step: 17195, 8.565 samples/sec, batch_loss: 0.1078, batch_loss_c: 0.1020, batch_loss_s: 0.1212, time:4.6701, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1580/3125], step: 17205, 8.929 samples/sec, batch_loss: 0.1802, batch_loss_c: 0.2189, batch_loss_s: 0.0899, time:4.4796, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1590/3125], step: 17215, 7.381 samples/sec, batch_loss: 0.1596, batch_loss_c: 0.1782, batch_loss_s: 0.1160, time:5.4195, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1600/3125], step: 17225, 7.676 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1102, batch_loss_s: 0.1138, time:5.2109, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1610/3125], step: 17235, 7.702 samples/sec, batch_loss: 0.3664, batch_loss_c: 0.3434, batch_loss_s: 0.4201, time:5.1936, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1620/3125], step: 17245, 8.502 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0863, batch_loss_s: 0.0840, time:4.7048, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1630/3125], step: 17255, 6.953 samples/sec, batch_loss: 0.1428, batch_loss_c: 0.1418, batch_loss_s: 0.1452, time:5.7532, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1640/3125], step: 17265, 7.422 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0726, batch_loss_s: 0.0725, time:5.3891, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:34:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1650/3125], step: 17275, 7.941 samples/sec, batch_loss: 0.2775, batch_loss_c: 0.2634, batch_loss_s: 0.3106, time:5.0373, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1660/3125], step: 17285, 7.128 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1185, batch_loss_s: 0.1061, time:5.6119, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1670/3125], step: 17295, 7.336 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0939, batch_loss_s: 0.1147, time:5.4524, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1680/3125], step: 17305, 7.555 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1207, batch_loss_s: 0.0651, time:5.2948, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1690/3125], step: 17315, 6.626 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0741, batch_loss_s: 0.0868, time:6.0368, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1700/3125], step: 17325, 7.114 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.1047, batch_loss_s: 0.0919, time:5.6230, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1710/3125], step: 17335, 7.430 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0637, batch_loss_s: 0.0752, time:5.3836, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1720/3125], step: 17345, 7.451 samples/sec, batch_loss: 0.4049, batch_loss_c: 0.4338, batch_loss_s: 0.3375, time:5.3686, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1730/3125], step: 17355, 7.826 samples/sec, batch_loss: 0.0854, batch_loss_c: 0.0882, batch_loss_s: 0.0788, time:5.1109, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1740/3125], step: 17365, 7.468 samples/sec, batch_loss: 0.4310, batch_loss_c: 0.4472, batch_loss_s: 0.3931, time:5.3560, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1750/3125], step: 17375, 7.634 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1089, batch_loss_s: 0.1007, time:5.2400, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:35:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1760/3125], step: 17385, 7.916 samples/sec, batch_loss: 0.1837, batch_loss_c: 0.1988, batch_loss_s: 0.1483, time:5.0530, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1770/3125], step: 17395, 7.445 samples/sec, batch_loss: 0.3983, batch_loss_c: 0.3785, batch_loss_s: 0.4446, time:5.3730, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1780/3125], step: 17405, 7.224 samples/sec, batch_loss: 0.3433, batch_loss_c: 0.3369, batch_loss_s: 0.3582, time:5.5372, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1790/3125], step: 17415, 7.555 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0631, batch_loss_s: 0.0782, time:5.2943, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1800/3125], step: 17425, 7.238 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.1091, batch_loss_s: 0.0864, time:5.5262, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1810/3125], step: 17435, 8.335 samples/sec, batch_loss: 0.1793, batch_loss_c: 0.2118, batch_loss_s: 0.1035, time:4.7993, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1820/3125], step: 17445, 7.727 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3137, batch_loss_s: 0.3114, time:5.1766, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1830/3125], step: 17455, 8.400 samples/sec, batch_loss: 0.3399, batch_loss_c: 0.3328, batch_loss_s: 0.3566, time:4.7621, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1840/3125], step: 17465, 8.563 samples/sec, batch_loss: 0.1156, batch_loss_c: 0.1115, batch_loss_s: 0.1252, time:4.6710, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1850/3125], step: 17475, 8.707 samples/sec, batch_loss: 0.1317, batch_loss_c: 0.1321, batch_loss_s: 0.1305, time:4.5942, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1860/3125], step: 17485, 8.706 samples/sec, batch_loss: 0.1615, batch_loss_c: 0.1919, batch_loss_s: 0.0906, time:4.5945, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1870/3125], step: 17495, 8.326 samples/sec, batch_loss: 0.1387, batch_loss_c: 0.1477, batch_loss_s: 0.1177, time:4.8041, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:36:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1880/3125], step: 17505, 6.983 samples/sec, batch_loss: 0.1232, batch_loss_c: 0.1245, batch_loss_s: 0.1201, time:5.7283, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1890/3125], step: 17515, 8.966 samples/sec, batch_loss: 0.0834, batch_loss_c: 0.0849, batch_loss_s: 0.0799, time:4.4614, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1900/3125], step: 17525, 8.376 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0856, batch_loss_s: 0.0974, time:4.7754, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1910/3125], step: 17535, 8.118 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0847, batch_loss_s: 0.0929, time:4.9276, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1920/3125], step: 17545, 8.124 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1406, batch_loss_s: 0.1039, time:4.9235, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1930/3125], step: 17555, 7.410 samples/sec, batch_loss: 0.0685, batch_loss_c: 0.0707, batch_loss_s: 0.0635, time:5.3983, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1940/3125], step: 17565, 8.055 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.1080, batch_loss_s: 0.1199, time:4.9660, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1950/3125], step: 17575, 8.148 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1119, batch_loss_s: 0.1209, time:4.9091, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1960/3125], step: 17585, 8.228 samples/sec, batch_loss: 0.3229, batch_loss_c: 0.3222, batch_loss_s: 0.3247, time:4.8617, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1970/3125], step: 17595, 8.774 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1376, batch_loss_s: 0.0848, time:4.5589, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1980/3125], step: 17605, 7.477 samples/sec, batch_loss: 0.1552, batch_loss_c: 0.1683, batch_loss_s: 0.1246, time:5.3494, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1990/3125], step: 17615, 8.330 samples/sec, batch_loss: 0.3962, batch_loss_c: 0.3913, batch_loss_s: 0.4076, time:4.8021, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:37:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2000/3125], step: 17625, 8.844 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0897, batch_loss_s: 0.0839, time:4.5229, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2010/3125], step: 17635, 8.084 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0742, batch_loss_s: 0.0848, time:4.9479, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2020/3125], step: 17645, 8.253 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0647, batch_loss_s: 0.0683, time:4.8468, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2030/3125], step: 17655, 8.246 samples/sec, batch_loss: 0.1312, batch_loss_c: 0.1343, batch_loss_s: 0.1238, time:4.8507, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2040/3125], step: 17665, 8.844 samples/sec, batch_loss: 0.1933, batch_loss_c: 0.2403, batch_loss_s: 0.0835, time:4.5230, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2050/3125], step: 17675, 7.622 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1252, batch_loss_s: 0.1076, time:5.2479, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2060/3125], step: 17685, 7.639 samples/sec, batch_loss: 0.1069, batch_loss_c: 0.1086, batch_loss_s: 0.1028, time:5.2361, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2070/3125], step: 17695, 7.905 samples/sec, batch_loss: 0.1805, batch_loss_c: 0.1902, batch_loss_s: 0.1578, time:5.0604, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2080/3125], step: 17705, 7.283 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1713, batch_loss_s: 0.1011, time:5.4922, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2090/3125], step: 17715, 8.257 samples/sec, batch_loss: 0.1335, batch_loss_c: 0.1457, batch_loss_s: 0.1049, time:4.8444, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2100/3125], step: 17725, 8.266 samples/sec, batch_loss: 0.1183, batch_loss_c: 0.1355, batch_loss_s: 0.0782, time:4.8388, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2110/3125], step: 17735, 8.706 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0922, batch_loss_s: 0.0751, time:4.5948, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:38:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2120/3125], step: 17745, 8.335 samples/sec, batch_loss: 0.5911, batch_loss_c: 0.6003, batch_loss_s: 0.5698, time:4.7990, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2130/3125], step: 17755, 9.247 samples/sec, batch_loss: 0.5552, batch_loss_c: 0.5562, batch_loss_s: 0.5528, time:4.3258, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2140/3125], step: 17765, 7.614 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1069, batch_loss_s: 0.1158, time:5.2537, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2150/3125], step: 17775, 7.542 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0873, batch_loss_s: 0.1096, time:5.3033, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2160/3125], step: 17785, 8.459 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3035, batch_loss_s: 0.3352, time:4.7289, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2170/3125], step: 17795, 7.559 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.1001, batch_loss_s: 0.0970, time:5.2920, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2180/3125], step: 17805, 8.219 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0854, batch_loss_s: 0.0914, time:4.8665, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2190/3125], step: 17815, 7.944 samples/sec, batch_loss: 0.1400, batch_loss_c: 0.1323, batch_loss_s: 0.1581, time:5.0355, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2200/3125], step: 17825, 8.286 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1450, batch_loss_s: 0.0982, time:4.8275, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2210/3125], step: 17835, 8.160 samples/sec, batch_loss: 0.6453, batch_loss_c: 0.6183, batch_loss_s: 0.7084, time:4.9020, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2220/3125], step: 17845, 8.486 samples/sec, batch_loss: 0.2993, batch_loss_c: 0.2953, batch_loss_s: 0.3087, time:4.7139, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2230/3125], step: 17855, 7.555 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1186, batch_loss_s: 0.1126, time:5.2942, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:39:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2240/3125], step: 17865, 7.565 samples/sec, batch_loss: 0.1652, batch_loss_c: 0.1791, batch_loss_s: 0.1328, time:5.2874, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2250/3125], step: 17875, 7.927 samples/sec, batch_loss: 0.1480, batch_loss_c: 0.1333, batch_loss_s: 0.1822, time:5.0458, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2260/3125], step: 17885, 7.972 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0774, batch_loss_s: 0.0878, time:5.0176, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2270/3125], step: 17895, 8.007 samples/sec, batch_loss: 0.1303, batch_loss_c: 0.1307, batch_loss_s: 0.1292, time:4.9956, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2280/3125], step: 17905, 8.000 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1340, batch_loss_s: 0.0877, time:4.9999, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2290/3125], step: 17915, 8.218 samples/sec, batch_loss: 0.3203, batch_loss_c: 0.3259, batch_loss_s: 0.3071, time:4.8671, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2300/3125], step: 17925, 7.762 samples/sec, batch_loss: 0.3123, batch_loss_c: 0.3136, batch_loss_s: 0.3094, time:5.1535, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2310/3125], step: 17935, 8.118 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1033, batch_loss_s: 0.1060, time:4.9274, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2320/3125], step: 17945, 7.488 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1578, batch_loss_s: 0.1575, time:5.3421, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2330/3125], step: 17955, 8.079 samples/sec, batch_loss: 0.2236, batch_loss_c: 0.2491, batch_loss_s: 0.1640, time:4.9509, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2340/3125], step: 17965, 8.761 samples/sec, batch_loss: 0.0948, batch_loss_c: 0.0929, batch_loss_s: 0.0994, time:4.5659, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2350/3125], step: 17975, 8.132 samples/sec, batch_loss: 0.1183, batch_loss_c: 0.1129, batch_loss_s: 0.1310, time:4.9186, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:40:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2360/3125], step: 17985, 8.981 samples/sec, batch_loss: 0.1110, batch_loss_c: 0.1094, batch_loss_s: 0.1147, time:4.4536, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2370/3125], step: 17995, 8.442 samples/sec, batch_loss: 0.1260, batch_loss_c: 0.1274, batch_loss_s: 0.1227, time:4.7381, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2380/3125], step: 18005, 7.939 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0672, batch_loss_s: 0.0797, time:5.0384, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2390/3125], step: 18015, 8.689 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1218, batch_loss_s: 0.1054, time:4.6038, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2400/3125], step: 18025, 8.267 samples/sec, batch_loss: 0.3290, batch_loss_c: 0.3266, batch_loss_s: 0.3346, time:4.8384, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2410/3125], step: 18035, 7.839 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1579, batch_loss_s: 0.1136, time:5.1030, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2420/3125], step: 18045, 8.028 samples/sec, batch_loss: 0.2338, batch_loss_c: 0.2336, batch_loss_s: 0.2343, time:4.9827, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2430/3125], step: 18055, 7.909 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.0990, batch_loss_s: 0.1021, time:5.0577, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2440/3125], step: 18065, 7.938 samples/sec, batch_loss: 0.1355, batch_loss_c: 0.1331, batch_loss_s: 0.1412, time:5.0391, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2450/3125], step: 18075, 8.371 samples/sec, batch_loss: 0.3964, batch_loss_c: 0.3946, batch_loss_s: 0.4005, time:4.7784, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2460/3125], step: 18085, 7.828 samples/sec, batch_loss: 0.1427, batch_loss_c: 0.1495, batch_loss_s: 0.1266, time:5.1099, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2470/3125], step: 18095, 8.170 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0938, batch_loss_s: 0.0998, time:4.8960, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:41:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2480/3125], step: 18105, 8.579 samples/sec, batch_loss: 0.1092, batch_loss_c: 0.1216, batch_loss_s: 0.0804, time:4.6627, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2490/3125], step: 18115, 7.880 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0763, batch_loss_s: 0.0916, time:5.0763, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2500/3125], step: 18125, 8.473 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1233, batch_loss_s: 0.1410, time:4.7208, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2510/3125], step: 18135, 8.451 samples/sec, batch_loss: 0.1221, batch_loss_c: 0.1432, batch_loss_s: 0.0727, time:4.7334, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2520/3125], step: 18145, 8.149 samples/sec, batch_loss: 0.3173, batch_loss_c: 0.3164, batch_loss_s: 0.3196, time:4.9084, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2530/3125], step: 18155, 7.470 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0762, batch_loss_s: 0.0742, time:5.3544, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2540/3125], step: 18165, 7.954 samples/sec, batch_loss: 0.3090, batch_loss_c: 0.3066, batch_loss_s: 0.3145, time:5.0289, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2550/3125], step: 18175, 8.048 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0759, batch_loss_s: 0.0897, time:4.9703, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2560/3125], step: 18185, 8.422 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1389, batch_loss_s: 0.0910, time:4.7495, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2570/3125], step: 18195, 7.779 samples/sec, batch_loss: 0.1003, batch_loss_c: 0.1006, batch_loss_s: 0.0997, time:5.1421, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2580/3125], step: 18205, 7.914 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0608, batch_loss_s: 0.0639, time:5.0543, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2590/3125], step: 18215, 8.288 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0833, batch_loss_s: 0.0994, time:4.8261, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2600/3125], step: 18225, 8.314 samples/sec, batch_loss: 0.2087, batch_loss_c: 0.1946, batch_loss_s: 0.2415, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:42:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2610/3125], step: 18235, 8.232 samples/sec, batch_loss: 0.1742, batch_loss_c: 0.1837, batch_loss_s: 0.1523, time:4.8590, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2620/3125], step: 18245, 7.889 samples/sec, batch_loss: 0.3151, batch_loss_c: 0.3097, batch_loss_s: 0.3276, time:5.0701, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2630/3125], step: 18255, 8.292 samples/sec, batch_loss: 0.2755, batch_loss_c: 0.2638, batch_loss_s: 0.3028, time:4.8239, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2640/3125], step: 18265, 8.133 samples/sec, batch_loss: 0.0604, batch_loss_c: 0.0588, batch_loss_s: 0.0641, time:4.9185, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2650/3125], step: 18275, 8.183 samples/sec, batch_loss: 0.1033, batch_loss_c: 0.1056, batch_loss_s: 0.0979, time:4.8880, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2660/3125], step: 18285, 7.643 samples/sec, batch_loss: 0.0579, batch_loss_c: 0.0540, batch_loss_s: 0.0668, time:5.2338, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2670/3125], step: 18295, 8.154 samples/sec, batch_loss: 0.0468, batch_loss_c: 0.0397, batch_loss_s: 0.0636, time:4.9054, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2680/3125], step: 18305, 8.423 samples/sec, batch_loss: 0.5506, batch_loss_c: 0.5538, batch_loss_s: 0.5431, time:4.7491, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2690/3125], step: 18315, 8.101 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1317, batch_loss_s: 0.1084, time:4.9376, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2700/3125], step: 18325, 7.947 samples/sec, batch_loss: 0.3119, batch_loss_c: 0.2980, batch_loss_s: 0.3442, time:5.0333, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2710/3125], step: 18335, 7.934 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.0968, batch_loss_s: 0.1067, time:5.0419, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2720/3125], step: 18345, 8.332 samples/sec, batch_loss: 0.4191, batch_loss_c: 0.3583, batch_loss_s: 0.5610, time:4.8009, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:43:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2730/3125], step: 18355, 7.632 samples/sec, batch_loss: 0.1620, batch_loss_c: 0.1855, batch_loss_s: 0.1069, time:5.2408, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2740/3125], step: 18365, 8.241 samples/sec, batch_loss: 0.1999, batch_loss_c: 0.1902, batch_loss_s: 0.2225, time:4.8537, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2750/3125], step: 18375, 7.993 samples/sec, batch_loss: 0.1411, batch_loss_c: 0.1497, batch_loss_s: 0.1212, time:5.0043, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2760/3125], step: 18385, 8.186 samples/sec, batch_loss: 0.1184, batch_loss_c: 0.1286, batch_loss_s: 0.0946, time:4.8861, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2770/3125], step: 18395, 8.519 samples/sec, batch_loss: 0.2790, batch_loss_c: 0.2660, batch_loss_s: 0.3092, time:4.6956, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2780/3125], step: 18405, 7.944 samples/sec, batch_loss: 0.0661, batch_loss_c: 0.0609, batch_loss_s: 0.0782, time:5.0351, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2790/3125], step: 18415, 8.017 samples/sec, batch_loss: 0.1227, batch_loss_c: 0.1435, batch_loss_s: 0.0743, time:4.9892, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2800/3125], step: 18425, 7.975 samples/sec, batch_loss: 0.3624, batch_loss_c: 0.3314, batch_loss_s: 0.4348, time:5.0159, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2810/3125], step: 18435, 8.331 samples/sec, batch_loss: 0.1450, batch_loss_c: 0.1428, batch_loss_s: 0.1499, time:4.8012, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2820/3125], step: 18445, 8.864 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0676, batch_loss_s: 0.0790, time:4.5125, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2830/3125], step: 18455, 7.960 samples/sec, batch_loss: 0.3063, batch_loss_c: 0.3011, batch_loss_s: 0.3185, time:5.0251, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2840/3125], step: 18465, 8.580 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1072, batch_loss_s: 0.1081, time:4.6621, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:44:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2850/3125], step: 18475, 8.511 samples/sec, batch_loss: 0.1789, batch_loss_c: 0.2053, batch_loss_s: 0.1173, time:4.6999, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2860/3125], step: 18485, 8.690 samples/sec, batch_loss: 0.1686, batch_loss_c: 0.1809, batch_loss_s: 0.1398, time:4.6032, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2870/3125], step: 18495, 7.797 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1029, batch_loss_s: 0.0845, time:5.1300, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2880/3125], step: 18505, 8.293 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1002, batch_loss_s: 0.1031, time:4.8234, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2890/3125], step: 18515, 8.275 samples/sec, batch_loss: 0.5705, batch_loss_c: 0.5752, batch_loss_s: 0.5594, time:4.8336, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2900/3125], step: 18525, 7.762 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0636, batch_loss_s: 0.0746, time:5.1532, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2910/3125], step: 18535, 7.496 samples/sec, batch_loss: 0.1306, batch_loss_c: 0.1415, batch_loss_s: 0.1052, time:5.3361, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2920/3125], step: 18545, 7.934 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0873, batch_loss_s: 0.1022, time:5.0416, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2930/3125], step: 18555, 8.327 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0701, batch_loss_s: 0.0857, time:4.8035, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2940/3125], step: 18565, 8.156 samples/sec, batch_loss: 0.3310, batch_loss_c: 0.3306, batch_loss_s: 0.3321, time:4.9046, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2950/3125], step: 18575, 7.155 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0961, batch_loss_s: 0.0819, time:5.5908, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2960/3125], step: 18585, 8.364 samples/sec, batch_loss: 0.1883, batch_loss_c: 0.2151, batch_loss_s: 0.1257, time:4.7822, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:45:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2970/3125], step: 18595, 8.327 samples/sec, batch_loss: 0.0530, batch_loss_c: 0.0506, batch_loss_s: 0.0585, time:4.8037, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2980/3125], step: 18605, 7.825 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0850, batch_loss_s: 0.0868, time:5.1121, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2990/3125], step: 18615, 7.229 samples/sec, batch_loss: 0.1739, batch_loss_c: 0.1839, batch_loss_s: 0.1505, time:5.5336, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3000/3125], step: 18625, 8.333 samples/sec, batch_loss: 0.1556, batch_loss_c: 0.1753, batch_loss_s: 0.1096, time:4.8001, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3010/3125], step: 18635, 7.642 samples/sec, batch_loss: 0.1624, batch_loss_c: 0.1894, batch_loss_s: 0.0992, time:5.2343, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3020/3125], step: 18645, 8.299 samples/sec, batch_loss: 0.1824, batch_loss_c: 0.1821, batch_loss_s: 0.1833, time:4.8198, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3030/3125], step: 18655, 8.035 samples/sec, batch_loss: 0.2951, batch_loss_c: 0.2863, batch_loss_s: 0.3155, time:4.9783, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3040/3125], step: 18665, 7.459 samples/sec, batch_loss: 0.1994, batch_loss_c: 0.2295, batch_loss_s: 0.1292, time:5.3625, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3050/3125], step: 18675, 7.624 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0724, batch_loss_s: 0.0741, time:5.2464, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3060/3125], step: 18685, 8.283 samples/sec, batch_loss: 0.5553, batch_loss_c: 0.5599, batch_loss_s: 0.5448, time:4.8293, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3070/3125], step: 18695, 7.508 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0873, batch_loss_s: 0.0819, time:5.3274, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3080/3125], step: 18705, 7.562 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1254, batch_loss_s: 0.1299, time:5.2899, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:46:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3090/3125], step: 18715, 7.099 samples/sec, batch_loss: 0.1051, batch_loss_c: 0.1050, batch_loss_s: 0.1054, time:5.6348, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3100/3125], step: 18725, 8.110 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.1044, batch_loss_s: 0.0785, time:4.9321, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3110/3125], step: 18735, 10.353 samples/sec, batch_loss: 0.2165, batch_loss_c: 0.2193, batch_loss_s: 0.2100, time:3.8637, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3120/3125], step: 18745, 10.346 samples/sec, batch_loss: 0.2758, batch_loss_c: 0.2550, batch_loss_s: 0.3245, time:3.8662, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], train_loss: 0.1828, time: 1566.5373, lr: 0.0001\u001b[0m\n",
            "2019-11-23 13:47:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [0/3125], step: 18750, 6.067 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0862, batch_loss_s: 0.0740, time:6.5928, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [10/3125], step: 18760, 8.276 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1249, batch_loss_s: 0.0934, time:4.8334, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [20/3125], step: 18770, 7.948 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0788, batch_loss_s: 0.0935, time:5.0326, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [30/3125], step: 18780, 8.314 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1037, batch_loss_s: 0.1332, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [40/3125], step: 18790, 8.256 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1419, batch_loss_s: 0.1177, time:4.8451, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [50/3125], step: 18800, 8.725 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0726, batch_loss_s: 0.0736, time:4.5843, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [60/3125], step: 18810, 7.151 samples/sec, batch_loss: 0.1947, batch_loss_c: 0.2368, batch_loss_s: 0.0964, time:5.5938, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:47:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [70/3125], step: 18820, 7.410 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0723, batch_loss_s: 0.0757, time:5.3983, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [80/3125], step: 18830, 8.317 samples/sec, batch_loss: 0.2084, batch_loss_c: 0.2328, batch_loss_s: 0.1514, time:4.8093, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [90/3125], step: 18840, 8.058 samples/sec, batch_loss: 0.1999, batch_loss_c: 0.2078, batch_loss_s: 0.1814, time:4.9641, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [100/3125], step: 18850, 8.335 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0920, batch_loss_s: 0.1072, time:4.7990, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [110/3125], step: 18860, 7.956 samples/sec, batch_loss: 0.1236, batch_loss_c: 0.1247, batch_loss_s: 0.1208, time:5.0278, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [120/3125], step: 18870, 6.550 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0813, batch_loss_s: 0.0882, time:6.1066, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [130/3125], step: 18880, 7.515 samples/sec, batch_loss: 0.0637, batch_loss_c: 0.0619, batch_loss_s: 0.0676, time:5.3224, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [140/3125], step: 18890, 8.588 samples/sec, batch_loss: 0.3125, batch_loss_c: 0.3093, batch_loss_s: 0.3197, time:4.6577, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [150/3125], step: 18900, 7.616 samples/sec, batch_loss: 0.1404, batch_loss_c: 0.1563, batch_loss_s: 0.1032, time:5.2523, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [160/3125], step: 18910, 7.523 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.0989, batch_loss_s: 0.0964, time:5.3170, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [170/3125], step: 18920, 8.158 samples/sec, batch_loss: 0.1037, batch_loss_c: 0.0997, batch_loss_s: 0.1130, time:4.9035, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [180/3125], step: 18930, 8.127 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0712, batch_loss_s: 0.0776, time:4.9220, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:48:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [190/3125], step: 18940, 9.007 samples/sec, batch_loss: 0.2007, batch_loss_c: 0.2147, batch_loss_s: 0.1680, time:4.4409, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [200/3125], step: 18950, 8.280 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0848, batch_loss_s: 0.1154, time:4.8307, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [210/3125], step: 18960, 7.838 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0736, batch_loss_s: 0.0887, time:5.1036, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [220/3125], step: 18970, 8.287 samples/sec, batch_loss: 0.1097, batch_loss_c: 0.0993, batch_loss_s: 0.1339, time:4.8270, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [230/3125], step: 18980, 7.680 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0856, batch_loss_s: 0.0680, time:5.2081, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [240/3125], step: 18990, 8.788 samples/sec, batch_loss: 0.2774, batch_loss_c: 0.2653, batch_loss_s: 0.3054, time:4.5517, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [250/3125], step: 19000, 7.967 samples/sec, batch_loss: 0.1571, batch_loss_c: 0.1650, batch_loss_s: 0.1388, time:5.0209, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [260/3125], step: 19010, 8.180 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0720, batch_loss_s: 0.0874, time:4.8900, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [270/3125], step: 19020, 8.214 samples/sec, batch_loss: 0.0687, batch_loss_c: 0.0637, batch_loss_s: 0.0802, time:4.8695, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [280/3125], step: 19030, 8.200 samples/sec, batch_loss: 0.3760, batch_loss_c: 0.3744, batch_loss_s: 0.3798, time:4.8778, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [290/3125], step: 19040, 8.168 samples/sec, batch_loss: 0.3526, batch_loss_c: 0.3571, batch_loss_s: 0.3421, time:4.8971, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [300/3125], step: 19050, 8.923 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.3136, batch_loss_s: 0.3271, time:4.4828, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [310/3125], step: 19060, 7.572 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1381, batch_loss_s: 0.1038, time:5.2825, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:49:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [320/3125], step: 19070, 8.142 samples/sec, batch_loss: 0.1110, batch_loss_c: 0.1151, batch_loss_s: 0.1015, time:4.9129, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:04 \u001b[32mINFO     \u001b[0m train.py: [6/10], [330/3125], step: 19080, 8.440 samples/sec, batch_loss: 0.1093, batch_loss_c: 0.1098, batch_loss_s: 0.1083, time:4.7394, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:09 \u001b[32mINFO     \u001b[0m train.py: [6/10], [340/3125], step: 19090, 7.704 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0967, batch_loss_s: 0.0917, time:5.1920, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [350/3125], step: 19100, 8.541 samples/sec, batch_loss: 0.1314, batch_loss_c: 0.1439, batch_loss_s: 0.1022, time:4.6832, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [360/3125], step: 19110, 7.937 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3652, batch_loss_s: 0.3119, time:5.0396, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [370/3125], step: 19120, 7.915 samples/sec, batch_loss: 0.1345, batch_loss_c: 0.1396, batch_loss_s: 0.1226, time:5.0536, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [380/3125], step: 19130, 7.631 samples/sec, batch_loss: 0.0684, batch_loss_c: 0.0670, batch_loss_s: 0.0718, time:5.2415, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [390/3125], step: 19140, 8.573 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0704, batch_loss_s: 0.0881, time:4.6658, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [400/3125], step: 19150, 8.228 samples/sec, batch_loss: 0.1742, batch_loss_c: 0.1801, batch_loss_s: 0.1603, time:4.8615, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [410/3125], step: 19160, 8.130 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0815, batch_loss_s: 0.0901, time:4.9202, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [420/3125], step: 19170, 7.088 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1192, batch_loss_s: 0.1021, time:5.6437, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [430/3125], step: 19180, 7.723 samples/sec, batch_loss: 0.1787, batch_loss_c: 0.2085, batch_loss_s: 0.1093, time:5.1795, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:50:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [440/3125], step: 19190, 8.621 samples/sec, batch_loss: 0.3273, batch_loss_c: 0.3305, batch_loss_s: 0.3198, time:4.6400, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:04 \u001b[32mINFO     \u001b[0m train.py: [6/10], [450/3125], step: 19200, 9.227 samples/sec, batch_loss: 0.3097, batch_loss_c: 0.2967, batch_loss_s: 0.3401, time:4.3351, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:08 \u001b[32mINFO     \u001b[0m train.py: [6/10], [460/3125], step: 19210, 8.638 samples/sec, batch_loss: 0.1311, batch_loss_c: 0.1080, batch_loss_s: 0.1852, time:4.6307, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:13 \u001b[32mINFO     \u001b[0m train.py: [6/10], [470/3125], step: 19220, 8.001 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0662, batch_loss_s: 0.0799, time:4.9991, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [480/3125], step: 19230, 8.517 samples/sec, batch_loss: 0.3348, batch_loss_c: 0.3388, batch_loss_s: 0.3256, time:4.6965, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [490/3125], step: 19240, 7.894 samples/sec, batch_loss: 0.3830, batch_loss_c: 0.3704, batch_loss_s: 0.4124, time:5.0673, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [500/3125], step: 19250, 8.324 samples/sec, batch_loss: 0.0986, batch_loss_c: 0.0955, batch_loss_s: 0.1060, time:4.8056, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [510/3125], step: 19260, 8.615 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0699, batch_loss_s: 0.0792, time:4.6433, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [520/3125], step: 19270, 8.884 samples/sec, batch_loss: 0.3413, batch_loss_c: 0.3522, batch_loss_s: 0.3160, time:4.5027, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [530/3125], step: 19280, 7.768 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.0952, batch_loss_s: 0.1142, time:5.1493, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [540/3125], step: 19290, 8.752 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1142, batch_loss_s: 0.1472, time:4.5702, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [550/3125], step: 19300, 8.195 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0634, batch_loss_s: 0.0762, time:4.8810, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:51:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [560/3125], step: 19310, 8.035 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1604, batch_loss_s: 0.0915, time:4.9780, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [570/3125], step: 19320, 7.738 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0876, batch_loss_s: 0.0936, time:5.1694, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [580/3125], step: 19330, 7.546 samples/sec, batch_loss: 0.2878, batch_loss_c: 0.2762, batch_loss_s: 0.3151, time:5.3009, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [590/3125], step: 19340, 8.380 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1297, batch_loss_s: 0.1298, time:4.7730, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [600/3125], step: 19350, 7.384 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0821, batch_loss_s: 0.0791, time:5.4168, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [610/3125], step: 19360, 7.710 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0909, batch_loss_s: 0.0829, time:5.1884, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [620/3125], step: 19370, 8.886 samples/sec, batch_loss: 0.0592, batch_loss_c: 0.0537, batch_loss_s: 0.0722, time:4.5012, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [630/3125], step: 19380, 7.692 samples/sec, batch_loss: 0.1747, batch_loss_c: 0.1806, batch_loss_s: 0.1611, time:5.2004, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [640/3125], step: 19390, 8.422 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0928, batch_loss_s: 0.0770, time:4.7495, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [650/3125], step: 19400, 7.571 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1052, batch_loss_s: 0.1107, time:5.2834, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [660/3125], step: 19410, 8.788 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1093, batch_loss_s: 0.0825, time:4.5517, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [670/3125], step: 19420, 7.724 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0803, batch_loss_s: 0.1050, time:5.1785, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:52:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [680/3125], step: 19430, 8.151 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1046, batch_loss_s: 0.1119, time:4.9071, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [690/3125], step: 19440, 8.895 samples/sec, batch_loss: 0.0755, batch_loss_c: 0.0726, batch_loss_s: 0.0823, time:4.4968, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [700/3125], step: 19450, 8.448 samples/sec, batch_loss: 0.5472, batch_loss_c: 0.5504, batch_loss_s: 0.5396, time:4.7347, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [710/3125], step: 19460, 8.265 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0746, batch_loss_s: 0.0875, time:4.8396, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [720/3125], step: 19470, 8.121 samples/sec, batch_loss: 0.0633, batch_loss_c: 0.0585, batch_loss_s: 0.0743, time:4.9258, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [730/3125], step: 19480, 7.861 samples/sec, batch_loss: 0.0696, batch_loss_c: 0.0672, batch_loss_s: 0.0754, time:5.0885, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [740/3125], step: 19490, 8.091 samples/sec, batch_loss: 0.5604, batch_loss_c: 0.5608, batch_loss_s: 0.5594, time:4.9438, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [750/3125], step: 19500, 8.356 samples/sec, batch_loss: 0.1071, batch_loss_c: 0.1086, batch_loss_s: 0.1036, time:4.7868, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [760/3125], step: 19510, 7.366 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1063, batch_loss_s: 0.1170, time:5.4302, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [770/3125], step: 19520, 7.679 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.2147, batch_loss_s: 0.1027, time:5.2090, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [780/3125], step: 19530, 8.083 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1022, batch_loss_s: 0.1112, time:4.9484, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [790/3125], step: 19540, 7.984 samples/sec, batch_loss: 0.2894, batch_loss_c: 0.2867, batch_loss_s: 0.2957, time:5.0098, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:53:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [800/3125], step: 19550, 7.514 samples/sec, batch_loss: 0.1437, batch_loss_c: 0.1359, batch_loss_s: 0.1620, time:5.3237, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [810/3125], step: 19560, 7.589 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0806, batch_loss_s: 0.1001, time:5.2708, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [820/3125], step: 19570, 7.725 samples/sec, batch_loss: 0.2544, batch_loss_c: 0.2590, batch_loss_s: 0.2436, time:5.1780, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [830/3125], step: 19580, 8.668 samples/sec, batch_loss: 0.2930, batch_loss_c: 0.2829, batch_loss_s: 0.3166, time:4.6147, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [840/3125], step: 19590, 8.104 samples/sec, batch_loss: 0.0798, batch_loss_c: 0.0757, batch_loss_s: 0.0894, time:4.9360, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [850/3125], step: 19600, 8.402 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0746, batch_loss_s: 0.0926, time:4.7607, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [860/3125], step: 19610, 8.397 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.1014, batch_loss_s: 0.0947, time:4.7636, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [870/3125], step: 19620, 8.013 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1250, batch_loss_s: 0.1385, time:4.9920, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [880/3125], step: 19630, 8.313 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1139, batch_loss_s: 0.1238, time:4.8116, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [890/3125], step: 19640, 8.074 samples/sec, batch_loss: 0.3270, batch_loss_c: 0.3269, batch_loss_s: 0.3271, time:4.9542, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [900/3125], step: 19650, 7.438 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0833, batch_loss_s: 0.1081, time:5.3777, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [910/3125], step: 19660, 7.812 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0684, batch_loss_s: 0.0825, time:5.1206, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:54:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [920/3125], step: 19670, 8.113 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0714, batch_loss_s: 0.0823, time:4.9302, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [930/3125], step: 19680, 8.375 samples/sec, batch_loss: 0.3540, batch_loss_c: 0.3490, batch_loss_s: 0.3658, time:4.7759, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [940/3125], step: 19690, 8.206 samples/sec, batch_loss: 0.1386, batch_loss_c: 0.1618, batch_loss_s: 0.0845, time:4.8744, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [950/3125], step: 19700, 8.675 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.1029, batch_loss_s: 0.0823, time:4.6110, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [960/3125], step: 19710, 8.367 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0585, batch_loss_s: 0.0699, time:4.7807, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [970/3125], step: 19720, 7.613 samples/sec, batch_loss: 0.1944, batch_loss_c: 0.2468, batch_loss_s: 0.0720, time:5.2539, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [980/3125], step: 19730, 7.730 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0841, batch_loss_s: 0.1000, time:5.1746, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [990/3125], step: 19740, 8.333 samples/sec, batch_loss: 0.3237, batch_loss_c: 0.3402, batch_loss_s: 0.2852, time:4.8003, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1000/3125], step: 19750, 8.006 samples/sec, batch_loss: 0.1481, batch_loss_c: 0.1447, batch_loss_s: 0.1559, time:4.9960, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1010/3125], step: 19760, 7.942 samples/sec, batch_loss: 0.5188, batch_loss_c: 0.5102, batch_loss_s: 0.5386, time:5.0366, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1020/3125], step: 19770, 7.844 samples/sec, batch_loss: 0.0927, batch_loss_c: 0.0929, batch_loss_s: 0.0923, time:5.0995, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1030/3125], step: 19780, 8.604 samples/sec, batch_loss: 0.3068, batch_loss_c: 0.3041, batch_loss_s: 0.3132, time:4.6490, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:55:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1040/3125], step: 19790, 8.123 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3214, batch_loss_s: 0.3250, time:4.9245, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1050/3125], step: 19800, 8.422 samples/sec, batch_loss: 0.1691, batch_loss_c: 0.1974, batch_loss_s: 0.1030, time:4.7497, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1060/3125], step: 19810, 8.311 samples/sec, batch_loss: 0.3641, batch_loss_c: 0.3597, batch_loss_s: 0.3744, time:4.8128, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:09 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1070/3125], step: 19820, 8.380 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3234, batch_loss_s: 0.3047, time:4.7733, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1080/3125], step: 19830, 8.130 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0691, batch_loss_s: 0.0784, time:4.9202, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1090/3125], step: 19840, 8.269 samples/sec, batch_loss: 0.4124, batch_loss_c: 0.4208, batch_loss_s: 0.3928, time:4.8371, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1100/3125], step: 19850, 8.488 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0591, batch_loss_s: 0.0813, time:4.7124, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1110/3125], step: 19860, 8.207 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0831, batch_loss_s: 0.0645, time:4.8740, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:33 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1120/3125], step: 19870, 9.125 samples/sec, batch_loss: 0.3317, batch_loss_c: 0.3272, batch_loss_s: 0.3421, time:4.3835, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1130/3125], step: 19880, 5.841 samples/sec, batch_loss: 0.1477, batch_loss_c: 0.1717, batch_loss_s: 0.0917, time:6.8483, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1140/3125], step: 19890, 7.791 samples/sec, batch_loss: 0.3212, batch_loss_c: 0.3221, batch_loss_s: 0.3191, time:5.1340, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1150/3125], step: 19900, 7.682 samples/sec, batch_loss: 0.3500, batch_loss_c: 0.3278, batch_loss_s: 0.4019, time:5.2070, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:56:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1160/3125], step: 19910, 8.036 samples/sec, batch_loss: 0.3005, batch_loss_c: 0.2977, batch_loss_s: 0.3072, time:4.9774, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1170/3125], step: 19920, 7.703 samples/sec, batch_loss: 0.3048, batch_loss_c: 0.2998, batch_loss_s: 0.3164, time:5.1927, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1180/3125], step: 19930, 7.888 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0634, batch_loss_s: 0.0760, time:5.0710, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1190/3125], step: 19940, 8.915 samples/sec, batch_loss: 0.3437, batch_loss_c: 0.3391, batch_loss_s: 0.3544, time:4.4866, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1200/3125], step: 19950, 7.924 samples/sec, batch_loss: 0.1448, batch_loss_c: 0.1618, batch_loss_s: 0.1049, time:5.0481, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1210/3125], step: 19960, 8.577 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.0939, batch_loss_s: 0.1170, time:4.6635, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1220/3125], step: 19970, 8.237 samples/sec, batch_loss: 0.2997, batch_loss_c: 0.2996, batch_loss_s: 0.3000, time:4.8561, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1230/3125], step: 19980, 8.413 samples/sec, batch_loss: 0.3191, batch_loss_c: 0.3152, batch_loss_s: 0.3282, time:4.7544, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1240/3125], step: 19990, 7.549 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1205, batch_loss_s: 0.1008, time:5.2984, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1250/3125], step: 20000, 8.123 samples/sec, batch_loss: 0.3766, batch_loss_c: 0.3899, batch_loss_s: 0.3457, time:4.9245, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1260/3125], step: 20010, 7.795 samples/sec, batch_loss: 0.1520, batch_loss_c: 0.1669, batch_loss_s: 0.1173, time:5.1317, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1270/3125], step: 20020, 7.881 samples/sec, batch_loss: 0.1597, batch_loss_c: 0.1853, batch_loss_s: 0.1000, time:5.0755, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:57:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1280/3125], step: 20030, 8.901 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0958, batch_loss_s: 0.0865, time:4.4939, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1290/3125], step: 20040, 7.276 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1373, batch_loss_s: 0.0829, time:5.4973, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1300/3125], step: 20050, 8.416 samples/sec, batch_loss: 0.0525, batch_loss_c: 0.0494, batch_loss_s: 0.0596, time:4.7527, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1310/3125], step: 20060, 7.556 samples/sec, batch_loss: 0.2663, batch_loss_c: 0.2519, batch_loss_s: 0.2999, time:5.2935, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1320/3125], step: 20070, 8.368 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0886, batch_loss_s: 0.0840, time:4.7803, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1330/3125], step: 20080, 8.234 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0956, batch_loss_s: 0.0831, time:4.8578, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1340/3125], step: 20090, 8.862 samples/sec, batch_loss: 0.1770, batch_loss_c: 0.1828, batch_loss_s: 0.1633, time:4.5135, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1350/3125], step: 20100, 7.698 samples/sec, batch_loss: 0.1173, batch_loss_c: 0.1159, batch_loss_s: 0.1207, time:5.1961, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1360/3125], step: 20110, 8.420 samples/sec, batch_loss: 0.1900, batch_loss_c: 0.2274, batch_loss_s: 0.1028, time:4.7507, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1370/3125], step: 20120, 7.289 samples/sec, batch_loss: 0.3008, batch_loss_c: 0.2781, batch_loss_s: 0.3536, time:5.4878, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1380/3125], step: 20130, 8.348 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0762, batch_loss_s: 0.0805, time:4.7915, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1390/3125], step: 20140, 8.349 samples/sec, batch_loss: 0.1264, batch_loss_c: 0.1412, batch_loss_s: 0.0921, time:4.7910, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1400/3125], step: 20150, 8.324 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0843, batch_loss_s: 0.0838, time:4.8056, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:58:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1410/3125], step: 20160, 7.772 samples/sec, batch_loss: 0.1658, batch_loss_c: 0.1833, batch_loss_s: 0.1250, time:5.1464, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1420/3125], step: 20170, 7.022 samples/sec, batch_loss: 0.3728, batch_loss_c: 0.3811, batch_loss_s: 0.3535, time:5.6961, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1430/3125], step: 20180, 7.599 samples/sec, batch_loss: 0.3267, batch_loss_c: 0.3333, batch_loss_s: 0.3111, time:5.2640, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1440/3125], step: 20190, 7.721 samples/sec, batch_loss: 0.3788, batch_loss_c: 0.3577, batch_loss_s: 0.4278, time:5.1805, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1450/3125], step: 20200, 7.849 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0668, batch_loss_s: 0.0841, time:5.0961, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1460/3125], step: 20210, 7.752 samples/sec, batch_loss: 0.3455, batch_loss_c: 0.3299, batch_loss_s: 0.3817, time:5.1599, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1470/3125], step: 20220, 7.786 samples/sec, batch_loss: 0.2725, batch_loss_c: 0.2619, batch_loss_s: 0.2973, time:5.1371, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1480/3125], step: 20230, 8.114 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1388, batch_loss_s: 0.1093, time:4.9298, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1490/3125], step: 20240, 7.865 samples/sec, batch_loss: 0.2830, batch_loss_c: 0.2765, batch_loss_s: 0.2980, time:5.0856, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1500/3125], step: 20250, 8.650 samples/sec, batch_loss: 0.1458, batch_loss_c: 0.1544, batch_loss_s: 0.1257, time:4.6243, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1510/3125], step: 20260, 8.241 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1146, batch_loss_s: 0.1145, time:4.8538, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1520/3125], step: 20270, 8.430 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0820, batch_loss_s: 0.1050, time:4.7449, lr:0.0001\u001b[0m\n",
            "2019-11-23 13:59:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1530/3125], step: 20280, 8.878 samples/sec, batch_loss: 0.1224, batch_loss_c: 0.1184, batch_loss_s: 0.1317, time:4.5058, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1540/3125], step: 20290, 7.792 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0779, batch_loss_s: 0.0854, time:5.1335, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1550/3125], step: 20300, 7.720 samples/sec, batch_loss: 0.0671, batch_loss_c: 0.0620, batch_loss_s: 0.0790, time:5.1813, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1560/3125], step: 20310, 8.485 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0864, batch_loss_s: 0.0995, time:4.7142, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1570/3125], step: 20320, 8.027 samples/sec, batch_loss: 0.3357, batch_loss_c: 0.3270, batch_loss_s: 0.3560, time:4.9831, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1580/3125], step: 20330, 8.321 samples/sec, batch_loss: 0.1060, batch_loss_c: 0.1076, batch_loss_s: 0.1020, time:4.8068, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1590/3125], step: 20340, 8.687 samples/sec, batch_loss: 0.4840, batch_loss_c: 0.4657, batch_loss_s: 0.5268, time:4.6045, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1600/3125], step: 20350, 7.830 samples/sec, batch_loss: 0.2353, batch_loss_c: 0.2377, batch_loss_s: 0.2298, time:5.1087, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1610/3125], step: 20360, 8.704 samples/sec, batch_loss: 0.2784, batch_loss_c: 0.2677, batch_loss_s: 0.3033, time:4.5957, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:43 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1620/3125], step: 20370, 9.542 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3123, batch_loss_s: 0.3192, time:4.1920, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:48 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1630/3125], step: 20380, 7.881 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0702, batch_loss_s: 0.0898, time:5.0758, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1640/3125], step: 20390, 8.396 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0679, batch_loss_s: 0.0955, time:4.7643, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:00:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1650/3125], step: 20400, 8.197 samples/sec, batch_loss: 0.3296, batch_loss_c: 0.3300, batch_loss_s: 0.3286, time:4.8796, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1660/3125], step: 20410, 8.604 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0643, batch_loss_s: 0.0594, time:4.6491, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1670/3125], step: 20420, 7.671 samples/sec, batch_loss: 0.0699, batch_loss_c: 0.0601, batch_loss_s: 0.0930, time:5.2144, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:13 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1680/3125], step: 20430, 7.183 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0841, batch_loss_s: 0.0969, time:5.5689, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1690/3125], step: 20440, 7.529 samples/sec, batch_loss: 0.0613, batch_loss_c: 0.0583, batch_loss_s: 0.0682, time:5.3125, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1700/3125], step: 20450, 7.855 samples/sec, batch_loss: 0.5495, batch_loss_c: 0.5462, batch_loss_s: 0.5573, time:5.0920, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1710/3125], step: 20460, 7.672 samples/sec, batch_loss: 0.3522, batch_loss_c: 0.3546, batch_loss_s: 0.3466, time:5.2141, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1720/3125], step: 20470, 7.687 samples/sec, batch_loss: 0.0548, batch_loss_c: 0.0503, batch_loss_s: 0.0653, time:5.2035, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1730/3125], step: 20480, 6.972 samples/sec, batch_loss: 0.2996, batch_loss_c: 0.2965, batch_loss_s: 0.3068, time:5.7372, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1740/3125], step: 20490, 7.002 samples/sec, batch_loss: 0.3259, batch_loss_c: 0.3238, batch_loss_s: 0.3307, time:5.7125, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1750/3125], step: 20500, 8.235 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2810, batch_loss_s: 0.3138, time:4.8575, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:01:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1760/3125], step: 20510, 7.995 samples/sec, batch_loss: 0.6929, batch_loss_c: 0.7347, batch_loss_s: 0.5954, time:5.0029, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1770/3125], step: 20520, 7.350 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0928, batch_loss_s: 0.1010, time:5.4425, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1780/3125], step: 20530, 7.529 samples/sec, batch_loss: 0.3387, batch_loss_c: 0.3456, batch_loss_s: 0.3227, time:5.3129, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1790/3125], step: 20540, 7.176 samples/sec, batch_loss: 0.3437, batch_loss_c: 0.3536, batch_loss_s: 0.3206, time:5.5744, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1800/3125], step: 20550, 7.222 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1181, batch_loss_s: 0.1230, time:5.5383, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1810/3125], step: 20560, 6.396 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1059, batch_loss_s: 0.1055, time:6.2535, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1820/3125], step: 20570, 8.765 samples/sec, batch_loss: 0.3626, batch_loss_c: 0.3711, batch_loss_s: 0.3428, time:4.5636, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1830/3125], step: 20580, 8.508 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1034, batch_loss_s: 0.1132, time:4.7017, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1840/3125], step: 20590, 8.244 samples/sec, batch_loss: 0.4008, batch_loss_c: 0.4390, batch_loss_s: 0.3116, time:4.8520, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1850/3125], step: 20600, 8.045 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.1053, batch_loss_s: 0.1052, time:4.9720, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1860/3125], step: 20610, 8.052 samples/sec, batch_loss: 0.0450, batch_loss_c: 0.0401, batch_loss_s: 0.0564, time:4.9680, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1870/3125], step: 20620, 8.248 samples/sec, batch_loss: 0.1975, batch_loss_c: 0.2239, batch_loss_s: 0.1357, time:4.8496, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:02:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1880/3125], step: 20630, 8.765 samples/sec, batch_loss: 0.0556, batch_loss_c: 0.0530, batch_loss_s: 0.0615, time:4.5634, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1890/3125], step: 20640, 9.015 samples/sec, batch_loss: 0.1929, batch_loss_c: 0.1875, batch_loss_s: 0.2057, time:4.4372, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1900/3125], step: 20650, 8.394 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1008, batch_loss_s: 0.1107, time:4.7655, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1910/3125], step: 20660, 7.720 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0910, batch_loss_s: 0.0802, time:5.1810, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1920/3125], step: 20670, 8.294 samples/sec, batch_loss: 0.1799, batch_loss_c: 0.2092, batch_loss_s: 0.1116, time:4.8226, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1930/3125], step: 20680, 8.165 samples/sec, batch_loss: 0.3001, batch_loss_c: 0.2972, batch_loss_s: 0.3069, time:4.8987, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1940/3125], step: 20690, 8.469 samples/sec, batch_loss: 0.1400, batch_loss_c: 0.1492, batch_loss_s: 0.1187, time:4.7230, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1950/3125], step: 20700, 7.898 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0749, batch_loss_s: 0.0927, time:5.0644, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1960/3125], step: 20710, 7.630 samples/sec, batch_loss: 0.2713, batch_loss_c: 0.2590, batch_loss_s: 0.2999, time:5.2426, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1970/3125], step: 20720, 7.387 samples/sec, batch_loss: 0.3005, batch_loss_c: 0.2974, batch_loss_s: 0.3078, time:5.4150, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1980/3125], step: 20730, 7.294 samples/sec, batch_loss: 0.0681, batch_loss_c: 0.0627, batch_loss_s: 0.0808, time:5.4843, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1990/3125], step: 20740, 7.999 samples/sec, batch_loss: 0.4715, batch_loss_c: 0.4517, batch_loss_s: 0.5177, time:5.0006, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:03:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2000/3125], step: 20750, 7.605 samples/sec, batch_loss: 0.3199, batch_loss_c: 0.3256, batch_loss_s: 0.3066, time:5.2594, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2010/3125], step: 20760, 7.643 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.0989, batch_loss_s: 0.1025, time:5.2334, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2020/3125], step: 20770, 8.275 samples/sec, batch_loss: 0.3733, batch_loss_c: 0.4011, batch_loss_s: 0.3086, time:4.8340, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2030/3125], step: 20780, 7.994 samples/sec, batch_loss: 0.5560, batch_loss_c: 0.5611, batch_loss_s: 0.5441, time:5.0037, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2040/3125], step: 20790, 8.559 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0568, batch_loss_s: 0.0782, time:4.6733, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2050/3125], step: 20800, 8.593 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1664, batch_loss_s: 0.0897, time:4.6551, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2060/3125], step: 20810, 7.780 samples/sec, batch_loss: 0.1227, batch_loss_c: 0.1323, batch_loss_s: 0.1003, time:5.1417, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2070/3125], step: 20820, 7.854 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.1038, batch_loss_s: 0.0816, time:5.0931, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2080/3125], step: 20830, 7.504 samples/sec, batch_loss: 0.3074, batch_loss_c: 0.3059, batch_loss_s: 0.3109, time:5.3305, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2090/3125], step: 20840, 8.465 samples/sec, batch_loss: 0.2346, batch_loss_c: 0.1917, batch_loss_s: 0.3345, time:4.7255, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2100/3125], step: 20850, 8.136 samples/sec, batch_loss: 0.1711, batch_loss_c: 0.1866, batch_loss_s: 0.1349, time:4.9165, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2110/3125], step: 20860, 8.108 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1037, batch_loss_s: 0.0982, time:4.9337, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:04:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2120/3125], step: 20870, 7.448 samples/sec, batch_loss: 0.1727, batch_loss_c: 0.1991, batch_loss_s: 0.1113, time:5.3702, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2130/3125], step: 20880, 8.178 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0860, batch_loss_s: 0.0994, time:4.8911, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2140/3125], step: 20890, 7.784 samples/sec, batch_loss: 0.0736, batch_loss_c: 0.0772, batch_loss_s: 0.0651, time:5.1387, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2150/3125], step: 20900, 7.270 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1304, batch_loss_s: 0.1129, time:5.5021, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2160/3125], step: 20910, 7.439 samples/sec, batch_loss: 0.1737, batch_loss_c: 0.1821, batch_loss_s: 0.1542, time:5.3774, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2170/3125], step: 20920, 8.561 samples/sec, batch_loss: 0.1393, batch_loss_c: 0.1572, batch_loss_s: 0.0976, time:4.6722, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2180/3125], step: 20930, 8.771 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3080, batch_loss_s: 0.3233, time:4.5606, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2190/3125], step: 20940, 7.591 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.1028, batch_loss_s: 0.0693, time:5.2694, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2200/3125], step: 20950, 7.705 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0903, batch_loss_s: 0.0948, time:5.1915, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2210/3125], step: 20960, 8.485 samples/sec, batch_loss: 0.1492, batch_loss_c: 0.1484, batch_loss_s: 0.1510, time:4.7144, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2220/3125], step: 20970, 7.676 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0844, batch_loss_s: 0.0792, time:5.2111, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2230/3125], step: 20980, 8.907 samples/sec, batch_loss: 0.3395, batch_loss_c: 0.3476, batch_loss_s: 0.3206, time:4.4909, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:05:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2240/3125], step: 20990, 7.680 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.1031, batch_loss_s: 0.0777, time:5.2080, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2250/3125], step: 21000, 7.664 samples/sec, batch_loss: 0.1529, batch_loss_c: 0.1553, batch_loss_s: 0.1471, time:5.2192, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2260/3125], step: 21010, 8.036 samples/sec, batch_loss: 0.3669, batch_loss_c: 0.3670, batch_loss_s: 0.3667, time:4.9775, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2270/3125], step: 21020, 7.703 samples/sec, batch_loss: 0.0535, batch_loss_c: 0.0490, batch_loss_s: 0.0639, time:5.1930, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2280/3125], step: 21030, 7.883 samples/sec, batch_loss: 0.5340, batch_loss_c: 0.5233, batch_loss_s: 0.5589, time:5.0743, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2290/3125], step: 21040, 8.766 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0708, batch_loss_s: 0.0834, time:4.5629, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2300/3125], step: 21050, 8.597 samples/sec, batch_loss: 0.1340, batch_loss_c: 0.1471, batch_loss_s: 0.1035, time:4.6530, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2310/3125], step: 21060, 8.428 samples/sec, batch_loss: 0.1494, batch_loss_c: 0.1468, batch_loss_s: 0.1556, time:4.7464, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2320/3125], step: 21070, 8.317 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1312, batch_loss_s: 0.0941, time:4.8097, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2330/3125], step: 21080, 8.168 samples/sec, batch_loss: 0.5119, batch_loss_c: 0.4880, batch_loss_s: 0.5675, time:4.8973, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2340/3125], step: 21090, 8.160 samples/sec, batch_loss: 0.0977, batch_loss_c: 0.0957, batch_loss_s: 0.1023, time:4.9018, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2350/3125], step: 21100, 7.394 samples/sec, batch_loss: 0.1429, batch_loss_c: 0.1471, batch_loss_s: 0.1332, time:5.4096, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:06:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2360/3125], step: 21110, 8.725 samples/sec, batch_loss: 0.2747, batch_loss_c: 0.2603, batch_loss_s: 0.3083, time:4.5846, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2370/3125], step: 21120, 8.286 samples/sec, batch_loss: 0.2765, batch_loss_c: 0.2555, batch_loss_s: 0.3256, time:4.8276, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2380/3125], step: 21130, 8.050 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1290, batch_loss_s: 0.1246, time:4.9692, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2390/3125], step: 21140, 8.617 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1262, batch_loss_s: 0.0962, time:4.6420, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2400/3125], step: 21150, 9.053 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1197, batch_loss_s: 0.1334, time:4.4184, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2410/3125], step: 21160, 8.103 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0985, batch_loss_s: 0.0726, time:4.9363, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2420/3125], step: 21170, 8.134 samples/sec, batch_loss: 0.3039, batch_loss_c: 0.3011, batch_loss_s: 0.3105, time:4.9177, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2430/3125], step: 21180, 7.701 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.1149, batch_loss_s: 0.0611, time:5.1943, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2440/3125], step: 21190, 8.944 samples/sec, batch_loss: 0.1256, batch_loss_c: 0.1294, batch_loss_s: 0.1167, time:4.4725, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2450/3125], step: 21200, 8.232 samples/sec, batch_loss: 0.3379, batch_loss_c: 0.3408, batch_loss_s: 0.3313, time:4.8593, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2460/3125], step: 21210, 8.437 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0957, batch_loss_s: 0.0792, time:4.7408, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2470/3125], step: 21220, 8.763 samples/sec, batch_loss: 0.3031, batch_loss_c: 0.2910, batch_loss_s: 0.3315, time:4.5648, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2480/3125], step: 21230, 9.198 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0781, batch_loss_s: 0.0770, time:4.3485, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:07:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2490/3125], step: 21240, 8.634 samples/sec, batch_loss: 0.1264, batch_loss_c: 0.1495, batch_loss_s: 0.0725, time:4.6331, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2500/3125], step: 21250, 8.254 samples/sec, batch_loss: 0.1179, batch_loss_c: 0.1301, batch_loss_s: 0.0895, time:4.8464, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2510/3125], step: 21260, 8.406 samples/sec, batch_loss: 0.1427, batch_loss_c: 0.1278, batch_loss_s: 0.1775, time:4.7587, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2520/3125], step: 21270, 9.001 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1284, batch_loss_s: 0.0884, time:4.4437, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2530/3125], step: 21280, 8.082 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0770, batch_loss_s: 0.0978, time:4.9490, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2540/3125], step: 21290, 7.930 samples/sec, batch_loss: 0.2926, batch_loss_c: 0.3311, batch_loss_s: 0.2028, time:5.0438, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2550/3125], step: 21300, 8.284 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.1048, batch_loss_s: 0.0718, time:4.8285, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2560/3125], step: 21310, 8.742 samples/sec, batch_loss: 0.1376, batch_loss_c: 0.1572, batch_loss_s: 0.0920, time:4.5756, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2570/3125], step: 21320, 8.436 samples/sec, batch_loss: 0.1665, batch_loss_c: 0.1989, batch_loss_s: 0.0908, time:4.7415, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2580/3125], step: 21330, 9.116 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0710, batch_loss_s: 0.0809, time:4.3880, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2590/3125], step: 21340, 7.655 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0824, batch_loss_s: 0.0987, time:5.2252, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2600/3125], step: 21350, 7.513 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.0976, batch_loss_s: 0.1038, time:5.3241, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:08:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2610/3125], step: 21360, 8.028 samples/sec, batch_loss: 0.1302, batch_loss_c: 0.1394, batch_loss_s: 0.1087, time:4.9824, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2620/3125], step: 21370, 7.420 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0755, batch_loss_s: 0.0956, time:5.3911, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2630/3125], step: 21380, 8.792 samples/sec, batch_loss: 0.1126, batch_loss_c: 0.0809, batch_loss_s: 0.1865, time:4.5496, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2640/3125], step: 21390, 8.056 samples/sec, batch_loss: 0.1701, batch_loss_c: 0.1717, batch_loss_s: 0.1665, time:4.9651, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2650/3125], step: 21400, 8.165 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1459, batch_loss_s: 0.0964, time:4.8992, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2660/3125], step: 21410, 8.140 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1325, batch_loss_s: 0.0917, time:4.9140, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2670/3125], step: 21420, 7.947 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1326, batch_loss_s: 0.1228, time:5.0337, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2680/3125], step: 21430, 8.715 samples/sec, batch_loss: 0.1086, batch_loss_c: 0.1244, batch_loss_s: 0.0719, time:4.5900, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2690/3125], step: 21440, 8.503 samples/sec, batch_loss: 0.1954, batch_loss_c: 0.2349, batch_loss_s: 0.1033, time:4.7042, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2700/3125], step: 21450, 8.095 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0783, batch_loss_s: 0.0856, time:4.9415, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2710/3125], step: 21460, 8.038 samples/sec, batch_loss: 0.1694, batch_loss_c: 0.1916, batch_loss_s: 0.1177, time:4.9761, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2720/3125], step: 21470, 7.272 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.0984, batch_loss_s: 0.1855, time:5.5009, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:09:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2730/3125], step: 21480, 7.829 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0781, batch_loss_s: 0.0853, time:5.1094, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2740/3125], step: 21490, 8.179 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0802, batch_loss_s: 0.1086, time:4.8906, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2750/3125], step: 21500, 8.872 samples/sec, batch_loss: 0.4288, batch_loss_c: 0.4279, batch_loss_s: 0.4309, time:4.5088, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2760/3125], step: 21510, 7.804 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1323, batch_loss_s: 0.1052, time:5.1256, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2770/3125], step: 21520, 8.002 samples/sec, batch_loss: 0.1767, batch_loss_c: 0.1758, batch_loss_s: 0.1790, time:4.9988, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2780/3125], step: 21530, 8.485 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0788, batch_loss_s: 0.0970, time:4.7140, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2790/3125], step: 21540, 8.068 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0652, batch_loss_s: 0.0910, time:4.9577, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2800/3125], step: 21550, 8.115 samples/sec, batch_loss: 0.0763, batch_loss_c: 0.0706, batch_loss_s: 0.0896, time:4.9292, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2810/3125], step: 21560, 8.147 samples/sec, batch_loss: 0.2899, batch_loss_c: 0.2861, batch_loss_s: 0.2988, time:4.9095, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2820/3125], step: 21570, 8.319 samples/sec, batch_loss: 0.5562, batch_loss_c: 0.5551, batch_loss_s: 0.5588, time:4.8085, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2830/3125], step: 21580, 7.445 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.1104, batch_loss_s: 0.0772, time:5.3730, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2840/3125], step: 21590, 8.146 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0745, batch_loss_s: 0.0649, time:4.9104, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2850/3125], step: 21600, 8.952 samples/sec, batch_loss: 0.5413, batch_loss_c: 0.5328, batch_loss_s: 0.5612, time:4.4683, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:10:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2860/3125], step: 21610, 7.742 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1623, batch_loss_s: 0.1025, time:5.1666, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:04 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2870/3125], step: 21620, 8.380 samples/sec, batch_loss: 0.1180, batch_loss_c: 0.1153, batch_loss_s: 0.1245, time:4.7733, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:09 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2880/3125], step: 21630, 8.208 samples/sec, batch_loss: 0.1603, batch_loss_c: 0.1652, batch_loss_s: 0.1488, time:4.8730, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2890/3125], step: 21640, 8.375 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0705, batch_loss_s: 0.0814, time:4.7759, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2900/3125], step: 21650, 8.277 samples/sec, batch_loss: 0.3525, batch_loss_c: 0.3560, batch_loss_s: 0.3445, time:4.8325, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2910/3125], step: 21660, 7.980 samples/sec, batch_loss: 0.1517, batch_loss_c: 0.1588, batch_loss_s: 0.1352, time:5.0124, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2920/3125], step: 21670, 8.152 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1206, batch_loss_s: 0.0991, time:4.9069, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2930/3125], step: 21680, 7.511 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1385, batch_loss_s: 0.1030, time:5.3258, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2940/3125], step: 21690, 7.337 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1312, batch_loss_s: 0.1099, time:5.4517, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2950/3125], step: 21700, 7.904 samples/sec, batch_loss: 0.0849, batch_loss_c: 0.0829, batch_loss_s: 0.0895, time:5.0609, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2960/3125], step: 21710, 7.947 samples/sec, batch_loss: 0.1519, batch_loss_c: 0.1501, batch_loss_s: 0.1560, time:5.0332, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2970/3125], step: 21720, 7.543 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0966, batch_loss_s: 0.0897, time:5.3030, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:11:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2980/3125], step: 21730, 8.229 samples/sec, batch_loss: 0.1264, batch_loss_c: 0.1357, batch_loss_s: 0.1045, time:4.8611, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2990/3125], step: 21740, 7.070 samples/sec, batch_loss: 0.0644, batch_loss_c: 0.0596, batch_loss_s: 0.0755, time:5.6580, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3000/3125], step: 21750, 8.305 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0711, batch_loss_s: 0.0826, time:4.8161, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3010/3125], step: 21760, 7.293 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0726, batch_loss_s: 0.1391, time:5.4851, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3020/3125], step: 21770, 7.005 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1473, batch_loss_s: 0.1460, time:5.7099, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3030/3125], step: 21780, 7.993 samples/sec, batch_loss: 0.1179, batch_loss_c: 0.1083, batch_loss_s: 0.1402, time:5.0046, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3040/3125], step: 21790, 7.281 samples/sec, batch_loss: 0.3177, batch_loss_c: 0.3168, batch_loss_s: 0.3198, time:5.4935, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3050/3125], step: 21800, 8.215 samples/sec, batch_loss: 0.4157, batch_loss_c: 0.4529, batch_loss_s: 0.3288, time:4.8694, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3060/3125], step: 21810, 7.568 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0920, batch_loss_s: 0.1045, time:5.2857, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3070/3125], step: 21820, 7.231 samples/sec, batch_loss: 0.1003, batch_loss_c: 0.0984, batch_loss_s: 0.1047, time:5.5318, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3080/3125], step: 21830, 7.298 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1240, batch_loss_s: 0.0996, time:5.4811, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:12:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3090/3125], step: 21840, 7.075 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0856, batch_loss_s: 0.0876, time:5.6538, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:04 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3100/3125], step: 21850, 7.810 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1015, batch_loss_s: 0.0908, time:5.1218, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3110/3125], step: 21860, 10.556 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1281, batch_loss_s: 0.1172, time:3.7891, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3120/3125], step: 21870, 10.325 samples/sec, batch_loss: 0.1776, batch_loss_c: 0.2135, batch_loss_s: 0.0937, time:3.8741, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:13 \u001b[32mINFO     \u001b[0m train.py: [6/10], train_loss: 0.1801, time: 1559.7118, lr: 0.0001\u001b[0m\n",
            "2019-11-23 14:13:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [0/3125], step: 21875, 7.736 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0957, batch_loss_s: 0.1010, time:5.1706, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [10/3125], step: 21885, 5.597 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.0906, batch_loss_s: 0.1084, time:7.1465, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [20/3125], step: 21895, 8.765 samples/sec, batch_loss: 0.4047, batch_loss_c: 0.4004, batch_loss_s: 0.4148, time:4.5637, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [30/3125], step: 21905, 7.757 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0827, batch_loss_s: 0.0814, time:5.1565, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [40/3125], step: 21915, 8.746 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0703, batch_loss_s: 0.0826, time:4.5733, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [50/3125], step: 21925, 8.287 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1439, batch_loss_s: 0.1300, time:4.8269, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [60/3125], step: 21935, 8.327 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0737, batch_loss_s: 0.0816, time:4.8034, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:13:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [70/3125], step: 21945, 7.046 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.0928, batch_loss_s: 0.1056, time:5.6769, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [80/3125], step: 21955, 7.826 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0935, batch_loss_s: 0.0928, time:5.1110, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [90/3125], step: 21965, 7.096 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1126, batch_loss_s: 0.1159, time:5.6373, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [100/3125], step: 21975, 7.732 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1352, batch_loss_s: 0.0833, time:5.1734, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [110/3125], step: 21985, 7.763 samples/sec, batch_loss: 0.1762, batch_loss_c: 0.1944, batch_loss_s: 0.1336, time:5.1527, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [120/3125], step: 21995, 7.848 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0937, batch_loss_s: 0.0908, time:5.0966, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [130/3125], step: 22005, 7.819 samples/sec, batch_loss: 0.3095, batch_loss_c: 0.3158, batch_loss_s: 0.2949, time:5.1160, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [140/3125], step: 22015, 7.839 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0899, batch_loss_s: 0.0787, time:5.1029, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [150/3125], step: 22025, 7.513 samples/sec, batch_loss: 0.1956, batch_loss_c: 0.1954, batch_loss_s: 0.1960, time:5.3244, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [160/3125], step: 22035, 7.905 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0737, batch_loss_s: 0.0898, time:5.0599, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [170/3125], step: 22045, 8.175 samples/sec, batch_loss: 0.5032, batch_loss_c: 0.4808, batch_loss_s: 0.5557, time:4.8927, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [180/3125], step: 22055, 7.879 samples/sec, batch_loss: 0.2944, batch_loss_c: 0.2917, batch_loss_s: 0.3007, time:5.0767, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:14:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [190/3125], step: 22065, 6.994 samples/sec, batch_loss: 0.1446, batch_loss_c: 0.1288, batch_loss_s: 0.1814, time:5.7190, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [200/3125], step: 22075, 7.256 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0625, batch_loss_s: 0.0761, time:5.5130, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [210/3125], step: 22085, 7.862 samples/sec, batch_loss: 0.3137, batch_loss_c: 0.3069, batch_loss_s: 0.3295, time:5.0881, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [220/3125], step: 22095, 7.715 samples/sec, batch_loss: 0.0736, batch_loss_c: 0.0735, batch_loss_s: 0.0738, time:5.1850, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [230/3125], step: 22105, 7.913 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0893, batch_loss_s: 0.0719, time:5.0547, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [240/3125], step: 22115, 8.633 samples/sec, batch_loss: 0.1752, batch_loss_c: 0.2214, batch_loss_s: 0.0673, time:4.6335, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [250/3125], step: 22125, 7.880 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3465, batch_loss_s: 0.3529, time:5.0760, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [260/3125], step: 22135, 8.582 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1351, batch_loss_s: 0.0604, time:4.6612, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [270/3125], step: 22145, 8.482 samples/sec, batch_loss: 0.2114, batch_loss_c: 0.2047, batch_loss_s: 0.2269, time:4.7157, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [280/3125], step: 22155, 8.994 samples/sec, batch_loss: 0.1101, batch_loss_c: 0.1136, batch_loss_s: 0.1020, time:4.4474, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [290/3125], step: 22165, 8.831 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0746, batch_loss_s: 0.0684, time:4.5296, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [300/3125], step: 22175, 7.716 samples/sec, batch_loss: 0.0780, batch_loss_c: 0.0793, batch_loss_s: 0.0751, time:5.1841, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:15:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [310/3125], step: 22185, 8.605 samples/sec, batch_loss: 0.2740, batch_loss_c: 0.2594, batch_loss_s: 0.3080, time:4.6485, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [320/3125], step: 22195, 7.985 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3391, batch_loss_s: 0.3365, time:5.0096, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [330/3125], step: 22205, 8.008 samples/sec, batch_loss: 0.3043, batch_loss_c: 0.3031, batch_loss_s: 0.3071, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [340/3125], step: 22215, 8.164 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1108, batch_loss_s: 0.1051, time:4.8997, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [350/3125], step: 22225, 7.389 samples/sec, batch_loss: 0.1509, batch_loss_c: 0.1759, batch_loss_s: 0.0926, time:5.4133, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [360/3125], step: 22235, 7.912 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0802, batch_loss_s: 0.0742, time:5.0555, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [370/3125], step: 22245, 8.290 samples/sec, batch_loss: 0.1185, batch_loss_c: 0.1306, batch_loss_s: 0.0901, time:4.8253, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [380/3125], step: 22255, 8.398 samples/sec, batch_loss: 0.3142, batch_loss_c: 0.3146, batch_loss_s: 0.3134, time:4.7633, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [390/3125], step: 22265, 7.044 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0880, batch_loss_s: 0.0992, time:5.6786, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [400/3125], step: 22275, 8.594 samples/sec, batch_loss: 0.4063, batch_loss_c: 0.3992, batch_loss_s: 0.4228, time:4.6544, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [410/3125], step: 22285, 8.118 samples/sec, batch_loss: 0.0938, batch_loss_c: 0.0943, batch_loss_s: 0.0926, time:4.9271, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [420/3125], step: 22295, 8.856 samples/sec, batch_loss: 0.1452, batch_loss_c: 0.1632, batch_loss_s: 0.1033, time:4.5166, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:16:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [430/3125], step: 22305, 6.766 samples/sec, batch_loss: 0.2940, batch_loss_c: 0.2863, batch_loss_s: 0.3120, time:5.9117, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [440/3125], step: 22315, 8.832 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2872, batch_loss_s: 0.2992, time:4.5288, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [450/3125], step: 22325, 8.735 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0830, batch_loss_s: 0.0874, time:4.5792, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [460/3125], step: 22335, 8.426 samples/sec, batch_loss: 0.0822, batch_loss_c: 0.0766, batch_loss_s: 0.0954, time:4.7474, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [470/3125], step: 22345, 8.566 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0804, batch_loss_s: 0.0841, time:4.6697, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [480/3125], step: 22355, 8.291 samples/sec, batch_loss: 0.3115, batch_loss_c: 0.3089, batch_loss_s: 0.3177, time:4.8244, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [490/3125], step: 22365, 7.561 samples/sec, batch_loss: 0.3123, batch_loss_c: 0.3139, batch_loss_s: 0.3086, time:5.2906, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [500/3125], step: 22375, 8.954 samples/sec, batch_loss: 0.3203, batch_loss_c: 0.3266, batch_loss_s: 0.3056, time:4.4671, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [510/3125], step: 22385, 8.556 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1084, batch_loss_s: 0.1178, time:4.6751, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [520/3125], step: 22395, 8.240 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.3012, batch_loss_s: 0.3086, time:4.8542, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [530/3125], step: 22405, 8.242 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0819, batch_loss_s: 0.0986, time:4.8531, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [540/3125], step: 22415, 8.016 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1205, batch_loss_s: 0.1204, time:4.9901, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [550/3125], step: 22425, 8.374 samples/sec, batch_loss: 0.2012, batch_loss_c: 0.2426, batch_loss_s: 0.1046, time:4.7764, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:17:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [560/3125], step: 22435, 7.960 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0838, batch_loss_s: 0.0886, time:5.0251, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [570/3125], step: 22445, 8.040 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1284, batch_loss_s: 0.1232, time:4.9753, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [580/3125], step: 22455, 7.017 samples/sec, batch_loss: 0.1382, batch_loss_c: 0.1426, batch_loss_s: 0.1281, time:5.7004, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [590/3125], step: 22465, 8.314 samples/sec, batch_loss: 0.5255, batch_loss_c: 0.5180, batch_loss_s: 0.5429, time:4.8109, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [600/3125], step: 22475, 7.367 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0707, batch_loss_s: 0.0770, time:5.4297, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [610/3125], step: 22485, 7.165 samples/sec, batch_loss: 0.2331, batch_loss_c: 0.2719, batch_loss_s: 0.1426, time:5.5827, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [620/3125], step: 22495, 8.693 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.0991, batch_loss_s: 0.1019, time:4.6014, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [630/3125], step: 22505, 8.277 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1140, batch_loss_s: 0.1350, time:4.8329, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [640/3125], step: 22515, 8.561 samples/sec, batch_loss: 0.2368, batch_loss_c: 0.2096, batch_loss_s: 0.3002, time:4.6722, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [650/3125], step: 22525, 7.588 samples/sec, batch_loss: 0.0950, batch_loss_c: 0.0920, batch_loss_s: 0.1020, time:5.2714, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [660/3125], step: 22535, 7.708 samples/sec, batch_loss: 0.1485, batch_loss_c: 0.1598, batch_loss_s: 0.1222, time:5.1891, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:18:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [670/3125], step: 22545, 8.122 samples/sec, batch_loss: 0.1306, batch_loss_c: 0.1259, batch_loss_s: 0.1416, time:4.9246, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [680/3125], step: 22555, 8.651 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1108, batch_loss_s: 0.1213, time:4.6238, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [690/3125], step: 22565, 8.246 samples/sec, batch_loss: 0.1256, batch_loss_c: 0.1171, batch_loss_s: 0.1454, time:4.8507, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [700/3125], step: 22575, 8.204 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1083, batch_loss_s: 0.1300, time:4.8755, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [710/3125], step: 22585, 7.302 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1278, batch_loss_s: 0.1017, time:5.4780, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [720/3125], step: 22595, 7.418 samples/sec, batch_loss: 0.2995, batch_loss_c: 0.2975, batch_loss_s: 0.3040, time:5.3922, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [730/3125], step: 22605, 9.029 samples/sec, batch_loss: 0.4553, batch_loss_c: 0.4204, batch_loss_s: 0.5367, time:4.4303, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [740/3125], step: 22615, 7.970 samples/sec, batch_loss: 0.0528, batch_loss_c: 0.0520, batch_loss_s: 0.0547, time:5.0188, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [750/3125], step: 22625, 7.645 samples/sec, batch_loss: 0.1394, batch_loss_c: 0.1377, batch_loss_s: 0.1434, time:5.2325, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [760/3125], step: 22635, 7.798 samples/sec, batch_loss: 0.3461, batch_loss_c: 0.3589, batch_loss_s: 0.3164, time:5.1295, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [770/3125], step: 22645, 7.378 samples/sec, batch_loss: 0.3107, batch_loss_c: 0.3073, batch_loss_s: 0.3189, time:5.4218, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [780/3125], step: 22655, 7.907 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0700, batch_loss_s: 0.0740, time:5.0587, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:19:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [790/3125], step: 22665, 6.911 samples/sec, batch_loss: 0.0646, batch_loss_c: 0.0623, batch_loss_s: 0.0698, time:5.7881, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [800/3125], step: 22675, 8.112 samples/sec, batch_loss: 0.3247, batch_loss_c: 0.3257, batch_loss_s: 0.3223, time:4.9308, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [810/3125], step: 22685, 8.294 samples/sec, batch_loss: 0.0737, batch_loss_c: 0.0685, batch_loss_s: 0.0859, time:4.8227, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [820/3125], step: 22695, 8.352 samples/sec, batch_loss: 0.5964, batch_loss_c: 0.5740, batch_loss_s: 0.6487, time:4.7891, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [830/3125], step: 22705, 7.654 samples/sec, batch_loss: 0.3128, batch_loss_c: 0.3169, batch_loss_s: 0.3033, time:5.2263, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [840/3125], step: 22715, 7.894 samples/sec, batch_loss: 0.3991, batch_loss_c: 0.4189, batch_loss_s: 0.3531, time:5.0671, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [850/3125], step: 22725, 8.382 samples/sec, batch_loss: 0.1663, batch_loss_c: 0.1936, batch_loss_s: 0.1026, time:4.7721, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [860/3125], step: 22735, 8.612 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0708, batch_loss_s: 0.0898, time:4.6446, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [870/3125], step: 22745, 7.570 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1382, batch_loss_s: 0.1587, time:5.2844, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [880/3125], step: 22755, 6.468 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0850, batch_loss_s: 0.0890, time:6.1846, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [890/3125], step: 22765, 7.868 samples/sec, batch_loss: 0.3625, batch_loss_c: 0.3878, batch_loss_s: 0.3036, time:5.0841, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [900/3125], step: 22775, 7.910 samples/sec, batch_loss: 0.0980, batch_loss_c: 0.1000, batch_loss_s: 0.0935, time:5.0571, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:20:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [910/3125], step: 22785, 7.847 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1097, batch_loss_s: 0.1094, time:5.0975, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [920/3125], step: 22795, 8.405 samples/sec, batch_loss: 0.4416, batch_loss_c: 0.4347, batch_loss_s: 0.4578, time:4.7593, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [930/3125], step: 22805, 8.688 samples/sec, batch_loss: 0.0675, batch_loss_c: 0.0674, batch_loss_s: 0.0679, time:4.6039, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [940/3125], step: 22815, 8.202 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1188, batch_loss_s: 0.0999, time:4.8769, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [950/3125], step: 22825, 8.010 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0594, batch_loss_s: 0.0712, time:4.9935, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [960/3125], step: 22835, 7.417 samples/sec, batch_loss: 0.1974, batch_loss_c: 0.2362, batch_loss_s: 0.1070, time:5.3929, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [970/3125], step: 22845, 8.379 samples/sec, batch_loss: 0.0735, batch_loss_c: 0.0694, batch_loss_s: 0.0833, time:4.7738, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [980/3125], step: 22855, 8.005 samples/sec, batch_loss: 0.1182, batch_loss_c: 0.1141, batch_loss_s: 0.1279, time:4.9968, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [990/3125], step: 22865, 8.318 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.1033, batch_loss_s: 0.0811, time:4.8087, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1000/3125], step: 22875, 8.359 samples/sec, batch_loss: 0.1304, batch_loss_c: 0.1424, batch_loss_s: 0.1023, time:4.7853, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1010/3125], step: 22885, 8.469 samples/sec, batch_loss: 0.3256, batch_loss_c: 0.3319, batch_loss_s: 0.3108, time:4.7232, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1020/3125], step: 22895, 8.119 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0890, batch_loss_s: 0.1069, time:4.9270, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:21:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1030/3125], step: 22905, 7.459 samples/sec, batch_loss: 0.0562, batch_loss_c: 0.0510, batch_loss_s: 0.0682, time:5.3625, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1040/3125], step: 22915, 8.915 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0698, batch_loss_s: 0.0766, time:4.4871, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1050/3125], step: 22925, 9.048 samples/sec, batch_loss: 0.3325, batch_loss_c: 0.3415, batch_loss_s: 0.3116, time:4.4211, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1060/3125], step: 22935, 7.826 samples/sec, batch_loss: 0.3068, batch_loss_c: 0.3057, batch_loss_s: 0.3094, time:5.1113, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1070/3125], step: 22945, 8.353 samples/sec, batch_loss: 0.0561, batch_loss_c: 0.0515, batch_loss_s: 0.0668, time:4.7886, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1080/3125], step: 22955, 7.754 samples/sec, batch_loss: 0.0402, batch_loss_c: 0.0363, batch_loss_s: 0.0492, time:5.1585, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1090/3125], step: 22965, 7.356 samples/sec, batch_loss: 0.0985, batch_loss_c: 0.0990, batch_loss_s: 0.0974, time:5.4379, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1100/3125], step: 22975, 9.101 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0851, batch_loss_s: 0.0880, time:4.3952, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1110/3125], step: 22985, 7.930 samples/sec, batch_loss: 0.3087, batch_loss_c: 0.3077, batch_loss_s: 0.3109, time:5.0439, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1120/3125], step: 22995, 7.824 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1039, batch_loss_s: 0.1022, time:5.1127, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1130/3125], step: 23005, 7.593 samples/sec, batch_loss: 0.5558, batch_loss_c: 0.5477, batch_loss_s: 0.5746, time:5.2680, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1140/3125], step: 23015, 7.248 samples/sec, batch_loss: 0.0735, batch_loss_c: 0.0687, batch_loss_s: 0.0847, time:5.5191, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:22:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1150/3125], step: 23025, 7.511 samples/sec, batch_loss: 0.0772, batch_loss_c: 0.0789, batch_loss_s: 0.0734, time:5.3258, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1160/3125], step: 23035, 7.075 samples/sec, batch_loss: 0.1821, batch_loss_c: 0.1983, batch_loss_s: 0.1442, time:5.6536, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1170/3125], step: 23045, 8.009 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1022, batch_loss_s: 0.1162, time:4.9944, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1180/3125], step: 23055, 7.815 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0855, batch_loss_s: 0.0815, time:5.1182, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1190/3125], step: 23065, 8.007 samples/sec, batch_loss: 0.0996, batch_loss_c: 0.0988, batch_loss_s: 0.1015, time:4.9957, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1200/3125], step: 23075, 8.132 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1536, batch_loss_s: 0.1051, time:4.9188, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1210/3125], step: 23085, 7.726 samples/sec, batch_loss: 0.3165, batch_loss_c: 0.3109, batch_loss_s: 0.3295, time:5.1771, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1220/3125], step: 23095, 8.013 samples/sec, batch_loss: 0.3233, batch_loss_c: 0.3202, batch_loss_s: 0.3306, time:4.9916, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1230/3125], step: 23105, 8.473 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0908, batch_loss_s: 0.0979, time:4.7211, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1240/3125], step: 23115, 8.525 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0801, batch_loss_s: 0.1067, time:4.6922, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1250/3125], step: 23125, 8.093 samples/sec, batch_loss: 0.0599, batch_loss_c: 0.0552, batch_loss_s: 0.0708, time:4.9426, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1260/3125], step: 23135, 8.495 samples/sec, batch_loss: 0.1930, batch_loss_c: 0.2245, batch_loss_s: 0.1195, time:4.7086, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:23:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1270/3125], step: 23145, 8.692 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.0936, batch_loss_s: 0.1168, time:4.6018, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1280/3125], step: 23155, 7.981 samples/sec, batch_loss: 0.1317, batch_loss_c: 0.1532, batch_loss_s: 0.0815, time:5.0119, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1290/3125], step: 23165, 7.228 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0638, batch_loss_s: 0.0821, time:5.5338, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1300/3125], step: 23175, 6.890 samples/sec, batch_loss: 0.3001, batch_loss_c: 0.2968, batch_loss_s: 0.3080, time:5.8057, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1310/3125], step: 23185, 8.382 samples/sec, batch_loss: 0.0914, batch_loss_c: 0.0904, batch_loss_s: 0.0936, time:4.7722, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1320/3125], step: 23195, 7.470 samples/sec, batch_loss: 0.1020, batch_loss_c: 0.0996, batch_loss_s: 0.1077, time:5.3544, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1330/3125], step: 23205, 7.837 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1033, batch_loss_s: 0.1156, time:5.1038, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1340/3125], step: 23215, 7.888 samples/sec, batch_loss: 0.5162, batch_loss_c: 0.5075, batch_loss_s: 0.5366, time:5.0708, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1350/3125], step: 23225, 7.990 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.0951, batch_loss_s: 0.1086, time:5.0064, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1360/3125], step: 23235, 7.959 samples/sec, batch_loss: 0.2366, batch_loss_c: 0.2492, batch_loss_s: 0.2071, time:5.0256, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1370/3125], step: 23245, 8.522 samples/sec, batch_loss: 0.1518, batch_loss_c: 0.1701, batch_loss_s: 0.1092, time:4.6936, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1380/3125], step: 23255, 7.879 samples/sec, batch_loss: 0.1972, batch_loss_c: 0.2060, batch_loss_s: 0.1766, time:5.0770, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:24:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1390/3125], step: 23265, 8.025 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0851, batch_loss_s: 0.0954, time:4.9846, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1400/3125], step: 23275, 8.186 samples/sec, batch_loss: 0.2714, batch_loss_c: 0.2570, batch_loss_s: 0.3050, time:4.8863, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1410/3125], step: 23285, 7.603 samples/sec, batch_loss: 0.1361, batch_loss_c: 0.1342, batch_loss_s: 0.1406, time:5.2611, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1420/3125], step: 23295, 6.270 samples/sec, batch_loss: 0.1600, batch_loss_c: 0.1967, batch_loss_s: 0.0743, time:6.3795, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1430/3125], step: 23305, 7.815 samples/sec, batch_loss: 0.7037, batch_loss_c: 0.6775, batch_loss_s: 0.7650, time:5.1181, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1440/3125], step: 23315, 8.267 samples/sec, batch_loss: 0.2954, batch_loss_c: 0.2926, batch_loss_s: 0.3020, time:4.8388, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1450/3125], step: 23325, 8.165 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0843, batch_loss_s: 0.1019, time:4.8992, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1460/3125], step: 23335, 7.619 samples/sec, batch_loss: 0.1822, batch_loss_c: 0.1811, batch_loss_s: 0.1847, time:5.2498, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1470/3125], step: 23345, 8.100 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0696, batch_loss_s: 0.0718, time:4.9382, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1480/3125], step: 23355, 8.210 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0950, batch_loss_s: 0.0974, time:4.8721, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1490/3125], step: 23365, 8.759 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0809, batch_loss_s: 0.0920, time:4.5667, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1500/3125], step: 23375, 7.443 samples/sec, batch_loss: 0.1526, batch_loss_c: 0.1573, batch_loss_s: 0.1418, time:5.3740, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:25:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1510/3125], step: 23385, 7.644 samples/sec, batch_loss: 0.3651, batch_loss_c: 0.3714, batch_loss_s: 0.3505, time:5.2331, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1520/3125], step: 23395, 8.291 samples/sec, batch_loss: 0.0524, batch_loss_c: 0.0469, batch_loss_s: 0.0653, time:4.8242, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1530/3125], step: 23405, 8.239 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0678, batch_loss_s: 0.0848, time:4.8550, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1540/3125], step: 23415, 8.538 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0601, batch_loss_s: 0.0635, time:4.6847, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1550/3125], step: 23425, 8.660 samples/sec, batch_loss: 0.3206, batch_loss_c: 0.3254, batch_loss_s: 0.3095, time:4.6191, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1560/3125], step: 23435, 6.838 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0670, batch_loss_s: 0.0877, time:5.8496, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1570/3125], step: 23445, 7.846 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1239, batch_loss_s: 0.1261, time:5.0982, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1580/3125], step: 23455, 8.315 samples/sec, batch_loss: 0.3252, batch_loss_c: 0.3313, batch_loss_s: 0.3108, time:4.8106, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1590/3125], step: 23465, 7.313 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0983, batch_loss_s: 0.0805, time:5.4701, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1600/3125], step: 23475, 8.103 samples/sec, batch_loss: 0.0591, batch_loss_c: 0.0553, batch_loss_s: 0.0679, time:4.9367, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1610/3125], step: 23485, 8.298 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0722, batch_loss_s: 0.0846, time:4.8203, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1620/3125], step: 23495, 7.994 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1136, batch_loss_s: 0.1030, time:5.0036, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:26:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1630/3125], step: 23505, 8.068 samples/sec, batch_loss: 0.1294, batch_loss_c: 0.1284, batch_loss_s: 0.1318, time:4.9576, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1640/3125], step: 23515, 6.728 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0981, batch_loss_s: 0.0724, time:5.9453, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1650/3125], step: 23525, 7.943 samples/sec, batch_loss: 0.3229, batch_loss_c: 0.3233, batch_loss_s: 0.3220, time:5.0361, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1660/3125], step: 23535, 8.449 samples/sec, batch_loss: 0.3249, batch_loss_c: 0.3364, batch_loss_s: 0.2982, time:4.7345, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1670/3125], step: 23545, 7.803 samples/sec, batch_loss: 0.3049, batch_loss_c: 0.3001, batch_loss_s: 0.3161, time:5.1262, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1680/3125], step: 23555, 7.718 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0845, batch_loss_s: 0.0700, time:5.1828, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1690/3125], step: 23565, 7.409 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1071, batch_loss_s: 0.1091, time:5.3992, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1700/3125], step: 23575, 7.882 samples/sec, batch_loss: 0.1851, batch_loss_c: 0.1746, batch_loss_s: 0.2094, time:5.0747, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1710/3125], step: 23585, 8.325 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0746, batch_loss_s: 0.0772, time:4.8049, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1720/3125], step: 23595, 6.815 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0872, batch_loss_s: 0.1098, time:5.8692, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1730/3125], step: 23605, 7.485 samples/sec, batch_loss: 0.1628, batch_loss_c: 0.1826, batch_loss_s: 0.1164, time:5.3440, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:27:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1740/3125], step: 23615, 8.060 samples/sec, batch_loss: 0.3595, batch_loss_c: 0.3562, batch_loss_s: 0.3674, time:4.9627, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1750/3125], step: 23625, 6.928 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1044, batch_loss_s: 0.1035, time:5.7738, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1760/3125], step: 23635, 6.502 samples/sec, batch_loss: 0.3256, batch_loss_c: 0.3243, batch_loss_s: 0.3284, time:6.1521, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1770/3125], step: 23645, 7.662 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1297, batch_loss_s: 0.1273, time:5.2204, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1780/3125], step: 23655, 7.520 samples/sec, batch_loss: 0.3889, batch_loss_c: 0.4243, batch_loss_s: 0.3065, time:5.3192, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1790/3125], step: 23665, 7.502 samples/sec, batch_loss: 0.0725, batch_loss_c: 0.0672, batch_loss_s: 0.0849, time:5.3320, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1800/3125], step: 23675, 7.794 samples/sec, batch_loss: 0.4016, batch_loss_c: 0.3889, batch_loss_s: 0.4312, time:5.1321, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1810/3125], step: 23685, 8.704 samples/sec, batch_loss: 0.1400, batch_loss_c: 0.1231, batch_loss_s: 0.1794, time:4.5958, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1820/3125], step: 23695, 7.573 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0644, batch_loss_s: 0.0741, time:5.2817, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1830/3125], step: 23705, 8.071 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0830, batch_loss_s: 0.0881, time:4.9560, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1840/3125], step: 23715, 8.148 samples/sec, batch_loss: 0.1251, batch_loss_c: 0.1324, batch_loss_s: 0.1083, time:4.9090, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1850/3125], step: 23725, 9.132 samples/sec, batch_loss: 0.5205, batch_loss_c: 0.4834, batch_loss_s: 0.6070, time:4.3800, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:28:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1860/3125], step: 23735, 9.168 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0696, batch_loss_s: 0.0801, time:4.3631, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1870/3125], step: 23745, 8.581 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1433, batch_loss_s: 0.1367, time:4.6613, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1880/3125], step: 23755, 9.230 samples/sec, batch_loss: 0.1251, batch_loss_c: 0.1515, batch_loss_s: 0.0636, time:4.3339, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1890/3125], step: 23765, 8.791 samples/sec, batch_loss: 0.1544, batch_loss_c: 0.1668, batch_loss_s: 0.1256, time:4.5501, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1900/3125], step: 23775, 8.512 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0768, batch_loss_s: 0.0841, time:4.6992, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1910/3125], step: 23785, 8.229 samples/sec, batch_loss: 0.2928, batch_loss_c: 0.2923, batch_loss_s: 0.2939, time:4.8608, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1920/3125], step: 23795, 7.934 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.1056, batch_loss_s: 0.0947, time:5.0417, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1930/3125], step: 23805, 8.091 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1236, batch_loss_s: 0.0827, time:4.9437, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1940/3125], step: 23815, 7.967 samples/sec, batch_loss: 0.0514, batch_loss_c: 0.0484, batch_loss_s: 0.0584, time:5.0206, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1950/3125], step: 23825, 8.452 samples/sec, batch_loss: 0.0508, batch_loss_c: 0.0449, batch_loss_s: 0.0648, time:4.7325, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1960/3125], step: 23835, 7.682 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1075, batch_loss_s: 0.1008, time:5.2069, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1970/3125], step: 23845, 8.309 samples/sec, batch_loss: 0.0595, batch_loss_c: 0.0577, batch_loss_s: 0.0635, time:4.8140, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:29:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1980/3125], step: 23855, 8.063 samples/sec, batch_loss: 0.1331, batch_loss_c: 0.1403, batch_loss_s: 0.1161, time:4.9607, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1990/3125], step: 23865, 8.415 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1289, batch_loss_s: 0.0786, time:4.7532, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2000/3125], step: 23875, 7.555 samples/sec, batch_loss: 0.1347, batch_loss_c: 0.1519, batch_loss_s: 0.0947, time:5.2948, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2010/3125], step: 23885, 8.404 samples/sec, batch_loss: 0.3971, batch_loss_c: 0.4045, batch_loss_s: 0.3800, time:4.7594, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2020/3125], step: 23895, 8.107 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0881, batch_loss_s: 0.1103, time:4.9341, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2030/3125], step: 23905, 7.473 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1120, batch_loss_s: 0.0965, time:5.3529, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2040/3125], step: 23915, 8.160 samples/sec, batch_loss: 0.3297, batch_loss_c: 0.3366, batch_loss_s: 0.3136, time:4.9019, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2050/3125], step: 23925, 8.595 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1173, batch_loss_s: 0.1166, time:4.6538, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2060/3125], step: 23935, 7.660 samples/sec, batch_loss: 0.3865, batch_loss_c: 0.3804, batch_loss_s: 0.4006, time:5.2216, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2070/3125], step: 23945, 7.735 samples/sec, batch_loss: 0.3754, batch_loss_c: 0.3798, batch_loss_s: 0.3651, time:5.1713, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2080/3125], step: 23955, 7.511 samples/sec, batch_loss: 0.4988, batch_loss_c: 0.4843, batch_loss_s: 0.5326, time:5.3259, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2090/3125], step: 23965, 8.047 samples/sec, batch_loss: 0.1799, batch_loss_c: 0.2078, batch_loss_s: 0.1147, time:4.9711, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:30:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2100/3125], step: 23975, 7.918 samples/sec, batch_loss: 0.3494, batch_loss_c: 0.3505, batch_loss_s: 0.3468, time:5.0515, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2110/3125], step: 23985, 8.762 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0820, batch_loss_s: 0.0680, time:4.5649, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2120/3125], step: 23995, 8.002 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0923, batch_loss_s: 0.0846, time:4.9985, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2130/3125], step: 24005, 8.842 samples/sec, batch_loss: 0.7172, batch_loss_c: 0.6902, batch_loss_s: 0.7803, time:4.5237, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2140/3125], step: 24015, 8.688 samples/sec, batch_loss: 0.1541, batch_loss_c: 0.1652, batch_loss_s: 0.1282, time:4.6042, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2150/3125], step: 24025, 8.558 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0903, batch_loss_s: 0.0760, time:4.6742, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2160/3125], step: 24035, 7.882 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.2973, batch_loss_s: 0.3221, time:5.0749, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2170/3125], step: 24045, 8.170 samples/sec, batch_loss: 0.0764, batch_loss_c: 0.0730, batch_loss_s: 0.0841, time:4.8957, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2180/3125], step: 24055, 8.438 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0594, batch_loss_s: 0.0706, time:4.7403, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2190/3125], step: 24065, 8.448 samples/sec, batch_loss: 0.2916, batch_loss_c: 0.2848, batch_loss_s: 0.3074, time:4.7349, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2200/3125], step: 24075, 8.249 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0711, batch_loss_s: 0.0779, time:4.8493, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2210/3125], step: 24085, 9.150 samples/sec, batch_loss: 0.3459, batch_loss_c: 0.3472, batch_loss_s: 0.3429, time:4.3716, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2220/3125], step: 24095, 8.371 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0968, batch_loss_s: 0.0684, time:4.7786, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:31:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2230/3125], step: 24105, 8.038 samples/sec, batch_loss: 0.3360, batch_loss_c: 0.3442, batch_loss_s: 0.3168, time:4.9765, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2240/3125], step: 24115, 8.492 samples/sec, batch_loss: 0.5256, batch_loss_c: 0.5233, batch_loss_s: 0.5310, time:4.7102, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2250/3125], step: 24125, 7.741 samples/sec, batch_loss: 0.3148, batch_loss_c: 0.3126, batch_loss_s: 0.3201, time:5.1673, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2260/3125], step: 24135, 8.315 samples/sec, batch_loss: 0.1710, batch_loss_c: 0.2081, batch_loss_s: 0.0845, time:4.8107, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2270/3125], step: 24145, 7.516 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1581, batch_loss_s: 0.1123, time:5.3222, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2280/3125], step: 24155, 8.636 samples/sec, batch_loss: 0.1224, batch_loss_c: 0.1197, batch_loss_s: 0.1287, time:4.6315, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2290/3125], step: 24165, 8.309 samples/sec, batch_loss: 0.1519, batch_loss_c: 0.1817, batch_loss_s: 0.0823, time:4.8143, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2300/3125], step: 24175, 7.667 samples/sec, batch_loss: 0.1330, batch_loss_c: 0.1644, batch_loss_s: 0.0598, time:5.2170, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2310/3125], step: 24185, 8.087 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0903, batch_loss_s: 0.1031, time:4.9464, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2320/3125], step: 24195, 8.276 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1040, batch_loss_s: 0.1100, time:4.8331, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2330/3125], step: 24205, 8.001 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.1162, batch_loss_s: 0.0507, time:4.9993, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2340/3125], step: 24215, 8.412 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0850, batch_loss_s: 0.0892, time:4.7554, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:32:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2350/3125], step: 24225, 8.035 samples/sec, batch_loss: 0.3761, batch_loss_c: 0.4097, batch_loss_s: 0.2977, time:4.9783, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2360/3125], step: 24235, 8.035 samples/sec, batch_loss: 0.3363, batch_loss_c: 0.3382, batch_loss_s: 0.3316, time:4.9781, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2370/3125], step: 24245, 8.831 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0799, batch_loss_s: 0.0840, time:4.5294, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2380/3125], step: 24255, 8.636 samples/sec, batch_loss: 0.3058, batch_loss_c: 0.2981, batch_loss_s: 0.3240, time:4.6317, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2390/3125], step: 24265, 7.930 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1138, batch_loss_s: 0.1310, time:5.0439, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2400/3125], step: 24275, 8.148 samples/sec, batch_loss: 0.2955, batch_loss_c: 0.2841, batch_loss_s: 0.3220, time:4.9093, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2410/3125], step: 24285, 8.606 samples/sec, batch_loss: 0.1352, batch_loss_c: 0.1315, batch_loss_s: 0.1439, time:4.6479, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2420/3125], step: 24295, 8.724 samples/sec, batch_loss: 0.1956, batch_loss_c: 0.2101, batch_loss_s: 0.1618, time:4.5849, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2430/3125], step: 24305, 8.395 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0883, batch_loss_s: 0.0888, time:4.7648, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2440/3125], step: 24315, 8.440 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0748, batch_loss_s: 0.0900, time:4.7393, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2450/3125], step: 24325, 8.377 samples/sec, batch_loss: 0.2160, batch_loss_c: 0.1826, batch_loss_s: 0.2939, time:4.7748, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2460/3125], step: 24335, 8.203 samples/sec, batch_loss: 0.1606, batch_loss_c: 0.1555, batch_loss_s: 0.1726, time:4.8761, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:33:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2470/3125], step: 24345, 8.537 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0990, batch_loss_s: 0.0803, time:4.6855, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2480/3125], step: 24355, 7.330 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0678, batch_loss_s: 0.0613, time:5.4568, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2490/3125], step: 24365, 8.907 samples/sec, batch_loss: 0.2106, batch_loss_c: 0.2625, batch_loss_s: 0.0894, time:4.4911, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2500/3125], step: 24375, 8.533 samples/sec, batch_loss: 0.5015, batch_loss_c: 0.5047, batch_loss_s: 0.4942, time:4.6879, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2510/3125], step: 24385, 8.231 samples/sec, batch_loss: 0.1060, batch_loss_c: 0.1121, batch_loss_s: 0.0919, time:4.8598, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2520/3125], step: 24395, 8.441 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0591, batch_loss_s: 0.0790, time:4.7386, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2530/3125], step: 24405, 8.270 samples/sec, batch_loss: 0.0630, batch_loss_c: 0.0585, batch_loss_s: 0.0736, time:4.8370, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2540/3125], step: 24415, 8.210 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1273, batch_loss_s: 0.0725, time:4.8722, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2550/3125], step: 24425, 8.718 samples/sec, batch_loss: 0.1331, batch_loss_c: 0.1574, batch_loss_s: 0.0765, time:4.5882, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2560/3125], step: 24435, 7.980 samples/sec, batch_loss: 0.1080, batch_loss_c: 0.1216, batch_loss_s: 0.0763, time:5.0122, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2570/3125], step: 24445, 8.686 samples/sec, batch_loss: 0.3155, batch_loss_c: 0.3154, batch_loss_s: 0.3155, time:4.6053, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2580/3125], step: 24455, 7.967 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0868, batch_loss_s: 0.0897, time:5.0207, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2590/3125], step: 24465, 8.395 samples/sec, batch_loss: 0.2037, batch_loss_c: 0.2496, batch_loss_s: 0.0964, time:4.7650, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:34:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2600/3125], step: 24475, 8.035 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.0980, batch_loss_s: 0.1166, time:4.9784, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2610/3125], step: 24485, 7.894 samples/sec, batch_loss: 0.5377, batch_loss_c: 0.5157, batch_loss_s: 0.5888, time:5.0669, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2620/3125], step: 24495, 7.706 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1007, batch_loss_s: 0.1117, time:5.1906, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2630/3125], step: 24505, 7.715 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.3087, batch_loss_s: 0.3038, time:5.1849, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2640/3125], step: 24515, 7.562 samples/sec, batch_loss: 0.1957, batch_loss_c: 0.2113, batch_loss_s: 0.1594, time:5.2895, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2650/3125], step: 24525, 8.256 samples/sec, batch_loss: 0.0511, batch_loss_c: 0.0470, batch_loss_s: 0.0609, time:4.8448, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2660/3125], step: 24535, 8.483 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1411, batch_loss_s: 0.0842, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2670/3125], step: 24545, 7.954 samples/sec, batch_loss: 0.1808, batch_loss_c: 0.1725, batch_loss_s: 0.2001, time:5.0292, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2680/3125], step: 24555, 7.589 samples/sec, batch_loss: 0.0602, batch_loss_c: 0.0555, batch_loss_s: 0.0713, time:5.2709, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2690/3125], step: 24565, 8.216 samples/sec, batch_loss: 0.3811, batch_loss_c: 0.3920, batch_loss_s: 0.3557, time:4.8686, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2700/3125], step: 24575, 8.412 samples/sec, batch_loss: 0.0859, batch_loss_c: 0.0818, batch_loss_s: 0.0955, time:4.7552, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2710/3125], step: 24585, 7.679 samples/sec, batch_loss: 0.2982, batch_loss_c: 0.2949, batch_loss_s: 0.3058, time:5.2089, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:35:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2720/3125], step: 24595, 7.856 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0593, batch_loss_s: 0.0746, time:5.0914, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2730/3125], step: 24605, 8.731 samples/sec, batch_loss: 0.3465, batch_loss_c: 0.3451, batch_loss_s: 0.3498, time:4.5811, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2740/3125], step: 24615, 7.846 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0794, batch_loss_s: 0.0738, time:5.0978, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2750/3125], step: 24625, 8.244 samples/sec, batch_loss: 0.0745, batch_loss_c: 0.0715, batch_loss_s: 0.0815, time:4.8517, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2760/3125], step: 24635, 8.137 samples/sec, batch_loss: 0.3234, batch_loss_c: 0.3222, batch_loss_s: 0.3262, time:4.9160, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2770/3125], step: 24645, 7.906 samples/sec, batch_loss: 0.2147, batch_loss_c: 0.2176, batch_loss_s: 0.2080, time:5.0594, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2780/3125], step: 24655, 8.262 samples/sec, batch_loss: 0.1217, batch_loss_c: 0.1357, batch_loss_s: 0.0889, time:4.8416, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2790/3125], step: 24665, 8.293 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1480, batch_loss_s: 0.0703, time:4.8233, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2800/3125], step: 24675, 7.770 samples/sec, batch_loss: 0.1499, batch_loss_c: 0.1661, batch_loss_s: 0.1120, time:5.1479, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2810/3125], step: 24685, 8.295 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1285, batch_loss_s: 0.1334, time:4.8220, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2820/3125], step: 24695, 8.260 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.1002, batch_loss_s: 0.0985, time:4.8427, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2830/3125], step: 24705, 7.859 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1166, batch_loss_s: 0.1095, time:5.0899, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:36:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2840/3125], step: 24715, 8.415 samples/sec, batch_loss: 0.1265, batch_loss_c: 0.1389, batch_loss_s: 0.0973, time:4.7533, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2850/3125], step: 24725, 7.998 samples/sec, batch_loss: 0.1103, batch_loss_c: 0.1055, batch_loss_s: 0.1214, time:5.0011, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2860/3125], step: 24735, 7.751 samples/sec, batch_loss: 0.3152, batch_loss_c: 0.3107, batch_loss_s: 0.3257, time:5.1609, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2870/3125], step: 24745, 8.462 samples/sec, batch_loss: 0.5443, batch_loss_c: 0.5451, batch_loss_s: 0.5426, time:4.7270, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2880/3125], step: 24755, 8.521 samples/sec, batch_loss: 0.0649, batch_loss_c: 0.0610, batch_loss_s: 0.0740, time:4.6944, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2890/3125], step: 24765, 8.491 samples/sec, batch_loss: 0.1717, batch_loss_c: 0.1565, batch_loss_s: 0.2072, time:4.7106, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2900/3125], step: 24775, 7.103 samples/sec, batch_loss: 0.2913, batch_loss_c: 0.2898, batch_loss_s: 0.2947, time:5.6313, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2910/3125], step: 24785, 7.720 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.0971, batch_loss_s: 0.1139, time:5.1814, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2920/3125], step: 24795, 8.357 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1173, batch_loss_s: 0.0850, time:4.7866, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2930/3125], step: 24805, 8.366 samples/sec, batch_loss: 0.0725, batch_loss_c: 0.0716, batch_loss_s: 0.0744, time:4.7812, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2940/3125], step: 24815, 7.410 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1327, batch_loss_s: 0.0794, time:5.3983, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2950/3125], step: 24825, 7.418 samples/sec, batch_loss: 0.2587, batch_loss_c: 0.3214, batch_loss_s: 0.1127, time:5.3924, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:37:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2960/3125], step: 24835, 7.588 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1421, batch_loss_s: 0.0758, time:5.2715, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2970/3125], step: 24845, 7.369 samples/sec, batch_loss: 0.1209, batch_loss_c: 0.1346, batch_loss_s: 0.0890, time:5.4279, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2980/3125], step: 24855, 8.686 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1076, batch_loss_s: 0.1305, time:4.6052, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2990/3125], step: 24865, 7.817 samples/sec, batch_loss: 0.0704, batch_loss_c: 0.0657, batch_loss_s: 0.0814, time:5.1171, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3000/3125], step: 24875, 7.620 samples/sec, batch_loss: 0.3317, batch_loss_c: 0.3329, batch_loss_s: 0.3289, time:5.2495, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3010/3125], step: 24885, 7.321 samples/sec, batch_loss: 0.1759, batch_loss_c: 0.1958, batch_loss_s: 0.1294, time:5.4639, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3020/3125], step: 24895, 8.263 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0674, batch_loss_s: 0.0848, time:4.8411, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3030/3125], step: 24905, 7.278 samples/sec, batch_loss: 0.1315, batch_loss_c: 0.1344, batch_loss_s: 0.1248, time:5.4962, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3040/3125], step: 24915, 7.955 samples/sec, batch_loss: 0.2322, batch_loss_c: 0.2245, batch_loss_s: 0.2504, time:5.0280, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3050/3125], step: 24925, 7.078 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0921, batch_loss_s: 0.1071, time:5.6512, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3060/3125], step: 24935, 7.027 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.0964, batch_loss_s: 0.1090, time:5.6926, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:38:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3070/3125], step: 24945, 7.751 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0779, batch_loss_s: 0.0675, time:5.1603, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3080/3125], step: 24955, 8.021 samples/sec, batch_loss: 0.3295, batch_loss_c: 0.3301, batch_loss_s: 0.3281, time:4.9869, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3090/3125], step: 24965, 7.673 samples/sec, batch_loss: 0.5007, batch_loss_c: 0.4910, batch_loss_s: 0.5232, time:5.2133, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3100/3125], step: 24975, 7.443 samples/sec, batch_loss: 0.0621, batch_loss_c: 0.0551, batch_loss_s: 0.0783, time:5.3744, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3110/3125], step: 24985, 10.320 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.0837, batch_loss_s: 0.2175, time:3.8761, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3120/3125], step: 24995, 10.166 samples/sec, batch_loss: 0.4035, batch_loss_c: 0.4342, batch_loss_s: 0.3319, time:3.9346, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], train_loss: 0.1798, time: 1567.6037, lr: 0.0001\u001b[0m\n",
            "2019-11-23 14:39:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [0/3125], step: 25000, 6.608 samples/sec, batch_loss: 0.2938, batch_loss_c: 0.3025, batch_loss_s: 0.2735, time:6.0534, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [10/3125], step: 25010, 6.553 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.0908, batch_loss_s: 0.1187, time:6.1036, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [20/3125], step: 25020, 8.860 samples/sec, batch_loss: 0.3593, batch_loss_c: 0.3558, batch_loss_s: 0.3673, time:4.5149, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [30/3125], step: 25030, 8.539 samples/sec, batch_loss: 0.3181, batch_loss_c: 0.3157, batch_loss_s: 0.3234, time:4.6842, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [40/3125], step: 25040, 9.334 samples/sec, batch_loss: 0.1679, batch_loss_c: 0.2058, batch_loss_s: 0.0794, time:4.2855, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [50/3125], step: 25050, 7.864 samples/sec, batch_loss: 0.1419, batch_loss_c: 0.1587, batch_loss_s: 0.1027, time:5.0862, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:39:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [60/3125], step: 25060, 7.398 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1069, batch_loss_s: 0.1032, time:5.4068, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [70/3125], step: 25070, 7.599 samples/sec, batch_loss: 0.1031, batch_loss_c: 0.0892, batch_loss_s: 0.1354, time:5.2642, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [80/3125], step: 25080, 8.377 samples/sec, batch_loss: 0.2391, batch_loss_c: 0.2094, batch_loss_s: 0.3085, time:4.7751, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [90/3125], step: 25090, 8.044 samples/sec, batch_loss: 0.2582, batch_loss_c: 0.2790, batch_loss_s: 0.2097, time:4.9725, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [100/3125], step: 25100, 7.817 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1470, batch_loss_s: 0.0577, time:5.1173, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [110/3125], step: 25110, 7.895 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0626, batch_loss_s: 0.0759, time:5.0665, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [120/3125], step: 25120, 7.459 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3273, batch_loss_s: 0.3044, time:5.3630, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [130/3125], step: 25130, 7.320 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.0951, batch_loss_s: 0.1074, time:5.4644, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [140/3125], step: 25140, 7.848 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0759, batch_loss_s: 0.0891, time:5.0971, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [150/3125], step: 25150, 8.366 samples/sec, batch_loss: 0.1983, batch_loss_c: 0.2215, batch_loss_s: 0.1441, time:4.7812, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [160/3125], step: 25160, 7.880 samples/sec, batch_loss: 0.2055, batch_loss_c: 0.2408, batch_loss_s: 0.1231, time:5.0760, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [170/3125], step: 25170, 7.698 samples/sec, batch_loss: 0.2638, batch_loss_c: 0.2446, batch_loss_s: 0.3084, time:5.1962, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:40:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [180/3125], step: 25180, 7.848 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1365, batch_loss_s: 0.1473, time:5.0971, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [190/3125], step: 25190, 8.605 samples/sec, batch_loss: 0.1269, batch_loss_c: 0.1230, batch_loss_s: 0.1361, time:4.6482, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [200/3125], step: 25200, 8.401 samples/sec, batch_loss: 0.2886, batch_loss_c: 0.2778, batch_loss_s: 0.3137, time:4.7612, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [210/3125], step: 25210, 7.952 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.1025, batch_loss_s: 0.0936, time:5.0302, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [220/3125], step: 25220, 7.970 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1261, batch_loss_s: 0.1192, time:5.0190, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [230/3125], step: 25230, 7.517 samples/sec, batch_loss: 0.1384, batch_loss_c: 0.1545, batch_loss_s: 0.1008, time:5.3216, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [240/3125], step: 25240, 7.866 samples/sec, batch_loss: 0.2903, batch_loss_c: 0.2845, batch_loss_s: 0.3040, time:5.0852, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [250/3125], step: 25250, 8.368 samples/sec, batch_loss: 0.2883, batch_loss_c: 0.2856, batch_loss_s: 0.2944, time:4.7803, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [260/3125], step: 25260, 7.818 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0785, batch_loss_s: 0.0973, time:5.1165, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [270/3125], step: 25270, 7.766 samples/sec, batch_loss: 0.2663, batch_loss_c: 0.2466, batch_loss_s: 0.3123, time:5.1503, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [280/3125], step: 25280, 9.003 samples/sec, batch_loss: 0.3163, batch_loss_c: 0.3137, batch_loss_s: 0.3225, time:4.4430, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [290/3125], step: 25290, 9.161 samples/sec, batch_loss: 0.0821, batch_loss_c: 0.0779, batch_loss_s: 0.0918, time:4.3661, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:41:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [300/3125], step: 25300, 8.146 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1802, batch_loss_s: 0.0988, time:4.9105, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [310/3125], step: 25310, 7.754 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0843, batch_loss_s: 0.0974, time:5.1583, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [320/3125], step: 25320, 8.801 samples/sec, batch_loss: 0.3170, batch_loss_c: 0.3221, batch_loss_s: 0.3051, time:4.5451, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [330/3125], step: 25330, 7.984 samples/sec, batch_loss: 0.0564, batch_loss_c: 0.0509, batch_loss_s: 0.0691, time:5.0101, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [340/3125], step: 25340, 7.759 samples/sec, batch_loss: 0.1460, batch_loss_c: 0.1562, batch_loss_s: 0.1222, time:5.1555, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [350/3125], step: 25350, 8.205 samples/sec, batch_loss: 0.3095, batch_loss_c: 0.3058, batch_loss_s: 0.3181, time:4.8751, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [360/3125], step: 25360, 6.948 samples/sec, batch_loss: 0.1658, batch_loss_c: 0.1734, batch_loss_s: 0.1482, time:5.7573, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [370/3125], step: 25370, 7.651 samples/sec, batch_loss: 0.1304, batch_loss_c: 0.1241, batch_loss_s: 0.1450, time:5.2281, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [380/3125], step: 25380, 8.589 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0708, batch_loss_s: 0.1026, time:4.6570, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [390/3125], step: 25390, 8.015 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.0981, batch_loss_s: 0.1069, time:4.9909, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [400/3125], step: 25400, 7.534 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1195, batch_loss_s: 0.1272, time:5.3092, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [410/3125], step: 25410, 8.307 samples/sec, batch_loss: 0.1792, batch_loss_c: 0.2016, batch_loss_s: 0.1271, time:4.8155, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:42:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [420/3125], step: 25420, 7.708 samples/sec, batch_loss: 0.0985, batch_loss_c: 0.1121, batch_loss_s: 0.0668, time:5.1895, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [430/3125], step: 25430, 7.659 samples/sec, batch_loss: 0.2461, batch_loss_c: 0.2208, batch_loss_s: 0.3050, time:5.2224, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [440/3125], step: 25440, 7.268 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0641, batch_loss_s: 0.1038, time:5.5034, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [450/3125], step: 25450, 8.027 samples/sec, batch_loss: 0.3919, batch_loss_c: 0.3889, batch_loss_s: 0.3989, time:4.9835, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [460/3125], step: 25460, 8.325 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1214, batch_loss_s: 0.1456, time:4.8048, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [470/3125], step: 25470, 7.877 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0928, batch_loss_s: 0.1074, time:5.0783, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [480/3125], step: 25480, 8.627 samples/sec, batch_loss: 0.2487, batch_loss_c: 0.2218, batch_loss_s: 0.3115, time:4.6369, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [490/3125], step: 25490, 8.008 samples/sec, batch_loss: 0.4283, batch_loss_c: 0.4354, batch_loss_s: 0.4116, time:4.9952, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [500/3125], step: 25500, 8.095 samples/sec, batch_loss: 0.0588, batch_loss_c: 0.0551, batch_loss_s: 0.0675, time:4.9411, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [510/3125], step: 25510, 8.456 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0905, batch_loss_s: 0.0694, time:4.7303, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [520/3125], step: 25520, 8.514 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.0987, batch_loss_s: 0.1066, time:4.6982, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [530/3125], step: 25530, 8.106 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.0988, batch_loss_s: 0.1156, time:4.9349, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:43:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [540/3125], step: 25540, 9.026 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.0991, batch_loss_s: 0.1081, time:4.4316, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [550/3125], step: 25550, 8.197 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1024, batch_loss_s: 0.1198, time:4.8796, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [560/3125], step: 25560, 7.370 samples/sec, batch_loss: 0.0842, batch_loss_c: 0.0831, batch_loss_s: 0.0867, time:5.4273, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [570/3125], step: 25570, 7.980 samples/sec, batch_loss: 0.1955, batch_loss_c: 0.2252, batch_loss_s: 0.1264, time:5.0127, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [580/3125], step: 25580, 8.656 samples/sec, batch_loss: 0.1066, batch_loss_c: 0.1086, batch_loss_s: 0.1019, time:4.6211, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [590/3125], step: 25590, 7.875 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0791, batch_loss_s: 0.0843, time:5.0791, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [600/3125], step: 25600, 7.907 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0796, batch_loss_s: 0.0831, time:5.0587, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [610/3125], step: 25610, 8.056 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0846, batch_loss_s: 0.1016, time:4.9654, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [620/3125], step: 25620, 9.253 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1190, batch_loss_s: 0.1009, time:4.3228, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [630/3125], step: 25630, 8.362 samples/sec, batch_loss: 0.1917, batch_loss_c: 0.2072, batch_loss_s: 0.1556, time:4.7834, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [640/3125], step: 25640, 8.052 samples/sec, batch_loss: 0.1599, batch_loss_c: 0.1780, batch_loss_s: 0.1176, time:4.9680, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [650/3125], step: 25650, 7.659 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1079, batch_loss_s: 0.1177, time:5.2229, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:44:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [660/3125], step: 25660, 7.917 samples/sec, batch_loss: 0.2917, batch_loss_c: 0.2886, batch_loss_s: 0.2987, time:5.0521, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [670/3125], step: 25670, 8.338 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0753, batch_loss_s: 0.0829, time:4.7975, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:06 \u001b[32mINFO     \u001b[0m train.py: [8/10], [680/3125], step: 25680, 8.557 samples/sec, batch_loss: 0.3026, batch_loss_c: 0.2978, batch_loss_s: 0.3139, time:4.6744, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:11 \u001b[32mINFO     \u001b[0m train.py: [8/10], [690/3125], step: 25690, 7.961 samples/sec, batch_loss: 0.0532, batch_loss_c: 0.0484, batch_loss_s: 0.0645, time:5.0244, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [700/3125], step: 25700, 8.318 samples/sec, batch_loss: 0.1117, batch_loss_c: 0.1316, batch_loss_s: 0.0653, time:4.8090, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [710/3125], step: 25710, 8.002 samples/sec, batch_loss: 0.1386, batch_loss_c: 0.1426, batch_loss_s: 0.1294, time:4.9988, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [720/3125], step: 25720, 8.311 samples/sec, batch_loss: 0.1464, batch_loss_c: 0.1547, batch_loss_s: 0.1270, time:4.8130, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [730/3125], step: 25730, 7.819 samples/sec, batch_loss: 0.0606, batch_loss_c: 0.0570, batch_loss_s: 0.0692, time:5.1158, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [740/3125], step: 25740, 7.900 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0759, batch_loss_s: 0.0765, time:5.0632, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [750/3125], step: 25750, 7.437 samples/sec, batch_loss: 0.1793, batch_loss_c: 0.1641, batch_loss_s: 0.2146, time:5.3788, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [760/3125], step: 25760, 7.847 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1315, batch_loss_s: 0.1158, time:5.0974, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [770/3125], step: 25770, 7.686 samples/sec, batch_loss: 0.3275, batch_loss_c: 0.3232, batch_loss_s: 0.3376, time:5.2041, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:45:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [780/3125], step: 25780, 8.474 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.0998, batch_loss_s: 0.0999, time:4.7203, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [790/3125], step: 25790, 8.429 samples/sec, batch_loss: 0.1162, batch_loss_c: 0.0924, batch_loss_s: 0.1718, time:4.7455, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:06 \u001b[32mINFO     \u001b[0m train.py: [8/10], [800/3125], step: 25800, 7.553 samples/sec, batch_loss: 0.1644, batch_loss_c: 0.1745, batch_loss_s: 0.1408, time:5.2958, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:11 \u001b[32mINFO     \u001b[0m train.py: [8/10], [810/3125], step: 25810, 7.797 samples/sec, batch_loss: 0.2180, batch_loss_c: 0.2281, batch_loss_s: 0.1945, time:5.1301, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [820/3125], step: 25820, 7.933 samples/sec, batch_loss: 0.2992, batch_loss_c: 0.2951, batch_loss_s: 0.3089, time:5.0425, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [830/3125], step: 25830, 7.297 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0611, batch_loss_s: 0.0743, time:5.4818, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [840/3125], step: 25840, 8.167 samples/sec, batch_loss: 0.3352, batch_loss_c: 0.3415, batch_loss_s: 0.3206, time:4.8980, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [850/3125], step: 25850, 7.573 samples/sec, batch_loss: 0.3501, batch_loss_c: 0.3577, batch_loss_s: 0.3325, time:5.2819, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [860/3125], step: 25860, 7.574 samples/sec, batch_loss: 0.1529, batch_loss_c: 0.1760, batch_loss_s: 0.0990, time:5.2811, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [870/3125], step: 25870, 8.133 samples/sec, batch_loss: 0.3125, batch_loss_c: 0.3067, batch_loss_s: 0.3261, time:4.9184, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [880/3125], step: 25880, 7.439 samples/sec, batch_loss: 0.1514, batch_loss_c: 0.1841, batch_loss_s: 0.0752, time:5.3769, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [890/3125], step: 25890, 8.158 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0869, batch_loss_s: 0.0951, time:4.9032, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:46:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [900/3125], step: 25900, 7.505 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1087, batch_loss_s: 0.1099, time:5.3300, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [910/3125], step: 25910, 8.336 samples/sec, batch_loss: 0.0834, batch_loss_c: 0.0798, batch_loss_s: 0.0919, time:4.7986, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [920/3125], step: 25920, 7.529 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.0972, batch_loss_s: 0.1139, time:5.3126, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [930/3125], step: 25930, 8.530 samples/sec, batch_loss: 0.0668, batch_loss_c: 0.0622, batch_loss_s: 0.0777, time:4.6893, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [940/3125], step: 25940, 7.678 samples/sec, batch_loss: 0.3217, batch_loss_c: 0.3305, batch_loss_s: 0.3011, time:5.2099, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [950/3125], step: 25950, 7.941 samples/sec, batch_loss: 0.0588, batch_loss_c: 0.0550, batch_loss_s: 0.0677, time:5.0374, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [960/3125], step: 25960, 7.569 samples/sec, batch_loss: 0.0616, batch_loss_c: 0.0534, batch_loss_s: 0.0807, time:5.2846, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [970/3125], step: 25970, 7.601 samples/sec, batch_loss: 0.1647, batch_loss_c: 0.1891, batch_loss_s: 0.1077, time:5.2623, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [980/3125], step: 25980, 8.350 samples/sec, batch_loss: 0.2057, batch_loss_c: 0.2404, batch_loss_s: 0.1246, time:4.7902, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [990/3125], step: 25990, 7.677 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0742, batch_loss_s: 0.0866, time:5.2101, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1000/3125], step: 26000, 8.159 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0772, batch_loss_s: 0.0853, time:4.9025, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1010/3125], step: 26010, 7.704 samples/sec, batch_loss: 0.2853, batch_loss_c: 0.2809, batch_loss_s: 0.2957, time:5.1919, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:47:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1020/3125], step: 26020, 7.780 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1090, batch_loss_s: 0.0973, time:5.1411, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1030/3125], step: 26030, 7.718 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2891, batch_loss_s: 0.3001, time:5.1827, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1040/3125], step: 26040, 7.928 samples/sec, batch_loss: 0.2123, batch_loss_c: 0.2338, batch_loss_s: 0.1623, time:5.0455, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1050/3125], step: 26050, 8.077 samples/sec, batch_loss: 0.3148, batch_loss_c: 0.3105, batch_loss_s: 0.3247, time:4.9520, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1060/3125], step: 26060, 8.516 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0850, batch_loss_s: 0.0707, time:4.6970, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1070/3125], step: 26070, 6.926 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1058, batch_loss_s: 0.0858, time:5.7756, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1080/3125], step: 26080, 8.658 samples/sec, batch_loss: 0.2932, batch_loss_c: 0.2900, batch_loss_s: 0.3007, time:4.6202, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1090/3125], step: 26090, 8.411 samples/sec, batch_loss: 0.3372, batch_loss_c: 0.3347, batch_loss_s: 0.3431, time:4.7559, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1100/3125], step: 26100, 8.688 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0588, batch_loss_s: 0.0563, time:4.6043, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1110/3125], step: 26110, 7.330 samples/sec, batch_loss: 0.5881, batch_loss_c: 0.6134, batch_loss_s: 0.5291, time:5.4569, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1120/3125], step: 26120, 7.671 samples/sec, batch_loss: 0.1760, batch_loss_c: 0.1709, batch_loss_s: 0.1880, time:5.2148, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1130/3125], step: 26130, 8.036 samples/sec, batch_loss: 0.3129, batch_loss_c: 0.3048, batch_loss_s: 0.3317, time:4.9776, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:48:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1140/3125], step: 26140, 7.742 samples/sec, batch_loss: 0.3589, batch_loss_c: 0.3751, batch_loss_s: 0.3213, time:5.1668, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1150/3125], step: 26150, 8.112 samples/sec, batch_loss: 0.3118, batch_loss_c: 0.3102, batch_loss_s: 0.3155, time:4.9308, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1160/3125], step: 26160, 8.094 samples/sec, batch_loss: 0.3220, batch_loss_c: 0.3259, batch_loss_s: 0.3128, time:4.9421, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1170/3125], step: 26170, 7.745 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0869, batch_loss_s: 0.0982, time:5.1648, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1180/3125], step: 26180, 7.987 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0765, batch_loss_s: 0.0904, time:5.0079, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1190/3125], step: 26190, 7.450 samples/sec, batch_loss: 0.4029, batch_loss_c: 0.4018, batch_loss_s: 0.4055, time:5.3691, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1200/3125], step: 26200, 7.779 samples/sec, batch_loss: 0.1279, batch_loss_c: 0.1396, batch_loss_s: 0.1005, time:5.1422, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1210/3125], step: 26210, 8.199 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1549, batch_loss_s: 0.0796, time:4.8784, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1220/3125], step: 26220, 8.053 samples/sec, batch_loss: 0.1844, batch_loss_c: 0.2299, batch_loss_s: 0.0782, time:4.9671, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1230/3125], step: 26230, 8.602 samples/sec, batch_loss: 0.1820, batch_loss_c: 0.2071, batch_loss_s: 0.1233, time:4.6499, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1240/3125], step: 26240, 8.346 samples/sec, batch_loss: 0.3105, batch_loss_c: 0.3129, batch_loss_s: 0.3050, time:4.7927, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1250/3125], step: 26250, 7.900 samples/sec, batch_loss: 0.3944, batch_loss_c: 0.4201, batch_loss_s: 0.3344, time:5.0630, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:49:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1260/3125], step: 26260, 8.474 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0778, batch_loss_s: 0.0571, time:4.7203, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1270/3125], step: 26270, 8.427 samples/sec, batch_loss: 0.1828, batch_loss_c: 0.2084, batch_loss_s: 0.1230, time:4.7465, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1280/3125], step: 26280, 8.022 samples/sec, batch_loss: 0.1123, batch_loss_c: 0.1195, batch_loss_s: 0.0955, time:4.9861, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1290/3125], step: 26290, 7.414 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1072, batch_loss_s: 0.0995, time:5.3952, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1300/3125], step: 26300, 8.111 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0704, batch_loss_s: 0.0667, time:4.9315, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1310/3125], step: 26310, 8.328 samples/sec, batch_loss: 0.3741, batch_loss_c: 0.4007, batch_loss_s: 0.3122, time:4.8028, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1320/3125], step: 26320, 6.954 samples/sec, batch_loss: 0.3014, batch_loss_c: 0.2980, batch_loss_s: 0.3094, time:5.7520, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1330/3125], step: 26330, 8.365 samples/sec, batch_loss: 0.1266, batch_loss_c: 0.1476, batch_loss_s: 0.0777, time:4.7818, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1340/3125], step: 26340, 8.027 samples/sec, batch_loss: 0.3284, batch_loss_c: 0.3287, batch_loss_s: 0.3276, time:4.9833, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1350/3125], step: 26350, 7.997 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0852, batch_loss_s: 0.1105, time:5.0017, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1360/3125], step: 26360, 8.401 samples/sec, batch_loss: 0.2992, batch_loss_c: 0.2959, batch_loss_s: 0.3069, time:4.7612, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1370/3125], step: 26370, 7.980 samples/sec, batch_loss: 0.0893, batch_loss_c: 0.0904, batch_loss_s: 0.0869, time:5.0126, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:50:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1380/3125], step: 26380, 8.181 samples/sec, batch_loss: 0.1588, batch_loss_c: 0.1835, batch_loss_s: 0.1012, time:4.8891, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1390/3125], step: 26390, 7.795 samples/sec, batch_loss: 0.1293, batch_loss_c: 0.1364, batch_loss_s: 0.1126, time:5.1317, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1400/3125], step: 26400, 8.606 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0902, batch_loss_s: 0.1040, time:4.6480, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1410/3125], step: 26410, 8.021 samples/sec, batch_loss: 0.3599, batch_loss_c: 0.3698, batch_loss_s: 0.3368, time:4.9867, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1420/3125], step: 26420, 7.709 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1143, batch_loss_s: 0.0905, time:5.1884, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1430/3125], step: 26430, 8.272 samples/sec, batch_loss: 0.0495, batch_loss_c: 0.0482, batch_loss_s: 0.0527, time:4.8356, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1440/3125], step: 26440, 7.422 samples/sec, batch_loss: 0.5188, batch_loss_c: 0.5080, batch_loss_s: 0.5439, time:5.3894, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1450/3125], step: 26450, 7.798 samples/sec, batch_loss: 0.3042, batch_loss_c: 0.3038, batch_loss_s: 0.3053, time:5.1298, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1460/3125], step: 26460, 8.452 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1052, batch_loss_s: 0.1035, time:4.7328, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1470/3125], step: 26470, 7.940 samples/sec, batch_loss: 0.2883, batch_loss_c: 0.2750, batch_loss_s: 0.3192, time:5.0380, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1480/3125], step: 26480, 8.105 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0910, batch_loss_s: 0.1020, time:4.9350, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1490/3125], step: 26490, 8.273 samples/sec, batch_loss: 0.1106, batch_loss_c: 0.1156, batch_loss_s: 0.0989, time:4.8351, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:51:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1500/3125], step: 26500, 8.814 samples/sec, batch_loss: 0.1299, batch_loss_c: 0.1092, batch_loss_s: 0.1780, time:4.5383, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1510/3125], step: 26510, 7.775 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1074, batch_loss_s: 0.0973, time:5.1448, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1520/3125], step: 26520, 8.348 samples/sec, batch_loss: 0.0603, batch_loss_c: 0.0568, batch_loss_s: 0.0684, time:4.7917, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1530/3125], step: 26530, 8.576 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1307, batch_loss_s: 0.1107, time:4.6642, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1540/3125], step: 26540, 8.357 samples/sec, batch_loss: 0.1037, batch_loss_c: 0.1020, batch_loss_s: 0.1077, time:4.7866, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1550/3125], step: 26550, 7.622 samples/sec, batch_loss: 0.3604, batch_loss_c: 0.3733, batch_loss_s: 0.3304, time:5.2477, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1560/3125], step: 26560, 7.994 samples/sec, batch_loss: 0.1600, batch_loss_c: 0.1859, batch_loss_s: 0.0995, time:5.0040, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1570/3125], step: 26570, 7.949 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.2919, batch_loss_s: 0.3325, time:5.0324, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1580/3125], step: 26580, 7.849 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.1022, batch_loss_s: 0.0928, time:5.0962, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1590/3125], step: 26590, 7.774 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0709, batch_loss_s: 0.0706, time:5.1451, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1600/3125], step: 26600, 7.607 samples/sec, batch_loss: 0.2705, batch_loss_c: 0.2621, batch_loss_s: 0.2900, time:5.2585, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1610/3125], step: 26610, 8.317 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.0978, batch_loss_s: 0.0949, time:4.8094, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:52:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1620/3125], step: 26620, 8.145 samples/sec, batch_loss: 0.0661, batch_loss_c: 0.0624, batch_loss_s: 0.0746, time:4.9109, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1630/3125], step: 26630, 7.638 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0936, batch_loss_s: 0.1021, time:5.2368, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1640/3125], step: 26640, 7.337 samples/sec, batch_loss: 0.1004, batch_loss_c: 0.1015, batch_loss_s: 0.0978, time:5.4516, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1650/3125], step: 26650, 7.292 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2937, batch_loss_s: 0.3055, time:5.4852, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1660/3125], step: 26660, 7.851 samples/sec, batch_loss: 0.2997, batch_loss_c: 0.2965, batch_loss_s: 0.3071, time:5.0952, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1670/3125], step: 26670, 7.554 samples/sec, batch_loss: 0.0813, batch_loss_c: 0.0801, batch_loss_s: 0.0840, time:5.2954, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1680/3125], step: 26680, 6.849 samples/sec, batch_loss: 0.1173, batch_loss_c: 0.1176, batch_loss_s: 0.1165, time:5.8400, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1690/3125], step: 26690, 6.870 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.3033, batch_loss_s: 0.3058, time:5.8225, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1700/3125], step: 26700, 8.274 samples/sec, batch_loss: 0.3155, batch_loss_c: 0.3159, batch_loss_s: 0.3146, time:4.8342, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1710/3125], step: 26710, 7.355 samples/sec, batch_loss: 0.3305, batch_loss_c: 0.3126, batch_loss_s: 0.3725, time:5.4387, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1720/3125], step: 26720, 7.785 samples/sec, batch_loss: 0.3094, batch_loss_c: 0.3094, batch_loss_s: 0.3096, time:5.1378, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:53:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1730/3125], step: 26730, 7.416 samples/sec, batch_loss: 0.1410, batch_loss_c: 0.1462, batch_loss_s: 0.1289, time:5.3934, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1740/3125], step: 26740, 7.653 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3291, batch_loss_s: 0.3149, time:5.2265, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1750/3125], step: 26750, 8.001 samples/sec, batch_loss: 0.2967, batch_loss_c: 0.2951, batch_loss_s: 0.3002, time:4.9995, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1760/3125], step: 26760, 8.238 samples/sec, batch_loss: 0.1908, batch_loss_c: 0.1947, batch_loss_s: 0.1815, time:4.8558, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1770/3125], step: 26770, 7.535 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1565, batch_loss_s: 0.1142, time:5.3083, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1780/3125], step: 26780, 7.489 samples/sec, batch_loss: 0.4917, batch_loss_c: 0.4756, batch_loss_s: 0.5293, time:5.3409, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1790/3125], step: 26790, 8.274 samples/sec, batch_loss: 0.1890, batch_loss_c: 0.1843, batch_loss_s: 0.2001, time:4.8345, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1800/3125], step: 26800, 7.542 samples/sec, batch_loss: 0.3354, batch_loss_c: 0.3485, batch_loss_s: 0.3051, time:5.3039, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1810/3125], step: 26810, 8.865 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1176, batch_loss_s: 0.0902, time:4.5119, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1820/3125], step: 26820, 8.051 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0836, batch_loss_s: 0.0926, time:4.9684, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1830/3125], step: 26830, 7.674 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1593, batch_loss_s: 0.0915, time:5.2125, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1840/3125], step: 26840, 8.252 samples/sec, batch_loss: 0.1107, batch_loss_c: 0.1079, batch_loss_s: 0.1172, time:4.8472, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:54:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1850/3125], step: 26850, 8.248 samples/sec, batch_loss: 0.1357, batch_loss_c: 0.1299, batch_loss_s: 0.1492, time:4.8496, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1860/3125], step: 26860, 8.185 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1468, batch_loss_s: 0.1128, time:4.8873, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1870/3125], step: 26870, 7.865 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0880, batch_loss_s: 0.0901, time:5.0855, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1880/3125], step: 26880, 7.843 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1193, batch_loss_s: 0.1041, time:5.0999, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1890/3125], step: 26890, 8.027 samples/sec, batch_loss: 0.2755, batch_loss_c: 0.2560, batch_loss_s: 0.3210, time:4.9829, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1900/3125], step: 26900, 8.513 samples/sec, batch_loss: 0.4102, batch_loss_c: 0.4206, batch_loss_s: 0.3860, time:4.6985, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1910/3125], step: 26910, 8.752 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0813, batch_loss_s: 0.0904, time:4.5704, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1920/3125], step: 26920, 8.695 samples/sec, batch_loss: 0.4023, batch_loss_c: 0.4062, batch_loss_s: 0.3932, time:4.6005, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1930/3125], step: 26930, 8.233 samples/sec, batch_loss: 0.2005, batch_loss_c: 0.1971, batch_loss_s: 0.2087, time:4.8588, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1940/3125], step: 26940, 8.256 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0871, batch_loss_s: 0.0790, time:4.8449, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1950/3125], step: 26950, 8.229 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0903, batch_loss_s: 0.0864, time:4.8607, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1960/3125], step: 26960, 7.980 samples/sec, batch_loss: 0.3345, batch_loss_c: 0.3396, batch_loss_s: 0.3226, time:5.0123, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:55:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1970/3125], step: 26970, 7.370 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0899, batch_loss_s: 0.0983, time:5.4276, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1980/3125], step: 26980, 7.815 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0788, batch_loss_s: 0.0682, time:5.1186, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1990/3125], step: 26990, 7.320 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0824, batch_loss_s: 0.0887, time:5.4647, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2000/3125], step: 27000, 8.420 samples/sec, batch_loss: 0.5034, batch_loss_c: 0.4891, batch_loss_s: 0.5370, time:4.7507, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2010/3125], step: 27010, 7.880 samples/sec, batch_loss: 0.4548, batch_loss_c: 0.4940, batch_loss_s: 0.3634, time:5.0764, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2020/3125], step: 27020, 7.689 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0815, batch_loss_s: 0.0679, time:5.2019, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2030/3125], step: 27030, 7.983 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.1029, batch_loss_s: 0.0995, time:5.0106, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2040/3125], step: 27040, 7.645 samples/sec, batch_loss: 0.1302, batch_loss_c: 0.1357, batch_loss_s: 0.1174, time:5.2321, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2050/3125], step: 27050, 7.796 samples/sec, batch_loss: 0.2052, batch_loss_c: 0.2166, batch_loss_s: 0.1786, time:5.1307, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2060/3125], step: 27060, 8.238 samples/sec, batch_loss: 0.1467, batch_loss_c: 0.1683, batch_loss_s: 0.0963, time:4.8558, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2070/3125], step: 27070, 7.757 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3413, batch_loss_s: 0.3314, time:5.1566, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2080/3125], step: 27080, 8.164 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0671, batch_loss_s: 0.0591, time:4.8994, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:56:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2090/3125], step: 27090, 8.285 samples/sec, batch_loss: 0.1263, batch_loss_c: 0.1361, batch_loss_s: 0.1033, time:4.8280, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2100/3125], step: 27100, 8.323 samples/sec, batch_loss: 0.0526, batch_loss_c: 0.0484, batch_loss_s: 0.0624, time:4.8061, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2110/3125], step: 27110, 7.826 samples/sec, batch_loss: 0.0963, batch_loss_c: 0.0873, batch_loss_s: 0.1175, time:5.1112, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:11 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2120/3125], step: 27120, 8.752 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0856, batch_loss_s: 0.1008, time:4.5704, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2130/3125], step: 27130, 8.624 samples/sec, batch_loss: 0.2933, batch_loss_c: 0.2645, batch_loss_s: 0.3606, time:4.6382, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2140/3125], step: 27140, 8.650 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1374, batch_loss_s: 0.1204, time:4.6242, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2150/3125], step: 27150, 7.527 samples/sec, batch_loss: 0.0681, batch_loss_c: 0.0656, batch_loss_s: 0.0738, time:5.3144, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2160/3125], step: 27160, 8.196 samples/sec, batch_loss: 0.0810, batch_loss_c: 0.0775, batch_loss_s: 0.0890, time:4.8801, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2170/3125], step: 27170, 8.581 samples/sec, batch_loss: 0.1583, batch_loss_c: 0.1319, batch_loss_s: 0.2199, time:4.6612, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2180/3125], step: 27180, 8.549 samples/sec, batch_loss: 0.3143, batch_loss_c: 0.3173, batch_loss_s: 0.3072, time:4.6787, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2190/3125], step: 27190, 7.790 samples/sec, batch_loss: 0.2751, batch_loss_c: 0.2608, batch_loss_s: 0.3084, time:5.1347, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2200/3125], step: 27200, 7.857 samples/sec, batch_loss: 0.2856, batch_loss_c: 0.2668, batch_loss_s: 0.3296, time:5.0912, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:57:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2210/3125], step: 27210, 7.657 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0978, batch_loss_s: 0.0553, time:5.2241, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2220/3125], step: 27220, 7.758 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.1004, batch_loss_s: 0.0839, time:5.1562, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:06 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2230/3125], step: 27230, 8.487 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0736, batch_loss_s: 0.0893, time:4.7129, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2240/3125], step: 27240, 8.347 samples/sec, batch_loss: 0.2874, batch_loss_c: 0.2840, batch_loss_s: 0.2952, time:4.7919, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2250/3125], step: 27250, 7.362 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0931, batch_loss_s: 0.0813, time:5.4333, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2260/3125], step: 27260, 8.301 samples/sec, batch_loss: 0.0642, batch_loss_c: 0.0591, batch_loss_s: 0.0759, time:4.8188, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2270/3125], step: 27270, 7.401 samples/sec, batch_loss: 0.1530, batch_loss_c: 0.1643, batch_loss_s: 0.1268, time:5.4045, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2280/3125], step: 27280, 8.109 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1141, batch_loss_s: 0.1114, time:4.9327, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2290/3125], step: 27290, 8.493 samples/sec, batch_loss: 0.3255, batch_loss_c: 0.3175, batch_loss_s: 0.3443, time:4.7095, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2300/3125], step: 27300, 7.794 samples/sec, batch_loss: 0.0608, batch_loss_c: 0.0588, batch_loss_s: 0.0655, time:5.1320, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2310/3125], step: 27310, 8.414 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1179, batch_loss_s: 0.1237, time:4.7540, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2320/3125], step: 27320, 8.092 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.1026, batch_loss_s: 0.0869, time:4.9430, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:58:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2330/3125], step: 27330, 7.964 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3241, batch_loss_s: 0.3032, time:5.0226, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:00 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2340/3125], step: 27340, 8.755 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1174, batch_loss_s: 0.1137, time:4.5687, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2350/3125], step: 27350, 8.010 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1152, batch_loss_s: 0.1113, time:4.9935, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2360/3125], step: 27360, 8.067 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0700, batch_loss_s: 0.0757, time:4.9584, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2370/3125], step: 27370, 7.638 samples/sec, batch_loss: 0.3097, batch_loss_c: 0.3103, batch_loss_s: 0.3082, time:5.2372, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2380/3125], step: 27380, 7.713 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1155, batch_loss_s: 0.0989, time:5.1858, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2390/3125], step: 27390, 8.195 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0737, batch_loss_s: 0.0834, time:4.8810, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2400/3125], step: 27400, 8.310 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0836, batch_loss_s: 0.0803, time:4.8134, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:35 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2410/3125], step: 27410, 8.108 samples/sec, batch_loss: 0.0734, batch_loss_c: 0.0673, batch_loss_s: 0.0877, time:4.9334, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2420/3125], step: 27420, 8.340 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0913, batch_loss_s: 0.0897, time:4.7960, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2430/3125], step: 27430, 8.593 samples/sec, batch_loss: 0.1089, batch_loss_c: 0.1133, batch_loss_s: 0.0985, time:4.6548, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2440/3125], step: 27440, 9.086 samples/sec, batch_loss: 0.1043, batch_loss_c: 0.1051, batch_loss_s: 0.1024, time:4.4023, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2450/3125], step: 27450, 8.571 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1168, batch_loss_s: 0.0899, time:4.6670, lr:0.0001\u001b[0m\n",
            "2019-11-23 14:59:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2460/3125], step: 27460, 8.799 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.0994, batch_loss_s: 0.1066, time:4.5461, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2470/3125], step: 27470, 8.333 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0823, batch_loss_s: 0.0753, time:4.8005, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2480/3125], step: 27480, 8.169 samples/sec, batch_loss: 0.1285, batch_loss_c: 0.1263, batch_loss_s: 0.1335, time:4.8966, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2490/3125], step: 27490, 8.079 samples/sec, batch_loss: 0.3759, batch_loss_c: 0.3801, batch_loss_s: 0.3662, time:4.9509, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2500/3125], step: 27500, 7.646 samples/sec, batch_loss: 0.1839, batch_loss_c: 0.2058, batch_loss_s: 0.1329, time:5.2318, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2510/3125], step: 27510, 9.106 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.1032, batch_loss_s: 0.0915, time:4.3926, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2520/3125], step: 27520, 7.947 samples/sec, batch_loss: 0.4810, batch_loss_c: 0.4617, batch_loss_s: 0.5258, time:5.0335, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2530/3125], step: 27530, 8.113 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0937, batch_loss_s: 0.0843, time:4.9305, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2540/3125], step: 27540, 8.183 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0771, batch_loss_s: 0.0812, time:4.8884, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2550/3125], step: 27550, 8.077 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0781, batch_loss_s: 0.0858, time:4.9522, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2560/3125], step: 27560, 7.853 samples/sec, batch_loss: 0.1329, batch_loss_c: 0.1513, batch_loss_s: 0.0901, time:5.0937, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2570/3125], step: 27570, 8.390 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0931, batch_loss_s: 0.0830, time:4.7674, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:00:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2580/3125], step: 27580, 8.235 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0707, batch_loss_s: 0.0899, time:4.8572, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2590/3125], step: 27590, 9.082 samples/sec, batch_loss: 0.1753, batch_loss_c: 0.2127, batch_loss_s: 0.0879, time:4.4041, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2600/3125], step: 27600, 7.504 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0707, batch_loss_s: 0.0780, time:5.3302, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:11 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2610/3125], step: 27610, 8.716 samples/sec, batch_loss: 0.2958, batch_loss_c: 0.2885, batch_loss_s: 0.3128, time:4.5894, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2620/3125], step: 27620, 8.343 samples/sec, batch_loss: 0.0678, batch_loss_c: 0.0619, batch_loss_s: 0.0814, time:4.7942, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2630/3125], step: 27630, 8.450 samples/sec, batch_loss: 0.3067, batch_loss_c: 0.2993, batch_loss_s: 0.3240, time:4.7336, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2640/3125], step: 27640, 8.289 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0995, batch_loss_s: 0.1015, time:4.8257, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2650/3125], step: 27650, 7.456 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0794, batch_loss_s: 0.0780, time:5.3647, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2660/3125], step: 27660, 8.100 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0934, batch_loss_s: 0.0977, time:4.9382, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2670/3125], step: 27670, 7.794 samples/sec, batch_loss: 0.0752, batch_loss_c: 0.0737, batch_loss_s: 0.0785, time:5.1321, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2680/3125], step: 27680, 8.041 samples/sec, batch_loss: 0.3083, batch_loss_c: 0.3107, batch_loss_s: 0.3026, time:4.9745, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2690/3125], step: 27690, 7.516 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0872, batch_loss_s: 0.0875, time:5.3219, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:01:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2700/3125], step: 27700, 7.870 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0870, batch_loss_s: 0.0663, time:5.0825, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2710/3125], step: 27710, 7.968 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0884, batch_loss_s: 0.0925, time:5.0202, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2720/3125], step: 27720, 7.660 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0806, batch_loss_s: 0.0755, time:5.2221, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2730/3125], step: 27730, 7.203 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0824, batch_loss_s: 0.0874, time:5.5535, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2740/3125], step: 27740, 8.202 samples/sec, batch_loss: 0.0700, batch_loss_c: 0.0666, batch_loss_s: 0.0781, time:4.8769, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2750/3125], step: 27750, 8.154 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0703, batch_loss_s: 0.0855, time:4.9056, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2760/3125], step: 27760, 7.847 samples/sec, batch_loss: 0.0631, batch_loss_c: 0.0567, batch_loss_s: 0.0780, time:5.0974, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2770/3125], step: 27770, 8.184 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1067, batch_loss_s: 0.1092, time:4.8874, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2780/3125], step: 27780, 7.864 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0730, batch_loss_s: 0.0785, time:5.0867, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2790/3125], step: 27790, 7.483 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.1015, batch_loss_s: 0.0683, time:5.3458, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2800/3125], step: 27800, 8.046 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0875, batch_loss_s: 0.1024, time:4.9712, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2810/3125], step: 27810, 8.122 samples/sec, batch_loss: 0.3550, batch_loss_c: 0.3705, batch_loss_s: 0.3188, time:4.9250, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:02:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2820/3125], step: 27820, 7.480 samples/sec, batch_loss: 0.2649, batch_loss_c: 0.2612, batch_loss_s: 0.2736, time:5.3478, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2830/3125], step: 27830, 8.691 samples/sec, batch_loss: 0.0820, batch_loss_c: 0.0819, batch_loss_s: 0.0822, time:4.6024, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2840/3125], step: 27840, 7.698 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0797, batch_loss_s: 0.0906, time:5.1962, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2850/3125], step: 27850, 7.975 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.1049, batch_loss_s: 0.0922, time:5.0158, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2860/3125], step: 27860, 8.398 samples/sec, batch_loss: 0.0570, batch_loss_c: 0.0553, batch_loss_s: 0.0608, time:4.7631, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2870/3125], step: 27870, 8.148 samples/sec, batch_loss: 0.0624, batch_loss_c: 0.0670, batch_loss_s: 0.0516, time:4.9091, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2880/3125], step: 27880, 7.784 samples/sec, batch_loss: 0.0846, batch_loss_c: 0.0849, batch_loss_s: 0.0837, time:5.1384, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2890/3125], step: 27890, 7.575 samples/sec, batch_loss: 0.1189, batch_loss_c: 0.1227, batch_loss_s: 0.1099, time:5.2808, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2900/3125], step: 27900, 7.855 samples/sec, batch_loss: 0.1130, batch_loss_c: 0.1115, batch_loss_s: 0.1163, time:5.0923, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2910/3125], step: 27910, 8.729 samples/sec, batch_loss: 0.0858, batch_loss_c: 0.0850, batch_loss_s: 0.0877, time:4.5824, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2920/3125], step: 27920, 7.658 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0932, batch_loss_s: 0.0937, time:5.2232, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2930/3125], step: 27930, 7.412 samples/sec, batch_loss: 0.0745, batch_loss_c: 0.0761, batch_loss_s: 0.0706, time:5.3966, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:03:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2940/3125], step: 27940, 7.704 samples/sec, batch_loss: 0.1039, batch_loss_c: 0.1046, batch_loss_s: 0.1024, time:5.1918, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2950/3125], step: 27950, 8.025 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0913, batch_loss_s: 0.0727, time:4.9843, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2960/3125], step: 27960, 8.219 samples/sec, batch_loss: 0.2077, batch_loss_c: 0.2419, batch_loss_s: 0.1279, time:4.8668, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2970/3125], step: 27970, 7.692 samples/sec, batch_loss: 0.0655, batch_loss_c: 0.0613, batch_loss_s: 0.0753, time:5.2005, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2980/3125], step: 27980, 6.849 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0902, batch_loss_s: 0.1037, time:5.8400, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2990/3125], step: 27990, 7.122 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0699, batch_loss_s: 0.0890, time:5.6162, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3000/3125], step: 28000, 7.071 samples/sec, batch_loss: 0.2845, batch_loss_c: 0.2720, batch_loss_s: 0.3138, time:5.6570, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:35 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3010/3125], step: 28010, 7.935 samples/sec, batch_loss: 0.3257, batch_loss_c: 0.3165, batch_loss_s: 0.3470, time:5.0407, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3020/3125], step: 28020, 7.560 samples/sec, batch_loss: 0.0831, batch_loss_c: 0.0830, batch_loss_s: 0.0834, time:5.2909, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3030/3125], step: 28030, 7.801 samples/sec, batch_loss: 0.1951, batch_loss_c: 0.1603, batch_loss_s: 0.2763, time:5.1274, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3040/3125], step: 28040, 6.854 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1077, batch_loss_s: 0.0960, time:5.8361, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:04:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3050/3125], step: 28050, 7.342 samples/sec, batch_loss: 0.4015, batch_loss_c: 0.4118, batch_loss_s: 0.3776, time:5.4480, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3060/3125], step: 28060, 7.675 samples/sec, batch_loss: 0.2886, batch_loss_c: 0.2761, batch_loss_s: 0.3177, time:5.2116, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3070/3125], step: 28070, 7.662 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0769, batch_loss_s: 0.0934, time:5.2205, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3080/3125], step: 28080, 6.957 samples/sec, batch_loss: 0.1689, batch_loss_c: 0.1953, batch_loss_s: 0.1075, time:5.7494, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3090/3125], step: 28090, 6.762 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1309, batch_loss_s: 0.1153, time:5.9158, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3100/3125], step: 28100, 7.164 samples/sec, batch_loss: 0.3205, batch_loss_c: 0.3171, batch_loss_s: 0.3285, time:5.5836, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3110/3125], step: 28110, 10.538 samples/sec, batch_loss: 0.5219, batch_loss_c: 0.5152, batch_loss_s: 0.5375, time:3.7958, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3120/3125], step: 28120, 10.207 samples/sec, batch_loss: 0.1063, batch_loss_c: 0.1039, batch_loss_s: 0.1121, time:3.9189, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], train_loss: 0.1783, time: 1573.3694, lr: 0.0001\u001b[0m\n",
            "2019-11-23 15:05:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [0/3125], step: 28125, 5.850 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0743, batch_loss_s: 0.0736, time:6.8374, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [10/3125], step: 28135, 8.252 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1102, batch_loss_s: 0.1214, time:4.8470, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [20/3125], step: 28145, 8.267 samples/sec, batch_loss: 0.2857, batch_loss_c: 0.2733, batch_loss_s: 0.3145, time:4.8383, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:05:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [30/3125], step: 28155, 7.943 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0640, batch_loss_s: 0.0741, time:5.0359, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [40/3125], step: 28165, 8.602 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1264, batch_loss_s: 0.1372, time:4.6500, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [50/3125], step: 28175, 8.208 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0782, batch_loss_s: 0.0900, time:4.8732, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [60/3125], step: 28185, 7.107 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1027, batch_loss_s: 0.1058, time:5.6281, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [70/3125], step: 28195, 6.880 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0840, batch_loss_s: 0.1052, time:5.8142, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [80/3125], step: 28205, 8.877 samples/sec, batch_loss: 0.3060, batch_loss_c: 0.3039, batch_loss_s: 0.3109, time:4.5062, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [90/3125], step: 28215, 7.579 samples/sec, batch_loss: 0.0599, batch_loss_c: 0.0612, batch_loss_s: 0.0570, time:5.2778, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [100/3125], step: 28225, 7.967 samples/sec, batch_loss: 0.1319, batch_loss_c: 0.1497, batch_loss_s: 0.0905, time:5.0209, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [110/3125], step: 28235, 7.142 samples/sec, batch_loss: 0.3159, batch_loss_c: 0.3144, batch_loss_s: 0.3195, time:5.6008, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [120/3125], step: 28245, 7.962 samples/sec, batch_loss: 0.0787, batch_loss_c: 0.0770, batch_loss_s: 0.0827, time:5.0238, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [130/3125], step: 28255, 7.103 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0888, batch_loss_s: 0.1072, time:5.6314, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [140/3125], step: 28265, 8.066 samples/sec, batch_loss: 0.3507, batch_loss_c: 0.3462, batch_loss_s: 0.3611, time:4.9589, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:06:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [150/3125], step: 28275, 8.183 samples/sec, batch_loss: 0.1175, batch_loss_c: 0.1123, batch_loss_s: 0.1298, time:4.8883, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [160/3125], step: 28285, 7.476 samples/sec, batch_loss: 0.4139, batch_loss_c: 0.4447, batch_loss_s: 0.3423, time:5.3506, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [170/3125], step: 28295, 8.538 samples/sec, batch_loss: 0.3430, batch_loss_c: 0.3423, batch_loss_s: 0.3446, time:4.6851, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [180/3125], step: 28305, 8.867 samples/sec, batch_loss: 0.3006, batch_loss_c: 0.2964, batch_loss_s: 0.3102, time:4.5110, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [190/3125], step: 28315, 7.394 samples/sec, batch_loss: 0.3585, batch_loss_c: 0.3708, batch_loss_s: 0.3296, time:5.4095, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [200/3125], step: 28325, 7.730 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0812, batch_loss_s: 0.0628, time:5.1743, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [210/3125], step: 28335, 8.080 samples/sec, batch_loss: 0.3525, batch_loss_c: 0.3618, batch_loss_s: 0.3309, time:4.9507, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [220/3125], step: 28345, 8.738 samples/sec, batch_loss: 0.3344, batch_loss_c: 0.3421, batch_loss_s: 0.3163, time:4.5778, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [230/3125], step: 28355, 8.029 samples/sec, batch_loss: 0.5227, batch_loss_c: 0.5202, batch_loss_s: 0.5286, time:4.9821, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [240/3125], step: 28365, 7.724 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0923, batch_loss_s: 0.0773, time:5.1789, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [250/3125], step: 28375, 8.330 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0952, batch_loss_s: 0.0955, time:4.8016, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [260/3125], step: 28385, 8.067 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0861, batch_loss_s: 0.0960, time:4.9585, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:07:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [270/3125], step: 28395, 7.558 samples/sec, batch_loss: 0.2459, batch_loss_c: 0.2265, batch_loss_s: 0.2913, time:5.2923, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [280/3125], step: 28405, 8.028 samples/sec, batch_loss: 0.2804, batch_loss_c: 0.2768, batch_loss_s: 0.2888, time:4.9827, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [290/3125], step: 28415, 8.035 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0801, batch_loss_s: 0.0860, time:4.9783, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [300/3125], step: 28425, 7.530 samples/sec, batch_loss: 0.0984, batch_loss_c: 0.1018, batch_loss_s: 0.0905, time:5.3124, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [310/3125], step: 28435, 7.801 samples/sec, batch_loss: 0.1337, batch_loss_c: 0.1448, batch_loss_s: 0.1080, time:5.1274, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [320/3125], step: 28445, 8.244 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.0980, batch_loss_s: 0.1067, time:4.8522, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [330/3125], step: 28455, 8.529 samples/sec, batch_loss: 0.5456, batch_loss_c: 0.5478, batch_loss_s: 0.5405, time:4.6900, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [340/3125], step: 28465, 7.860 samples/sec, batch_loss: 0.1747, batch_loss_c: 0.1522, batch_loss_s: 0.2270, time:5.0890, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [350/3125], step: 28475, 7.829 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0767, batch_loss_s: 0.0805, time:5.1090, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [360/3125], step: 28485, 8.782 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1112, batch_loss_s: 0.1231, time:4.5547, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [370/3125], step: 28495, 7.966 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0769, batch_loss_s: 0.0646, time:5.0212, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [380/3125], step: 28505, 7.588 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0662, batch_loss_s: 0.0667, time:5.2718, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:08:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [390/3125], step: 28515, 7.396 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0873, batch_loss_s: 0.0995, time:5.4084, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [400/3125], step: 28525, 7.460 samples/sec, batch_loss: 0.0705, batch_loss_c: 0.0632, batch_loss_s: 0.0875, time:5.3617, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [410/3125], step: 28535, 7.797 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0777, batch_loss_s: 0.0775, time:5.1303, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [420/3125], step: 28545, 7.436 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1010, batch_loss_s: 0.1081, time:5.3789, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:19 \u001b[32mINFO     \u001b[0m train.py: [9/10], [430/3125], step: 28555, 8.364 samples/sec, batch_loss: 0.5780, batch_loss_c: 0.5796, batch_loss_s: 0.5742, time:4.7824, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [440/3125], step: 28565, 8.528 samples/sec, batch_loss: 0.3466, batch_loss_c: 0.3605, batch_loss_s: 0.3141, time:4.6902, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [450/3125], step: 28575, 8.140 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1354, batch_loss_s: 0.0740, time:4.9143, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [460/3125], step: 28585, 8.261 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0781, batch_loss_s: 0.0809, time:4.8423, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [470/3125], step: 28595, 8.669 samples/sec, batch_loss: 0.0614, batch_loss_c: 0.0554, batch_loss_s: 0.0752, time:4.6140, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [480/3125], step: 28605, 8.636 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0670, batch_loss_s: 0.0645, time:4.6316, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [490/3125], step: 28615, 8.307 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1078, batch_loss_s: 0.0754, time:4.8152, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [500/3125], step: 28625, 8.235 samples/sec, batch_loss: 0.2825, batch_loss_c: 0.2681, batch_loss_s: 0.3163, time:4.8572, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:09:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [510/3125], step: 28635, 8.323 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0739, batch_loss_s: 0.0983, time:4.8060, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [520/3125], step: 28645, 8.665 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1389, batch_loss_s: 0.0841, time:4.6161, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [530/3125], step: 28655, 8.379 samples/sec, batch_loss: 0.1738, batch_loss_c: 0.2134, batch_loss_s: 0.0812, time:4.7740, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [540/3125], step: 28665, 8.146 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.1082, batch_loss_s: 0.0827, time:4.9104, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [550/3125], step: 28675, 8.445 samples/sec, batch_loss: 0.1087, batch_loss_c: 0.1177, batch_loss_s: 0.0878, time:4.7367, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [560/3125], step: 28685, 7.855 samples/sec, batch_loss: 0.1992, batch_loss_c: 0.2314, batch_loss_s: 0.1240, time:5.0925, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [570/3125], step: 28695, 8.165 samples/sec, batch_loss: 0.2981, batch_loss_c: 0.2871, batch_loss_s: 0.3235, time:4.8990, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [580/3125], step: 28705, 7.857 samples/sec, batch_loss: 0.5230, batch_loss_c: 0.5067, batch_loss_s: 0.5611, time:5.0909, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [590/3125], step: 28715, 8.008 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0650, batch_loss_s: 0.0697, time:4.9949, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [600/3125], step: 28725, 8.362 samples/sec, batch_loss: 0.1744, batch_loss_c: 0.1796, batch_loss_s: 0.1623, time:4.7834, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [610/3125], step: 28735, 8.990 samples/sec, batch_loss: 0.1733, batch_loss_c: 0.2031, batch_loss_s: 0.1036, time:4.4492, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [620/3125], step: 28745, 8.233 samples/sec, batch_loss: 0.4009, batch_loss_c: 0.4047, batch_loss_s: 0.3920, time:4.8584, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:10:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [630/3125], step: 28755, 7.391 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1194, batch_loss_s: 0.1030, time:5.4118, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [640/3125], step: 28765, 8.231 samples/sec, batch_loss: 0.1128, batch_loss_c: 0.1216, batch_loss_s: 0.0922, time:4.8599, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [650/3125], step: 28775, 7.517 samples/sec, batch_loss: 0.3339, batch_loss_c: 0.3252, batch_loss_s: 0.3542, time:5.3210, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [660/3125], step: 28785, 7.564 samples/sec, batch_loss: 0.1672, batch_loss_c: 0.2016, batch_loss_s: 0.0868, time:5.2881, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [670/3125], step: 28795, 8.121 samples/sec, batch_loss: 0.3301, batch_loss_c: 0.3033, batch_loss_s: 0.3927, time:4.9252, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [680/3125], step: 28805, 8.021 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.1015, batch_loss_s: 0.1008, time:4.9868, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [690/3125], step: 28815, 7.812 samples/sec, batch_loss: 0.3075, batch_loss_c: 0.3029, batch_loss_s: 0.3184, time:5.1206, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [700/3125], step: 28825, 8.468 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0664, batch_loss_s: 0.0738, time:4.7238, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [710/3125], step: 28835, 7.421 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0784, batch_loss_s: 0.0691, time:5.3902, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [720/3125], step: 28845, 7.693 samples/sec, batch_loss: 0.1963, batch_loss_c: 0.1938, batch_loss_s: 0.2022, time:5.1995, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [730/3125], step: 28855, 7.924 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1032, batch_loss_s: 0.1038, time:5.0478, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [740/3125], step: 28865, 7.590 samples/sec, batch_loss: 0.1572, batch_loss_c: 0.1640, batch_loss_s: 0.1411, time:5.2698, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:11:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [750/3125], step: 28875, 7.168 samples/sec, batch_loss: 0.3242, batch_loss_c: 0.3237, batch_loss_s: 0.3253, time:5.5806, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [760/3125], step: 28885, 7.453 samples/sec, batch_loss: 0.4951, batch_loss_c: 0.4746, batch_loss_s: 0.5429, time:5.3667, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [770/3125], step: 28895, 8.027 samples/sec, batch_loss: 0.1358, batch_loss_c: 0.1445, batch_loss_s: 0.1154, time:4.9833, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [780/3125], step: 28905, 7.469 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0660, batch_loss_s: 0.0641, time:5.3555, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [790/3125], step: 28915, 7.813 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0767, batch_loss_s: 0.0966, time:5.1194, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [800/3125], step: 28925, 7.133 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0899, batch_loss_s: 0.1053, time:5.6077, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [810/3125], step: 28935, 7.346 samples/sec, batch_loss: 0.1545, batch_loss_c: 0.1821, batch_loss_s: 0.0902, time:5.4449, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [820/3125], step: 28945, 7.413 samples/sec, batch_loss: 0.3087, batch_loss_c: 0.3051, batch_loss_s: 0.3173, time:5.3958, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [830/3125], step: 28955, 6.486 samples/sec, batch_loss: 0.1549, batch_loss_c: 0.1495, batch_loss_s: 0.1674, time:6.1671, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [840/3125], step: 28965, 7.745 samples/sec, batch_loss: 0.1177, batch_loss_c: 0.1013, batch_loss_s: 0.1560, time:5.1647, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [850/3125], step: 28975, 8.558 samples/sec, batch_loss: 0.1583, batch_loss_c: 0.1749, batch_loss_s: 0.1197, time:4.6741, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:12:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [860/3125], step: 28985, 8.407 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.0953, batch_loss_s: 0.1049, time:4.7579, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [870/3125], step: 28995, 8.410 samples/sec, batch_loss: 0.0744, batch_loss_c: 0.0727, batch_loss_s: 0.0783, time:4.7562, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [880/3125], step: 29005, 7.958 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.0994, batch_loss_s: 0.1031, time:5.0262, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [890/3125], step: 29015, 8.362 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0917, batch_loss_s: 0.0853, time:4.7837, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [900/3125], step: 29025, 6.925 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1486, batch_loss_s: 0.1357, time:5.7764, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [910/3125], step: 29035, 8.322 samples/sec, batch_loss: 0.5081, batch_loss_c: 0.4834, batch_loss_s: 0.5658, time:4.8065, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [920/3125], step: 29045, 9.183 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1279, batch_loss_s: 0.0892, time:4.3560, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [930/3125], step: 29055, 8.092 samples/sec, batch_loss: 0.1512, batch_loss_c: 0.1617, batch_loss_s: 0.1267, time:4.9433, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [940/3125], step: 29065, 8.172 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0931, batch_loss_s: 0.0698, time:4.8949, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [950/3125], step: 29075, 8.038 samples/sec, batch_loss: 0.2986, batch_loss_c: 0.2938, batch_loss_s: 0.3098, time:4.9766, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [960/3125], step: 29085, 7.933 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0733, batch_loss_s: 0.0804, time:5.0424, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [970/3125], step: 29095, 8.304 samples/sec, batch_loss: 0.1122, batch_loss_c: 0.1108, batch_loss_s: 0.1154, time:4.8167, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:13:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [980/3125], step: 29105, 7.751 samples/sec, batch_loss: 0.3182, batch_loss_c: 0.3176, batch_loss_s: 0.3196, time:5.1608, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [990/3125], step: 29115, 6.958 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3181, batch_loss_s: 0.3169, time:5.7490, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1000/3125], step: 29125, 7.921 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3159, batch_loss_s: 0.3357, time:5.0500, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1010/3125], step: 29135, 7.943 samples/sec, batch_loss: 0.3141, batch_loss_c: 0.3141, batch_loss_s: 0.3141, time:5.0358, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1020/3125], step: 29145, 7.830 samples/sec, batch_loss: 0.3159, batch_loss_c: 0.3107, batch_loss_s: 0.3281, time:5.1083, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1030/3125], step: 29155, 7.665 samples/sec, batch_loss: 0.1578, batch_loss_c: 0.1853, batch_loss_s: 0.0938, time:5.2184, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1040/3125], step: 29165, 7.625 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1109, batch_loss_s: 0.0661, time:5.2461, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1050/3125], step: 29175, 8.794 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0995, batch_loss_s: 0.0990, time:4.5486, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1060/3125], step: 29185, 7.940 samples/sec, batch_loss: 0.3074, batch_loss_c: 0.3092, batch_loss_s: 0.3031, time:5.0378, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1070/3125], step: 29195, 8.628 samples/sec, batch_loss: 0.0876, batch_loss_c: 0.0850, batch_loss_s: 0.0938, time:4.6363, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1080/3125], step: 29205, 8.205 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0908, batch_loss_s: 0.0907, time:4.8752, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1090/3125], step: 29215, 9.037 samples/sec, batch_loss: 0.1436, batch_loss_c: 0.1555, batch_loss_s: 0.1159, time:4.4261, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1100/3125], step: 29225, 8.414 samples/sec, batch_loss: 0.7030, batch_loss_c: 0.6956, batch_loss_s: 0.7202, time:4.7539, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:14:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1110/3125], step: 29235, 8.680 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1400, batch_loss_s: 0.0721, time:4.6085, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1120/3125], step: 29245, 7.331 samples/sec, batch_loss: 0.1787, batch_loss_c: 0.2031, batch_loss_s: 0.1217, time:5.4564, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1130/3125], step: 29255, 7.730 samples/sec, batch_loss: 0.2635, batch_loss_c: 0.3075, batch_loss_s: 0.1608, time:5.1746, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1140/3125], step: 29265, 7.923 samples/sec, batch_loss: 0.2711, batch_loss_c: 0.3419, batch_loss_s: 0.1060, time:5.0486, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1150/3125], step: 29275, 6.889 samples/sec, batch_loss: 0.1855, batch_loss_c: 0.1827, batch_loss_s: 0.1918, time:5.8068, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1160/3125], step: 29285, 7.239 samples/sec, batch_loss: 0.1374, batch_loss_c: 0.1356, batch_loss_s: 0.1417, time:5.5255, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1170/3125], step: 29295, 7.123 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1079, batch_loss_s: 0.1059, time:5.6153, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1180/3125], step: 29305, 7.624 samples/sec, batch_loss: 0.2028, batch_loss_c: 0.1989, batch_loss_s: 0.2119, time:5.2466, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1190/3125], step: 29315, 8.201 samples/sec, batch_loss: 0.1185, batch_loss_c: 0.1212, batch_loss_s: 0.1122, time:4.8777, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1200/3125], step: 29325, 8.351 samples/sec, batch_loss: 0.3254, batch_loss_c: 0.3314, batch_loss_s: 0.3115, time:4.7896, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1210/3125], step: 29335, 8.519 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1057, batch_loss_s: 0.1100, time:4.6954, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:15:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1220/3125], step: 29345, 7.567 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0885, batch_loss_s: 0.0995, time:5.2862, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1230/3125], step: 29355, 7.295 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0720, batch_loss_s: 0.0885, time:5.4833, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1240/3125], step: 29365, 8.187 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0804, batch_loss_s: 0.0812, time:4.8855, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1250/3125], step: 29375, 8.106 samples/sec, batch_loss: 0.4114, batch_loss_c: 0.4376, batch_loss_s: 0.3503, time:4.9348, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1260/3125], step: 29385, 7.237 samples/sec, batch_loss: 0.2884, batch_loss_c: 0.2828, batch_loss_s: 0.3014, time:5.5273, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1270/3125], step: 29395, 7.857 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.0852, batch_loss_s: 0.1062, time:5.0910, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1280/3125], step: 29405, 8.290 samples/sec, batch_loss: 0.3179, batch_loss_c: 0.3089, batch_loss_s: 0.3390, time:4.8252, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1290/3125], step: 29415, 8.436 samples/sec, batch_loss: 0.1376, batch_loss_c: 0.1528, batch_loss_s: 0.1021, time:4.7416, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1300/3125], step: 29425, 7.545 samples/sec, batch_loss: 0.5357, batch_loss_c: 0.5301, batch_loss_s: 0.5486, time:5.3013, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1310/3125], step: 29435, 8.303 samples/sec, batch_loss: 0.3784, batch_loss_c: 0.4026, batch_loss_s: 0.3219, time:4.8173, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1320/3125], step: 29445, 7.559 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0594, batch_loss_s: 0.0679, time:5.2915, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1330/3125], step: 29455, 7.756 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0804, batch_loss_s: 0.0849, time:5.1576, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:16:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1340/3125], step: 29465, 7.834 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0829, batch_loss_s: 0.0932, time:5.1057, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1350/3125], step: 29475, 8.614 samples/sec, batch_loss: 0.1313, batch_loss_c: 0.1272, batch_loss_s: 0.1406, time:4.6435, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1360/3125], step: 29485, 8.257 samples/sec, batch_loss: 0.3188, batch_loss_c: 0.3150, batch_loss_s: 0.3276, time:4.8445, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1370/3125], step: 29495, 8.784 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0763, batch_loss_s: 0.0894, time:4.5537, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1380/3125], step: 29505, 7.569 samples/sec, batch_loss: 0.0517, batch_loss_c: 0.0462, batch_loss_s: 0.0644, time:5.2847, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1390/3125], step: 29515, 7.646 samples/sec, batch_loss: 0.0564, batch_loss_c: 0.0550, batch_loss_s: 0.0598, time:5.2317, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1400/3125], step: 29525, 6.816 samples/sec, batch_loss: 0.3023, batch_loss_c: 0.2980, batch_loss_s: 0.3123, time:5.8685, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:34 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1410/3125], step: 29535, 7.441 samples/sec, batch_loss: 0.1732, batch_loss_c: 0.1975, batch_loss_s: 0.1165, time:5.3754, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1420/3125], step: 29545, 7.584 samples/sec, batch_loss: 0.0782, batch_loss_c: 0.0762, batch_loss_s: 0.0828, time:5.2744, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1430/3125], step: 29555, 8.427 samples/sec, batch_loss: 0.0798, batch_loss_c: 0.0790, batch_loss_s: 0.0816, time:4.7465, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1440/3125], step: 29565, 8.599 samples/sec, batch_loss: 0.0820, batch_loss_c: 0.0726, batch_loss_s: 0.1040, time:4.6517, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1450/3125], step: 29575, 8.008 samples/sec, batch_loss: 0.2625, batch_loss_c: 0.2480, batch_loss_s: 0.2963, time:4.9949, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:17:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1460/3125], step: 29585, 7.221 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1137, batch_loss_s: 0.0929, time:5.5395, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1470/3125], step: 29595, 7.722 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.1060, batch_loss_s: 0.0741, time:5.1798, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1480/3125], step: 29605, 8.124 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0546, batch_loss_s: 0.0663, time:4.9235, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1490/3125], step: 29615, 7.497 samples/sec, batch_loss: 0.1757, batch_loss_c: 0.1765, batch_loss_s: 0.1739, time:5.3351, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1500/3125], step: 29625, 7.799 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0961, batch_loss_s: 0.1066, time:5.1288, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1510/3125], step: 29635, 7.597 samples/sec, batch_loss: 0.4469, batch_loss_c: 0.4971, batch_loss_s: 0.3299, time:5.2652, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1520/3125], step: 29645, 7.840 samples/sec, batch_loss: 0.1442, batch_loss_c: 0.1409, batch_loss_s: 0.1520, time:5.1018, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1530/3125], step: 29655, 8.276 samples/sec, batch_loss: 0.5164, batch_loss_c: 0.5039, batch_loss_s: 0.5454, time:4.8333, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1540/3125], step: 29665, 8.820 samples/sec, batch_loss: 0.3015, batch_loss_c: 0.2901, batch_loss_s: 0.3279, time:4.5351, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1550/3125], step: 29675, 8.082 samples/sec, batch_loss: 0.0636, batch_loss_c: 0.0585, batch_loss_s: 0.0755, time:4.9492, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1560/3125], step: 29685, 8.331 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1016, batch_loss_s: 0.1218, time:4.8011, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1570/3125], step: 29695, 8.135 samples/sec, batch_loss: 0.0874, batch_loss_c: 0.0804, batch_loss_s: 0.1038, time:4.9170, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:18:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1580/3125], step: 29705, 8.648 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0902, batch_loss_s: 0.0932, time:4.6256, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1590/3125], step: 29715, 7.319 samples/sec, batch_loss: 0.1693, batch_loss_c: 0.1948, batch_loss_s: 0.1100, time:5.4649, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1600/3125], step: 29725, 7.383 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1016, batch_loss_s: 0.1108, time:5.4181, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1610/3125], step: 29735, 7.386 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0829, batch_loss_s: 0.1000, time:5.4156, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1620/3125], step: 29745, 8.503 samples/sec, batch_loss: 0.0650, batch_loss_c: 0.0593, batch_loss_s: 0.0783, time:4.7042, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1630/3125], step: 29755, 7.428 samples/sec, batch_loss: 0.1129, batch_loss_c: 0.1053, batch_loss_s: 0.1307, time:5.3853, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1640/3125], step: 29765, 6.702 samples/sec, batch_loss: 0.1482, batch_loss_c: 0.1438, batch_loss_s: 0.1583, time:5.9680, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1650/3125], step: 29775, 8.144 samples/sec, batch_loss: 0.2497, batch_loss_c: 0.3093, batch_loss_s: 0.1107, time:4.9114, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1660/3125], step: 29785, 8.032 samples/sec, batch_loss: 0.1355, batch_loss_c: 0.1523, batch_loss_s: 0.0963, time:4.9799, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1670/3125], step: 29795, 7.104 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0866, batch_loss_s: 0.1076, time:5.6305, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1680/3125], step: 29805, 7.477 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0861, batch_loss_s: 0.1022, time:5.3498, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:19:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1690/3125], step: 29815, 7.443 samples/sec, batch_loss: 0.0546, batch_loss_c: 0.0493, batch_loss_s: 0.0669, time:5.3743, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1700/3125], step: 29825, 7.035 samples/sec, batch_loss: 0.3060, batch_loss_c: 0.2945, batch_loss_s: 0.3330, time:5.6859, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1710/3125], step: 29835, 6.884 samples/sec, batch_loss: 0.1649, batch_loss_c: 0.1943, batch_loss_s: 0.0963, time:5.8106, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1720/3125], step: 29845, 7.178 samples/sec, batch_loss: 0.1817, batch_loss_c: 0.1675, batch_loss_s: 0.2148, time:5.5725, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1730/3125], step: 29855, 7.676 samples/sec, batch_loss: 0.5410, batch_loss_c: 0.5454, batch_loss_s: 0.5308, time:5.2111, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1740/3125], step: 29865, 8.125 samples/sec, batch_loss: 0.1899, batch_loss_c: 0.1942, batch_loss_s: 0.1796, time:4.9233, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1750/3125], step: 29875, 6.976 samples/sec, batch_loss: 0.0578, batch_loss_c: 0.0507, batch_loss_s: 0.0742, time:5.7337, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1760/3125], step: 29885, 8.220 samples/sec, batch_loss: 0.3301, batch_loss_c: 0.3169, batch_loss_s: 0.3607, time:4.8663, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1770/3125], step: 29895, 8.010 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1126, batch_loss_s: 0.1152, time:4.9938, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1780/3125], step: 29905, 8.110 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1358, batch_loss_s: 0.0730, time:4.9323, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1790/3125], step: 29915, 7.545 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0915, batch_loss_s: 0.0595, time:5.3013, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:20:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1800/3125], step: 29925, 8.020 samples/sec, batch_loss: 0.3045, batch_loss_c: 0.3045, batch_loss_s: 0.3045, time:4.9874, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1810/3125], step: 29935, 7.825 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1009, batch_loss_s: 0.1549, time:5.1120, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1820/3125], step: 29945, 8.302 samples/sec, batch_loss: 0.2909, batch_loss_c: 0.2861, batch_loss_s: 0.3019, time:4.8184, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1830/3125], step: 29955, 7.860 samples/sec, batch_loss: 0.1938, batch_loss_c: 0.2032, batch_loss_s: 0.1720, time:5.0893, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1840/3125], step: 29965, 8.214 samples/sec, batch_loss: 0.2882, batch_loss_c: 0.2733, batch_loss_s: 0.3229, time:4.8696, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1850/3125], step: 29975, 8.815 samples/sec, batch_loss: 0.0700, batch_loss_c: 0.0684, batch_loss_s: 0.0737, time:4.5379, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1860/3125], step: 29985, 8.339 samples/sec, batch_loss: 0.4827, batch_loss_c: 0.4751, batch_loss_s: 0.5004, time:4.7968, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1870/3125], step: 29995, 9.071 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0656, batch_loss_s: 0.0705, time:4.4097, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1880/3125], step: 30005, 9.064 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0728, batch_loss_s: 0.0933, time:4.4130, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1890/3125], step: 30015, 7.503 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.0913, batch_loss_s: 0.1102, time:5.3313, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1900/3125], step: 30025, 8.143 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1729, batch_loss_s: 0.0780, time:4.9124, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1910/3125], step: 30035, 8.236 samples/sec, batch_loss: 0.4952, batch_loss_c: 0.4697, batch_loss_s: 0.5547, time:4.8570, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1920/3125], step: 30045, 8.641 samples/sec, batch_loss: 0.1066, batch_loss_c: 0.1103, batch_loss_s: 0.0978, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:21:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1930/3125], step: 30055, 7.431 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0575, batch_loss_s: 0.0708, time:5.3828, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1940/3125], step: 30065, 8.660 samples/sec, batch_loss: 0.3528, batch_loss_c: 0.3646, batch_loss_s: 0.3252, time:4.6188, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1950/3125], step: 30075, 6.967 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1607, batch_loss_s: 0.1106, time:5.7415, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1960/3125], step: 30085, 8.181 samples/sec, batch_loss: 0.1046, batch_loss_c: 0.1064, batch_loss_s: 0.1004, time:4.8893, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1970/3125], step: 30095, 8.824 samples/sec, batch_loss: 0.1103, batch_loss_c: 0.1160, batch_loss_s: 0.0972, time:4.5332, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1980/3125], step: 30105, 8.133 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0640, batch_loss_s: 0.0816, time:4.9180, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1990/3125], step: 30115, 7.912 samples/sec, batch_loss: 0.2938, batch_loss_c: 0.2921, batch_loss_s: 0.2979, time:5.0557, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2000/3125], step: 30125, 7.626 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0920, batch_loss_s: 0.0864, time:5.2450, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2010/3125], step: 30135, 7.863 samples/sec, batch_loss: 0.3743, batch_loss_c: 0.3956, batch_loss_s: 0.3246, time:5.0868, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2020/3125], step: 30145, 7.873 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0945, batch_loss_s: 0.1131, time:5.0806, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2030/3125], step: 30155, 8.081 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0737, batch_loss_s: 0.0850, time:4.9501, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2040/3125], step: 30165, 8.771 samples/sec, batch_loss: 0.4117, batch_loss_c: 0.4245, batch_loss_s: 0.3819, time:4.5603, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:22:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2050/3125], step: 30175, 8.428 samples/sec, batch_loss: 0.3412, batch_loss_c: 0.3536, batch_loss_s: 0.3121, time:4.7461, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2060/3125], step: 30185, 8.059 samples/sec, batch_loss: 0.5315, batch_loss_c: 0.5300, batch_loss_s: 0.5352, time:4.9633, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2070/3125], step: 30195, 7.582 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0852, batch_loss_s: 0.0895, time:5.2753, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2080/3125], step: 30205, 8.032 samples/sec, batch_loss: 0.0661, batch_loss_c: 0.0630, batch_loss_s: 0.0733, time:4.9800, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2090/3125], step: 30215, 7.905 samples/sec, batch_loss: 0.2703, batch_loss_c: 0.2421, batch_loss_s: 0.3360, time:5.0601, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2100/3125], step: 30225, 7.964 samples/sec, batch_loss: 0.1111, batch_loss_c: 0.1091, batch_loss_s: 0.1157, time:5.0227, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2110/3125], step: 30235, 8.343 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1009, batch_loss_s: 0.1018, time:4.7942, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2120/3125], step: 30245, 7.934 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1149, batch_loss_s: 0.1190, time:5.0415, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2130/3125], step: 30255, 8.225 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1145, batch_loss_s: 0.1041, time:4.8632, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2140/3125], step: 30265, 7.693 samples/sec, batch_loss: 0.0976, batch_loss_c: 0.1005, batch_loss_s: 0.0909, time:5.1998, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2150/3125], step: 30275, 8.425 samples/sec, batch_loss: 0.4476, batch_loss_c: 0.5002, batch_loss_s: 0.3248, time:4.7478, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2160/3125], step: 30285, 7.923 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0804, batch_loss_s: 0.0890, time:5.0488, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:23:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2170/3125], step: 30295, 8.063 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0777, batch_loss_s: 0.0751, time:4.9607, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2180/3125], step: 30305, 8.081 samples/sec, batch_loss: 0.2106, batch_loss_c: 0.2435, batch_loss_s: 0.1340, time:4.9501, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2190/3125], step: 30315, 8.448 samples/sec, batch_loss: 0.3476, batch_loss_c: 0.3498, batch_loss_s: 0.3424, time:4.7348, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2200/3125], step: 30325, 8.802 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0783, batch_loss_s: 0.0755, time:4.5442, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2210/3125], step: 30335, 7.962 samples/sec, batch_loss: 0.3002, batch_loss_c: 0.3025, batch_loss_s: 0.2948, time:5.0236, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2220/3125], step: 30345, 8.078 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0759, batch_loss_s: 0.0648, time:4.9516, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2230/3125], step: 30355, 7.977 samples/sec, batch_loss: 0.3909, batch_loss_c: 0.4103, batch_loss_s: 0.3457, time:5.0147, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2240/3125], step: 30365, 7.757 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0921, batch_loss_s: 0.0773, time:5.1565, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2250/3125], step: 30375, 7.457 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.0932, batch_loss_s: 0.1088, time:5.3644, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2260/3125], step: 30385, 7.486 samples/sec, batch_loss: 0.1565, batch_loss_c: 0.1786, batch_loss_s: 0.1051, time:5.3430, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2270/3125], step: 30395, 7.379 samples/sec, batch_loss: 0.1590, batch_loss_c: 0.1517, batch_loss_s: 0.1761, time:5.4209, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2280/3125], step: 30405, 8.227 samples/sec, batch_loss: 0.1828, batch_loss_c: 0.2000, batch_loss_s: 0.1426, time:4.8619, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:24:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2290/3125], step: 30415, 7.932 samples/sec, batch_loss: 0.2916, batch_loss_c: 0.2827, batch_loss_s: 0.3124, time:5.0430, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2300/3125], step: 30425, 7.871 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0973, batch_loss_s: 0.0971, time:5.0818, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2310/3125], step: 30435, 7.646 samples/sec, batch_loss: 0.0636, batch_loss_c: 0.0627, batch_loss_s: 0.0656, time:5.2317, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2320/3125], step: 30445, 8.251 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0725, batch_loss_s: 0.0833, time:4.8480, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2330/3125], step: 30455, 8.199 samples/sec, batch_loss: 0.2855, batch_loss_c: 0.2753, batch_loss_s: 0.3094, time:4.8786, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2340/3125], step: 30465, 8.565 samples/sec, batch_loss: 0.5854, batch_loss_c: 0.6001, batch_loss_s: 0.5511, time:4.6704, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2350/3125], step: 30475, 8.645 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0904, batch_loss_s: 0.0785, time:4.6268, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2360/3125], step: 30485, 8.433 samples/sec, batch_loss: 0.1299, batch_loss_c: 0.1453, batch_loss_s: 0.0940, time:4.7434, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2370/3125], step: 30495, 7.664 samples/sec, batch_loss: 0.3152, batch_loss_c: 0.3145, batch_loss_s: 0.3170, time:5.2189, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2380/3125], step: 30505, 8.682 samples/sec, batch_loss: 0.0652, batch_loss_c: 0.0663, batch_loss_s: 0.0626, time:4.6075, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2390/3125], step: 30515, 8.004 samples/sec, batch_loss: 0.2937, batch_loss_c: 0.2925, batch_loss_s: 0.2966, time:4.9978, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2400/3125], step: 30525, 7.491 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0872, batch_loss_s: 0.0982, time:5.3400, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:25:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2410/3125], step: 30535, 8.073 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0703, batch_loss_s: 0.0833, time:4.9547, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2420/3125], step: 30545, 8.164 samples/sec, batch_loss: 0.1329, batch_loss_c: 0.1320, batch_loss_s: 0.1348, time:4.8996, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2430/3125], step: 30555, 8.086 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0796, batch_loss_s: 0.0733, time:4.9471, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2440/3125], step: 30565, 8.247 samples/sec, batch_loss: 0.1828, batch_loss_c: 0.2001, batch_loss_s: 0.1423, time:4.8503, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2450/3125], step: 30575, 8.409 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1193, batch_loss_s: 0.1189, time:4.7566, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2460/3125], step: 30585, 8.555 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0677, batch_loss_s: 0.0600, time:4.6759, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2470/3125], step: 30595, 8.872 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0881, batch_loss_s: 0.0931, time:4.5086, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2480/3125], step: 30605, 8.091 samples/sec, batch_loss: 0.1046, batch_loss_c: 0.1085, batch_loss_s: 0.0956, time:4.9438, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2490/3125], step: 30615, 7.558 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0588, batch_loss_s: 0.0663, time:5.2922, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2500/3125], step: 30625, 8.517 samples/sec, batch_loss: 0.2987, batch_loss_c: 0.2913, batch_loss_s: 0.3157, time:4.6963, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2510/3125], step: 30635, 8.418 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1110, batch_loss_s: 0.0883, time:4.7520, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2520/3125], step: 30645, 7.967 samples/sec, batch_loss: 0.1829, batch_loss_c: 0.2013, batch_loss_s: 0.1400, time:5.0206, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:26:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2530/3125], step: 30655, 8.273 samples/sec, batch_loss: 0.1266, batch_loss_c: 0.1276, batch_loss_s: 0.1241, time:4.8347, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2540/3125], step: 30665, 8.394 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1144, batch_loss_s: 0.1303, time:4.7650, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2550/3125], step: 30675, 8.222 samples/sec, batch_loss: 0.7890, batch_loss_c: 0.7820, batch_loss_s: 0.8054, time:4.8647, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2560/3125], step: 30685, 8.225 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0954, batch_loss_s: 0.0863, time:4.8632, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2570/3125], step: 30695, 7.510 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.0946, batch_loss_s: 0.1086, time:5.3261, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2580/3125], step: 30705, 8.002 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0882, batch_loss_s: 0.0971, time:4.9987, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2590/3125], step: 30715, 8.001 samples/sec, batch_loss: 0.0605, batch_loss_c: 0.0580, batch_loss_s: 0.0663, time:4.9995, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2600/3125], step: 30725, 8.613 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0635, batch_loss_s: 0.0835, time:4.6442, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2610/3125], step: 30735, 8.513 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1288, batch_loss_s: 0.0872, time:4.6988, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2620/3125], step: 30745, 8.017 samples/sec, batch_loss: 0.1311, batch_loss_c: 0.1497, batch_loss_s: 0.0878, time:4.9894, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2630/3125], step: 30755, 7.785 samples/sec, batch_loss: 0.1207, batch_loss_c: 0.1252, batch_loss_s: 0.1101, time:5.1379, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2640/3125], step: 30765, 7.747 samples/sec, batch_loss: 0.1369, batch_loss_c: 0.1503, batch_loss_s: 0.1055, time:5.1634, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:27:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2650/3125], step: 30775, 7.935 samples/sec, batch_loss: 0.2487, batch_loss_c: 0.2253, batch_loss_s: 0.3033, time:5.0409, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2660/3125], step: 30785, 7.626 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1098, batch_loss_s: 0.1088, time:5.2453, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2670/3125], step: 30795, 8.230 samples/sec, batch_loss: 0.3413, batch_loss_c: 0.3407, batch_loss_s: 0.3427, time:4.8600, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2680/3125], step: 30805, 8.610 samples/sec, batch_loss: 0.0699, batch_loss_c: 0.0683, batch_loss_s: 0.0736, time:4.6457, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2690/3125], step: 30815, 8.274 samples/sec, batch_loss: 0.5612, batch_loss_c: 0.5699, batch_loss_s: 0.5409, time:4.8346, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2700/3125], step: 30825, 7.930 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3093, batch_loss_s: 0.3215, time:5.0439, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2710/3125], step: 30835, 7.872 samples/sec, batch_loss: 0.1421, batch_loss_c: 0.1539, batch_loss_s: 0.1145, time:5.0815, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2720/3125], step: 30845, 7.798 samples/sec, batch_loss: 0.2964, batch_loss_c: 0.2951, batch_loss_s: 0.2995, time:5.1297, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2730/3125], step: 30855, 8.163 samples/sec, batch_loss: 0.3284, batch_loss_c: 0.3315, batch_loss_s: 0.3211, time:4.9003, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2740/3125], step: 30865, 8.519 samples/sec, batch_loss: 0.3455, batch_loss_c: 0.3446, batch_loss_s: 0.3478, time:4.6952, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2750/3125], step: 30875, 8.024 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0758, batch_loss_s: 0.0899, time:4.9848, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2760/3125], step: 30885, 8.762 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0984, batch_loss_s: 0.0698, time:4.5653, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2770/3125], step: 30895, 7.440 samples/sec, batch_loss: 0.3402, batch_loss_c: 0.3427, batch_loss_s: 0.3345, time:5.3764, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:28:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2780/3125], step: 30905, 8.263 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0951, batch_loss_s: 0.0931, time:4.8408, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2790/3125], step: 30915, 8.749 samples/sec, batch_loss: 0.3589, batch_loss_c: 0.3567, batch_loss_s: 0.3640, time:4.5719, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2800/3125], step: 30925, 8.623 samples/sec, batch_loss: 0.3298, batch_loss_c: 0.3230, batch_loss_s: 0.3457, time:4.6388, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2810/3125], step: 30935, 8.285 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.1088, batch_loss_s: 0.0649, time:4.8280, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:19 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2820/3125], step: 30945, 7.704 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1014, batch_loss_s: 0.1006, time:5.1919, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2830/3125], step: 30955, 7.744 samples/sec, batch_loss: 0.1766, batch_loss_c: 0.1679, batch_loss_s: 0.1970, time:5.1654, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2840/3125], step: 30965, 7.469 samples/sec, batch_loss: 0.0986, batch_loss_c: 0.1048, batch_loss_s: 0.0841, time:5.3558, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2850/3125], step: 30975, 7.219 samples/sec, batch_loss: 0.0978, batch_loss_c: 0.1035, batch_loss_s: 0.0844, time:5.5408, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2860/3125], step: 30985, 7.244 samples/sec, batch_loss: 0.1313, batch_loss_c: 0.1442, batch_loss_s: 0.1014, time:5.5218, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2870/3125], step: 30995, 7.577 samples/sec, batch_loss: 0.0787, batch_loss_c: 0.0794, batch_loss_s: 0.0770, time:5.2788, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2880/3125], step: 31005, 8.947 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0643, batch_loss_s: 0.0751, time:4.4708, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:29:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2890/3125], step: 31015, 7.405 samples/sec, batch_loss: 0.3307, batch_loss_c: 0.3330, batch_loss_s: 0.3251, time:5.4017, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2900/3125], step: 31025, 8.114 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0939, batch_loss_s: 0.1085, time:4.9298, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2910/3125], step: 31035, 7.944 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0841, batch_loss_s: 0.0938, time:5.0355, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2920/3125], step: 31045, 8.501 samples/sec, batch_loss: 0.1449, batch_loss_c: 0.1545, batch_loss_s: 0.1226, time:4.7052, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2930/3125], step: 31055, 7.102 samples/sec, batch_loss: 0.0939, batch_loss_c: 0.0900, batch_loss_s: 0.1029, time:5.6323, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2940/3125], step: 31065, 7.418 samples/sec, batch_loss: 0.0607, batch_loss_c: 0.0572, batch_loss_s: 0.0687, time:5.3923, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2950/3125], step: 31075, 7.351 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1226, batch_loss_s: 0.1436, time:5.4416, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2960/3125], step: 31085, 7.786 samples/sec, batch_loss: 0.1843, batch_loss_c: 0.2248, batch_loss_s: 0.0899, time:5.1372, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2970/3125], step: 31095, 7.252 samples/sec, batch_loss: 0.5541, batch_loss_c: 0.5496, batch_loss_s: 0.5647, time:5.5157, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2980/3125], step: 31105, 8.629 samples/sec, batch_loss: 0.0780, batch_loss_c: 0.0753, batch_loss_s: 0.0842, time:4.6355, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2990/3125], step: 31115, 7.250 samples/sec, batch_loss: 0.1045, batch_loss_c: 0.1067, batch_loss_s: 0.0994, time:5.5173, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3000/3125], step: 31125, 7.507 samples/sec, batch_loss: 0.0821, batch_loss_c: 0.0851, batch_loss_s: 0.0750, time:5.3284, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:30:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3010/3125], step: 31135, 7.754 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3380, batch_loss_s: 0.3612, time:5.1585, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3020/3125], step: 31145, 7.700 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1292, batch_loss_s: 0.1071, time:5.1950, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3030/3125], step: 31155, 6.650 samples/sec, batch_loss: 0.1428, batch_loss_c: 0.1433, batch_loss_s: 0.1418, time:6.0153, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3040/3125], step: 31165, 8.151 samples/sec, batch_loss: 0.1149, batch_loss_c: 0.1267, batch_loss_s: 0.0874, time:4.9074, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3050/3125], step: 31175, 6.822 samples/sec, batch_loss: 0.3499, batch_loss_c: 0.3558, batch_loss_s: 0.3362, time:5.8635, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3060/3125], step: 31185, 6.708 samples/sec, batch_loss: 0.3480, batch_loss_c: 0.3389, batch_loss_s: 0.3692, time:5.9629, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3070/3125], step: 31195, 6.372 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1155, batch_loss_s: 0.1184, time:6.2778, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3080/3125], step: 31205, 8.198 samples/sec, batch_loss: 0.1348, batch_loss_c: 0.1420, batch_loss_s: 0.1180, time:4.8794, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3090/3125], step: 31215, 7.457 samples/sec, batch_loss: 0.3291, batch_loss_c: 0.3248, batch_loss_s: 0.3391, time:5.3641, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3100/3125], step: 31225, 7.178 samples/sec, batch_loss: 0.3299, batch_loss_c: 0.3107, batch_loss_s: 0.3746, time:5.5722, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3110/3125], step: 31235, 10.234 samples/sec, batch_loss: 0.3110, batch_loss_c: 0.3079, batch_loss_s: 0.3184, time:3.9086, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3120/3125], step: 31245, 10.301 samples/sec, batch_loss: 0.1549, batch_loss_c: 0.1668, batch_loss_s: 0.1273, time:3.8829, lr:0.0001\u001b[0m\n",
            "2019-11-23 15:31:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], train_loss: 0.1762, time: 1582.9708, lr: 0.0001\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}