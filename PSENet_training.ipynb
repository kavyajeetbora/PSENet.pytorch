{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSENet_trial_run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/PSENet.pytorch/blob/master/PSENet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UByxwp0F3QUp",
        "colab_type": "text"
      },
      "source": [
        "## Installing softwares and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSEHnmCxK_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99kqKlHoYkz",
        "colab_type": "code",
        "outputId": "6958b357-f47a-4083-e049-04761624cf9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install pyclipper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyclipper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/67/2691f7cbb28fb9dbf423f2302fe489f9cee34d9a50a743c95032a24ac597/pyclipper-1.1.0.post1-cp36-cp36m-manylinux1_x86_64.whl (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pyclipper\n",
            "Successfully installed pyclipper-1.1.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoynOlfnIW1",
        "colab_type": "code",
        "outputId": "e4b76b45-7091-4827-f3cc-4e8846ed9845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhJ-6yyXcnRx",
        "colab_type": "code",
        "outputId": "c0a8a7f4-9da4-42c7-dd12-d902ffff92ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "import shutil, os\n",
        "os.chdir('/content')\n",
        "directory = '/content/cloned-repo'\n",
        "if os.path.exists(directory):\n",
        "  shutil.rmtree(directory)\n",
        "\n",
        "!git clone https://github.com/kavyajeetbora/PSENet.pytorch.git /content/cloned-repo\n",
        "print(\"Cloned the repository\")\n",
        "os.chdir('/content/cloned-repo')\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/cloned-repo'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/39)\u001b[K\rremote: Counting objects:   5% (2/39)\u001b[K\rremote: Counting objects:   7% (3/39)\u001b[K\rremote: Counting objects:  10% (4/39)\u001b[K\rremote: Counting objects:  12% (5/39)\u001b[K\rremote: Counting objects:  15% (6/39)\u001b[K\rremote: Counting objects:  17% (7/39)\u001b[K\rremote: Counting objects:  20% (8/39)\u001b[K\rremote: Counting objects:  23% (9/39)\u001b[K\rremote: Counting objects:  25% (10/39)\u001b[K\rremote: Counting objects:  28% (11/39)\u001b[K\rremote: Counting objects:  30% (12/39)\u001b[K\rremote: Counting objects:  33% (13/39)\u001b[K\rremote: Counting objects:  35% (14/39)\u001b[K\rremote: Counting objects:  38% (15/39)\u001b[K\rremote: Counting objects:  41% (16/39)\u001b[K\rremote: Counting objects:  43% (17/39)\u001b[K\rremote: Counting objects:  46% (18/39)\u001b[K\rremote: Counting objects:  48% (19/39)\u001b[K\rremote: Counting objects:  51% (20/39)\u001b[K\rremote: Counting objects:  53% (21/39)\u001b[K\rremote: Counting objects:  56% (22/39)\u001b[K\rremote: Counting objects:  58% (23/39)\u001b[K\rremote: Counting objects:  61% (24/39)\u001b[K\rremote: Counting objects:  64% (25/39)\u001b[K\rremote: Counting objects:  66% (26/39)\u001b[K\rremote: Counting objects:  69% (27/39)\u001b[K\rremote: Counting objects:  71% (28/39)\u001b[K\rremote: Counting objects:  74% (29/39)\u001b[K\rremote: Counting objects:  76% (30/39)\u001b[K\rremote: Counting objects:  79% (31/39)\u001b[K\rremote: Counting objects:  82% (32/39)\u001b[K\rremote: Counting objects:  84% (33/39)\u001b[K\rremote: Counting objects:  87% (34/39)\u001b[K\rremote: Counting objects:  89% (35/39)\u001b[K\rremote: Counting objects:  92% (36/39)\u001b[K\rremote: Counting objects:  94% (37/39)\u001b[K\rremote: Counting objects:  97% (38/39)\u001b[K\rremote: Counting objects: 100% (39/39)\u001b[K\rremote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/39)\u001b[K\rremote: Compressing objects:   5% (2/39)\u001b[K\rremote: Compressing objects:   7% (3/39)\u001b[K\rremote: Compressing objects:  10% (4/39)\u001b[K\rremote: Compressing objects:  12% (5/39)\u001b[K\rremote: Compressing objects:  15% (6/39)\u001b[K\rremote: Compressing objects:  17% (7/39)\u001b[K\rremote: Compressing objects:  20% (8/39)\u001b[K\rremote: Compressing objects:  23% (9/39)\u001b[K\rremote: Compressing objects:  25% (10/39)\u001b[K\rremote: Compressing objects:  28% (11/39)\u001b[K\rremote: Compressing objects:  30% (12/39)\u001b[K\rremote: Compressing objects:  33% (13/39)\u001b[K\rremote: Compressing objects:  35% (14/39)\u001b[K\rremote: Compressing objects:  38% (15/39)\u001b[K\rremote: Compressing objects:  41% (16/39)\u001b[K\rremote: Compressing objects:  43% (17/39)\u001b[K\rremote: Compressing objects:  46% (18/39)\u001b[K\rremote: Compressing objects:  48% (19/39)\u001b[K\rremote: Compressing objects:  51% (20/39)\u001b[K\rremote: Compressing objects:  53% (21/39)\u001b[K\rremote: Compressing objects:  56% (22/39)\u001b[K\rremote: Compressing objects:  58% (23/39)\u001b[K\rremote: Compressing objects:  61% (24/39)\u001b[K\rremote: Compressing objects:  64% (25/39)\u001b[K\rremote: Compressing objects:  66% (26/39)\u001b[K\rremote: Compressing objects:  69% (27/39)\u001b[K\rremote: Compressing objects:  71% (28/39)\u001b[K\rremote: Compressing objects:  74% (29/39)\u001b[K\rremote: Compressing objects:  76% (30/39)\u001b[K\rremote: Compressing objects:  79% (31/39)\u001b[K\rremote: Compressing objects:  82% (32/39)\u001b[K\rremote: Compressing objects:  84% (33/39)\u001b[K\rremote: Compressing objects:  87% (34/39)\u001b[K\rremote: Compressing objects:  89% (35/39)\u001b[K\rremote: Compressing objects:  92% (36/39)\u001b[K\rremote: Compressing objects:  94% (37/39)\u001b[K\rremote: Compressing objects:  97% (38/39)\u001b[K\rremote: Compressing objects: 100% (39/39)\u001b[K\rremote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "Receiving objects:   0% (1/439)   \rReceiving objects:   1% (5/439)   \rReceiving objects:   2% (9/439)   \rReceiving objects:   3% (14/439)   \rReceiving objects:   4% (18/439)   \rReceiving objects:   5% (22/439)   \rReceiving objects:   6% (27/439)   \rReceiving objects:   7% (31/439)   \rReceiving objects:   8% (36/439)   \rReceiving objects:   9% (40/439)   \rReceiving objects:  10% (44/439)   \rReceiving objects:  11% (49/439)   \rReceiving objects:  12% (53/439)   \rReceiving objects:  13% (58/439)   \rReceiving objects:  14% (62/439)   \rReceiving objects:  15% (66/439)   \rReceiving objects:  16% (71/439)   \rReceiving objects:  17% (75/439)   \rReceiving objects:  18% (80/439)   \rReceiving objects:  19% (84/439)   \rReceiving objects:  20% (88/439)   \rReceiving objects:  21% (93/439)   \rReceiving objects:  22% (97/439)   \rReceiving objects:  23% (101/439)   \rReceiving objects:  24% (106/439)   \rReceiving objects:  25% (110/439)   \rReceiving objects:  26% (115/439)   \rReceiving objects:  27% (119/439)   \rReceiving objects:  28% (123/439)   \rReceiving objects:  29% (128/439)   \rReceiving objects:  30% (132/439)   \rReceiving objects:  31% (137/439)   \rReceiving objects:  32% (141/439)   \rReceiving objects:  33% (145/439)   \rReceiving objects:  34% (150/439)   \rReceiving objects:  35% (154/439)   \rReceiving objects:  36% (159/439)   \rReceiving objects:  37% (163/439)   \rReceiving objects:  38% (167/439)   \rReceiving objects:  39% (172/439)   \rReceiving objects:  40% (176/439)   \rReceiving objects:  41% (180/439)   \rReceiving objects:  42% (185/439)   \rReceiving objects:  43% (189/439)   \rReceiving objects:  44% (194/439)   \rReceiving objects:  45% (198/439)   \rReceiving objects:  46% (202/439)   \rReceiving objects:  47% (207/439)   \rReceiving objects:  48% (211/439)   \rReceiving objects:  49% (216/439)   \rReceiving objects:  50% (220/439)   \rReceiving objects:  51% (224/439)   \rReceiving objects:  52% (229/439)   \rReceiving objects:  53% (233/439)   \rReceiving objects:  54% (238/439)   \rReceiving objects:  55% (242/439)   \rReceiving objects:  56% (246/439)   \rReceiving objects:  57% (251/439)   \rReceiving objects:  58% (255/439)   \rReceiving objects:  59% (260/439)   \rReceiving objects:  60% (264/439)   \rReceiving objects:  61% (268/439)   \rReceiving objects:  62% (273/439)   \rReceiving objects:  63% (277/439)   \rReceiving objects:  64% (281/439)   \rReceiving objects:  65% (286/439)   \rReceiving objects:  66% (290/439)   \rReceiving objects:  67% (295/439)   \rReceiving objects:  68% (299/439)   \rReceiving objects:  69% (303/439)   \rReceiving objects:  70% (308/439)   \rReceiving objects:  71% (312/439)   \rReceiving objects:  72% (317/439)   \rReceiving objects:  73% (321/439)   \rReceiving objects:  74% (325/439)   \rReceiving objects:  75% (330/439)   \rReceiving objects:  76% (334/439)   \rReceiving objects:  77% (339/439)   \rReceiving objects:  78% (343/439)   \rReceiving objects:  79% (347/439)   \rReceiving objects:  80% (352/439)   \rReceiving objects:  81% (356/439)   \rReceiving objects:  82% (360/439)   \rReceiving objects:  83% (365/439)   \rReceiving objects:  84% (369/439)   \rReceiving objects:  85% (374/439)   \rReceiving objects:  86% (378/439)   \rReceiving objects:  87% (382/439)   \rReceiving objects:  88% (387/439)   \rReceiving objects:  89% (391/439)   \rReceiving objects:  90% (396/439)   \rReceiving objects:  91% (400/439)   \rReceiving objects:  92% (404/439)   \rReceiving objects:  93% (409/439)   \rReceiving objects:  94% (413/439)   \rremote: Total 439 (delta 20), reused 0 (delta 0), pack-reused 400\u001b[K\n",
            "Receiving objects:  95% (418/439)   \rReceiving objects:  96% (422/439)   \rReceiving objects:  97% (426/439)   \rReceiving objects:  98% (431/439)   \rReceiving objects:  99% (435/439)   \rReceiving objects: 100% (439/439)   \rReceiving objects: 100% (439/439), 8.29 MiB | 38.57 MiB/s, done.\n",
            "Resolving deltas:   0% (0/214)   \rResolving deltas:   2% (6/214)   \rResolving deltas:  10% (23/214)   \rResolving deltas:  11% (24/214)   \rResolving deltas:  13% (29/214)   \rResolving deltas:  16% (35/214)   \rResolving deltas:  17% (38/214)   \rResolving deltas:  18% (40/214)   \rResolving deltas:  20% (44/214)   \rResolving deltas:  21% (46/214)   \rResolving deltas:  25% (54/214)   \rResolving deltas:  26% (56/214)   \rResolving deltas:  28% (60/214)   \rResolving deltas:  29% (63/214)   \rResolving deltas:  34% (73/214)   \rResolving deltas:  39% (84/214)   \rResolving deltas:  41% (89/214)   \rResolving deltas:  45% (97/214)   \rResolving deltas:  50% (107/214)   \rResolving deltas:  52% (112/214)   \rResolving deltas:  56% (120/214)   \rResolving deltas:  61% (131/214)   \rResolving deltas:  63% (136/214)   \rResolving deltas:  66% (142/214)   \rResolving deltas:  67% (144/214)   \rResolving deltas:  68% (147/214)   \rResolving deltas:  69% (148/214)   \rResolving deltas:  70% (150/214)   \rResolving deltas:  72% (155/214)   \rResolving deltas:  73% (157/214)   \rResolving deltas:  74% (159/214)   \rResolving deltas:  75% (162/214)   \rResolving deltas:  76% (163/214)   \rResolving deltas:  77% (165/214)   \rResolving deltas:  78% (167/214)   \rResolving deltas:  79% (170/214)   \rResolving deltas:  88% (190/214)   \rResolving deltas:  90% (193/214)   \rResolving deltas:  95% (205/214)   \rResolving deltas:  96% (207/214)   \rResolving deltas:  98% (210/214)   \rResolving deltas:  99% (212/214)   \rResolving deltas: 100% (214/214)   \rResolving deltas: 100% (214/214), done.\n",
            "Cloned the repository\n",
            "cal_recall  install_dependencies.sh  PSENet.ipynb\t     train.py\n",
            "config.py   LICENSE\t\t     PSENet_predict.ipynb    utils\n",
            "dataset     models\t\t     PSENet_training.ipynb\n",
            "eval.py     predict.py\t\t     PSENet_trial_run.ipynb\n",
            "imgs\t    pse\t\t\t     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrOmfo6_3X2I",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the data and setting up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLMxTujlm0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping the files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def unzip_files(file,output_dir):\n",
        "  with ZipFile(file, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall(output_dir)\n",
        "  print('Extracted to',output_dir)\n",
        "\n",
        "def make_directory(directory):\n",
        "  if os.path.isdir(directory):\n",
        "    shutil.rmtree(directory)\n",
        "  \n",
        "  os.mkdir(directory)\n",
        "  print('Created a new directory')\n",
        "\n",
        "training_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Training Set/Random 5000.zip'\n",
        "test_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Test Set/real_Image_dataset_Detection.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJ6xb5u2dgg",
        "colab_type": "code",
        "outputId": "cfb11807-4a9f-4726-d38e-005665d5545a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# make directories\n",
        "make_directory('Training Set')\n",
        "make_directory('Test Set')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created a new directory\n",
            "Created a new directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSaSXr-m-K4",
        "colab_type": "code",
        "outputId": "d46a730d-121b-4264-ee7f-4709f25f834f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(training_data_zip,'Training Set')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Training Set\n",
            "CPU times: user 3.64 s, sys: 1.24 s, total: 4.88 s\n",
            "Wall time: 8.39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSeyluknVH4",
        "colab_type": "code",
        "outputId": "114c7a1e-5de3-472e-f261-5b76967c2373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Images')))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOp4JsZ6nXvn",
        "colab_type": "code",
        "outputId": "cb84c67a-10f3-4aa5-9e8b-f7fe74edf93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Annotations')))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvg89mXn8zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset.data_utils import *\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JeHTz3G6Lyj",
        "colab_type": "code",
        "outputId": "27af8587-2072-4d14-a31b-9320eb6e9dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = MyDataset('Training Set',transform=transforms.ToTensor())\n",
        "len(train_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLKMn-5SBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9a9PsyF3dqo",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9x221Ya0RBGO",
        "outputId": "3e89a5e3-44c2-4011-d732-986578699cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "!chmod +x install_dependencies.sh # make shell script executable\n",
        "!./install_dependencies.sh # run the shell script"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.6/dist-packages (1.1.0.post1)\n",
            "Collecting Polygon3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/a0/d07a4f3e80ed7020a33f3111db217f54ac44a485ff45da3c21ce49f65041/Polygon3-3.0.8.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Polygon3\n",
            "  Building wheel for Polygon3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Polygon3: filename=Polygon3-3.0.8-cp36-cp36m-linux_x86_64.whl size=101489 sha256=3ab398658392c0de3b7c042ed154e6316257f9ffa478af0d82bce4a1c698fb1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/32/f1/5525b233996d9d99cbce2f0a8da60d137ddddc555d3e8b0e2a\n",
            "Successfully built Polygon3\n",
            "Installing collected packages: Polygon3\n",
            "Successfully installed Polygon3-3.0.8\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/68/4d/892728b0c14547224f0ac40884e722a3d00cb54e7a146aea0b3186806c9e/colorlog-4.0.2-py2.py3-none-any.whl\n",
            "Installing collected packages: colorlog\n",
            "Successfully installed colorlog-4.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD4GuTKC3wXY",
        "colab_type": "code",
        "outputId": "4526ae23-faeb-44b7-e283-f8e4ef99e163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make: Entering directory '/content/cloned-repo/pse'\n",
            "make: 'pse.so' is up to date.\n",
            "make: Leaving directory '/content/cloned-repo/pse'\n",
            "2019-11-24 09:07:02 \u001b[32mINFO     \u001b[0m utils.py: logger init finished\u001b[0m\n",
            "2019-11-24 09:07:02 \u001b[32mINFO     \u001b[0m train.py: {'Lambda': 0.7,\n",
            " 'OHEM_ratio': 3,\n",
            " 'backbone': 'resnet18',\n",
            " 'checkpoint': '',\n",
            " 'data_shape': 640,\n",
            " 'display_input_images': False,\n",
            " 'display_interval': 10,\n",
            " 'display_output_images': False,\n",
            " 'end_lr': 1e-07,\n",
            " 'epochs': 10,\n",
            " 'gpu_id': '0',\n",
            " 'lr': 0.0001,\n",
            " 'lr_decay_step': [200, 400],\n",
            " 'lr_gamma': 0.1,\n",
            " 'm': 0.5,\n",
            " 'n': 6,\n",
            " 'output_dir': '/content/drive/My Drive/PSENet',\n",
            " 'pretrained': False,\n",
            " 'pretrained_path': '/content/drive/My Drive/PSENet/PSENet_resnet18.pth',\n",
            " 'restart_training': False,\n",
            " 'scale': 1,\n",
            " 'seed': 2,\n",
            " 'show_images_interval': 50,\n",
            " 'start_epoch': 0,\n",
            " 'testroot': 'Test Set',\n",
            " 'train_batch_size': 4,\n",
            " 'trainroot': 'Training Set',\n",
            " 'warm_up_epoch': 6,\n",
            " 'warm_up_lr': 1e-05,\n",
            " 'weight_decay': 0.0005,\n",
            " 'workers': 12}\u001b[0m\n",
            "2019-11-24 09:07:02 \u001b[32mINFO     \u001b[0m train.py: train with gpu 0 and pytorch 1.3.1\u001b[0m\n",
            "2019-11-24 09:07:13 \u001b[32mINFO     \u001b[0m train.py: train dataset has 12500 samples,3125 in dataloader\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "2019-11-24 09:07:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [0/3125], step: 0, 3.824 samples/sec, batch_loss: 0.1188, batch_loss_c: 0.1157, batch_loss_s: 0.1258, time:10.4612, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [10/3125], step: 10, 7.792 samples/sec, batch_loss: 0.0987, batch_loss_c: 0.1055, batch_loss_s: 0.0828, time:5.1333, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [20/3125], step: 20, 7.112 samples/sec, batch_loss: 0.0638, batch_loss_c: 0.0623, batch_loss_s: 0.0675, time:5.6240, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [30/3125], step: 30, 6.919 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0684, batch_loss_s: 0.0802, time:5.7808, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [40/3125], step: 40, 7.666 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1055, batch_loss_s: 0.0959, time:5.2176, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [50/3125], step: 50, 8.391 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0724, batch_loss_s: 0.0893, time:4.7668, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:07:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [60/3125], step: 60, 7.411 samples/sec, batch_loss: 0.0723, batch_loss_c: 0.0693, batch_loss_s: 0.0794, time:5.3973, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [70/3125], step: 70, 8.241 samples/sec, batch_loss: 0.0690, batch_loss_c: 0.0665, batch_loss_s: 0.0747, time:4.8536, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [80/3125], step: 80, 7.998 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1766, batch_loss_s: 0.0902, time:5.0010, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [90/3125], step: 90, 7.807 samples/sec, batch_loss: 0.5438, batch_loss_c: 0.5426, batch_loss_s: 0.5466, time:5.1233, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [100/3125], step: 100, 7.602 samples/sec, batch_loss: 0.0821, batch_loss_c: 0.0876, batch_loss_s: 0.0692, time:5.2620, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [110/3125], step: 110, 7.213 samples/sec, batch_loss: 0.0856, batch_loss_c: 0.0840, batch_loss_s: 0.0894, time:5.5458, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [120/3125], step: 120, 8.471 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0926, batch_loss_s: 0.0842, time:4.7221, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [130/3125], step: 130, 7.915 samples/sec, batch_loss: 0.1377, batch_loss_c: 0.1405, batch_loss_s: 0.1311, time:5.0538, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [140/3125], step: 140, 7.436 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1029, batch_loss_s: 0.1167, time:5.3795, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [150/3125], step: 150, 7.700 samples/sec, batch_loss: 0.3038, batch_loss_c: 0.3037, batch_loss_s: 0.3040, time:5.1951, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [160/3125], step: 160, 7.740 samples/sec, batch_loss: 0.1355, batch_loss_c: 0.1606, batch_loss_s: 0.0770, time:5.1683, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [170/3125], step: 170, 6.245 samples/sec, batch_loss: 0.0616, batch_loss_c: 0.0588, batch_loss_s: 0.0683, time:6.4055, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:08:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [180/3125], step: 180, 6.434 samples/sec, batch_loss: 0.4390, batch_loss_c: 0.4543, batch_loss_s: 0.4035, time:6.2168, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [190/3125], step: 190, 6.196 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0843, batch_loss_s: 0.0738, time:6.4553, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [200/3125], step: 200, 7.929 samples/sec, batch_loss: 0.3507, batch_loss_c: 0.3490, batch_loss_s: 0.3549, time:5.0446, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [210/3125], step: 210, 7.606 samples/sec, batch_loss: 0.3754, batch_loss_c: 0.3204, batch_loss_s: 0.5039, time:5.2591, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [220/3125], step: 220, 7.579 samples/sec, batch_loss: 0.3992, batch_loss_c: 0.4173, batch_loss_s: 0.3570, time:5.2780, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [230/3125], step: 230, 8.129 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1133, batch_loss_s: 0.0932, time:4.9209, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [240/3125], step: 240, 8.475 samples/sec, batch_loss: 0.3053, batch_loss_c: 0.3071, batch_loss_s: 0.3010, time:4.7196, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [250/3125], step: 250, 7.635 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.0972, batch_loss_s: 0.1385, time:5.2391, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [260/3125], step: 260, 7.621 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0710, batch_loss_s: 0.0844, time:5.2488, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [270/3125], step: 270, 7.138 samples/sec, batch_loss: 0.3574, batch_loss_c: 0.3721, batch_loss_s: 0.3231, time:5.6037, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [280/3125], step: 280, 7.875 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0855, batch_loss_s: 0.0838, time:5.0796, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:09:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [290/3125], step: 290, 7.572 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0827, batch_loss_s: 0.0902, time:5.2825, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [300/3125], step: 300, 7.503 samples/sec, batch_loss: 0.0768, batch_loss_c: 0.0752, batch_loss_s: 0.0804, time:5.3311, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [310/3125], step: 310, 7.348 samples/sec, batch_loss: 0.1705, batch_loss_c: 0.1896, batch_loss_s: 0.1261, time:5.4436, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [320/3125], step: 320, 7.661 samples/sec, batch_loss: 0.2345, batch_loss_c: 0.2098, batch_loss_s: 0.2921, time:5.2210, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [330/3125], step: 330, 7.697 samples/sec, batch_loss: 0.3123, batch_loss_c: 0.3162, batch_loss_s: 0.3032, time:5.1969, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [340/3125], step: 340, 7.276 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0946, batch_loss_s: 0.0907, time:5.4974, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [350/3125], step: 350, 7.807 samples/sec, batch_loss: 0.1273, batch_loss_c: 0.1339, batch_loss_s: 0.1119, time:5.1234, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [360/3125], step: 360, 8.198 samples/sec, batch_loss: 0.3266, batch_loss_c: 0.3218, batch_loss_s: 0.3379, time:4.8794, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [370/3125], step: 370, 6.543 samples/sec, batch_loss: 0.1091, batch_loss_c: 0.1078, batch_loss_s: 0.1121, time:6.1138, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [380/3125], step: 380, 6.583 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.0972, batch_loss_s: 0.1248, time:6.0764, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [390/3125], step: 390, 6.834 samples/sec, batch_loss: 0.3465, batch_loss_c: 0.3513, batch_loss_s: 0.3352, time:5.8533, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:10:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [400/3125], step: 400, 7.901 samples/sec, batch_loss: 0.0813, batch_loss_c: 0.0809, batch_loss_s: 0.0824, time:5.0629, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [410/3125], step: 410, 8.019 samples/sec, batch_loss: 0.3044, batch_loss_c: 0.3054, batch_loss_s: 0.3022, time:4.9883, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [420/3125], step: 420, 7.646 samples/sec, batch_loss: 0.3070, batch_loss_c: 0.2931, batch_loss_s: 0.3396, time:5.2313, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [430/3125], step: 430, 7.169 samples/sec, batch_loss: 0.2940, batch_loss_c: 0.2932, batch_loss_s: 0.2959, time:5.5796, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [440/3125], step: 440, 8.118 samples/sec, batch_loss: 0.2583, batch_loss_c: 0.2396, batch_loss_s: 0.3020, time:4.9271, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [450/3125], step: 450, 7.747 samples/sec, batch_loss: 0.0594, batch_loss_c: 0.0569, batch_loss_s: 0.0651, time:5.1630, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [460/3125], step: 460, 8.963 samples/sec, batch_loss: 0.3545, batch_loss_c: 0.3562, batch_loss_s: 0.3506, time:4.4630, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [470/3125], step: 470, 7.963 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0904, batch_loss_s: 0.0852, time:5.0232, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [480/3125], step: 480, 7.646 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0711, batch_loss_s: 0.0716, time:5.2312, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [490/3125], step: 490, 7.369 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0893, batch_loss_s: 0.1075, time:5.4280, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [500/3125], step: 500, 7.884 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1875, batch_loss_s: 0.0871, time:5.0735, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [510/3125], step: 510, 8.024 samples/sec, batch_loss: 0.2902, batch_loss_c: 0.3559, batch_loss_s: 0.1368, time:4.9850, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:11:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [520/3125], step: 520, 7.716 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0836, batch_loss_s: 0.0980, time:5.1842, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [530/3125], step: 530, 8.121 samples/sec, batch_loss: 0.3087, batch_loss_c: 0.3017, batch_loss_s: 0.3249, time:4.9257, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [540/3125], step: 540, 8.187 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0586, batch_loss_s: 0.0727, time:4.8860, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [550/3125], step: 550, 7.245 samples/sec, batch_loss: 0.3253, batch_loss_c: 0.3335, batch_loss_s: 0.3060, time:5.5214, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [560/3125], step: 560, 7.974 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0706, batch_loss_s: 0.0943, time:5.0163, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [570/3125], step: 570, 8.438 samples/sec, batch_loss: 0.2805, batch_loss_c: 0.2816, batch_loss_s: 0.2779, time:4.7407, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [580/3125], step: 580, 7.911 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.0931, batch_loss_s: 0.1255, time:5.0560, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [590/3125], step: 590, 8.363 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0564, batch_loss_s: 0.0718, time:4.7827, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [600/3125], step: 600, 8.388 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0978, batch_loss_s: 0.0715, time:4.7688, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [610/3125], step: 610, 8.304 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0721, batch_loss_s: 0.0914, time:4.8168, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [620/3125], step: 620, 7.394 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0778, batch_loss_s: 0.0863, time:5.4096, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [630/3125], step: 630, 7.604 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0762, batch_loss_s: 0.0835, time:5.2603, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:12:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [640/3125], step: 640, 7.504 samples/sec, batch_loss: 0.1675, batch_loss_c: 0.1806, batch_loss_s: 0.1370, time:5.3308, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [650/3125], step: 650, 7.374 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0747, batch_loss_s: 0.0889, time:5.4245, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [660/3125], step: 660, 7.522 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1087, batch_loss_s: 0.1037, time:5.3178, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [670/3125], step: 670, 7.732 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0813, batch_loss_s: 0.0756, time:5.1735, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [680/3125], step: 680, 8.308 samples/sec, batch_loss: 0.3089, batch_loss_c: 0.3142, batch_loss_s: 0.2967, time:4.8148, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [690/3125], step: 690, 7.899 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1220, batch_loss_s: 0.0691, time:5.0641, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [700/3125], step: 700, 6.946 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0685, batch_loss_s: 0.0914, time:5.7583, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [710/3125], step: 710, 7.689 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0655, batch_loss_s: 0.0580, time:5.2020, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [720/3125], step: 720, 7.575 samples/sec, batch_loss: 0.3760, batch_loss_c: 0.3972, batch_loss_s: 0.3266, time:5.2807, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [730/3125], step: 730, 7.768 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1036, batch_loss_s: 0.1104, time:5.1494, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [740/3125], step: 740, 7.818 samples/sec, batch_loss: 0.2870, batch_loss_c: 0.2749, batch_loss_s: 0.3153, time:5.1166, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:13:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [750/3125], step: 750, 7.849 samples/sec, batch_loss: 0.2989, batch_loss_c: 0.2969, batch_loss_s: 0.3034, time:5.0965, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [760/3125], step: 760, 7.591 samples/sec, batch_loss: 0.3466, batch_loss_c: 0.3478, batch_loss_s: 0.3438, time:5.2696, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [770/3125], step: 770, 6.842 samples/sec, batch_loss: 0.3478, batch_loss_c: 0.3691, batch_loss_s: 0.2979, time:5.8463, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [780/3125], step: 780, 8.027 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0594, batch_loss_s: 0.1195, time:4.9834, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [790/3125], step: 790, 6.588 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0859, batch_loss_s: 0.1177, time:6.0720, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [800/3125], step: 800, 8.313 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0959, batch_loss_s: 0.0878, time:4.8116, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [810/3125], step: 810, 8.133 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.1087, batch_loss_s: 0.0819, time:4.9185, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [820/3125], step: 820, 7.594 samples/sec, batch_loss: 0.3649, batch_loss_c: 0.3804, batch_loss_s: 0.3289, time:5.2671, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [830/3125], step: 830, 7.299 samples/sec, batch_loss: 0.0614, batch_loss_c: 0.0576, batch_loss_s: 0.0702, time:5.4804, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [840/3125], step: 840, 7.537 samples/sec, batch_loss: 0.1069, batch_loss_c: 0.1033, batch_loss_s: 0.1151, time:5.3070, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [850/3125], step: 850, 6.477 samples/sec, batch_loss: 0.1404, batch_loss_c: 0.1423, batch_loss_s: 0.1361, time:6.1757, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:14:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [860/3125], step: 860, 7.703 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0909, batch_loss_s: 0.0896, time:5.1930, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [870/3125], step: 870, 7.037 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0852, batch_loss_s: 0.0815, time:5.6843, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [880/3125], step: 880, 7.286 samples/sec, batch_loss: 0.1233, batch_loss_c: 0.1369, batch_loss_s: 0.0916, time:5.4899, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [890/3125], step: 890, 7.211 samples/sec, batch_loss: 0.2867, batch_loss_c: 0.2797, batch_loss_s: 0.3032, time:5.5472, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [900/3125], step: 900, 7.233 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1118, batch_loss_s: 0.0910, time:5.5301, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [910/3125], step: 910, 7.521 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.1079, batch_loss_s: 0.0867, time:5.3184, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [920/3125], step: 920, 8.228 samples/sec, batch_loss: 0.3156, batch_loss_c: 0.3108, batch_loss_s: 0.3267, time:4.8614, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [930/3125], step: 930, 7.435 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1188, batch_loss_s: 0.0998, time:5.3798, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [940/3125], step: 940, 7.735 samples/sec, batch_loss: 0.3932, batch_loss_c: 0.4236, batch_loss_s: 0.3224, time:5.1713, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [950/3125], step: 950, 8.481 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0610, batch_loss_s: 0.0670, time:4.7163, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [960/3125], step: 960, 8.169 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0700, batch_loss_s: 0.0758, time:4.8966, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [970/3125], step: 970, 7.816 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1285, batch_loss_s: 0.1294, time:5.1179, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:15:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [980/3125], step: 980, 8.017 samples/sec, batch_loss: 0.0680, batch_loss_c: 0.0646, batch_loss_s: 0.0761, time:4.9893, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [990/3125], step: 990, 8.705 samples/sec, batch_loss: 0.3590, batch_loss_c: 0.3610, batch_loss_s: 0.3543, time:4.5949, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1000/3125], step: 1000, 6.705 samples/sec, batch_loss: 0.1475, batch_loss_c: 0.1501, batch_loss_s: 0.1416, time:5.9658, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1010/3125], step: 1010, 7.589 samples/sec, batch_loss: 0.2337, batch_loss_c: 0.2847, batch_loss_s: 0.1148, time:5.2710, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1020/3125], step: 1020, 8.294 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0717, batch_loss_s: 0.0541, time:4.8229, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1030/3125], step: 1030, 8.623 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1720, batch_loss_s: 0.1101, time:4.6387, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1040/3125], step: 1040, 7.072 samples/sec, batch_loss: 0.2692, batch_loss_c: 0.2486, batch_loss_s: 0.3173, time:5.6561, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1050/3125], step: 1050, 7.817 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1046, batch_loss_s: 0.0828, time:5.1173, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1060/3125], step: 1060, 7.837 samples/sec, batch_loss: 0.3093, batch_loss_c: 0.3065, batch_loss_s: 0.3158, time:5.1040, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1070/3125], step: 1070, 6.723 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0581, batch_loss_s: 0.0735, time:5.9493, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1080/3125], step: 1080, 7.424 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0808, batch_loss_s: 0.1099, time:5.3877, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:16:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1090/3125], step: 1090, 6.803 samples/sec, batch_loss: 0.3214, batch_loss_c: 0.3201, batch_loss_s: 0.3243, time:5.8798, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1100/3125], step: 1100, 7.843 samples/sec, batch_loss: 0.3165, batch_loss_c: 0.3124, batch_loss_s: 0.3262, time:5.0999, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1110/3125], step: 1110, 7.256 samples/sec, batch_loss: 0.1675, batch_loss_c: 0.1744, batch_loss_s: 0.1516, time:5.5128, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1120/3125], step: 1120, 7.294 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3027, batch_loss_s: 0.3419, time:5.4840, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1130/3125], step: 1130, 6.669 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0987, batch_loss_s: 0.0916, time:5.9981, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1140/3125], step: 1140, 7.202 samples/sec, batch_loss: 0.2805, batch_loss_c: 0.2649, batch_loss_s: 0.3170, time:5.5537, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1150/3125], step: 1150, 8.009 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3490, batch_loss_s: 0.3470, time:4.9945, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1160/3125], step: 1160, 6.720 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1150, batch_loss_s: 0.1092, time:5.9520, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1170/3125], step: 1170, 7.305 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0759, batch_loss_s: 0.0813, time:5.4756, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1180/3125], step: 1180, 7.910 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.0913, batch_loss_s: 0.0920, time:5.0569, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1190/3125], step: 1190, 7.547 samples/sec, batch_loss: 0.0937, batch_loss_c: 0.0975, batch_loss_s: 0.0850, time:5.2999, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:17:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1200/3125], step: 1200, 7.122 samples/sec, batch_loss: 0.1043, batch_loss_c: 0.1073, batch_loss_s: 0.0973, time:5.6161, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1210/3125], step: 1210, 7.927 samples/sec, batch_loss: 0.1003, batch_loss_c: 0.0810, batch_loss_s: 0.1454, time:5.0461, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1220/3125], step: 1220, 7.917 samples/sec, batch_loss: 0.0638, batch_loss_c: 0.0593, batch_loss_s: 0.0744, time:5.0524, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1230/3125], step: 1230, 7.734 samples/sec, batch_loss: 0.1734, batch_loss_c: 0.1829, batch_loss_s: 0.1512, time:5.1721, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1240/3125], step: 1240, 7.916 samples/sec, batch_loss: 0.0566, batch_loss_c: 0.0507, batch_loss_s: 0.0702, time:5.0529, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1250/3125], step: 1250, 7.814 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0717, batch_loss_s: 0.0804, time:5.1189, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1260/3125], step: 1260, 8.321 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0590, batch_loss_s: 0.0686, time:4.8072, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1270/3125], step: 1270, 8.227 samples/sec, batch_loss: 0.1427, batch_loss_c: 0.1499, batch_loss_s: 0.1260, time:4.8620, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1280/3125], step: 1280, 8.775 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1315, batch_loss_s: 0.1031, time:4.5585, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1290/3125], step: 1290, 8.865 samples/sec, batch_loss: 0.2727, batch_loss_c: 0.2625, batch_loss_s: 0.2967, time:4.5121, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1300/3125], step: 1300, 9.116 samples/sec, batch_loss: 0.2585, batch_loss_c: 0.2277, batch_loss_s: 0.3305, time:4.3880, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1310/3125], step: 1310, 8.333 samples/sec, batch_loss: 0.1747, batch_loss_c: 0.1858, batch_loss_s: 0.1490, time:4.8002, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:18:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1320/3125], step: 1320, 8.038 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0567, batch_loss_s: 0.0713, time:4.9761, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1330/3125], step: 1330, 8.152 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0939, batch_loss_s: 0.0868, time:4.9066, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1340/3125], step: 1340, 8.045 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.0894, batch_loss_s: 0.1137, time:4.9722, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1350/3125], step: 1350, 8.192 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1553, batch_loss_s: 0.0603, time:4.8828, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1360/3125], step: 1360, 8.732 samples/sec, batch_loss: 0.0587, batch_loss_c: 0.0555, batch_loss_s: 0.0663, time:4.5809, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1370/3125], step: 1370, 8.475 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0918, batch_loss_s: 0.0829, time:4.7200, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1380/3125], step: 1380, 8.554 samples/sec, batch_loss: 0.1320, batch_loss_c: 0.1317, batch_loss_s: 0.1327, time:4.6763, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1390/3125], step: 1390, 7.686 samples/sec, batch_loss: 0.3044, batch_loss_c: 0.3044, batch_loss_s: 0.3044, time:5.2044, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1400/3125], step: 1400, 7.765 samples/sec, batch_loss: 0.3891, batch_loss_c: 0.3281, batch_loss_s: 0.5315, time:5.1511, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1410/3125], step: 1410, 8.601 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0742, batch_loss_s: 0.0912, time:4.6507, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1420/3125], step: 1420, 7.435 samples/sec, batch_loss: 0.2035, batch_loss_c: 0.2469, batch_loss_s: 0.1023, time:5.3799, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1430/3125], step: 1430, 7.693 samples/sec, batch_loss: 0.3438, batch_loss_c: 0.3464, batch_loss_s: 0.3378, time:5.1996, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:19:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1440/3125], step: 1440, 7.642 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0833, batch_loss_s: 0.0853, time:5.2342, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1450/3125], step: 1450, 7.479 samples/sec, batch_loss: 0.5203, batch_loss_c: 0.5017, batch_loss_s: 0.5636, time:5.3481, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1460/3125], step: 1460, 7.165 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1484, batch_loss_s: 0.1023, time:5.5828, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1470/3125], step: 1470, 6.964 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.0893, batch_loss_s: 0.1079, time:5.7435, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1480/3125], step: 1480, 7.727 samples/sec, batch_loss: 0.2970, batch_loss_c: 0.2823, batch_loss_s: 0.3314, time:5.1763, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1490/3125], step: 1490, 7.739 samples/sec, batch_loss: 0.3140, batch_loss_c: 0.3124, batch_loss_s: 0.3180, time:5.1685, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1500/3125], step: 1500, 6.978 samples/sec, batch_loss: 0.3848, batch_loss_c: 0.3856, batch_loss_s: 0.3829, time:5.7322, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1510/3125], step: 1510, 7.762 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0589, batch_loss_s: 0.0732, time:5.1536, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1520/3125], step: 1520, 7.018 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0754, batch_loss_s: 0.0876, time:5.6992, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1530/3125], step: 1530, 8.353 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0982, batch_loss_s: 0.0915, time:4.7884, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1540/3125], step: 1540, 6.549 samples/sec, batch_loss: 0.1760, batch_loss_c: 0.1661, batch_loss_s: 0.1992, time:6.1078, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1550/3125], step: 1550, 7.568 samples/sec, batch_loss: 0.0691, batch_loss_c: 0.0641, batch_loss_s: 0.0808, time:5.2853, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:20:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1560/3125], step: 1560, 8.804 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.1052, batch_loss_s: 0.0664, time:4.5435, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1570/3125], step: 1570, 8.330 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0811, batch_loss_s: 0.0688, time:4.8022, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1580/3125], step: 1580, 6.989 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0799, batch_loss_s: 0.0881, time:5.7231, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1590/3125], step: 1590, 8.043 samples/sec, batch_loss: 0.3529, batch_loss_c: 0.3683, batch_loss_s: 0.3171, time:4.9732, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1600/3125], step: 1600, 8.262 samples/sec, batch_loss: 0.0751, batch_loss_c: 0.0710, batch_loss_s: 0.0845, time:4.8412, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1610/3125], step: 1610, 7.660 samples/sec, batch_loss: 0.1745, batch_loss_c: 0.2011, batch_loss_s: 0.1126, time:5.2220, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1620/3125], step: 1620, 7.816 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.1147, batch_loss_s: 0.0631, time:5.1177, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1630/3125], step: 1630, 6.956 samples/sec, batch_loss: 0.1128, batch_loss_c: 0.1157, batch_loss_s: 0.1061, time:5.7507, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1640/3125], step: 1640, 7.649 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1122, batch_loss_s: 0.1371, time:5.2297, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1650/3125], step: 1650, 7.539 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1058, batch_loss_s: 0.0895, time:5.3055, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1660/3125], step: 1660, 7.657 samples/sec, batch_loss: 0.1135, batch_loss_c: 0.1185, batch_loss_s: 0.1018, time:5.2240, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:21:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1670/3125], step: 1670, 8.156 samples/sec, batch_loss: 0.0949, batch_loss_c: 0.0984, batch_loss_s: 0.0867, time:4.9042, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1680/3125], step: 1680, 7.836 samples/sec, batch_loss: 0.2975, batch_loss_c: 0.2945, batch_loss_s: 0.3045, time:5.1044, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1690/3125], step: 1690, 6.985 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1030, batch_loss_s: 0.1016, time:5.7263, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1700/3125], step: 1700, 7.556 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.1004, batch_loss_s: 0.0646, time:5.2937, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1710/3125], step: 1710, 6.832 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0587, batch_loss_s: 0.0762, time:5.8548, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1720/3125], step: 1720, 8.333 samples/sec, batch_loss: 0.1031, batch_loss_c: 0.1022, batch_loss_s: 0.1052, time:4.8003, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1730/3125], step: 1730, 7.316 samples/sec, batch_loss: 0.2876, batch_loss_c: 0.2850, batch_loss_s: 0.2936, time:5.4672, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1740/3125], step: 1740, 7.728 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0786, batch_loss_s: 0.0678, time:5.1762, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1750/3125], step: 1750, 8.662 samples/sec, batch_loss: 0.0744, batch_loss_c: 0.0701, batch_loss_s: 0.0842, time:4.6178, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1760/3125], step: 1760, 8.029 samples/sec, batch_loss: 0.1526, batch_loss_c: 0.1542, batch_loss_s: 0.1489, time:4.9817, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1770/3125], step: 1770, 8.308 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0838, batch_loss_s: 0.0839, time:4.8146, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1780/3125], step: 1780, 7.978 samples/sec, batch_loss: 0.1043, batch_loss_c: 0.1125, batch_loss_s: 0.0851, time:5.0135, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:22:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1790/3125], step: 1790, 8.189 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0914, batch_loss_s: 0.0904, time:4.8845, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1800/3125], step: 1800, 7.142 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0993, batch_loss_s: 0.0904, time:5.6007, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1810/3125], step: 1810, 7.960 samples/sec, batch_loss: 0.5289, batch_loss_c: 0.5266, batch_loss_s: 0.5341, time:5.0248, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1820/3125], step: 1820, 8.218 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0808, batch_loss_s: 0.0702, time:4.8674, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1830/3125], step: 1830, 7.271 samples/sec, batch_loss: 0.3076, batch_loss_c: 0.3096, batch_loss_s: 0.3030, time:5.5012, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1840/3125], step: 1840, 7.166 samples/sec, batch_loss: 0.3786, batch_loss_c: 0.3794, batch_loss_s: 0.3767, time:5.5820, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1850/3125], step: 1850, 8.093 samples/sec, batch_loss: 0.0763, batch_loss_c: 0.0809, batch_loss_s: 0.0656, time:4.9425, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1860/3125], step: 1860, 8.508 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0796, batch_loss_s: 0.0862, time:4.7015, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1870/3125], step: 1870, 7.164 samples/sec, batch_loss: 0.3199, batch_loss_c: 0.3168, batch_loss_s: 0.3271, time:5.5833, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1880/3125], step: 1880, 8.228 samples/sec, batch_loss: 0.3102, batch_loss_c: 0.3089, batch_loss_s: 0.3133, time:4.8617, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1890/3125], step: 1890, 8.582 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.1045, batch_loss_s: 0.0711, time:4.6609, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1900/3125], step: 1900, 8.678 samples/sec, batch_loss: 0.4884, batch_loss_c: 0.4930, batch_loss_s: 0.4777, time:4.6092, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:23:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1910/3125], step: 1910, 7.939 samples/sec, batch_loss: 0.0568, batch_loss_c: 0.0542, batch_loss_s: 0.0628, time:5.0387, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1920/3125], step: 1920, 7.740 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1344, batch_loss_s: 0.0991, time:5.1681, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1930/3125], step: 1930, 7.539 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1131, batch_loss_s: 0.1249, time:5.3058, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1940/3125], step: 1940, 7.683 samples/sec, batch_loss: 0.3201, batch_loss_c: 0.3162, batch_loss_s: 0.3292, time:5.2066, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1950/3125], step: 1950, 8.257 samples/sec, batch_loss: 0.1193, batch_loss_c: 0.1292, batch_loss_s: 0.0962, time:4.8446, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1960/3125], step: 1960, 8.024 samples/sec, batch_loss: 0.3030, batch_loss_c: 0.3000, batch_loss_s: 0.3099, time:4.9852, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1970/3125], step: 1970, 8.122 samples/sec, batch_loss: 0.2986, batch_loss_c: 0.2933, batch_loss_s: 0.3109, time:4.9251, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1980/3125], step: 1980, 7.281 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1084, batch_loss_s: 0.1184, time:5.4937, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1990/3125], step: 1990, 8.442 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0775, batch_loss_s: 0.0731, time:4.7381, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2000/3125], step: 2000, 7.166 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1026, batch_loss_s: 0.1013, time:5.5817, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2010/3125], step: 2010, 7.944 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0930, batch_loss_s: 0.0863, time:5.0351, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:24:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2020/3125], step: 2020, 7.331 samples/sec, batch_loss: 0.1370, batch_loss_c: 0.1458, batch_loss_s: 0.1164, time:5.4559, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2030/3125], step: 2030, 7.926 samples/sec, batch_loss: 0.0510, batch_loss_c: 0.0475, batch_loss_s: 0.0593, time:5.0469, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2040/3125], step: 2040, 7.612 samples/sec, batch_loss: 0.0977, batch_loss_c: 0.0998, batch_loss_s: 0.0929, time:5.2546, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2050/3125], step: 2050, 6.833 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0846, batch_loss_s: 0.0915, time:5.8543, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2060/3125], step: 2060, 7.659 samples/sec, batch_loss: 0.0844, batch_loss_c: 0.0839, batch_loss_s: 0.0855, time:5.2223, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2070/3125], step: 2070, 7.505 samples/sec, batch_loss: 0.1194, batch_loss_c: 0.1218, batch_loss_s: 0.1135, time:5.3301, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2080/3125], step: 2080, 7.941 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0707, batch_loss_s: 0.0908, time:5.0369, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2090/3125], step: 2090, 8.319 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0797, batch_loss_s: 0.0731, time:4.8082, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2100/3125], step: 2100, 8.027 samples/sec, batch_loss: 0.2932, batch_loss_c: 0.2843, batch_loss_s: 0.3141, time:4.9834, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2110/3125], step: 2110, 7.123 samples/sec, batch_loss: 0.1341, batch_loss_c: 0.1334, batch_loss_s: 0.1358, time:5.6160, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2120/3125], step: 2120, 8.015 samples/sec, batch_loss: 0.2363, batch_loss_c: 0.1957, batch_loss_s: 0.3311, time:4.9904, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2130/3125], step: 2130, 8.023 samples/sec, batch_loss: 0.0434, batch_loss_c: 0.0384, batch_loss_s: 0.0553, time:4.9855, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:25:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2140/3125], step: 2140, 6.894 samples/sec, batch_loss: 0.1213, batch_loss_c: 0.1371, batch_loss_s: 0.0845, time:5.8019, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2150/3125], step: 2150, 8.483 samples/sec, batch_loss: 0.2993, batch_loss_c: 0.2911, batch_loss_s: 0.3183, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2160/3125], step: 2160, 7.898 samples/sec, batch_loss: 0.3247, batch_loss_c: 0.3230, batch_loss_s: 0.3288, time:5.0649, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2170/3125], step: 2170, 8.034 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.0932, batch_loss_s: 0.1184, time:4.9786, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2180/3125], step: 2180, 8.669 samples/sec, batch_loss: 0.1380, batch_loss_c: 0.1408, batch_loss_s: 0.1314, time:4.6140, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2190/3125], step: 2190, 7.802 samples/sec, batch_loss: 0.1062, batch_loss_c: 0.1132, batch_loss_s: 0.0899, time:5.1271, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2200/3125], step: 2200, 8.870 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0877, batch_loss_s: 0.0986, time:4.5094, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2210/3125], step: 2210, 8.470 samples/sec, batch_loss: 0.3326, batch_loss_c: 0.3334, batch_loss_s: 0.3306, time:4.7224, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2220/3125], step: 2220, 8.695 samples/sec, batch_loss: 0.0566, batch_loss_c: 0.0541, batch_loss_s: 0.0626, time:4.6004, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2230/3125], step: 2230, 7.964 samples/sec, batch_loss: 0.3155, batch_loss_c: 0.3192, batch_loss_s: 0.3070, time:5.0223, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2240/3125], step: 2240, 7.791 samples/sec, batch_loss: 0.0691, batch_loss_c: 0.0638, batch_loss_s: 0.0816, time:5.1342, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2250/3125], step: 2250, 8.542 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0925, batch_loss_s: 0.1179, time:4.6830, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:26:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2260/3125], step: 2260, 8.629 samples/sec, batch_loss: 0.1524, batch_loss_c: 0.1814, batch_loss_s: 0.0846, time:4.6355, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2270/3125], step: 2270, 7.393 samples/sec, batch_loss: 0.4091, batch_loss_c: 0.4436, batch_loss_s: 0.3285, time:5.4107, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2280/3125], step: 2280, 8.469 samples/sec, batch_loss: 0.1520, batch_loss_c: 0.1586, batch_loss_s: 0.1368, time:4.7234, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2290/3125], step: 2290, 8.114 samples/sec, batch_loss: 0.1847, batch_loss_c: 0.1937, batch_loss_s: 0.1639, time:4.9296, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2300/3125], step: 2300, 7.883 samples/sec, batch_loss: 0.2515, batch_loss_c: 0.2566, batch_loss_s: 0.2395, time:5.0745, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2310/3125], step: 2310, 7.089 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.0969, batch_loss_s: 0.1120, time:5.6424, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2320/3125], step: 2320, 8.866 samples/sec, batch_loss: 0.2514, batch_loss_c: 0.2532, batch_loss_s: 0.2471, time:4.5116, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2330/3125], step: 2330, 8.258 samples/sec, batch_loss: 0.1057, batch_loss_c: 0.0991, batch_loss_s: 0.1209, time:4.8437, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2340/3125], step: 2340, 7.986 samples/sec, batch_loss: 0.1972, batch_loss_c: 0.2426, batch_loss_s: 0.0913, time:5.0090, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2350/3125], step: 2350, 8.295 samples/sec, batch_loss: 0.2677, batch_loss_c: 0.2515, batch_loss_s: 0.3055, time:4.8224, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2360/3125], step: 2360, 8.354 samples/sec, batch_loss: 0.5349, batch_loss_c: 0.5327, batch_loss_s: 0.5401, time:4.7884, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2370/3125], step: 2370, 8.789 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1296, batch_loss_s: 0.1981, time:4.5511, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:27:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2380/3125], step: 2380, 7.512 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0815, batch_loss_s: 0.0790, time:5.3251, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2390/3125], step: 2390, 8.336 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0741, batch_loss_s: 0.0800, time:4.7985, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2400/3125], step: 2400, 8.688 samples/sec, batch_loss: 0.2797, batch_loss_c: 0.2677, batch_loss_s: 0.3076, time:4.6043, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2410/3125], step: 2410, 7.925 samples/sec, batch_loss: 0.0814, batch_loss_c: 0.0867, batch_loss_s: 0.0691, time:5.0475, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2420/3125], step: 2420, 8.716 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0799, batch_loss_s: 0.0597, time:4.5894, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2430/3125], step: 2430, 8.589 samples/sec, batch_loss: 0.1265, batch_loss_c: 0.1418, batch_loss_s: 0.0907, time:4.6571, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2440/3125], step: 2440, 8.093 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0738, batch_loss_s: 0.0920, time:4.9426, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2450/3125], step: 2450, 7.806 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0820, batch_loss_s: 0.0981, time:5.1243, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2460/3125], step: 2460, 8.176 samples/sec, batch_loss: 0.2871, batch_loss_c: 0.2749, batch_loss_s: 0.3155, time:4.8923, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2470/3125], step: 2470, 7.445 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1005, batch_loss_s: 0.1281, time:5.3728, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2480/3125], step: 2480, 8.322 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0729, batch_loss_s: 0.0808, time:4.8063, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2490/3125], step: 2490, 8.302 samples/sec, batch_loss: 0.3407, batch_loss_c: 0.3470, batch_loss_s: 0.3262, time:4.8179, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2500/3125], step: 2500, 8.736 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0855, batch_loss_s: 0.0749, time:4.5786, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:28:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2510/3125], step: 2510, 8.523 samples/sec, batch_loss: 0.2797, batch_loss_c: 0.2613, batch_loss_s: 0.3227, time:4.6934, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2520/3125], step: 2520, 8.275 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0687, batch_loss_s: 0.0752, time:4.8339, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2530/3125], step: 2530, 8.110 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2517, batch_loss_s: 0.0899, time:4.9322, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2540/3125], step: 2540, 8.302 samples/sec, batch_loss: 0.1720, batch_loss_c: 0.1817, batch_loss_s: 0.1495, time:4.8182, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2550/3125], step: 2550, 9.095 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1021, batch_loss_s: 0.0981, time:4.3978, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2560/3125], step: 2560, 8.813 samples/sec, batch_loss: 0.0846, batch_loss_c: 0.0863, batch_loss_s: 0.0807, time:4.5389, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2570/3125], step: 2570, 8.751 samples/sec, batch_loss: 0.1386, batch_loss_c: 0.1681, batch_loss_s: 0.0698, time:4.5709, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2580/3125], step: 2580, 7.450 samples/sec, batch_loss: 0.1336, batch_loss_c: 0.1494, batch_loss_s: 0.0966, time:5.3695, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2590/3125], step: 2590, 8.694 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0721, batch_loss_s: 0.0753, time:4.6007, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2600/3125], step: 2600, 7.776 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1043, batch_loss_s: 0.1133, time:5.1441, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2610/3125], step: 2610, 8.802 samples/sec, batch_loss: 0.1615, batch_loss_c: 0.1557, batch_loss_s: 0.1751, time:4.5446, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2620/3125], step: 2620, 8.369 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0759, batch_loss_s: 0.0767, time:4.7794, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:29:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2630/3125], step: 2630, 8.011 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1186, batch_loss_s: 0.1152, time:4.9932, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2640/3125], step: 2640, 8.585 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.3112, batch_loss_s: 0.3012, time:4.6591, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2650/3125], step: 2650, 8.896 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1149, batch_loss_s: 0.0893, time:4.4963, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2660/3125], step: 2660, 8.035 samples/sec, batch_loss: 0.1189, batch_loss_c: 0.1113, batch_loss_s: 0.1365, time:4.9784, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2670/3125], step: 2670, 8.106 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1026, batch_loss_s: 0.1180, time:4.9345, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2680/3125], step: 2680, 8.158 samples/sec, batch_loss: 0.1045, batch_loss_c: 0.1041, batch_loss_s: 0.1054, time:4.9033, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2690/3125], step: 2690, 8.483 samples/sec, batch_loss: 0.0848, batch_loss_c: 0.0919, batch_loss_s: 0.0682, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2700/3125], step: 2700, 7.886 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1311, batch_loss_s: 0.0930, time:5.0720, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2710/3125], step: 2710, 7.207 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0696, batch_loss_s: 0.0730, time:5.5503, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2720/3125], step: 2720, 7.581 samples/sec, batch_loss: 0.1157, batch_loss_c: 0.1222, batch_loss_s: 0.1004, time:5.2763, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2730/3125], step: 2730, 7.605 samples/sec, batch_loss: 0.2738, batch_loss_c: 0.3219, batch_loss_s: 0.1615, time:5.2600, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2740/3125], step: 2740, 7.683 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0589, batch_loss_s: 0.0683, time:5.2061, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:30:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2750/3125], step: 2750, 6.961 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0869, batch_loss_s: 0.0973, time:5.7464, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2760/3125], step: 2760, 8.473 samples/sec, batch_loss: 0.3401, batch_loss_c: 0.3523, batch_loss_s: 0.3116, time:4.7207, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2770/3125], step: 2770, 7.906 samples/sec, batch_loss: 0.1791, batch_loss_c: 0.1855, batch_loss_s: 0.1642, time:5.0594, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2780/3125], step: 2780, 8.057 samples/sec, batch_loss: 0.1157, batch_loss_c: 0.1126, batch_loss_s: 0.1228, time:4.9645, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2790/3125], step: 2790, 8.289 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.1052, batch_loss_s: 0.0884, time:4.8257, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2800/3125], step: 2800, 8.248 samples/sec, batch_loss: 0.1291, batch_loss_c: 0.1189, batch_loss_s: 0.1529, time:4.8498, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2810/3125], step: 2810, 7.818 samples/sec, batch_loss: 0.1512, batch_loss_c: 0.1443, batch_loss_s: 0.1675, time:5.1165, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2820/3125], step: 2820, 8.389 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1159, batch_loss_s: 0.1160, time:4.7681, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2830/3125], step: 2830, 7.544 samples/sec, batch_loss: 0.1751, batch_loss_c: 0.2054, batch_loss_s: 0.1044, time:5.3023, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2840/3125], step: 2840, 7.596 samples/sec, batch_loss: 0.0996, batch_loss_c: 0.1068, batch_loss_s: 0.0830, time:5.2658, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2850/3125], step: 2850, 7.756 samples/sec, batch_loss: 0.4143, batch_loss_c: 0.4376, batch_loss_s: 0.3599, time:5.1573, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2860/3125], step: 2860, 7.476 samples/sec, batch_loss: 0.3432, batch_loss_c: 0.3390, batch_loss_s: 0.3531, time:5.3503, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:31:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2870/3125], step: 2870, 8.925 samples/sec, batch_loss: 0.1027, batch_loss_c: 0.1094, batch_loss_s: 0.0871, time:4.4816, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2880/3125], step: 2880, 8.616 samples/sec, batch_loss: 0.1853, batch_loss_c: 0.1984, batch_loss_s: 0.1545, time:4.6425, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2890/3125], step: 2890, 7.474 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1404, batch_loss_s: 0.0644, time:5.3522, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2900/3125], step: 2900, 8.704 samples/sec, batch_loss: 0.0542, batch_loss_c: 0.0514, batch_loss_s: 0.0606, time:4.5956, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2910/3125], step: 2910, 8.202 samples/sec, batch_loss: 0.2913, batch_loss_c: 0.2893, batch_loss_s: 0.2960, time:4.8770, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2920/3125], step: 2920, 7.211 samples/sec, batch_loss: 0.3153, batch_loss_c: 0.3138, batch_loss_s: 0.3187, time:5.5471, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2930/3125], step: 2930, 7.145 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0844, batch_loss_s: 0.0982, time:5.5986, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2940/3125], step: 2940, 8.296 samples/sec, batch_loss: 0.2927, batch_loss_c: 0.2891, batch_loss_s: 0.3011, time:4.8218, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2950/3125], step: 2950, 8.301 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0979, batch_loss_s: 0.0909, time:4.8187, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2960/3125], step: 2960, 9.019 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1161, batch_loss_s: 0.1040, time:4.4352, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2970/3125], step: 2970, 7.121 samples/sec, batch_loss: 0.1130, batch_loss_c: 0.1288, batch_loss_s: 0.0760, time:5.6169, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2980/3125], step: 2980, 9.026 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1034, batch_loss_s: 0.1205, time:4.4316, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:32:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2990/3125], step: 2990, 9.041 samples/sec, batch_loss: 0.1439, batch_loss_c: 0.1366, batch_loss_s: 0.1609, time:4.4245, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3000/3125], step: 3000, 8.002 samples/sec, batch_loss: 0.1522, batch_loss_c: 0.1698, batch_loss_s: 0.1109, time:4.9987, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3010/3125], step: 3010, 8.889 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0838, batch_loss_s: 0.0946, time:4.4999, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3020/3125], step: 3020, 8.481 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1056, batch_loss_s: 0.1007, time:4.7165, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3030/3125], step: 3030, 7.916 samples/sec, batch_loss: 0.3230, batch_loss_c: 0.3151, batch_loss_s: 0.3416, time:5.0532, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3040/3125], step: 3040, 8.983 samples/sec, batch_loss: 0.2804, batch_loss_c: 0.2772, batch_loss_s: 0.2878, time:4.4529, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3050/3125], step: 3050, 7.608 samples/sec, batch_loss: 0.1054, batch_loss_c: 0.1084, batch_loss_s: 0.0985, time:5.2575, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3060/3125], step: 3060, 7.601 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1260, batch_loss_s: 0.0807, time:5.2622, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3070/3125], step: 3070, 7.944 samples/sec, batch_loss: 0.0730, batch_loss_c: 0.0691, batch_loss_s: 0.0820, time:5.0350, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3080/3125], step: 3080, 7.836 samples/sec, batch_loss: 0.2706, batch_loss_c: 0.2439, batch_loss_s: 0.3328, time:5.1047, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3090/3125], step: 3090, 7.747 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0901, batch_loss_s: 0.0877, time:5.1631, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3100/3125], step: 3100, 8.406 samples/sec, batch_loss: 0.1024, batch_loss_c: 0.1008, batch_loss_s: 0.1060, time:4.7583, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3110/3125], step: 3110, 10.147 samples/sec, batch_loss: 0.3163, batch_loss_c: 0.3124, batch_loss_s: 0.3254, time:3.9422, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:33:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3120/3125], step: 3120, 10.053 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.1042, batch_loss_s: 0.0591, time:3.9790, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], train_loss: 0.1710, time: 1607.7008, lr: 0.0001\u001b[0m\n",
            "2019-11-24 09:34:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [0/3125], step: 3125, 8.314 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1323, batch_loss_s: 0.0922, time:4.8111, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [10/3125], step: 3135, 6.845 samples/sec, batch_loss: 0.2550, batch_loss_c: 0.2504, batch_loss_s: 0.2659, time:5.8441, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [20/3125], step: 3145, 7.984 samples/sec, batch_loss: 0.0737, batch_loss_c: 0.0735, batch_loss_s: 0.0741, time:5.0100, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [30/3125], step: 3155, 9.234 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.0978, batch_loss_s: 0.0949, time:4.3317, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [40/3125], step: 3165, 8.827 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1145, batch_loss_s: 0.1294, time:4.5314, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [50/3125], step: 3175, 8.286 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1233, batch_loss_s: 0.0894, time:4.8273, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [60/3125], step: 3185, 8.813 samples/sec, batch_loss: 0.4561, batch_loss_c: 0.4964, batch_loss_s: 0.3622, time:4.5388, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [70/3125], step: 3195, 8.324 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1058, batch_loss_s: 0.0801, time:4.8055, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [80/3125], step: 3205, 8.202 samples/sec, batch_loss: 0.1292, batch_loss_c: 0.1540, batch_loss_s: 0.0716, time:4.8767, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [90/3125], step: 3215, 8.095 samples/sec, batch_loss: 0.3075, batch_loss_c: 0.3073, batch_loss_s: 0.3080, time:4.9411, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [100/3125], step: 3225, 8.074 samples/sec, batch_loss: 0.3552, batch_loss_c: 0.3649, batch_loss_s: 0.3328, time:4.9544, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:34:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [110/3125], step: 3235, 8.204 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0733, batch_loss_s: 0.0765, time:4.8754, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [120/3125], step: 3245, 8.810 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0919, batch_loss_s: 0.0819, time:4.5402, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [130/3125], step: 3255, 7.926 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0847, batch_loss_s: 0.1126, time:5.0464, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [140/3125], step: 3265, 8.305 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.3032, batch_loss_s: 0.3062, time:4.8166, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [150/3125], step: 3275, 8.722 samples/sec, batch_loss: 0.1354, batch_loss_c: 0.1609, batch_loss_s: 0.0761, time:4.5861, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [160/3125], step: 3285, 8.268 samples/sec, batch_loss: 0.3534, batch_loss_c: 0.3635, batch_loss_s: 0.3298, time:4.8381, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [170/3125], step: 3295, 7.228 samples/sec, batch_loss: 0.3605, batch_loss_c: 0.3782, batch_loss_s: 0.3192, time:5.5344, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [180/3125], step: 3305, 7.070 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1261, batch_loss_s: 0.0968, time:5.6578, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [190/3125], step: 3315, 7.858 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0770, batch_loss_s: 0.0835, time:5.0906, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [200/3125], step: 3325, 7.120 samples/sec, batch_loss: 0.2680, batch_loss_c: 0.3456, batch_loss_s: 0.0869, time:5.6178, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [210/3125], step: 3335, 8.083 samples/sec, batch_loss: 0.2777, batch_loss_c: 0.2629, batch_loss_s: 0.3123, time:4.9487, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:35:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [220/3125], step: 3345, 7.783 samples/sec, batch_loss: 0.1753, batch_loss_c: 0.2069, batch_loss_s: 0.1015, time:5.1392, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [230/3125], step: 3355, 8.187 samples/sec, batch_loss: 0.1485, batch_loss_c: 0.1385, batch_loss_s: 0.1719, time:4.8858, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [240/3125], step: 3365, 7.850 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0695, batch_loss_s: 0.0847, time:5.0957, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [250/3125], step: 3375, 7.757 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.1009, batch_loss_s: 0.0824, time:5.1566, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [260/3125], step: 3385, 7.634 samples/sec, batch_loss: 0.3136, batch_loss_c: 0.3084, batch_loss_s: 0.3258, time:5.2396, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [270/3125], step: 3395, 8.436 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0763, batch_loss_s: 0.0711, time:4.7417, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [280/3125], step: 3405, 8.187 samples/sec, batch_loss: 0.3179, batch_loss_c: 0.3152, batch_loss_s: 0.3240, time:4.8859, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [290/3125], step: 3415, 8.786 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0988, batch_loss_s: 0.0665, time:4.5525, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [300/3125], step: 3425, 7.972 samples/sec, batch_loss: 0.0614, batch_loss_c: 0.0587, batch_loss_s: 0.0676, time:5.0176, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [310/3125], step: 3435, 8.601 samples/sec, batch_loss: 0.1045, batch_loss_c: 0.1006, batch_loss_s: 0.1136, time:4.6506, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [320/3125], step: 3445, 8.339 samples/sec, batch_loss: 0.0677, batch_loss_c: 0.0658, batch_loss_s: 0.0721, time:4.7969, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [330/3125], step: 3455, 8.179 samples/sec, batch_loss: 0.1390, batch_loss_c: 0.1352, batch_loss_s: 0.1477, time:4.8906, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [340/3125], step: 3465, 8.109 samples/sec, batch_loss: 0.3246, batch_loss_c: 0.3106, batch_loss_s: 0.3572, time:4.9330, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:36:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [350/3125], step: 3475, 9.234 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0794, batch_loss_s: 0.0853, time:4.3317, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [360/3125], step: 3485, 7.942 samples/sec, batch_loss: 0.0612, batch_loss_c: 0.0565, batch_loss_s: 0.0721, time:5.0364, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [370/3125], step: 3495, 7.863 samples/sec, batch_loss: 0.3571, batch_loss_c: 0.3736, batch_loss_s: 0.3186, time:5.0873, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [380/3125], step: 3505, 8.125 samples/sec, batch_loss: 0.0987, batch_loss_c: 0.0970, batch_loss_s: 0.1028, time:4.9230, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [390/3125], step: 3515, 8.017 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0613, batch_loss_s: 0.0817, time:4.9891, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [400/3125], step: 3525, 8.120 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1712, batch_loss_s: 0.0827, time:4.9261, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [410/3125], step: 3535, 8.537 samples/sec, batch_loss: 0.1237, batch_loss_c: 0.1434, batch_loss_s: 0.0777, time:4.6856, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [420/3125], step: 3545, 8.349 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0819, batch_loss_s: 0.0964, time:4.7908, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [430/3125], step: 3555, 8.379 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.1063, batch_loss_s: 0.0741, time:4.7741, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [440/3125], step: 3565, 8.935 samples/sec, batch_loss: 0.2507, batch_loss_c: 0.2350, batch_loss_s: 0.2872, time:4.4768, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [450/3125], step: 3575, 8.750 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0947, batch_loss_s: 0.0946, time:4.5712, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [460/3125], step: 3585, 8.217 samples/sec, batch_loss: 0.0677, batch_loss_c: 0.0653, batch_loss_s: 0.0735, time:4.8682, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:37:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [470/3125], step: 3595, 8.154 samples/sec, batch_loss: 0.1586, batch_loss_c: 0.1758, batch_loss_s: 0.1184, time:4.9057, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [480/3125], step: 3605, 8.643 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1285, batch_loss_s: 0.1134, time:4.6278, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [490/3125], step: 3615, 8.132 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0559, batch_loss_s: 0.0745, time:4.9188, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [500/3125], step: 3625, 8.018 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1203, batch_loss_s: 0.1130, time:4.9888, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [510/3125], step: 3635, 7.962 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1136, batch_loss_s: 0.0966, time:5.0241, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [520/3125], step: 3645, 8.599 samples/sec, batch_loss: 0.3302, batch_loss_c: 0.3402, batch_loss_s: 0.3069, time:4.6515, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [530/3125], step: 3655, 7.885 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0789, batch_loss_s: 0.0903, time:5.0732, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [540/3125], step: 3665, 7.919 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0692, batch_loss_s: 0.0738, time:5.0512, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [550/3125], step: 3675, 8.487 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1047, batch_loss_s: 0.0962, time:4.7129, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [560/3125], step: 3685, 7.797 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0938, batch_loss_s: 0.0716, time:5.1299, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [570/3125], step: 3695, 8.615 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0837, batch_loss_s: 0.0849, time:4.6430, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [580/3125], step: 3705, 8.531 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0683, batch_loss_s: 0.0832, time:4.6890, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [590/3125], step: 3715, 8.670 samples/sec, batch_loss: 0.0541, batch_loss_c: 0.0524, batch_loss_s: 0.0581, time:4.6135, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:38:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [600/3125], step: 3725, 8.243 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0819, batch_loss_s: 0.1063, time:4.8528, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [610/3125], step: 3735, 8.299 samples/sec, batch_loss: 0.1589, batch_loss_c: 0.1794, batch_loss_s: 0.1111, time:4.8201, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [620/3125], step: 3745, 8.612 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1193, batch_loss_s: 0.1109, time:4.6449, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [630/3125], step: 3755, 8.956 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1621, batch_loss_s: 0.1042, time:4.4662, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [640/3125], step: 3765, 7.157 samples/sec, batch_loss: 0.0564, batch_loss_c: 0.0521, batch_loss_s: 0.0665, time:5.5889, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [650/3125], step: 3775, 8.734 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.1041, batch_loss_s: 0.0780, time:4.5796, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [660/3125], step: 3785, 8.590 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0941, batch_loss_s: 0.1008, time:4.6565, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [670/3125], step: 3795, 8.177 samples/sec, batch_loss: 0.0709, batch_loss_c: 0.0669, batch_loss_s: 0.0804, time:4.8919, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [680/3125], step: 3805, 8.055 samples/sec, batch_loss: 0.3511, batch_loss_c: 0.3521, batch_loss_s: 0.3488, time:4.9661, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [690/3125], step: 3815, 8.442 samples/sec, batch_loss: 0.3008, batch_loss_c: 0.2987, batch_loss_s: 0.3056, time:4.7382, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [700/3125], step: 3825, 8.237 samples/sec, batch_loss: 0.1191, batch_loss_c: 0.1245, batch_loss_s: 0.1067, time:4.8562, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [710/3125], step: 3835, 8.173 samples/sec, batch_loss: 0.1086, batch_loss_c: 0.1252, batch_loss_s: 0.0701, time:4.8939, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:39:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [720/3125], step: 3845, 8.320 samples/sec, batch_loss: 0.1379, batch_loss_c: 0.1405, batch_loss_s: 0.1320, time:4.8075, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [730/3125], step: 3855, 9.248 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0748, batch_loss_s: 0.0957, time:4.3251, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [740/3125], step: 3865, 7.706 samples/sec, batch_loss: 0.1123, batch_loss_c: 0.1141, batch_loss_s: 0.1081, time:5.1907, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [750/3125], step: 3875, 6.570 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0776, batch_loss_s: 0.0743, time:6.0880, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [760/3125], step: 3885, 8.770 samples/sec, batch_loss: 0.3007, batch_loss_c: 0.2982, batch_loss_s: 0.3065, time:4.5608, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [770/3125], step: 3895, 8.595 samples/sec, batch_loss: 0.5409, batch_loss_c: 0.5446, batch_loss_s: 0.5323, time:4.6537, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [780/3125], step: 3905, 7.657 samples/sec, batch_loss: 0.1358, batch_loss_c: 0.1477, batch_loss_s: 0.1080, time:5.2240, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [790/3125], step: 3915, 8.641 samples/sec, batch_loss: 0.2005, batch_loss_c: 0.1811, batch_loss_s: 0.2458, time:4.6290, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [800/3125], step: 3925, 7.884 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1002, batch_loss_s: 0.1092, time:5.0735, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [810/3125], step: 3935, 7.311 samples/sec, batch_loss: 0.0814, batch_loss_c: 0.0776, batch_loss_s: 0.0904, time:5.4713, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [820/3125], step: 3945, 8.509 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.0962, batch_loss_s: 0.1276, time:4.7008, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [830/3125], step: 3955, 7.598 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1836, batch_loss_s: 0.0719, time:5.2648, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:40:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [840/3125], step: 3965, 7.985 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0791, batch_loss_s: 0.1085, time:5.0096, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [850/3125], step: 3975, 7.789 samples/sec, batch_loss: 0.0730, batch_loss_c: 0.0706, batch_loss_s: 0.0786, time:5.1354, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [860/3125], step: 3985, 8.797 samples/sec, batch_loss: 0.1894, batch_loss_c: 0.2151, batch_loss_s: 0.1294, time:4.5471, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [870/3125], step: 3995, 7.347 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0831, batch_loss_s: 0.0823, time:5.4443, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [880/3125], step: 4005, 8.384 samples/sec, batch_loss: 0.1575, batch_loss_c: 0.1773, batch_loss_s: 0.1113, time:4.7711, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [890/3125], step: 4015, 7.957 samples/sec, batch_loss: 0.3300, batch_loss_c: 0.3314, batch_loss_s: 0.3267, time:5.0271, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [900/3125], step: 4025, 8.413 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0777, batch_loss_s: 0.0700, time:4.7544, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [910/3125], step: 4035, 8.253 samples/sec, batch_loss: 0.2844, batch_loss_c: 0.2754, batch_loss_s: 0.3054, time:4.8468, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [920/3125], step: 4045, 8.289 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1255, batch_loss_s: 0.0755, time:4.8258, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [930/3125], step: 4055, 8.374 samples/sec, batch_loss: 0.3346, batch_loss_c: 0.3480, batch_loss_s: 0.3032, time:4.7768, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [940/3125], step: 4065, 7.666 samples/sec, batch_loss: 0.3399, batch_loss_c: 0.3452, batch_loss_s: 0.3275, time:5.2177, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [950/3125], step: 4075, 8.289 samples/sec, batch_loss: 0.0752, batch_loss_c: 0.0771, batch_loss_s: 0.0707, time:4.8259, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:41:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [960/3125], step: 4085, 8.640 samples/sec, batch_loss: 0.1435, batch_loss_c: 0.1514, batch_loss_s: 0.1250, time:4.6294, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [970/3125], step: 4095, 8.649 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0871, batch_loss_s: 0.0811, time:4.6248, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [980/3125], step: 4105, 8.307 samples/sec, batch_loss: 0.2202, batch_loss_c: 0.2201, batch_loss_s: 0.2206, time:4.8153, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [990/3125], step: 4115, 7.918 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0676, batch_loss_s: 0.0634, time:5.0519, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1000/3125], step: 4125, 8.197 samples/sec, batch_loss: 0.1731, batch_loss_c: 0.1772, batch_loss_s: 0.1636, time:4.8797, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1010/3125], step: 4135, 7.730 samples/sec, batch_loss: 0.5070, batch_loss_c: 0.4861, batch_loss_s: 0.5559, time:5.1743, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1020/3125], step: 4145, 8.813 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1237, batch_loss_s: 0.1106, time:4.5386, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1030/3125], step: 4155, 7.643 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1286, batch_loss_s: 0.0660, time:5.2332, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1040/3125], step: 4165, 8.179 samples/sec, batch_loss: 0.1695, batch_loss_c: 0.2058, batch_loss_s: 0.0848, time:4.8903, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1050/3125], step: 4175, 8.875 samples/sec, batch_loss: 0.2313, batch_loss_c: 0.2290, batch_loss_s: 0.2368, time:4.5072, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1060/3125], step: 4185, 7.699 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1436, batch_loss_s: 0.1111, time:5.1957, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1070/3125], step: 4195, 8.468 samples/sec, batch_loss: 0.3673, batch_loss_c: 0.3669, batch_loss_s: 0.3683, time:4.7237, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:42:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1080/3125], step: 4205, 7.967 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1154, batch_loss_s: 0.1095, time:5.0204, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1090/3125], step: 4215, 7.958 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0841, batch_loss_s: 0.0706, time:5.0262, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1100/3125], step: 4225, 7.445 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1343, batch_loss_s: 0.0996, time:5.3725, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1110/3125], step: 4235, 8.179 samples/sec, batch_loss: 0.0691, batch_loss_c: 0.0648, batch_loss_s: 0.0789, time:4.8903, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1120/3125], step: 4245, 8.328 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0912, batch_loss_s: 0.0950, time:4.8033, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1130/3125], step: 4255, 7.364 samples/sec, batch_loss: 0.0854, batch_loss_c: 0.0783, batch_loss_s: 0.1020, time:5.4319, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1140/3125], step: 4265, 7.818 samples/sec, batch_loss: 0.1395, batch_loss_c: 0.1612, batch_loss_s: 0.0890, time:5.1162, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1150/3125], step: 4275, 7.833 samples/sec, batch_loss: 0.3357, batch_loss_c: 0.3319, batch_loss_s: 0.3447, time:5.1065, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1160/3125], step: 4285, 7.979 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3130, batch_loss_s: 0.3935, time:5.0132, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1170/3125], step: 4295, 7.969 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1145, batch_loss_s: 0.0829, time:5.0197, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1180/3125], step: 4305, 8.378 samples/sec, batch_loss: 0.1550, batch_loss_c: 0.1583, batch_loss_s: 0.1474, time:4.7742, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1190/3125], step: 4315, 8.491 samples/sec, batch_loss: 0.2901, batch_loss_c: 0.2785, batch_loss_s: 0.3172, time:4.7110, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1200/3125], step: 4325, 8.193 samples/sec, batch_loss: 0.3366, batch_loss_c: 0.3328, batch_loss_s: 0.3454, time:4.8822, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:43:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1210/3125], step: 4335, 8.817 samples/sec, batch_loss: 0.1867, batch_loss_c: 0.2238, batch_loss_s: 0.1004, time:4.5368, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1220/3125], step: 4345, 8.001 samples/sec, batch_loss: 0.1060, batch_loss_c: 0.1138, batch_loss_s: 0.0878, time:4.9996, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1230/3125], step: 4355, 8.402 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1125, batch_loss_s: 0.0912, time:4.7606, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1240/3125], step: 4365, 8.118 samples/sec, batch_loss: 0.1089, batch_loss_c: 0.1178, batch_loss_s: 0.0880, time:4.9275, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1250/3125], step: 4375, 8.835 samples/sec, batch_loss: 0.2958, batch_loss_c: 0.2842, batch_loss_s: 0.3229, time:4.5275, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1260/3125], step: 4385, 8.870 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1080, batch_loss_s: 0.0854, time:4.5097, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1270/3125], step: 4395, 9.294 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1055, batch_loss_s: 0.1068, time:4.3037, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1280/3125], step: 4405, 9.332 samples/sec, batch_loss: 0.1079, batch_loss_c: 0.1250, batch_loss_s: 0.0680, time:4.2864, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1290/3125], step: 4415, 8.765 samples/sec, batch_loss: 0.0640, batch_loss_c: 0.0602, batch_loss_s: 0.0729, time:4.5634, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1300/3125], step: 4425, 9.263 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0741, batch_loss_s: 0.0709, time:4.3181, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1310/3125], step: 4435, 8.526 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.1936, batch_loss_s: 0.1519, time:4.6915, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1320/3125], step: 4445, 8.650 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1098, batch_loss_s: 0.0811, time:4.6244, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1330/3125], step: 4455, 8.822 samples/sec, batch_loss: 0.0627, batch_loss_c: 0.0625, batch_loss_s: 0.0632, time:4.5343, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:44:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1340/3125], step: 4465, 9.138 samples/sec, batch_loss: 0.3083, batch_loss_c: 0.3117, batch_loss_s: 0.3006, time:4.3772, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1350/3125], step: 4475, 8.421 samples/sec, batch_loss: 0.2796, batch_loss_c: 0.2669, batch_loss_s: 0.3093, time:4.7500, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1360/3125], step: 4485, 8.123 samples/sec, batch_loss: 0.1107, batch_loss_c: 0.1130, batch_loss_s: 0.1053, time:4.9242, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1370/3125], step: 4495, 8.418 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0854, batch_loss_s: 0.0825, time:4.7519, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1380/3125], step: 4505, 8.414 samples/sec, batch_loss: 0.3293, batch_loss_c: 0.3312, batch_loss_s: 0.3249, time:4.7537, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1390/3125], step: 4515, 8.694 samples/sec, batch_loss: 0.4261, batch_loss_c: 0.4109, batch_loss_s: 0.4617, time:4.6011, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1400/3125], step: 4525, 7.932 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1646, batch_loss_s: 0.1090, time:5.0427, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1410/3125], step: 4535, 8.020 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0684, batch_loss_s: 0.0870, time:4.9875, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1420/3125], step: 4545, 7.990 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.0983, batch_loss_s: 0.1083, time:5.0062, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1430/3125], step: 4555, 6.875 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0722, batch_loss_s: 0.0884, time:5.8179, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1440/3125], step: 4565, 7.607 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.1944, batch_loss_s: 0.1500, time:5.2581, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1450/3125], step: 4575, 8.298 samples/sec, batch_loss: 0.1150, batch_loss_c: 0.1268, batch_loss_s: 0.0873, time:4.8207, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:45:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1460/3125], step: 4585, 8.343 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1228, batch_loss_s: 0.1275, time:4.7947, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1470/3125], step: 4595, 8.646 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0728, batch_loss_s: 0.0893, time:4.6265, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1480/3125], step: 4605, 7.156 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0897, batch_loss_s: 0.0788, time:5.5898, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1490/3125], step: 4615, 8.539 samples/sec, batch_loss: 0.5324, batch_loss_c: 0.5290, batch_loss_s: 0.5404, time:4.6843, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1500/3125], step: 4625, 8.167 samples/sec, batch_loss: 0.2997, batch_loss_c: 0.2967, batch_loss_s: 0.3068, time:4.8979, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1510/3125], step: 4635, 8.680 samples/sec, batch_loss: 0.5518, batch_loss_c: 0.5545, batch_loss_s: 0.5457, time:4.6083, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1520/3125], step: 4645, 8.469 samples/sec, batch_loss: 0.0645, batch_loss_c: 0.0681, batch_loss_s: 0.0561, time:4.7234, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:32 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1530/3125], step: 4655, 8.859 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.1008, batch_loss_s: 0.0823, time:4.5151, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1540/3125], step: 4665, 8.206 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1334, batch_loss_s: 0.0841, time:4.8743, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1550/3125], step: 4675, 7.620 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0895, batch_loss_s: 0.1054, time:5.2491, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1560/3125], step: 4685, 7.980 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1366, batch_loss_s: 0.1179, time:5.0125, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1570/3125], step: 4695, 8.272 samples/sec, batch_loss: 0.2611, batch_loss_c: 0.2441, batch_loss_s: 0.3010, time:4.8354, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:46:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1580/3125], step: 4705, 8.819 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1067, batch_loss_s: 0.1056, time:4.5357, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1590/3125], step: 4715, 8.688 samples/sec, batch_loss: 0.1562, batch_loss_c: 0.1534, batch_loss_s: 0.1628, time:4.6043, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1600/3125], step: 4725, 8.556 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1467, batch_loss_s: 0.0804, time:4.6751, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1610/3125], step: 4735, 8.433 samples/sec, batch_loss: 0.1762, batch_loss_c: 0.1722, batch_loss_s: 0.1854, time:4.7433, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1620/3125], step: 4745, 8.514 samples/sec, batch_loss: 0.1826, batch_loss_c: 0.2098, batch_loss_s: 0.1191, time:4.6983, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1630/3125], step: 4755, 8.999 samples/sec, batch_loss: 0.2884, batch_loss_c: 0.2851, batch_loss_s: 0.2960, time:4.4448, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1640/3125], step: 4765, 8.147 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1205, batch_loss_s: 0.0882, time:4.9095, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1650/3125], step: 4775, 8.371 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0685, batch_loss_s: 0.0800, time:4.7785, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1660/3125], step: 4785, 8.044 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0548, batch_loss_s: 0.0686, time:4.9725, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1670/3125], step: 4795, 8.038 samples/sec, batch_loss: 0.3575, batch_loss_c: 0.3774, batch_loss_s: 0.3111, time:4.9764, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1680/3125], step: 4805, 8.839 samples/sec, batch_loss: 0.1625, batch_loss_c: 0.1839, batch_loss_s: 0.1126, time:4.5252, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1690/3125], step: 4815, 7.776 samples/sec, batch_loss: 0.1416, batch_loss_c: 0.1495, batch_loss_s: 0.1231, time:5.1440, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1700/3125], step: 4825, 9.276 samples/sec, batch_loss: 0.3166, batch_loss_c: 0.3170, batch_loss_s: 0.3157, time:4.3123, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:47:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1710/3125], step: 4835, 8.214 samples/sec, batch_loss: 0.0606, batch_loss_c: 0.0574, batch_loss_s: 0.0678, time:4.8700, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1720/3125], step: 4845, 8.430 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0893, batch_loss_s: 0.0913, time:4.7448, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1730/3125], step: 4855, 8.015 samples/sec, batch_loss: 0.3743, batch_loss_c: 0.3703, batch_loss_s: 0.3836, time:4.9909, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1740/3125], step: 4865, 8.625 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1052, batch_loss_s: 0.1258, time:4.6377, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1750/3125], step: 4875, 8.116 samples/sec, batch_loss: 0.3122, batch_loss_c: 0.3088, batch_loss_s: 0.3202, time:4.9288, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1760/3125], step: 4885, 8.786 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0679, batch_loss_s: 0.0632, time:4.5524, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1770/3125], step: 4895, 8.482 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0941, batch_loss_s: 0.1044, time:4.7161, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1780/3125], step: 4905, 9.187 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1176, batch_loss_s: 0.1024, time:4.3540, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1790/3125], step: 4915, 8.332 samples/sec, batch_loss: 0.1480, batch_loss_c: 0.1653, batch_loss_s: 0.1078, time:4.8008, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1800/3125], step: 4925, 8.082 samples/sec, batch_loss: 0.3370, batch_loss_c: 0.3537, batch_loss_s: 0.2981, time:4.9491, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1810/3125], step: 4935, 8.258 samples/sec, batch_loss: 0.0927, batch_loss_c: 0.0913, batch_loss_s: 0.0959, time:4.8436, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1820/3125], step: 4945, 8.891 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0714, batch_loss_s: 0.0700, time:4.4990, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:48:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1830/3125], step: 4955, 7.949 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.1041, batch_loss_s: 0.0763, time:5.0324, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1840/3125], step: 4965, 8.291 samples/sec, batch_loss: 0.5508, batch_loss_c: 0.5532, batch_loss_s: 0.5450, time:4.8243, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1850/3125], step: 4975, 8.797 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0702, batch_loss_s: 0.0775, time:4.5472, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1860/3125], step: 4985, 8.891 samples/sec, batch_loss: 0.0539, batch_loss_c: 0.0497, batch_loss_s: 0.0636, time:4.4990, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1870/3125], step: 4995, 8.462 samples/sec, batch_loss: 0.3036, batch_loss_c: 0.3005, batch_loss_s: 0.3107, time:4.7269, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1880/3125], step: 5005, 8.781 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0746, batch_loss_s: 0.0868, time:4.5555, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1890/3125], step: 5015, 8.402 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0680, batch_loss_s: 0.0630, time:4.7606, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1900/3125], step: 5025, 8.348 samples/sec, batch_loss: 0.0607, batch_loss_c: 0.0552, batch_loss_s: 0.0736, time:4.7913, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1910/3125], step: 5035, 8.017 samples/sec, batch_loss: 0.0580, batch_loss_c: 0.0541, batch_loss_s: 0.0672, time:4.9896, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1920/3125], step: 5045, 7.496 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0781, batch_loss_s: 0.1057, time:5.3362, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1930/3125], step: 5055, 7.758 samples/sec, batch_loss: 0.0932, batch_loss_c: 0.0890, batch_loss_s: 0.1029, time:5.1562, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1940/3125], step: 5065, 7.144 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1125, batch_loss_s: 0.1022, time:5.5991, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1950/3125], step: 5075, 8.142 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0786, batch_loss_s: 0.0776, time:4.9128, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:49:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1960/3125], step: 5085, 8.041 samples/sec, batch_loss: 0.1168, batch_loss_c: 0.1100, batch_loss_s: 0.1328, time:4.9744, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1970/3125], step: 5095, 8.035 samples/sec, batch_loss: 0.2277, batch_loss_c: 0.2416, batch_loss_s: 0.1951, time:4.9780, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1980/3125], step: 5105, 8.075 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1318, batch_loss_s: 0.0985, time:4.9533, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1990/3125], step: 5115, 8.108 samples/sec, batch_loss: 0.5427, batch_loss_c: 0.5432, batch_loss_s: 0.5416, time:4.9336, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2000/3125], step: 5125, 8.523 samples/sec, batch_loss: 0.0418, batch_loss_c: 0.0376, batch_loss_s: 0.0514, time:4.6930, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2010/3125], step: 5135, 7.675 samples/sec, batch_loss: 0.2940, batch_loss_c: 0.2882, batch_loss_s: 0.3075, time:5.2118, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2020/3125], step: 5145, 8.445 samples/sec, batch_loss: 0.2991, batch_loss_c: 0.2968, batch_loss_s: 0.3047, time:4.7364, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2030/3125], step: 5155, 7.227 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.1058, batch_loss_s: 0.0917, time:5.5349, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2040/3125], step: 5165, 8.286 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1228, batch_loss_s: 0.0892, time:4.8272, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2050/3125], step: 5175, 7.883 samples/sec, batch_loss: 0.1250, batch_loss_c: 0.1423, batch_loss_s: 0.0844, time:5.0741, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2060/3125], step: 5185, 7.429 samples/sec, batch_loss: 0.0946, batch_loss_c: 0.0942, batch_loss_s: 0.0954, time:5.3841, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2070/3125], step: 5195, 7.764 samples/sec, batch_loss: 0.5289, batch_loss_c: 0.5263, batch_loss_s: 0.5348, time:5.1523, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:50:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2080/3125], step: 5205, 8.289 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1371, batch_loss_s: 0.1122, time:4.8257, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2090/3125], step: 5215, 8.238 samples/sec, batch_loss: 0.3268, batch_loss_c: 0.3303, batch_loss_s: 0.3186, time:4.8558, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2100/3125], step: 5225, 7.402 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0741, batch_loss_s: 0.0924, time:5.4037, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2110/3125], step: 5235, 8.330 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.0986, batch_loss_s: 0.1090, time:4.8021, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2120/3125], step: 5245, 7.700 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0926, batch_loss_s: 0.1058, time:5.1950, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2130/3125], step: 5255, 8.228 samples/sec, batch_loss: 0.3192, batch_loss_c: 0.3260, batch_loss_s: 0.3035, time:4.8612, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2140/3125], step: 5265, 7.606 samples/sec, batch_loss: 0.4016, batch_loss_c: 0.4147, batch_loss_s: 0.3711, time:5.2587, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2150/3125], step: 5275, 8.000 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.1221, batch_loss_s: 0.0489, time:5.0002, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2160/3125], step: 5285, 8.018 samples/sec, batch_loss: 0.0624, batch_loss_c: 0.0602, batch_loss_s: 0.0674, time:4.9891, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2170/3125], step: 5295, 8.870 samples/sec, batch_loss: 0.1211, batch_loss_c: 0.1345, batch_loss_s: 0.0898, time:4.5094, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2180/3125], step: 5305, 8.213 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1146, batch_loss_s: 0.1184, time:4.8703, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2190/3125], step: 5315, 7.348 samples/sec, batch_loss: 0.0917, batch_loss_c: 0.0905, batch_loss_s: 0.0947, time:5.4437, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:51:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2200/3125], step: 5325, 8.483 samples/sec, batch_loss: 0.1429, batch_loss_c: 0.1582, batch_loss_s: 0.1072, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2210/3125], step: 5335, 8.601 samples/sec, batch_loss: 0.2847, batch_loss_c: 0.2745, batch_loss_s: 0.3086, time:4.6508, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2220/3125], step: 5345, 8.844 samples/sec, batch_loss: 0.3700, batch_loss_c: 0.3935, batch_loss_s: 0.3153, time:4.5228, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2230/3125], step: 5355, 8.649 samples/sec, batch_loss: 0.1692, batch_loss_c: 0.1811, batch_loss_s: 0.1416, time:4.6249, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2240/3125], step: 5365, 8.494 samples/sec, batch_loss: 0.1403, batch_loss_c: 0.1450, batch_loss_s: 0.1293, time:4.7093, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2250/3125], step: 5375, 7.116 samples/sec, batch_loss: 0.2505, batch_loss_c: 0.2955, batch_loss_s: 0.1457, time:5.6211, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2260/3125], step: 5385, 8.374 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0795, batch_loss_s: 0.0674, time:4.7768, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2270/3125], step: 5395, 8.361 samples/sec, batch_loss: 0.0903, batch_loss_c: 0.0850, batch_loss_s: 0.1029, time:4.7841, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2280/3125], step: 5405, 8.389 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.0937, batch_loss_s: 0.1060, time:4.7682, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2290/3125], step: 5415, 8.184 samples/sec, batch_loss: 0.1947, batch_loss_c: 0.2173, batch_loss_s: 0.1418, time:4.8876, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2300/3125], step: 5425, 9.065 samples/sec, batch_loss: 0.0597, batch_loss_c: 0.0596, batch_loss_s: 0.0599, time:4.4123, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2310/3125], step: 5435, 8.231 samples/sec, batch_loss: 0.1302, batch_loss_c: 0.1449, batch_loss_s: 0.0958, time:4.8595, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:52:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2320/3125], step: 5445, 8.264 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0977, batch_loss_s: 0.0910, time:4.8402, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2330/3125], step: 5455, 7.811 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0575, batch_loss_s: 0.0722, time:5.1213, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2340/3125], step: 5465, 8.454 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1118, batch_loss_s: 0.1192, time:4.7316, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2350/3125], step: 5475, 7.233 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0623, batch_loss_s: 0.0654, time:5.5304, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2360/3125], step: 5485, 8.575 samples/sec, batch_loss: 0.3560, batch_loss_c: 0.3726, batch_loss_s: 0.3175, time:4.6649, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2370/3125], step: 5495, 8.051 samples/sec, batch_loss: 0.1311, batch_loss_c: 0.1465, batch_loss_s: 0.0954, time:4.9681, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2380/3125], step: 5505, 8.596 samples/sec, batch_loss: 0.0755, batch_loss_c: 0.0682, batch_loss_s: 0.0924, time:4.6531, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2390/3125], step: 5515, 8.733 samples/sec, batch_loss: 0.4220, batch_loss_c: 0.4073, batch_loss_s: 0.4562, time:4.5806, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2400/3125], step: 5525, 8.086 samples/sec, batch_loss: 0.1211, batch_loss_c: 0.1144, batch_loss_s: 0.1368, time:4.9470, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2410/3125], step: 5535, 7.948 samples/sec, batch_loss: 0.1349, batch_loss_c: 0.1472, batch_loss_s: 0.1062, time:5.0329, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2420/3125], step: 5545, 8.774 samples/sec, batch_loss: 0.0521, batch_loss_c: 0.0480, batch_loss_s: 0.0618, time:4.5591, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2430/3125], step: 5555, 8.476 samples/sec, batch_loss: 0.3017, batch_loss_c: 0.3058, batch_loss_s: 0.2922, time:4.7192, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:53:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2440/3125], step: 5565, 7.809 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0856, batch_loss_s: 0.0694, time:5.1224, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2450/3125], step: 5575, 8.172 samples/sec, batch_loss: 0.0682, batch_loss_c: 0.0682, batch_loss_s: 0.0680, time:4.8949, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2460/3125], step: 5585, 7.580 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0834, batch_loss_s: 0.1044, time:5.2772, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2470/3125], step: 5595, 7.985 samples/sec, batch_loss: 0.3198, batch_loss_c: 0.3166, batch_loss_s: 0.3274, time:5.0093, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2480/3125], step: 5605, 7.949 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0569, batch_loss_s: 0.0768, time:5.0323, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2490/3125], step: 5615, 9.028 samples/sec, batch_loss: 0.2063, batch_loss_c: 0.2082, batch_loss_s: 0.2017, time:4.4307, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2500/3125], step: 5625, 8.307 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1014, batch_loss_s: 0.1041, time:4.8154, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2510/3125], step: 5635, 7.776 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0720, batch_loss_s: 0.0718, time:5.1442, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2520/3125], step: 5645, 8.720 samples/sec, batch_loss: 0.1360, batch_loss_c: 0.1323, batch_loss_s: 0.1447, time:4.5870, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2530/3125], step: 5655, 8.707 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.1056, batch_loss_s: 0.0968, time:4.5942, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2540/3125], step: 5665, 7.942 samples/sec, batch_loss: 0.0692, batch_loss_c: 0.0617, batch_loss_s: 0.0866, time:5.0368, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2550/3125], step: 5675, 8.349 samples/sec, batch_loss: 0.1672, batch_loss_c: 0.1718, batch_loss_s: 0.1567, time:4.7908, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2560/3125], step: 5685, 8.794 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0989, batch_loss_s: 0.0879, time:4.5486, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:54:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2570/3125], step: 5695, 8.800 samples/sec, batch_loss: 0.3517, batch_loss_c: 0.3575, batch_loss_s: 0.3381, time:4.5452, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2580/3125], step: 5705, 8.874 samples/sec, batch_loss: 0.0688, batch_loss_c: 0.0641, batch_loss_s: 0.0796, time:4.5075, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2590/3125], step: 5715, 8.710 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0768, batch_loss_s: 0.1049, time:4.5924, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2600/3125], step: 5725, 8.816 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0946, batch_loss_s: 0.0696, time:4.5373, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2610/3125], step: 5735, 8.518 samples/sec, batch_loss: 0.1411, batch_loss_c: 0.1384, batch_loss_s: 0.1474, time:4.6960, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2620/3125], step: 5745, 8.779 samples/sec, batch_loss: 0.3271, batch_loss_c: 0.3308, batch_loss_s: 0.3186, time:4.5563, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2630/3125], step: 5755, 8.395 samples/sec, batch_loss: 0.3474, batch_loss_c: 0.3632, batch_loss_s: 0.3105, time:4.7647, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2640/3125], step: 5765, 8.737 samples/sec, batch_loss: 0.2743, batch_loss_c: 0.2615, batch_loss_s: 0.3041, time:4.5781, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2650/3125], step: 5775, 8.982 samples/sec, batch_loss: 0.1111, batch_loss_c: 0.1126, batch_loss_s: 0.1076, time:4.4531, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2660/3125], step: 5785, 8.754 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0835, batch_loss_s: 0.1005, time:4.5695, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2670/3125], step: 5795, 7.691 samples/sec, batch_loss: 0.3479, batch_loss_c: 0.3608, batch_loss_s: 0.3176, time:5.2008, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2680/3125], step: 5805, 7.954 samples/sec, batch_loss: 0.2945, batch_loss_c: 0.2930, batch_loss_s: 0.2980, time:5.0290, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2690/3125], step: 5815, 8.026 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1083, batch_loss_s: 0.1181, time:4.9839, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:55:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2700/3125], step: 5825, 8.901 samples/sec, batch_loss: 0.4257, batch_loss_c: 0.4599, batch_loss_s: 0.3459, time:4.4938, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2710/3125], step: 5835, 9.041 samples/sec, batch_loss: 0.2716, batch_loss_c: 0.2610, batch_loss_s: 0.2961, time:4.4242, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2720/3125], step: 5845, 8.440 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0937, batch_loss_s: 0.0881, time:4.7393, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2730/3125], step: 5855, 8.489 samples/sec, batch_loss: 0.1410, batch_loss_c: 0.1369, batch_loss_s: 0.1506, time:4.7120, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2740/3125], step: 5865, 7.145 samples/sec, batch_loss: 0.0561, batch_loss_c: 0.0541, batch_loss_s: 0.0608, time:5.5983, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2750/3125], step: 5875, 7.072 samples/sec, batch_loss: 0.3036, batch_loss_c: 0.3027, batch_loss_s: 0.3057, time:5.6561, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2760/3125], step: 5885, 8.296 samples/sec, batch_loss: 0.1880, batch_loss_c: 0.1703, batch_loss_s: 0.2295, time:4.8216, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2770/3125], step: 5895, 7.442 samples/sec, batch_loss: 0.1189, batch_loss_c: 0.1373, batch_loss_s: 0.0760, time:5.3750, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2780/3125], step: 5905, 8.442 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0661, batch_loss_s: 0.0816, time:4.7381, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2790/3125], step: 5915, 7.758 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1158, batch_loss_s: 0.0749, time:5.1562, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2800/3125], step: 5925, 8.158 samples/sec, batch_loss: 0.4987, batch_loss_c: 0.4805, batch_loss_s: 0.5410, time:4.9030, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2810/3125], step: 5935, 8.531 samples/sec, batch_loss: 0.5462, batch_loss_c: 0.5448, batch_loss_s: 0.5495, time:4.6887, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:56:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2820/3125], step: 5945, 7.731 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0680, batch_loss_s: 0.0803, time:5.1742, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2830/3125], step: 5955, 7.535 samples/sec, batch_loss: 0.4036, batch_loss_c: 0.4029, batch_loss_s: 0.4054, time:5.3088, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2840/3125], step: 5965, 7.674 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1295, batch_loss_s: 0.1032, time:5.2127, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2850/3125], step: 5975, 8.847 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0741, batch_loss_s: 0.0780, time:4.5215, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2860/3125], step: 5985, 7.849 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0743, batch_loss_s: 0.0854, time:5.0964, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2870/3125], step: 5995, 8.364 samples/sec, batch_loss: 0.2375, batch_loss_c: 0.2762, batch_loss_s: 0.1471, time:4.7822, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2880/3125], step: 6005, 8.332 samples/sec, batch_loss: 0.2114, batch_loss_c: 0.2078, batch_loss_s: 0.2197, time:4.8008, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2890/3125], step: 6015, 8.780 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0837, batch_loss_s: 0.0933, time:4.5559, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2900/3125], step: 6025, 7.987 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1033, batch_loss_s: 0.0956, time:5.0082, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2910/3125], step: 6035, 7.877 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0971, batch_loss_s: 0.0819, time:5.0779, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2920/3125], step: 6045, 8.440 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1169, batch_loss_s: 0.1177, time:4.7395, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2930/3125], step: 6055, 8.874 samples/sec, batch_loss: 0.3090, batch_loss_c: 0.3054, batch_loss_s: 0.3173, time:4.5077, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:57:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2940/3125], step: 6065, 8.020 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0801, batch_loss_s: 0.0885, time:4.9878, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2950/3125], step: 6075, 8.741 samples/sec, batch_loss: 0.1108, batch_loss_c: 0.1040, batch_loss_s: 0.1265, time:4.5759, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2960/3125], step: 6085, 8.774 samples/sec, batch_loss: 0.0697, batch_loss_c: 0.0709, batch_loss_s: 0.0667, time:4.5591, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2970/3125], step: 6095, 8.127 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1179, batch_loss_s: 0.1129, time:4.9217, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2980/3125], step: 6105, 8.532 samples/sec, batch_loss: 0.0575, batch_loss_c: 0.0535, batch_loss_s: 0.0670, time:4.6881, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2990/3125], step: 6115, 7.956 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0879, batch_loss_s: 0.1089, time:5.0278, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3000/3125], step: 6125, 8.086 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1302, batch_loss_s: 0.1373, time:4.9471, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3010/3125], step: 6135, 9.070 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0703, batch_loss_s: 0.0898, time:4.4100, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3020/3125], step: 6145, 8.055 samples/sec, batch_loss: 0.1119, batch_loss_c: 0.1275, batch_loss_s: 0.0755, time:4.9657, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3030/3125], step: 6155, 8.202 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0881, batch_loss_s: 0.0870, time:4.8771, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3040/3125], step: 6165, 8.229 samples/sec, batch_loss: 0.3409, batch_loss_c: 0.3416, batch_loss_s: 0.3394, time:4.8611, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3050/3125], step: 6175, 7.398 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.0940, batch_loss_s: 0.1042, time:5.4066, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:58:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3060/3125], step: 6185, 7.976 samples/sec, batch_loss: 0.0681, batch_loss_c: 0.0715, batch_loss_s: 0.0601, time:5.0149, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3070/3125], step: 6195, 8.340 samples/sec, batch_loss: 0.1314, batch_loss_c: 0.1550, batch_loss_s: 0.0765, time:4.7960, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3080/3125], step: 6205, 8.505 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0878, batch_loss_s: 0.0908, time:4.7030, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3090/3125], step: 6215, 7.902 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0933, batch_loss_s: 0.0627, time:5.0621, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3100/3125], step: 6225, 8.669 samples/sec, batch_loss: 0.3165, batch_loss_c: 0.3171, batch_loss_s: 0.3152, time:4.6141, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3110/3125], step: 6235, 10.385 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0887, batch_loss_s: 0.0724, time:3.8518, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3120/3125], step: 6245, 10.203 samples/sec, batch_loss: 0.2005, batch_loss_c: 0.2420, batch_loss_s: 0.1038, time:3.9204, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], train_loss: 0.1718, time: 1523.8803, lr: 0.0001\u001b[0m\n",
            "2019-11-24 09:59:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [0/3125], step: 6250, 8.895 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1310, batch_loss_s: 0.0801, time:4.4967, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [10/3125], step: 6260, 6.309 samples/sec, batch_loss: 0.1828, batch_loss_c: 0.2216, batch_loss_s: 0.0924, time:6.3404, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [20/3125], step: 6270, 8.086 samples/sec, batch_loss: 0.1787, batch_loss_c: 0.1961, batch_loss_s: 0.1380, time:4.9468, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [30/3125], step: 6280, 8.278 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0959, batch_loss_s: 0.0949, time:4.8318, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [40/3125], step: 6290, 8.807 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0950, batch_loss_s: 0.0876, time:4.5418, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [50/3125], step: 6300, 8.926 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1148, batch_loss_s: 0.0889, time:4.4811, lr:0.0001\u001b[0m\n",
            "2019-11-24 09:59:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [60/3125], step: 6310, 8.794 samples/sec, batch_loss: 0.0640, batch_loss_c: 0.0590, batch_loss_s: 0.0755, time:4.5485, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [70/3125], step: 6320, 8.202 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1370, batch_loss_s: 0.1291, time:4.8768, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [80/3125], step: 6330, 8.872 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.0945, batch_loss_s: 0.1009, time:4.5088, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [90/3125], step: 6340, 7.925 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1206, batch_loss_s: 0.0799, time:5.0476, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [100/3125], step: 6350, 8.377 samples/sec, batch_loss: 0.1890, batch_loss_c: 0.1894, batch_loss_s: 0.1879, time:4.7752, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [110/3125], step: 6360, 8.417 samples/sec, batch_loss: 0.5344, batch_loss_c: 0.4905, batch_loss_s: 0.6368, time:4.7522, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [120/3125], step: 6370, 9.086 samples/sec, batch_loss: 0.3676, batch_loss_c: 0.3740, batch_loss_s: 0.3525, time:4.4024, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [130/3125], step: 6380, 8.105 samples/sec, batch_loss: 0.1003, batch_loss_c: 0.0973, batch_loss_s: 0.1073, time:4.9351, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [140/3125], step: 6390, 7.855 samples/sec, batch_loss: 0.0563, batch_loss_c: 0.0527, batch_loss_s: 0.0646, time:5.0923, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [150/3125], step: 6400, 8.660 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0671, batch_loss_s: 0.0895, time:4.6190, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [160/3125], step: 6410, 7.919 samples/sec, batch_loss: 0.1188, batch_loss_c: 0.1328, batch_loss_s: 0.0860, time:5.0510, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [170/3125], step: 6420, 8.134 samples/sec, batch_loss: 0.1024, batch_loss_c: 0.0961, batch_loss_s: 0.1170, time:4.9177, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:00:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [180/3125], step: 6430, 7.853 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0987, batch_loss_s: 0.0749, time:5.0935, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [190/3125], step: 6440, 8.181 samples/sec, batch_loss: 0.2784, batch_loss_c: 0.2802, batch_loss_s: 0.2743, time:4.8894, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [200/3125], step: 6450, 8.777 samples/sec, batch_loss: 0.3507, batch_loss_c: 0.3550, batch_loss_s: 0.3405, time:4.5573, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [210/3125], step: 6460, 8.373 samples/sec, batch_loss: 0.1275, batch_loss_c: 0.1289, batch_loss_s: 0.1244, time:4.7773, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [220/3125], step: 6470, 8.671 samples/sec, batch_loss: 0.1025, batch_loss_c: 0.1114, batch_loss_s: 0.0820, time:4.6133, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [230/3125], step: 6480, 7.633 samples/sec, batch_loss: 0.3613, batch_loss_c: 0.3569, batch_loss_s: 0.3715, time:5.2402, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [240/3125], step: 6490, 8.659 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3287, batch_loss_s: 0.3192, time:4.6194, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [250/3125], step: 6500, 8.738 samples/sec, batch_loss: 0.3198, batch_loss_c: 0.3229, batch_loss_s: 0.3126, time:4.5779, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [260/3125], step: 6510, 9.200 samples/sec, batch_loss: 0.1079, batch_loss_c: 0.1108, batch_loss_s: 0.1011, time:4.3480, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [270/3125], step: 6520, 8.020 samples/sec, batch_loss: 0.1062, batch_loss_c: 0.1075, batch_loss_s: 0.1032, time:4.9877, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [280/3125], step: 6530, 8.465 samples/sec, batch_loss: 0.1917, batch_loss_c: 0.2186, batch_loss_s: 0.1289, time:4.7253, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [290/3125], step: 6540, 8.284 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0731, batch_loss_s: 0.0906, time:4.8286, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [300/3125], step: 6550, 7.470 samples/sec, batch_loss: 0.1487, batch_loss_c: 0.1572, batch_loss_s: 0.1288, time:5.3545, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:01:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [310/3125], step: 6560, 8.100 samples/sec, batch_loss: 0.3017, batch_loss_c: 0.2999, batch_loss_s: 0.3057, time:4.9382, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [320/3125], step: 6570, 7.580 samples/sec, batch_loss: 0.0565, batch_loss_c: 0.0540, batch_loss_s: 0.0625, time:5.2771, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [330/3125], step: 6580, 7.693 samples/sec, batch_loss: 0.1972, batch_loss_c: 0.2082, batch_loss_s: 0.1716, time:5.1999, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [340/3125], step: 6590, 8.893 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0892, batch_loss_s: 0.1110, time:4.4980, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [350/3125], step: 6600, 8.398 samples/sec, batch_loss: 0.3134, batch_loss_c: 0.3096, batch_loss_s: 0.3223, time:4.7631, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [360/3125], step: 6610, 7.303 samples/sec, batch_loss: 0.2965, batch_loss_c: 0.2871, batch_loss_s: 0.3183, time:5.4770, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [370/3125], step: 6620, 8.367 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0628, batch_loss_s: 0.0727, time:4.7805, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [380/3125], step: 6630, 7.869 samples/sec, batch_loss: 0.3081, batch_loss_c: 0.3090, batch_loss_s: 0.3062, time:5.0833, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [390/3125], step: 6640, 7.796 samples/sec, batch_loss: 0.3084, batch_loss_c: 0.3071, batch_loss_s: 0.3115, time:5.1307, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [400/3125], step: 6650, 7.265 samples/sec, batch_loss: 0.1336, batch_loss_c: 0.1301, batch_loss_s: 0.1418, time:5.5062, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [410/3125], step: 6660, 7.783 samples/sec, batch_loss: 0.3208, batch_loss_c: 0.3194, batch_loss_s: 0.3240, time:5.1395, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:02:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [420/3125], step: 6670, 8.740 samples/sec, batch_loss: 0.1651, batch_loss_c: 0.1656, batch_loss_s: 0.1639, time:4.5767, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [430/3125], step: 6680, 8.074 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0936, batch_loss_s: 0.1020, time:4.9544, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [440/3125], step: 6690, 8.731 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0909, batch_loss_s: 0.0934, time:4.5813, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [450/3125], step: 6700, 8.140 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0610, batch_loss_s: 0.0719, time:4.9138, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [460/3125], step: 6710, 8.181 samples/sec, batch_loss: 0.0477, batch_loss_c: 0.0398, batch_loss_s: 0.0662, time:4.8892, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [470/3125], step: 6720, 8.450 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0589, batch_loss_s: 0.0676, time:4.7336, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [480/3125], step: 6730, 7.724 samples/sec, batch_loss: 0.0714, batch_loss_c: 0.0696, batch_loss_s: 0.0757, time:5.1789, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [490/3125], step: 6740, 8.693 samples/sec, batch_loss: 0.0636, batch_loss_c: 0.0639, batch_loss_s: 0.0627, time:4.6015, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [500/3125], step: 6750, 9.091 samples/sec, batch_loss: 0.5218, batch_loss_c: 0.5184, batch_loss_s: 0.5298, time:4.3998, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [510/3125], step: 6760, 9.114 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0809, batch_loss_s: 0.0653, time:4.3889, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [520/3125], step: 6770, 8.909 samples/sec, batch_loss: 0.2900, batch_loss_c: 0.2877, batch_loss_s: 0.2955, time:4.4897, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [530/3125], step: 6780, 7.894 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0682, batch_loss_s: 0.1049, time:5.0668, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [540/3125], step: 6790, 9.166 samples/sec, batch_loss: 0.1537, batch_loss_c: 0.1892, batch_loss_s: 0.0710, time:4.3639, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:03:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [550/3125], step: 6800, 8.924 samples/sec, batch_loss: 0.4023, batch_loss_c: 0.4210, batch_loss_s: 0.3586, time:4.4824, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [560/3125], step: 6810, 8.137 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0626, batch_loss_s: 0.0670, time:4.9157, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [570/3125], step: 6820, 8.752 samples/sec, batch_loss: 0.0821, batch_loss_c: 0.0820, batch_loss_s: 0.0825, time:4.5702, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [580/3125], step: 6830, 8.375 samples/sec, batch_loss: 0.3123, batch_loss_c: 0.3166, batch_loss_s: 0.3021, time:4.7759, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [590/3125], step: 6840, 8.952 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0690, batch_loss_s: 0.0852, time:4.4684, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [600/3125], step: 6850, 8.339 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1021, batch_loss_s: 0.1210, time:4.7966, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [610/3125], step: 6860, 9.088 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0797, batch_loss_s: 0.0772, time:4.4015, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [620/3125], step: 6870, 8.525 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3060, batch_loss_s: 0.3719, time:4.6921, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [630/3125], step: 6880, 8.228 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0915, batch_loss_s: 0.0774, time:4.8615, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [640/3125], step: 6890, 8.033 samples/sec, batch_loss: 0.1023, batch_loss_c: 0.1015, batch_loss_s: 0.1041, time:4.9793, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [650/3125], step: 6900, 8.487 samples/sec, batch_loss: 0.0548, batch_loss_c: 0.0492, batch_loss_s: 0.0679, time:4.7132, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [660/3125], step: 6910, 6.946 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0669, batch_loss_s: 0.0806, time:5.7591, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [670/3125], step: 6920, 8.275 samples/sec, batch_loss: 0.1860, batch_loss_c: 0.2052, batch_loss_s: 0.1411, time:4.8337, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:04:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [680/3125], step: 6930, 8.223 samples/sec, batch_loss: 0.3285, batch_loss_c: 0.3051, batch_loss_s: 0.3829, time:4.8644, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [690/3125], step: 6940, 7.957 samples/sec, batch_loss: 0.4083, batch_loss_c: 0.4354, batch_loss_s: 0.3449, time:5.0271, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [700/3125], step: 6950, 7.846 samples/sec, batch_loss: 0.1033, batch_loss_c: 0.1163, batch_loss_s: 0.0729, time:5.0982, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [710/3125], step: 6960, 8.336 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0873, batch_loss_s: 0.0851, time:4.7984, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [720/3125], step: 6970, 8.248 samples/sec, batch_loss: 0.3984, batch_loss_c: 0.3953, batch_loss_s: 0.4057, time:4.8497, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [730/3125], step: 6980, 8.587 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0758, batch_loss_s: 0.0830, time:4.6583, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [740/3125], step: 6990, 7.939 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0865, batch_loss_s: 0.0879, time:5.0386, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [750/3125], step: 7000, 9.046 samples/sec, batch_loss: 0.1881, batch_loss_c: 0.2169, batch_loss_s: 0.1209, time:4.4218, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [760/3125], step: 7010, 7.528 samples/sec, batch_loss: 0.3108, batch_loss_c: 0.3108, batch_loss_s: 0.3107, time:5.3136, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [770/3125], step: 7020, 8.138 samples/sec, batch_loss: 0.2898, batch_loss_c: 0.2872, batch_loss_s: 0.2959, time:4.9155, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [780/3125], step: 7030, 8.137 samples/sec, batch_loss: 0.2337, batch_loss_c: 0.1986, batch_loss_s: 0.3157, time:4.9161, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [790/3125], step: 7040, 7.264 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.0926, batch_loss_s: 0.1156, time:5.5065, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:05:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [800/3125], step: 7050, 7.020 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1066, batch_loss_s: 0.1222, time:5.6983, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [810/3125], step: 7060, 8.108 samples/sec, batch_loss: 0.1633, batch_loss_c: 0.1754, batch_loss_s: 0.1348, time:4.9332, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [820/3125], step: 7070, 8.236 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1078, batch_loss_s: 0.0945, time:4.8568, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [830/3125], step: 7080, 8.589 samples/sec, batch_loss: 0.3211, batch_loss_c: 0.3213, batch_loss_s: 0.3207, time:4.6572, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [840/3125], step: 7090, 8.379 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1910, batch_loss_s: 0.0800, time:4.7740, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [850/3125], step: 7100, 8.735 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1603, batch_loss_s: 0.0845, time:4.5793, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [860/3125], step: 7110, 7.952 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0781, batch_loss_s: 0.1044, time:5.0304, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [870/3125], step: 7120, 8.760 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0773, batch_loss_s: 0.0710, time:4.5661, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [880/3125], step: 7130, 7.758 samples/sec, batch_loss: 0.0699, batch_loss_c: 0.0630, batch_loss_s: 0.0860, time:5.1559, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [890/3125], step: 7140, 9.060 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.1055, batch_loss_s: 0.0917, time:4.4148, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [900/3125], step: 7150, 8.582 samples/sec, batch_loss: 0.3378, batch_loss_c: 0.3383, batch_loss_s: 0.3366, time:4.6611, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [910/3125], step: 7160, 7.168 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0719, batch_loss_s: 0.0639, time:5.5802, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:06:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [920/3125], step: 7170, 8.087 samples/sec, batch_loss: 0.3089, batch_loss_c: 0.2962, batch_loss_s: 0.3387, time:4.9464, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [930/3125], step: 7180, 8.138 samples/sec, batch_loss: 0.1581, batch_loss_c: 0.1621, batch_loss_s: 0.1488, time:4.9150, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [940/3125], step: 7190, 8.359 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.1004, batch_loss_s: 0.0900, time:4.7850, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [950/3125], step: 7200, 8.478 samples/sec, batch_loss: 0.3823, batch_loss_c: 0.3824, batch_loss_s: 0.3822, time:4.7180, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [960/3125], step: 7210, 8.644 samples/sec, batch_loss: 0.1686, batch_loss_c: 0.1332, batch_loss_s: 0.2513, time:4.6276, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [970/3125], step: 7220, 9.311 samples/sec, batch_loss: 0.0852, batch_loss_c: 0.0835, batch_loss_s: 0.0892, time:4.2958, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [980/3125], step: 7230, 8.675 samples/sec, batch_loss: 0.1378, batch_loss_c: 0.1378, batch_loss_s: 0.1378, time:4.6108, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [990/3125], step: 7240, 8.446 samples/sec, batch_loss: 0.3111, batch_loss_c: 0.3143, batch_loss_s: 0.3037, time:4.7360, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1000/3125], step: 7250, 8.099 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1193, batch_loss_s: 0.0782, time:4.9388, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1010/3125], step: 7260, 9.097 samples/sec, batch_loss: 0.3116, batch_loss_c: 0.3084, batch_loss_s: 0.3191, time:4.3968, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1020/3125], step: 7270, 8.960 samples/sec, batch_loss: 0.2904, batch_loss_c: 0.2880, batch_loss_s: 0.2959, time:4.4645, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1030/3125], step: 7280, 9.217 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1322, batch_loss_s: 0.1065, time:4.3398, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1040/3125], step: 7290, 7.965 samples/sec, batch_loss: 0.1608, batch_loss_c: 0.1901, batch_loss_s: 0.0925, time:5.0221, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:07:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1050/3125], step: 7300, 8.860 samples/sec, batch_loss: 0.3384, batch_loss_c: 0.3542, batch_loss_s: 0.3017, time:4.5147, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1060/3125], step: 7310, 7.996 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0784, batch_loss_s: 0.1159, time:5.0027, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1070/3125], step: 7320, 7.816 samples/sec, batch_loss: 0.0660, batch_loss_c: 0.0617, batch_loss_s: 0.0760, time:5.1176, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1080/3125], step: 7330, 8.891 samples/sec, batch_loss: 0.0917, batch_loss_c: 0.0899, batch_loss_s: 0.0961, time:4.4991, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1090/3125], step: 7340, 8.019 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0958, batch_loss_s: 0.0756, time:4.9882, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1100/3125], step: 7350, 8.227 samples/sec, batch_loss: 0.0717, batch_loss_c: 0.0670, batch_loss_s: 0.0827, time:4.8620, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1110/3125], step: 7360, 7.345 samples/sec, batch_loss: 0.3245, batch_loss_c: 0.3273, batch_loss_s: 0.3179, time:5.4459, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1120/3125], step: 7370, 8.132 samples/sec, batch_loss: 0.3517, batch_loss_c: 0.3430, batch_loss_s: 0.3721, time:4.9189, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1130/3125], step: 7380, 7.137 samples/sec, batch_loss: 0.1100, batch_loss_c: 0.1106, batch_loss_s: 0.1088, time:5.6050, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1140/3125], step: 7390, 7.923 samples/sec, batch_loss: 0.1430, batch_loss_c: 0.1584, batch_loss_s: 0.1070, time:5.0484, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1150/3125], step: 7400, 8.144 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0843, batch_loss_s: 0.0800, time:4.9114, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1160/3125], step: 7410, 7.293 samples/sec, batch_loss: 0.3886, batch_loss_c: 0.4120, batch_loss_s: 0.3340, time:5.4851, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:08:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1170/3125], step: 7420, 7.069 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0718, batch_loss_s: 0.0719, time:5.6589, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1180/3125], step: 7430, 7.569 samples/sec, batch_loss: 0.2968, batch_loss_c: 0.2944, batch_loss_s: 0.3024, time:5.2849, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1190/3125], step: 7440, 8.418 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1223, batch_loss_s: 0.0947, time:4.7516, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1200/3125], step: 7450, 7.840 samples/sec, batch_loss: 0.2889, batch_loss_c: 0.2783, batch_loss_s: 0.3134, time:5.1022, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1210/3125], step: 7460, 8.502 samples/sec, batch_loss: 0.1707, batch_loss_c: 0.1801, batch_loss_s: 0.1488, time:4.7048, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1220/3125], step: 7470, 9.257 samples/sec, batch_loss: 0.3363, batch_loss_c: 0.3134, batch_loss_s: 0.3897, time:4.3212, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1230/3125], step: 7480, 8.829 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0811, batch_loss_s: 0.0719, time:4.5307, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1240/3125], step: 7490, 8.876 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3235, batch_loss_s: 0.3046, time:4.5067, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1250/3125], step: 7500, 8.616 samples/sec, batch_loss: 0.3013, batch_loss_c: 0.2952, batch_loss_s: 0.3157, time:4.6426, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1260/3125], step: 7510, 7.753 samples/sec, batch_loss: 0.0798, batch_loss_c: 0.0754, batch_loss_s: 0.0899, time:5.1596, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1270/3125], step: 7520, 8.037 samples/sec, batch_loss: 0.1617, batch_loss_c: 0.1579, batch_loss_s: 0.1706, time:4.9768, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1280/3125], step: 7530, 8.271 samples/sec, batch_loss: 0.2873, batch_loss_c: 0.2861, batch_loss_s: 0.2901, time:4.8361, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:09:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1290/3125], step: 7540, 8.995 samples/sec, batch_loss: 0.1500, batch_loss_c: 0.1790, batch_loss_s: 0.0822, time:4.4467, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1300/3125], step: 7550, 9.285 samples/sec, batch_loss: 0.1621, batch_loss_c: 0.1907, batch_loss_s: 0.0954, time:4.3080, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1310/3125], step: 7560, 9.188 samples/sec, batch_loss: 0.3306, batch_loss_c: 0.3292, batch_loss_s: 0.3339, time:4.3535, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1320/3125], step: 7570, 8.318 samples/sec, batch_loss: 0.0786, batch_loss_c: 0.0795, batch_loss_s: 0.0767, time:4.8087, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1330/3125], step: 7580, 7.966 samples/sec, batch_loss: 0.1520, batch_loss_c: 0.1712, batch_loss_s: 0.1074, time:5.0213, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1340/3125], step: 7590, 8.615 samples/sec, batch_loss: 0.0775, batch_loss_c: 0.0791, batch_loss_s: 0.0738, time:4.6432, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1350/3125], step: 7600, 7.501 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1798, batch_loss_s: 0.1051, time:5.3329, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1360/3125], step: 7610, 8.268 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0903, batch_loss_s: 0.1036, time:4.8382, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1370/3125], step: 7620, 8.772 samples/sec, batch_loss: 0.5187, batch_loss_c: 0.5093, batch_loss_s: 0.5405, time:4.5600, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1380/3125], step: 7630, 8.645 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0894, batch_loss_s: 0.0737, time:4.6271, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1390/3125], step: 7640, 8.165 samples/sec, batch_loss: 0.5156, batch_loss_c: 0.4885, batch_loss_s: 0.5788, time:4.8991, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1400/3125], step: 7650, 8.042 samples/sec, batch_loss: 0.2861, batch_loss_c: 0.2795, batch_loss_s: 0.3016, time:4.9739, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1410/3125], step: 7660, 8.057 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0881, batch_loss_s: 0.0947, time:4.9645, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:10:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1420/3125], step: 7670, 8.059 samples/sec, batch_loss: 0.0723, batch_loss_c: 0.0684, batch_loss_s: 0.0814, time:4.9631, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1430/3125], step: 7680, 8.198 samples/sec, batch_loss: 0.3520, batch_loss_c: 0.3541, batch_loss_s: 0.3471, time:4.8795, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1440/3125], step: 7690, 8.728 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0764, batch_loss_s: 0.0656, time:4.5828, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1450/3125], step: 7700, 7.399 samples/sec, batch_loss: 0.1062, batch_loss_c: 0.1100, batch_loss_s: 0.0972, time:5.4058, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1460/3125], step: 7710, 8.136 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0941, batch_loss_s: 0.0920, time:4.9164, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1470/3125], step: 7720, 9.314 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0782, batch_loss_s: 0.0791, time:4.2946, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1480/3125], step: 7730, 7.316 samples/sec, batch_loss: 0.3090, batch_loss_c: 0.3055, batch_loss_s: 0.3171, time:5.4678, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1490/3125], step: 7740, 8.446 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3139, batch_loss_s: 0.3096, time:4.7357, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1500/3125], step: 7750, 8.171 samples/sec, batch_loss: 0.2711, batch_loss_c: 0.2506, batch_loss_s: 0.3189, time:4.8952, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1510/3125], step: 7760, 8.946 samples/sec, batch_loss: 0.7255, batch_loss_c: 0.7161, batch_loss_s: 0.7473, time:4.4714, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1520/3125], step: 7770, 7.509 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0699, batch_loss_s: 0.0781, time:5.3269, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1530/3125], step: 7780, 8.147 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3114, batch_loss_s: 0.3261, time:4.9099, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:11:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1540/3125], step: 7790, 9.512 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0883, batch_loss_s: 0.0876, time:4.2052, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1550/3125], step: 7800, 8.819 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1201, batch_loss_s: 0.1284, time:4.5354, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1560/3125], step: 7810, 8.590 samples/sec, batch_loss: 0.3418, batch_loss_c: 0.3495, batch_loss_s: 0.3236, time:4.6563, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1570/3125], step: 7820, 7.903 samples/sec, batch_loss: 0.1870, batch_loss_c: 0.2293, batch_loss_s: 0.0883, time:5.0613, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1580/3125], step: 7830, 8.475 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.2875, batch_loss_s: 0.3157, time:4.7200, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1590/3125], step: 7840, 8.238 samples/sec, batch_loss: 0.2693, batch_loss_c: 0.2584, batch_loss_s: 0.2947, time:4.8553, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1600/3125], step: 7850, 8.399 samples/sec, batch_loss: 0.3174, batch_loss_c: 0.3150, batch_loss_s: 0.3231, time:4.7627, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1610/3125], step: 7860, 8.305 samples/sec, batch_loss: 0.1825, batch_loss_c: 0.1906, batch_loss_s: 0.1636, time:4.8161, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1620/3125], step: 7870, 8.467 samples/sec, batch_loss: 0.3169, batch_loss_c: 0.3133, batch_loss_s: 0.3252, time:4.7243, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1630/3125], step: 7880, 7.827 samples/sec, batch_loss: 0.0450, batch_loss_c: 0.0419, batch_loss_s: 0.0520, time:5.1108, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1640/3125], step: 7890, 7.308 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0974, batch_loss_s: 0.0919, time:5.4733, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1650/3125], step: 7900, 8.494 samples/sec, batch_loss: 0.1583, batch_loss_c: 0.1780, batch_loss_s: 0.1123, time:4.7091, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:12:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1660/3125], step: 7910, 8.279 samples/sec, batch_loss: 0.3129, batch_loss_c: 0.3116, batch_loss_s: 0.3161, time:4.8315, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1670/3125], step: 7920, 7.559 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0509, batch_loss_s: 0.0873, time:5.2914, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1680/3125], step: 7930, 7.984 samples/sec, batch_loss: 0.0985, batch_loss_c: 0.0955, batch_loss_s: 0.1057, time:5.0100, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1690/3125], step: 7940, 8.222 samples/sec, batch_loss: 0.3268, batch_loss_c: 0.3284, batch_loss_s: 0.3230, time:4.8650, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1700/3125], step: 7950, 8.043 samples/sec, batch_loss: 0.1275, batch_loss_c: 0.1299, batch_loss_s: 0.1220, time:4.9734, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1710/3125], step: 7960, 8.403 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.0965, batch_loss_s: 0.1138, time:4.7601, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1720/3125], step: 7970, 7.653 samples/sec, batch_loss: 0.0605, batch_loss_c: 0.0561, batch_loss_s: 0.0708, time:5.2265, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1730/3125], step: 7980, 9.054 samples/sec, batch_loss: 0.1243, batch_loss_c: 0.1350, batch_loss_s: 0.0992, time:4.4180, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1740/3125], step: 7990, 9.224 samples/sec, batch_loss: 0.0536, batch_loss_c: 0.0481, batch_loss_s: 0.0665, time:4.3367, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1750/3125], step: 8000, 8.406 samples/sec, batch_loss: 0.3134, batch_loss_c: 0.3122, batch_loss_s: 0.3162, time:4.7583, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1760/3125], step: 8010, 8.182 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0956, batch_loss_s: 0.0943, time:4.8885, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1770/3125], step: 8020, 8.652 samples/sec, batch_loss: 0.0888, batch_loss_c: 0.0802, batch_loss_s: 0.1088, time:4.6230, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1780/3125], step: 8030, 9.168 samples/sec, batch_loss: 0.5288, batch_loss_c: 0.5270, batch_loss_s: 0.5329, time:4.3630, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:13:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1790/3125], step: 8040, 8.872 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0663, batch_loss_s: 0.0852, time:4.5087, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1800/3125], step: 8050, 8.735 samples/sec, batch_loss: 0.3212, batch_loss_c: 0.3203, batch_loss_s: 0.3234, time:4.5792, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1810/3125], step: 8060, 7.809 samples/sec, batch_loss: 0.1976, batch_loss_c: 0.1902, batch_loss_s: 0.2149, time:5.1220, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1820/3125], step: 8070, 8.266 samples/sec, batch_loss: 0.3391, batch_loss_c: 0.3362, batch_loss_s: 0.3457, time:4.8389, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1830/3125], step: 8080, 7.730 samples/sec, batch_loss: 0.2588, batch_loss_c: 0.2573, batch_loss_s: 0.2622, time:5.1744, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1840/3125], step: 8090, 8.670 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1154, batch_loss_s: 0.1303, time:4.6137, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1850/3125], step: 8100, 9.083 samples/sec, batch_loss: 0.1652, batch_loss_c: 0.1697, batch_loss_s: 0.1545, time:4.4037, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1860/3125], step: 8110, 8.901 samples/sec, batch_loss: 0.0932, batch_loss_c: 0.0906, batch_loss_s: 0.0994, time:4.4937, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1870/3125], step: 8120, 8.864 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0762, batch_loss_s: 0.0817, time:4.5126, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1880/3125], step: 8130, 9.193 samples/sec, batch_loss: 0.0586, batch_loss_c: 0.0559, batch_loss_s: 0.0649, time:4.3513, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1890/3125], step: 8140, 7.809 samples/sec, batch_loss: 0.2969, batch_loss_c: 0.2935, batch_loss_s: 0.3047, time:5.1223, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1900/3125], step: 8150, 8.583 samples/sec, batch_loss: 0.0648, batch_loss_c: 0.0585, batch_loss_s: 0.0796, time:4.6603, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1910/3125], step: 8160, 8.152 samples/sec, batch_loss: 0.1397, batch_loss_c: 0.1399, batch_loss_s: 0.1393, time:4.9067, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:14:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1920/3125], step: 8170, 9.105 samples/sec, batch_loss: 0.3189, batch_loss_c: 0.3265, batch_loss_s: 0.3012, time:4.3930, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1930/3125], step: 8180, 8.428 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.0964, batch_loss_s: 0.1107, time:4.7459, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1940/3125], step: 8190, 8.565 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0728, batch_loss_s: 0.0851, time:4.6703, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1950/3125], step: 8200, 7.984 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0641, batch_loss_s: 0.0734, time:5.0101, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1960/3125], step: 8210, 8.190 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0747, batch_loss_s: 0.0751, time:4.8842, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1970/3125], step: 8220, 8.531 samples/sec, batch_loss: 0.0612, batch_loss_c: 0.0588, batch_loss_s: 0.0668, time:4.6891, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1980/3125], step: 8230, 8.481 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1443, batch_loss_s: 0.0891, time:4.7165, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1990/3125], step: 8240, 7.937 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1085, batch_loss_s: 0.0899, time:5.0399, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2000/3125], step: 8250, 8.703 samples/sec, batch_loss: 0.3164, batch_loss_c: 0.3152, batch_loss_s: 0.3193, time:4.5960, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2010/3125], step: 8260, 7.906 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0759, batch_loss_s: 0.0910, time:5.0593, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2020/3125], step: 8270, 7.661 samples/sec, batch_loss: 0.3138, batch_loss_c: 0.3055, batch_loss_s: 0.3332, time:5.2213, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2030/3125], step: 8280, 8.719 samples/sec, batch_loss: 0.1060, batch_loss_c: 0.1217, batch_loss_s: 0.0695, time:4.5878, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:15:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2040/3125], step: 8290, 7.686 samples/sec, batch_loss: 0.1304, batch_loss_c: 0.1511, batch_loss_s: 0.0820, time:5.2040, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2050/3125], step: 8300, 8.106 samples/sec, batch_loss: 0.7544, batch_loss_c: 0.7492, batch_loss_s: 0.7664, time:4.9344, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2060/3125], step: 8310, 8.222 samples/sec, batch_loss: 0.1248, batch_loss_c: 0.1301, batch_loss_s: 0.1123, time:4.8650, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2070/3125], step: 8320, 7.368 samples/sec, batch_loss: 0.3422, batch_loss_c: 0.3466, batch_loss_s: 0.3319, time:5.4287, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2080/3125], step: 8330, 7.834 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0953, batch_loss_s: 0.1052, time:5.1056, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2090/3125], step: 8340, 7.996 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1201, batch_loss_s: 0.0945, time:5.0026, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2100/3125], step: 8350, 8.522 samples/sec, batch_loss: 0.2367, batch_loss_c: 0.2145, batch_loss_s: 0.2884, time:4.6939, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2110/3125], step: 8360, 8.715 samples/sec, batch_loss: 0.0931, batch_loss_c: 0.0895, batch_loss_s: 0.1015, time:4.5896, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2120/3125], step: 8370, 7.931 samples/sec, batch_loss: 0.2895, batch_loss_c: 0.2805, batch_loss_s: 0.3106, time:5.0437, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2130/3125], step: 8380, 8.059 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1242, batch_loss_s: 0.0621, time:4.9635, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2140/3125], step: 8390, 8.482 samples/sec, batch_loss: 0.3989, batch_loss_c: 0.4384, batch_loss_s: 0.3068, time:4.7156, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2150/3125], step: 8400, 8.749 samples/sec, batch_loss: 0.0629, batch_loss_c: 0.0582, batch_loss_s: 0.0739, time:4.5721, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:16:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2160/3125], step: 8410, 7.428 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0694, batch_loss_s: 0.0625, time:5.3853, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2170/3125], step: 8420, 8.377 samples/sec, batch_loss: 0.1504, batch_loss_c: 0.1533, batch_loss_s: 0.1437, time:4.7748, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2180/3125], step: 8430, 8.844 samples/sec, batch_loss: 0.2777, batch_loss_c: 0.2647, batch_loss_s: 0.3080, time:4.5227, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2190/3125], step: 8440, 8.975 samples/sec, batch_loss: 0.1666, batch_loss_c: 0.1790, batch_loss_s: 0.1377, time:4.4570, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2200/3125], step: 8450, 7.422 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2939, batch_loss_s: 0.3051, time:5.3896, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2210/3125], step: 8460, 8.930 samples/sec, batch_loss: 0.5116, batch_loss_c: 0.4879, batch_loss_s: 0.5667, time:4.4795, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2220/3125], step: 8470, 8.912 samples/sec, batch_loss: 0.2957, batch_loss_c: 0.2930, batch_loss_s: 0.3021, time:4.4885, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2230/3125], step: 8480, 8.544 samples/sec, batch_loss: 0.1169, batch_loss_c: 0.1359, batch_loss_s: 0.0726, time:4.6816, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2240/3125], step: 8490, 7.893 samples/sec, batch_loss: 0.3724, batch_loss_c: 0.3566, batch_loss_s: 0.4094, time:5.0677, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2250/3125], step: 8500, 8.478 samples/sec, batch_loss: 0.1775, batch_loss_c: 0.1774, batch_loss_s: 0.1778, time:4.7182, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2260/3125], step: 8510, 8.464 samples/sec, batch_loss: 0.3702, batch_loss_c: 0.3773, batch_loss_s: 0.3537, time:4.7259, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2270/3125], step: 8520, 8.118 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1484, batch_loss_s: 0.1332, time:4.9271, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2280/3125], step: 8530, 8.420 samples/sec, batch_loss: 0.3646, batch_loss_c: 0.3765, batch_loss_s: 0.3370, time:4.7509, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:17:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2290/3125], step: 8540, 8.250 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0898, batch_loss_s: 0.0957, time:4.8487, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2300/3125], step: 8550, 8.614 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0745, batch_loss_s: 0.0915, time:4.6436, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2310/3125], step: 8560, 8.642 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3399, batch_loss_s: 0.3345, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2320/3125], step: 8570, 8.275 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1161, batch_loss_s: 0.0765, time:4.8336, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2330/3125], step: 8580, 8.651 samples/sec, batch_loss: 0.3184, batch_loss_c: 0.3180, batch_loss_s: 0.3194, time:4.6238, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2340/3125], step: 8590, 8.279 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0882, batch_loss_s: 0.1109, time:4.8317, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2350/3125], step: 8600, 8.045 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0673, batch_loss_s: 0.0717, time:4.9720, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2360/3125], step: 8610, 7.949 samples/sec, batch_loss: 0.3032, batch_loss_c: 0.2981, batch_loss_s: 0.3153, time:5.0318, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2370/3125], step: 8620, 8.237 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0712, batch_loss_s: 0.1003, time:4.8560, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2380/3125], step: 8630, 8.766 samples/sec, batch_loss: 0.3029, batch_loss_c: 0.3019, batch_loss_s: 0.3051, time:4.5633, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2390/3125], step: 8640, 7.825 samples/sec, batch_loss: 0.3142, batch_loss_c: 0.3131, batch_loss_s: 0.3167, time:5.1120, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2400/3125], step: 8650, 8.741 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0756, batch_loss_s: 0.1127, time:4.5761, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:18:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2410/3125], step: 8660, 7.906 samples/sec, batch_loss: 0.1368, batch_loss_c: 0.1306, batch_loss_s: 0.1513, time:5.0598, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2420/3125], step: 8670, 7.706 samples/sec, batch_loss: 0.3106, batch_loss_c: 0.2974, batch_loss_s: 0.3414, time:5.1910, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2430/3125], step: 8680, 9.021 samples/sec, batch_loss: 0.3121, batch_loss_c: 0.3088, batch_loss_s: 0.3198, time:4.4340, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2440/3125], step: 8690, 8.378 samples/sec, batch_loss: 0.2396, batch_loss_c: 0.2045, batch_loss_s: 0.3214, time:4.7744, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2450/3125], step: 8700, 8.938 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.0946, batch_loss_s: 0.1179, time:4.4752, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2460/3125], step: 8710, 7.725 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0772, batch_loss_s: 0.0893, time:5.1779, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2470/3125], step: 8720, 7.608 samples/sec, batch_loss: 0.3545, batch_loss_c: 0.3552, batch_loss_s: 0.3530, time:5.2574, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2480/3125], step: 8730, 8.732 samples/sec, batch_loss: 0.2310, batch_loss_c: 0.1933, batch_loss_s: 0.3191, time:4.5810, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2490/3125], step: 8740, 7.671 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0900, batch_loss_s: 0.0803, time:5.2142, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2500/3125], step: 8750, 8.210 samples/sec, batch_loss: 0.1193, batch_loss_c: 0.1266, batch_loss_s: 0.1022, time:4.8720, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2510/3125], step: 8760, 7.719 samples/sec, batch_loss: 0.0976, batch_loss_c: 0.1052, batch_loss_s: 0.0801, time:5.1821, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2520/3125], step: 8770, 8.369 samples/sec, batch_loss: 0.3923, batch_loss_c: 0.4223, batch_loss_s: 0.3224, time:4.7793, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2530/3125], step: 8780, 9.183 samples/sec, batch_loss: 0.5237, batch_loss_c: 0.5206, batch_loss_s: 0.5308, time:4.3558, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:19:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2540/3125], step: 8790, 8.080 samples/sec, batch_loss: 0.5510, batch_loss_c: 0.5518, batch_loss_s: 0.5492, time:4.9507, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2550/3125], step: 8800, 8.263 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1208, batch_loss_s: 0.1097, time:4.8407, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2560/3125], step: 8810, 8.922 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0679, batch_loss_s: 0.0649, time:4.4831, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2570/3125], step: 8820, 7.792 samples/sec, batch_loss: 0.3003, batch_loss_c: 0.2972, batch_loss_s: 0.3075, time:5.1336, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2580/3125], step: 8830, 8.299 samples/sec, batch_loss: 0.0592, batch_loss_c: 0.0562, batch_loss_s: 0.0663, time:4.8198, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2590/3125], step: 8840, 8.072 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0921, batch_loss_s: 0.0849, time:4.9556, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2600/3125], step: 8850, 8.156 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1159, batch_loss_s: 0.0735, time:4.9044, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2610/3125], step: 8860, 8.680 samples/sec, batch_loss: 0.2959, batch_loss_c: 0.2909, batch_loss_s: 0.3076, time:4.6084, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2620/3125], step: 8870, 8.362 samples/sec, batch_loss: 0.3728, batch_loss_c: 0.4038, batch_loss_s: 0.3004, time:4.7833, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2630/3125], step: 8880, 9.043 samples/sec, batch_loss: 0.5146, batch_loss_c: 0.5063, batch_loss_s: 0.5340, time:4.4231, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2640/3125], step: 8890, 8.373 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1119, batch_loss_s: 0.1043, time:4.7774, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2650/3125], step: 8900, 8.572 samples/sec, batch_loss: 0.1422, batch_loss_c: 0.1607, batch_loss_s: 0.0990, time:4.6664, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:20:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2660/3125], step: 8910, 8.035 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0873, batch_loss_s: 0.1151, time:4.9779, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2670/3125], step: 8920, 8.650 samples/sec, batch_loss: 0.3742, batch_loss_c: 0.3873, batch_loss_s: 0.3436, time:4.6245, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2680/3125], step: 8930, 8.486 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0900, batch_loss_s: 0.0845, time:4.7137, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2690/3125], step: 8940, 8.662 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1147, batch_loss_s: 0.1346, time:4.6177, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2700/3125], step: 8950, 7.311 samples/sec, batch_loss: 0.3184, batch_loss_c: 0.3124, batch_loss_s: 0.3325, time:5.4710, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2710/3125], step: 8960, 8.926 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0903, batch_loss_s: 0.0914, time:4.4812, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2720/3125], step: 8970, 8.863 samples/sec, batch_loss: 0.3173, batch_loss_c: 0.3211, batch_loss_s: 0.3084, time:4.5130, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2730/3125], step: 8980, 7.597 samples/sec, batch_loss: 0.3180, batch_loss_c: 0.3182, batch_loss_s: 0.3175, time:5.2653, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2740/3125], step: 8990, 8.747 samples/sec, batch_loss: 0.1494, batch_loss_c: 0.1524, batch_loss_s: 0.1425, time:4.5732, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2750/3125], step: 9000, 7.925 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0840, batch_loss_s: 0.0796, time:5.0472, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2760/3125], step: 9010, 7.970 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0584, batch_loss_s: 0.0990, time:5.0188, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2770/3125], step: 9020, 8.312 samples/sec, batch_loss: 0.3137, batch_loss_c: 0.3118, batch_loss_s: 0.3180, time:4.8124, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2780/3125], step: 9030, 8.284 samples/sec, batch_loss: 0.2724, batch_loss_c: 0.2553, batch_loss_s: 0.3124, time:4.8289, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:21:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2790/3125], step: 9040, 8.241 samples/sec, batch_loss: 0.1096, batch_loss_c: 0.1047, batch_loss_s: 0.1212, time:4.8536, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2800/3125], step: 9050, 7.807 samples/sec, batch_loss: 0.1815, batch_loss_c: 0.2096, batch_loss_s: 0.1159, time:5.1236, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2810/3125], step: 9060, 8.627 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0557, batch_loss_s: 0.0858, time:4.6364, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2820/3125], step: 9070, 8.338 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.1072, batch_loss_s: 0.0698, time:4.7975, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2830/3125], step: 9080, 8.508 samples/sec, batch_loss: 0.0662, batch_loss_c: 0.0663, batch_loss_s: 0.0659, time:4.7015, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2840/3125], step: 9090, 8.159 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.0845, batch_loss_s: 0.1425, time:4.9023, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2850/3125], step: 9100, 7.744 samples/sec, batch_loss: 0.1398, batch_loss_c: 0.1468, batch_loss_s: 0.1232, time:5.1652, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2860/3125], step: 9110, 7.662 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3267, batch_loss_s: 0.3109, time:5.2205, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2870/3125], step: 9120, 8.884 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0904, batch_loss_s: 0.0987, time:4.5023, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2880/3125], step: 9130, 8.100 samples/sec, batch_loss: 0.3412, batch_loss_c: 0.3432, batch_loss_s: 0.3367, time:4.9381, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2890/3125], step: 9140, 8.319 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1252, batch_loss_s: 0.0854, time:4.8081, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2900/3125], step: 9150, 8.693 samples/sec, batch_loss: 0.0595, batch_loss_c: 0.0537, batch_loss_s: 0.0729, time:4.6013, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:22:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2910/3125], step: 9160, 8.678 samples/sec, batch_loss: 0.1389, batch_loss_c: 0.1510, batch_loss_s: 0.1108, time:4.6096, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2920/3125], step: 9170, 8.331 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0880, batch_loss_s: 0.0951, time:4.8012, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2930/3125], step: 9180, 9.102 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0652, batch_loss_s: 0.0622, time:4.3947, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2940/3125], step: 9190, 7.935 samples/sec, batch_loss: 0.3723, batch_loss_c: 0.3723, batch_loss_s: 0.3723, time:5.0408, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2950/3125], step: 9200, 8.409 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1156, batch_loss_s: 0.1153, time:4.7567, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2960/3125], step: 9210, 8.727 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0990, batch_loss_s: 0.0776, time:4.5834, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2970/3125], step: 9220, 9.294 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1162, batch_loss_s: 0.0995, time:4.3039, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2980/3125], step: 9230, 8.209 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0629, batch_loss_s: 0.0779, time:4.8725, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2990/3125], step: 9240, 8.066 samples/sec, batch_loss: 0.3356, batch_loss_c: 0.3339, batch_loss_s: 0.3394, time:4.9589, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3000/3125], step: 9250, 8.657 samples/sec, batch_loss: 0.3211, batch_loss_c: 0.3186, batch_loss_s: 0.3270, time:4.6205, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3010/3125], step: 9260, 8.457 samples/sec, batch_loss: 0.3053, batch_loss_c: 0.2999, batch_loss_s: 0.3179, time:4.7301, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3020/3125], step: 9270, 9.030 samples/sec, batch_loss: 0.0573, batch_loss_c: 0.0557, batch_loss_s: 0.0608, time:4.4295, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3030/3125], step: 9280, 8.748 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0713, batch_loss_s: 0.0967, time:4.5727, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:23:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3040/3125], step: 9290, 8.402 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0739, batch_loss_s: 0.0903, time:4.7606, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3050/3125], step: 9300, 9.087 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0791, batch_loss_s: 0.1052, time:4.4020, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3060/3125], step: 9310, 8.454 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0769, batch_loss_s: 0.0957, time:4.7313, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3070/3125], step: 9320, 8.439 samples/sec, batch_loss: 0.1635, batch_loss_c: 0.1883, batch_loss_s: 0.1057, time:4.7399, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3080/3125], step: 9330, 8.743 samples/sec, batch_loss: 0.2379, batch_loss_c: 0.2452, batch_loss_s: 0.2208, time:4.5753, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3090/3125], step: 9340, 7.908 samples/sec, batch_loss: 0.2755, batch_loss_c: 0.2684, batch_loss_s: 0.2920, time:5.0580, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3100/3125], step: 9350, 7.529 samples/sec, batch_loss: 0.2963, batch_loss_c: 0.2917, batch_loss_s: 0.3070, time:5.3127, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3110/3125], step: 9360, 10.005 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1266, batch_loss_s: 0.1308, time:3.9978, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3120/3125], step: 9370, 10.220 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1383, batch_loss_s: 0.1184, time:3.9138, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], train_loss: 0.1720, time: 1511.6568, lr: 0.0001\u001b[0m\n",
            "2019-11-24 10:24:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [0/3125], step: 9375, 6.702 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0950, batch_loss_s: 0.0654, time:5.9684, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [10/3125], step: 9385, 7.497 samples/sec, batch_loss: 0.1235, batch_loss_c: 0.1145, batch_loss_s: 0.1444, time:5.3351, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [20/3125], step: 9395, 7.743 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0626, batch_loss_s: 0.0905, time:5.1658, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:24:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [30/3125], step: 9405, 8.272 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0921, batch_loss_s: 0.0785, time:4.8357, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [40/3125], step: 9415, 8.656 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0828, batch_loss_s: 0.0866, time:4.6213, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [50/3125], step: 9425, 8.878 samples/sec, batch_loss: 0.2677, batch_loss_c: 0.2599, batch_loss_s: 0.2860, time:4.5053, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [60/3125], step: 9435, 8.784 samples/sec, batch_loss: 0.3611, batch_loss_c: 0.3715, batch_loss_s: 0.3367, time:4.5538, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [70/3125], step: 9445, 8.332 samples/sec, batch_loss: 0.3154, batch_loss_c: 0.3262, batch_loss_s: 0.2903, time:4.8005, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [80/3125], step: 9455, 7.519 samples/sec, batch_loss: 0.0901, batch_loss_c: 0.0853, batch_loss_s: 0.1012, time:5.3201, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [90/3125], step: 9465, 8.698 samples/sec, batch_loss: 0.1032, batch_loss_c: 0.1067, batch_loss_s: 0.0950, time:4.5989, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [100/3125], step: 9475, 8.244 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.0923, batch_loss_s: 0.1069, time:4.8522, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [110/3125], step: 9485, 8.811 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1170, batch_loss_s: 0.0949, time:4.5399, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [120/3125], step: 9495, 8.864 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0727, batch_loss_s: 0.0777, time:4.5126, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [130/3125], step: 9505, 7.748 samples/sec, batch_loss: 0.2921, batch_loss_c: 0.2811, batch_loss_s: 0.3176, time:5.1629, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [140/3125], step: 9515, 8.688 samples/sec, batch_loss: 0.3167, batch_loss_c: 0.3132, batch_loss_s: 0.3249, time:4.6040, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:25:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [150/3125], step: 9525, 8.108 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0902, batch_loss_s: 0.0848, time:4.9334, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [160/3125], step: 9535, 8.393 samples/sec, batch_loss: 0.4112, batch_loss_c: 0.4615, batch_loss_s: 0.2940, time:4.7661, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [170/3125], step: 9545, 8.791 samples/sec, batch_loss: 0.3351, batch_loss_c: 0.3416, batch_loss_s: 0.3199, time:4.5503, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [180/3125], step: 9555, 5.872 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1246, batch_loss_s: 0.0720, time:6.8117, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [190/3125], step: 9565, 7.303 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0778, batch_loss_s: 0.0584, time:5.4771, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [200/3125], step: 9575, 8.480 samples/sec, batch_loss: 0.0874, batch_loss_c: 0.0874, batch_loss_s: 0.0873, time:4.7172, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [210/3125], step: 9585, 8.637 samples/sec, batch_loss: 0.1432, batch_loss_c: 0.1417, batch_loss_s: 0.1469, time:4.6312, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [220/3125], step: 9595, 7.913 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0914, batch_loss_s: 0.0956, time:5.0551, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [230/3125], step: 9605, 8.066 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.1134, batch_loss_s: 0.1074, time:4.9592, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [240/3125], step: 9615, 9.222 samples/sec, batch_loss: 0.0660, batch_loss_c: 0.0606, batch_loss_s: 0.0785, time:4.3377, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [250/3125], step: 9625, 8.466 samples/sec, batch_loss: 0.2846, batch_loss_c: 0.2695, batch_loss_s: 0.3197, time:4.7250, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [260/3125], step: 9635, 7.844 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0709, batch_loss_s: 0.0751, time:5.0995, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:26:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [270/3125], step: 9645, 8.331 samples/sec, batch_loss: 0.5499, batch_loss_c: 0.5501, batch_loss_s: 0.5494, time:4.8016, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [280/3125], step: 9655, 7.841 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0774, batch_loss_s: 0.0749, time:5.1014, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [290/3125], step: 9665, 8.327 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0808, batch_loss_s: 0.0840, time:4.8037, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [300/3125], step: 9675, 7.787 samples/sec, batch_loss: 0.0513, batch_loss_c: 0.0470, batch_loss_s: 0.0614, time:5.1367, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [310/3125], step: 9685, 7.665 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0740, batch_loss_s: 0.0852, time:5.2185, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [320/3125], step: 9695, 8.148 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0760, batch_loss_s: 0.0913, time:4.9092, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [330/3125], step: 9705, 7.682 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0716, batch_loss_s: 0.0860, time:5.2072, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [340/3125], step: 9715, 8.950 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3138, batch_loss_s: 0.3205, time:4.4691, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [350/3125], step: 9725, 8.431 samples/sec, batch_loss: 0.3463, batch_loss_c: 0.3460, batch_loss_s: 0.3471, time:4.7443, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [360/3125], step: 9735, 8.700 samples/sec, batch_loss: 0.1349, batch_loss_c: 0.1561, batch_loss_s: 0.0853, time:4.5979, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [370/3125], step: 9745, 8.365 samples/sec, batch_loss: 0.6270, batch_loss_c: 0.6653, batch_loss_s: 0.5376, time:4.7821, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [380/3125], step: 9755, 8.103 samples/sec, batch_loss: 0.0692, batch_loss_c: 0.0632, batch_loss_s: 0.0831, time:4.9363, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [390/3125], step: 9765, 7.444 samples/sec, batch_loss: 0.1393, batch_loss_c: 0.1436, batch_loss_s: 0.1291, time:5.3732, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:27:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [400/3125], step: 9775, 8.456 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1449, batch_loss_s: 0.0975, time:4.7303, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [410/3125], step: 9785, 8.654 samples/sec, batch_loss: 0.1000, batch_loss_c: 0.1079, batch_loss_s: 0.0816, time:4.6221, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [420/3125], step: 9795, 8.191 samples/sec, batch_loss: 0.1688, batch_loss_c: 0.2026, batch_loss_s: 0.0899, time:4.8836, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [430/3125], step: 9805, 7.916 samples/sec, batch_loss: 0.3262, batch_loss_c: 0.3365, batch_loss_s: 0.3023, time:5.0531, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [440/3125], step: 9815, 8.638 samples/sec, batch_loss: 0.0787, batch_loss_c: 0.0812, batch_loss_s: 0.0730, time:4.6304, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [450/3125], step: 9825, 7.946 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3333, batch_loss_s: 0.3049, time:5.0342, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [460/3125], step: 9835, 7.754 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1123, batch_loss_s: 0.0938, time:5.1589, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [470/3125], step: 9845, 8.857 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0872, batch_loss_s: 0.0730, time:4.5163, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [480/3125], step: 9855, 7.572 samples/sec, batch_loss: 0.1327, batch_loss_c: 0.1301, batch_loss_s: 0.1388, time:5.2827, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [490/3125], step: 9865, 8.952 samples/sec, batch_loss: 0.2719, batch_loss_c: 0.2599, batch_loss_s: 0.2998, time:4.4684, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [500/3125], step: 9875, 8.287 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0935, batch_loss_s: 0.0958, time:4.8266, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [510/3125], step: 9885, 8.491 samples/sec, batch_loss: 0.1257, batch_loss_c: 0.1408, batch_loss_s: 0.0903, time:4.7109, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:28:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [520/3125], step: 9895, 8.527 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0906, batch_loss_s: 0.0792, time:4.6910, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [530/3125], step: 9905, 8.283 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0726, batch_loss_s: 0.0828, time:4.8290, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [540/3125], step: 9915, 8.798 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0627, batch_loss_s: 0.0694, time:4.5465, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [550/3125], step: 9925, 8.788 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.1034, batch_loss_s: 0.0589, time:4.5516, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [560/3125], step: 9935, 8.744 samples/sec, batch_loss: 0.2831, batch_loss_c: 0.2713, batch_loss_s: 0.3107, time:4.5745, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [570/3125], step: 9945, 9.140 samples/sec, batch_loss: 0.3455, batch_loss_c: 0.3531, batch_loss_s: 0.3277, time:4.3765, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [580/3125], step: 9955, 8.249 samples/sec, batch_loss: 0.0613, batch_loss_c: 0.0548, batch_loss_s: 0.0765, time:4.8488, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [590/3125], step: 9965, 8.759 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1148, batch_loss_s: 0.1331, time:4.5667, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [600/3125], step: 9975, 9.114 samples/sec, batch_loss: 0.2872, batch_loss_c: 0.2824, batch_loss_s: 0.2984, time:4.3888, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [610/3125], step: 9985, 8.685 samples/sec, batch_loss: 0.0536, batch_loss_c: 0.0497, batch_loss_s: 0.0627, time:4.6056, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [620/3125], step: 9995, 8.872 samples/sec, batch_loss: 0.2994, batch_loss_c: 0.2982, batch_loss_s: 0.3020, time:4.5086, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [630/3125], step: 10005, 7.872 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0908, batch_loss_s: 0.0838, time:5.0811, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [640/3125], step: 10015, 8.266 samples/sec, batch_loss: 0.1483, batch_loss_c: 0.1473, batch_loss_s: 0.1505, time:4.8389, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:29:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [650/3125], step: 10025, 7.806 samples/sec, batch_loss: 0.2231, batch_loss_c: 0.2637, batch_loss_s: 0.1285, time:5.1244, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [660/3125], step: 10035, 7.254 samples/sec, batch_loss: 0.0627, batch_loss_c: 0.0582, batch_loss_s: 0.0732, time:5.5143, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [670/3125], step: 10045, 8.591 samples/sec, batch_loss: 0.3079, batch_loss_c: 0.3088, batch_loss_s: 0.3057, time:4.6560, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [680/3125], step: 10055, 8.320 samples/sec, batch_loss: 0.1832, batch_loss_c: 0.1941, batch_loss_s: 0.1576, time:4.8076, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [690/3125], step: 10065, 8.307 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1363, batch_loss_s: 0.0831, time:4.8153, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [700/3125], step: 10075, 8.524 samples/sec, batch_loss: 0.0442, batch_loss_c: 0.0380, batch_loss_s: 0.0587, time:4.6924, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [710/3125], step: 10085, 8.291 samples/sec, batch_loss: 0.3279, batch_loss_c: 0.3306, batch_loss_s: 0.3215, time:4.8244, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [720/3125], step: 10095, 8.469 samples/sec, batch_loss: 0.0652, batch_loss_c: 0.0636, batch_loss_s: 0.0690, time:4.7232, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [730/3125], step: 10105, 7.459 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0630, batch_loss_s: 0.0751, time:5.3630, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [740/3125], step: 10115, 7.069 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0681, batch_loss_s: 0.0627, time:5.6587, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [750/3125], step: 10125, 8.610 samples/sec, batch_loss: 0.3447, batch_loss_c: 0.3633, batch_loss_s: 0.3014, time:4.6459, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [760/3125], step: 10135, 7.658 samples/sec, batch_loss: 0.0668, batch_loss_c: 0.0597, batch_loss_s: 0.0834, time:5.2233, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:30:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [770/3125], step: 10145, 7.622 samples/sec, batch_loss: 0.1234, batch_loss_c: 0.1434, batch_loss_s: 0.0768, time:5.2482, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [780/3125], step: 10155, 8.394 samples/sec, batch_loss: 0.0770, batch_loss_c: 0.0746, batch_loss_s: 0.0825, time:4.7655, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [790/3125], step: 10165, 7.097 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1045, batch_loss_s: 0.1137, time:5.6360, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [800/3125], step: 10175, 8.163 samples/sec, batch_loss: 0.2444, batch_loss_c: 0.2218, batch_loss_s: 0.2969, time:4.9001, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [810/3125], step: 10185, 7.689 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0864, batch_loss_s: 0.0969, time:5.2020, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [820/3125], step: 10195, 9.165 samples/sec, batch_loss: 0.3052, batch_loss_c: 0.3034, batch_loss_s: 0.3095, time:4.3646, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [830/3125], step: 10205, 8.754 samples/sec, batch_loss: 0.0897, batch_loss_c: 0.0928, batch_loss_s: 0.0826, time:4.5696, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [840/3125], step: 10215, 8.388 samples/sec, batch_loss: 0.4072, batch_loss_c: 0.4123, batch_loss_s: 0.3953, time:4.7689, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [850/3125], step: 10225, 8.530 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.1039, batch_loss_s: 0.0934, time:4.6892, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [860/3125], step: 10235, 7.265 samples/sec, batch_loss: 0.2866, batch_loss_c: 0.2787, batch_loss_s: 0.3052, time:5.5059, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [870/3125], step: 10245, 7.414 samples/sec, batch_loss: 0.5664, batch_loss_c: 0.5664, batch_loss_s: 0.5664, time:5.3949, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [880/3125], step: 10255, 8.576 samples/sec, batch_loss: 0.1875, batch_loss_c: 0.1869, batch_loss_s: 0.1890, time:4.6644, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:31:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [890/3125], step: 10265, 7.927 samples/sec, batch_loss: 0.2801, batch_loss_c: 0.2724, batch_loss_s: 0.2981, time:5.0460, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [900/3125], step: 10275, 8.139 samples/sec, batch_loss: 0.3382, batch_loss_c: 0.3492, batch_loss_s: 0.3124, time:4.9148, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [910/3125], step: 10285, 7.848 samples/sec, batch_loss: 0.1387, batch_loss_c: 0.1534, batch_loss_s: 0.1043, time:5.0969, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [920/3125], step: 10295, 7.949 samples/sec, batch_loss: 0.0685, batch_loss_c: 0.0651, batch_loss_s: 0.0764, time:5.0321, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [930/3125], step: 10305, 8.511 samples/sec, batch_loss: 0.2537, batch_loss_c: 0.2953, batch_loss_s: 0.1564, time:4.7001, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [940/3125], step: 10315, 8.785 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0854, batch_loss_s: 0.0791, time:4.5533, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [950/3125], step: 10325, 8.852 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1040, batch_loss_s: 0.1052, time:4.5186, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [960/3125], step: 10335, 8.298 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.1056, batch_loss_s: 0.0679, time:4.8202, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [970/3125], step: 10345, 8.871 samples/sec, batch_loss: 0.0609, batch_loss_c: 0.0566, batch_loss_s: 0.0711, time:4.5089, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [980/3125], step: 10355, 8.993 samples/sec, batch_loss: 0.1408, batch_loss_c: 0.1362, batch_loss_s: 0.1515, time:4.4477, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [990/3125], step: 10365, 8.537 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0759, batch_loss_s: 0.0878, time:4.6857, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1000/3125], step: 10375, 9.066 samples/sec, batch_loss: 0.3529, batch_loss_c: 0.3602, batch_loss_s: 0.3361, time:4.4121, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1010/3125], step: 10385, 8.749 samples/sec, batch_loss: 0.0567, batch_loss_c: 0.0514, batch_loss_s: 0.0691, time:4.5720, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:32:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1020/3125], step: 10395, 8.951 samples/sec, batch_loss: 0.1452, batch_loss_c: 0.1528, batch_loss_s: 0.1274, time:4.4685, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1030/3125], step: 10405, 8.104 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1135, batch_loss_s: 0.1097, time:4.9356, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1040/3125], step: 10415, 7.944 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0774, batch_loss_s: 0.0686, time:5.0354, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1050/3125], step: 10425, 8.249 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.0980, batch_loss_s: 0.1183, time:4.8490, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1060/3125], step: 10435, 7.897 samples/sec, batch_loss: 0.0851, batch_loss_c: 0.0840, batch_loss_s: 0.0875, time:5.0653, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1070/3125], step: 10445, 7.613 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.0945, batch_loss_s: 0.0991, time:5.2541, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1080/3125], step: 10455, 8.064 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0858, batch_loss_s: 0.0930, time:4.9603, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1090/3125], step: 10465, 8.196 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3221, batch_loss_s: 0.3011, time:4.8804, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1100/3125], step: 10475, 8.233 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0786, batch_loss_s: 0.0960, time:4.8584, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1110/3125], step: 10485, 7.494 samples/sec, batch_loss: 0.0618, batch_loss_c: 0.0612, batch_loss_s: 0.0631, time:5.3378, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1120/3125], step: 10495, 8.364 samples/sec, batch_loss: 0.4107, batch_loss_c: 0.4067, batch_loss_s: 0.4199, time:4.7824, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1130/3125], step: 10505, 8.679 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3013, batch_loss_s: 0.3391, time:4.6089, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:33:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1140/3125], step: 10515, 6.981 samples/sec, batch_loss: 0.1642, batch_loss_c: 0.1557, batch_loss_s: 0.1840, time:5.7302, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1150/3125], step: 10525, 7.740 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0784, batch_loss_s: 0.0821, time:5.1681, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1160/3125], step: 10535, 7.170 samples/sec, batch_loss: 0.1129, batch_loss_c: 0.1176, batch_loss_s: 0.1018, time:5.5786, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1170/3125], step: 10545, 7.869 samples/sec, batch_loss: 0.1897, batch_loss_c: 0.1916, batch_loss_s: 0.1853, time:5.0831, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1180/3125], step: 10555, 8.760 samples/sec, batch_loss: 0.3007, batch_loss_c: 0.3002, batch_loss_s: 0.3019, time:4.5663, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1190/3125], step: 10565, 7.647 samples/sec, batch_loss: 0.3088, batch_loss_c: 0.3084, batch_loss_s: 0.3098, time:5.2310, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1200/3125], step: 10575, 8.436 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1327, batch_loss_s: 0.1365, time:4.7415, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1210/3125], step: 10585, 8.441 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0992, batch_loss_s: 0.0856, time:4.7388, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1220/3125], step: 10595, 7.865 samples/sec, batch_loss: 0.0764, batch_loss_c: 0.0747, batch_loss_s: 0.0803, time:5.0861, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1230/3125], step: 10605, 9.411 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3489, batch_loss_s: 0.3359, time:4.2501, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1240/3125], step: 10615, 8.280 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0730, batch_loss_s: 0.0775, time:4.8310, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1250/3125], step: 10625, 8.736 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0928, batch_loss_s: 0.0944, time:4.5786, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:34:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1260/3125], step: 10635, 9.282 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0514, batch_loss_s: 0.0740, time:4.3093, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1270/3125], step: 10645, 8.522 samples/sec, batch_loss: 0.1522, batch_loss_c: 0.1496, batch_loss_s: 0.1581, time:4.6939, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1280/3125], step: 10655, 9.303 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0910, batch_loss_s: 0.1009, time:4.2999, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1290/3125], step: 10665, 7.536 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0625, batch_loss_s: 0.0774, time:5.3080, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1300/3125], step: 10675, 8.846 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.1045, batch_loss_s: 0.0862, time:4.5220, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1310/3125], step: 10685, 9.201 samples/sec, batch_loss: 0.1309, batch_loss_c: 0.1226, batch_loss_s: 0.1504, time:4.3474, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1320/3125], step: 10695, 8.500 samples/sec, batch_loss: 0.1898, batch_loss_c: 0.2161, batch_loss_s: 0.1284, time:4.7059, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1330/3125], step: 10705, 8.790 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1505, batch_loss_s: 0.0846, time:4.5505, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1340/3125], step: 10715, 8.373 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1644, batch_loss_s: 0.0973, time:4.7772, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1350/3125], step: 10725, 8.779 samples/sec, batch_loss: 0.3433, batch_loss_c: 0.3460, batch_loss_s: 0.3369, time:4.5564, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1360/3125], step: 10735, 8.267 samples/sec, batch_loss: 0.0573, batch_loss_c: 0.0555, batch_loss_s: 0.0616, time:4.8385, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1370/3125], step: 10745, 8.929 samples/sec, batch_loss: 0.1528, batch_loss_c: 0.1849, batch_loss_s: 0.0778, time:4.4800, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1380/3125], step: 10755, 7.916 samples/sec, batch_loss: 0.1194, batch_loss_c: 0.1304, batch_loss_s: 0.0936, time:5.0528, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:35:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1390/3125], step: 10765, 8.456 samples/sec, batch_loss: 0.0662, batch_loss_c: 0.0671, batch_loss_s: 0.0641, time:4.7305, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1400/3125], step: 10775, 7.432 samples/sec, batch_loss: 0.1373, batch_loss_c: 0.1385, batch_loss_s: 0.1345, time:5.3825, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1410/3125], step: 10785, 7.515 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1238, batch_loss_s: 0.0990, time:5.3225, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1420/3125], step: 10795, 9.037 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0927, batch_loss_s: 0.0681, time:4.4262, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1430/3125], step: 10805, 8.676 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0754, batch_loss_s: 0.0964, time:4.6104, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1440/3125], step: 10815, 7.985 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0867, batch_loss_s: 0.1036, time:5.0096, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1450/3125], step: 10825, 7.864 samples/sec, batch_loss: 0.3380, batch_loss_c: 0.3363, batch_loss_s: 0.3421, time:5.0863, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1460/3125], step: 10835, 8.924 samples/sec, batch_loss: 0.5310, batch_loss_c: 0.5253, batch_loss_s: 0.5443, time:4.4821, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1470/3125], step: 10845, 7.147 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0954, batch_loss_s: 0.0887, time:5.5967, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1480/3125], step: 10855, 8.078 samples/sec, batch_loss: 0.0596, batch_loss_c: 0.0541, batch_loss_s: 0.0725, time:4.9519, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1490/3125], step: 10865, 7.815 samples/sec, batch_loss: 0.1164, batch_loss_c: 0.1182, batch_loss_s: 0.1120, time:5.1184, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1500/3125], step: 10875, 8.576 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0836, batch_loss_s: 0.0930, time:4.6639, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:36:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1510/3125], step: 10885, 8.729 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3235, batch_loss_s: 0.3132, time:4.5824, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1520/3125], step: 10895, 7.985 samples/sec, batch_loss: 0.4113, batch_loss_c: 0.4344, batch_loss_s: 0.3573, time:5.0094, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1530/3125], step: 10905, 8.306 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0769, batch_loss_s: 0.0855, time:4.8160, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1540/3125], step: 10915, 8.713 samples/sec, batch_loss: 0.2809, batch_loss_c: 0.2535, batch_loss_s: 0.3448, time:4.5906, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1550/3125], step: 10925, 8.209 samples/sec, batch_loss: 0.3965, batch_loss_c: 0.4044, batch_loss_s: 0.3780, time:4.8724, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1560/3125], step: 10935, 8.441 samples/sec, batch_loss: 0.1180, batch_loss_c: 0.1247, batch_loss_s: 0.1022, time:4.7390, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1570/3125], step: 10945, 8.317 samples/sec, batch_loss: 0.0561, batch_loss_c: 0.0584, batch_loss_s: 0.0506, time:4.8095, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1580/3125], step: 10955, 8.558 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.0988, batch_loss_s: 0.1090, time:4.6742, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1590/3125], step: 10965, 8.869 samples/sec, batch_loss: 0.0840, batch_loss_c: 0.0850, batch_loss_s: 0.0815, time:4.5102, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1600/3125], step: 10975, 8.813 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0669, batch_loss_s: 0.0868, time:4.5390, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1610/3125], step: 10985, 8.270 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.3007, batch_loss_s: 0.3120, time:4.8367, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1620/3125], step: 10995, 8.573 samples/sec, batch_loss: 0.1581, batch_loss_c: 0.1767, batch_loss_s: 0.1145, time:4.6659, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1630/3125], step: 11005, 7.269 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1326, batch_loss_s: 0.1035, time:5.5025, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:37:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1640/3125], step: 11015, 8.414 samples/sec, batch_loss: 0.1037, batch_loss_c: 0.1088, batch_loss_s: 0.0918, time:4.7540, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1650/3125], step: 11025, 8.182 samples/sec, batch_loss: 0.1329, batch_loss_c: 0.1438, batch_loss_s: 0.1076, time:4.8890, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1660/3125], step: 11035, 7.995 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0743, batch_loss_s: 0.0780, time:5.0034, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1670/3125], step: 11045, 8.079 samples/sec, batch_loss: 0.3160, batch_loss_c: 0.3111, batch_loss_s: 0.3275, time:4.9509, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1680/3125], step: 11055, 8.984 samples/sec, batch_loss: 0.3210, batch_loss_c: 0.3206, batch_loss_s: 0.3219, time:4.4521, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1690/3125], step: 11065, 8.446 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.1061, batch_loss_s: 0.0760, time:4.7362, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1700/3125], step: 11075, 8.952 samples/sec, batch_loss: 0.2712, batch_loss_c: 0.2539, batch_loss_s: 0.3117, time:4.4685, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1710/3125], step: 11085, 8.588 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0814, batch_loss_s: 0.0876, time:4.6576, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1720/3125], step: 11095, 7.452 samples/sec, batch_loss: 0.0751, batch_loss_c: 0.0701, batch_loss_s: 0.0869, time:5.3673, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1730/3125], step: 11105, 8.152 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0957, batch_loss_s: 0.0955, time:4.9065, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1740/3125], step: 11115, 8.708 samples/sec, batch_loss: 0.1255, batch_loss_c: 0.1291, batch_loss_s: 0.1171, time:4.5933, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1750/3125], step: 11125, 8.566 samples/sec, batch_loss: 0.3553, batch_loss_c: 0.3476, batch_loss_s: 0.3732, time:4.6696, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:38:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1760/3125], step: 11135, 7.875 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0914, batch_loss_s: 0.0807, time:5.0793, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1770/3125], step: 11145, 8.295 samples/sec, batch_loss: 0.3046, batch_loss_c: 0.3050, batch_loss_s: 0.3039, time:4.8220, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1780/3125], step: 11155, 7.832 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0654, batch_loss_s: 0.0827, time:5.1072, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1790/3125], step: 11165, 8.086 samples/sec, batch_loss: 0.5280, batch_loss_c: 0.5273, batch_loss_s: 0.5296, time:4.9469, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1800/3125], step: 11175, 8.127 samples/sec, batch_loss: 0.3580, batch_loss_c: 0.3827, batch_loss_s: 0.3002, time:4.9219, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1810/3125], step: 11185, 8.541 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0955, batch_loss_s: 0.0857, time:4.6831, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1820/3125], step: 11195, 9.100 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1447, batch_loss_s: 0.0762, time:4.3955, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1830/3125], step: 11205, 7.297 samples/sec, batch_loss: 0.1493, batch_loss_c: 0.1645, batch_loss_s: 0.1137, time:5.4816, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1840/3125], step: 11215, 8.359 samples/sec, batch_loss: 0.3002, batch_loss_c: 0.3288, batch_loss_s: 0.2336, time:4.7854, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1850/3125], step: 11225, 7.299 samples/sec, batch_loss: 0.3193, batch_loss_c: 0.3150, batch_loss_s: 0.3293, time:5.4805, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1860/3125], step: 11235, 8.363 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0876, batch_loss_s: 0.0903, time:4.7830, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1870/3125], step: 11245, 7.800 samples/sec, batch_loss: 0.1217, batch_loss_c: 0.1217, batch_loss_s: 0.1217, time:5.1283, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:39:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1880/3125], step: 11255, 8.792 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1611, batch_loss_s: 0.0952, time:4.5496, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1890/3125], step: 11265, 8.002 samples/sec, batch_loss: 0.0682, batch_loss_c: 0.0663, batch_loss_s: 0.0729, time:4.9986, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1900/3125], step: 11275, 8.876 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1096, batch_loss_s: 0.0964, time:4.5067, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1910/3125], step: 11285, 8.392 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1239, batch_loss_s: 0.1000, time:4.7667, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1920/3125], step: 11295, 8.127 samples/sec, batch_loss: 0.0631, batch_loss_c: 0.0605, batch_loss_s: 0.0692, time:4.9221, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1930/3125], step: 11305, 8.184 samples/sec, batch_loss: 0.1602, batch_loss_c: 0.1774, batch_loss_s: 0.1200, time:4.8874, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1940/3125], step: 11315, 8.341 samples/sec, batch_loss: 0.1698, batch_loss_c: 0.1853, batch_loss_s: 0.1338, time:4.7953, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1950/3125], step: 11325, 8.504 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0621, batch_loss_s: 0.0731, time:4.7035, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1960/3125], step: 11335, 8.774 samples/sec, batch_loss: 0.5154, batch_loss_c: 0.5073, batch_loss_s: 0.5343, time:4.5588, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1970/3125], step: 11345, 7.986 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.1073, batch_loss_s: 0.1004, time:5.0090, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1980/3125], step: 11355, 8.410 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0760, batch_loss_s: 0.1000, time:4.7563, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1990/3125], step: 11365, 7.563 samples/sec, batch_loss: 0.0517, batch_loss_c: 0.0523, batch_loss_s: 0.0504, time:5.2890, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2000/3125], step: 11375, 8.904 samples/sec, batch_loss: 0.0637, batch_loss_c: 0.0627, batch_loss_s: 0.0659, time:4.4923, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:40:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2010/3125], step: 11385, 8.487 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0666, batch_loss_s: 0.0772, time:4.7129, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2020/3125], step: 11395, 7.916 samples/sec, batch_loss: 0.0598, batch_loss_c: 0.0564, batch_loss_s: 0.0679, time:5.0533, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2030/3125], step: 11405, 7.878 samples/sec, batch_loss: 0.0943, batch_loss_c: 0.0899, batch_loss_s: 0.1044, time:5.0775, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2040/3125], step: 11415, 7.770 samples/sec, batch_loss: 0.4156, batch_loss_c: 0.4431, batch_loss_s: 0.3515, time:5.1479, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2050/3125], step: 11425, 8.890 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0905, batch_loss_s: 0.1072, time:4.4997, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2060/3125], step: 11435, 7.915 samples/sec, batch_loss: 0.2524, batch_loss_c: 0.2963, batch_loss_s: 0.1501, time:5.0536, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2070/3125], step: 11445, 7.429 samples/sec, batch_loss: 0.0888, batch_loss_c: 0.0876, batch_loss_s: 0.0918, time:5.3841, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2080/3125], step: 11455, 8.355 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0985, batch_loss_s: 0.0920, time:4.7876, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2090/3125], step: 11465, 7.778 samples/sec, batch_loss: 0.2082, batch_loss_c: 0.1980, batch_loss_s: 0.2321, time:5.1427, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2100/3125], step: 11475, 8.477 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0821, batch_loss_s: 0.0858, time:4.7189, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2110/3125], step: 11485, 8.821 samples/sec, batch_loss: 0.3051, batch_loss_c: 0.3021, batch_loss_s: 0.3119, time:4.5349, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2120/3125], step: 11495, 7.887 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0702, batch_loss_s: 0.0492, time:5.0718, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:41:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2130/3125], step: 11505, 8.238 samples/sec, batch_loss: 0.3376, batch_loss_c: 0.3313, batch_loss_s: 0.3523, time:4.8558, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2140/3125], step: 11515, 8.117 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1597, batch_loss_s: 0.1087, time:4.9277, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2150/3125], step: 11525, 8.414 samples/sec, batch_loss: 0.3014, batch_loss_c: 0.2981, batch_loss_s: 0.3092, time:4.7539, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2160/3125], step: 11535, 8.583 samples/sec, batch_loss: 0.2653, batch_loss_c: 0.2522, batch_loss_s: 0.2959, time:4.6605, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2170/3125], step: 11545, 8.199 samples/sec, batch_loss: 0.1194, batch_loss_c: 0.1272, batch_loss_s: 0.1011, time:4.8784, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2180/3125], step: 11555, 8.877 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1580, batch_loss_s: 0.1022, time:4.5060, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2190/3125], step: 11565, 8.563 samples/sec, batch_loss: 0.3516, batch_loss_c: 0.3459, batch_loss_s: 0.3647, time:4.6712, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2200/3125], step: 11575, 8.326 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1150, batch_loss_s: 0.1330, time:4.8043, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2210/3125], step: 11585, 8.880 samples/sec, batch_loss: 0.5289, batch_loss_c: 0.5069, batch_loss_s: 0.5803, time:4.5046, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2220/3125], step: 11595, 8.220 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0755, batch_loss_s: 0.0659, time:4.8663, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2230/3125], step: 11605, 8.824 samples/sec, batch_loss: 0.3115, batch_loss_c: 0.3098, batch_loss_s: 0.3155, time:4.5331, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2240/3125], step: 11615, 8.544 samples/sec, batch_loss: 0.4217, batch_loss_c: 0.4390, batch_loss_s: 0.3812, time:4.6816, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2250/3125], step: 11625, 7.690 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.1010, batch_loss_s: 0.0918, time:5.2017, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:42:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2260/3125], step: 11635, 8.402 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0915, batch_loss_s: 0.1038, time:4.7606, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2270/3125], step: 11645, 8.673 samples/sec, batch_loss: 0.3287, batch_loss_c: 0.3361, batch_loss_s: 0.3116, time:4.6122, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2280/3125], step: 11655, 8.690 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1002, batch_loss_s: 0.1093, time:4.6030, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2290/3125], step: 11665, 8.152 samples/sec, batch_loss: 0.1914, batch_loss_c: 0.1926, batch_loss_s: 0.1886, time:4.9068, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2300/3125], step: 11675, 8.364 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0712, batch_loss_s: 0.0752, time:4.7823, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2310/3125], step: 11685, 8.474 samples/sec, batch_loss: 0.2859, batch_loss_c: 0.2836, batch_loss_s: 0.2914, time:4.7205, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2320/3125], step: 11695, 8.229 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0929, batch_loss_s: 0.0972, time:4.8607, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2330/3125], step: 11705, 7.366 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0845, batch_loss_s: 0.1050, time:5.4301, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2340/3125], step: 11715, 8.623 samples/sec, batch_loss: 0.4394, batch_loss_c: 0.4275, batch_loss_s: 0.4671, time:4.6388, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2350/3125], step: 11725, 7.473 samples/sec, batch_loss: 0.1219, batch_loss_c: 0.1123, batch_loss_s: 0.1445, time:5.3525, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2360/3125], step: 11735, 8.569 samples/sec, batch_loss: 0.2744, batch_loss_c: 0.2603, batch_loss_s: 0.3071, time:4.6682, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2370/3125], step: 11745, 8.506 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1359, batch_loss_s: 0.0814, time:4.7025, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:43:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2380/3125], step: 11755, 8.976 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1253, batch_loss_s: 0.0757, time:4.4564, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2390/3125], step: 11765, 8.450 samples/sec, batch_loss: 0.2443, batch_loss_c: 0.2203, batch_loss_s: 0.3004, time:4.7338, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2400/3125], step: 11775, 8.102 samples/sec, batch_loss: 0.3377, batch_loss_c: 0.3410, batch_loss_s: 0.3301, time:4.9370, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2410/3125], step: 11785, 9.128 samples/sec, batch_loss: 0.1360, batch_loss_c: 0.0818, batch_loss_s: 0.2627, time:4.3821, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2420/3125], step: 11795, 7.526 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0635, batch_loss_s: 0.0751, time:5.3147, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2430/3125], step: 11805, 8.434 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0704, batch_loss_s: 0.0764, time:4.7427, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2440/3125], step: 11815, 8.318 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0892, batch_loss_s: 0.0806, time:4.8086, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2450/3125], step: 11825, 8.719 samples/sec, batch_loss: 0.1458, batch_loss_c: 0.1396, batch_loss_s: 0.1601, time:4.5877, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2460/3125], step: 11835, 8.200 samples/sec, batch_loss: 0.1530, batch_loss_c: 0.1528, batch_loss_s: 0.1536, time:4.8781, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2470/3125], step: 11845, 8.452 samples/sec, batch_loss: 0.0745, batch_loss_c: 0.0706, batch_loss_s: 0.0835, time:4.7325, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2480/3125], step: 11855, 7.323 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0735, batch_loss_s: 0.0839, time:5.4620, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2490/3125], step: 11865, 7.740 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1116, batch_loss_s: 0.0973, time:5.1677, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:44:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2500/3125], step: 11875, 8.303 samples/sec, batch_loss: 0.3661, batch_loss_c: 0.3736, batch_loss_s: 0.3487, time:4.8176, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2510/3125], step: 11885, 8.198 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0920, batch_loss_s: 0.0993, time:4.8793, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2520/3125], step: 11895, 8.078 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0826, batch_loss_s: 0.1011, time:4.9517, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2530/3125], step: 11905, 8.751 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0641, batch_loss_s: 0.0647, time:4.5709, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2540/3125], step: 11915, 8.284 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1148, batch_loss_s: 0.1322, time:4.8286, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2550/3125], step: 11925, 8.517 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0694, batch_loss_s: 0.0690, time:4.6963, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2560/3125], step: 11935, 8.512 samples/sec, batch_loss: 0.0536, batch_loss_c: 0.0513, batch_loss_s: 0.0591, time:4.6991, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2570/3125], step: 11945, 8.670 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.1021, batch_loss_s: 0.0715, time:4.6135, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2580/3125], step: 11955, 8.658 samples/sec, batch_loss: 0.3149, batch_loss_c: 0.3107, batch_loss_s: 0.3249, time:4.6199, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2590/3125], step: 11965, 7.906 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1053, batch_loss_s: 0.1205, time:5.0597, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2600/3125], step: 11975, 8.760 samples/sec, batch_loss: 0.1420, batch_loss_c: 0.1612, batch_loss_s: 0.0973, time:4.5662, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2610/3125], step: 11985, 8.862 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0971, batch_loss_s: 0.0912, time:4.5138, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2620/3125], step: 11995, 9.024 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0870, batch_loss_s: 0.0643, time:4.4324, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:45:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2630/3125], step: 12005, 9.301 samples/sec, batch_loss: 0.1953, batch_loss_c: 0.2270, batch_loss_s: 0.1214, time:4.3007, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2640/3125], step: 12015, 8.520 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0912, batch_loss_s: 0.1074, time:4.6946, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2650/3125], step: 12025, 9.085 samples/sec, batch_loss: 0.1389, batch_loss_c: 0.1455, batch_loss_s: 0.1236, time:4.4030, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2660/3125], step: 12035, 7.994 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0921, batch_loss_s: 0.0756, time:5.0036, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2670/3125], step: 12045, 7.257 samples/sec, batch_loss: 0.3195, batch_loss_c: 0.3193, batch_loss_s: 0.3200, time:5.5117, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2680/3125], step: 12055, 7.951 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.1117, batch_loss_s: 0.0744, time:5.0307, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2690/3125], step: 12065, 8.155 samples/sec, batch_loss: 0.2707, batch_loss_c: 0.2543, batch_loss_s: 0.3090, time:4.9049, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2700/3125], step: 12075, 7.655 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0737, batch_loss_s: 0.1138, time:5.2257, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2710/3125], step: 12085, 8.437 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0971, batch_loss_s: 0.0976, time:4.7411, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2720/3125], step: 12095, 8.682 samples/sec, batch_loss: 0.3032, batch_loss_c: 0.3014, batch_loss_s: 0.3073, time:4.6074, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2730/3125], step: 12105, 8.369 samples/sec, batch_loss: 0.3367, batch_loss_c: 0.3354, batch_loss_s: 0.3399, time:4.7794, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2740/3125], step: 12115, 8.069 samples/sec, batch_loss: 0.2824, batch_loss_c: 0.2810, batch_loss_s: 0.2857, time:4.9574, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:46:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2750/3125], step: 12125, 8.596 samples/sec, batch_loss: 0.1033, batch_loss_c: 0.1032, batch_loss_s: 0.1036, time:4.6534, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2760/3125], step: 12135, 8.078 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.1012, batch_loss_s: 0.0854, time:4.9519, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2770/3125], step: 12145, 7.215 samples/sec, batch_loss: 0.0604, batch_loss_c: 0.0575, batch_loss_s: 0.0674, time:5.5440, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2780/3125], step: 12155, 8.423 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0722, batch_loss_s: 0.0852, time:4.7491, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2790/3125], step: 12165, 8.436 samples/sec, batch_loss: 0.1785, batch_loss_c: 0.2106, batch_loss_s: 0.1037, time:4.7413, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2800/3125], step: 12175, 7.485 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1286, batch_loss_s: 0.1291, time:5.3439, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2810/3125], step: 12185, 8.693 samples/sec, batch_loss: 0.5217, batch_loss_c: 0.5132, batch_loss_s: 0.5414, time:4.6015, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2820/3125], step: 12195, 8.756 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1179, batch_loss_s: 0.0653, time:4.5681, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2830/3125], step: 12205, 7.641 samples/sec, batch_loss: 0.0821, batch_loss_c: 0.0795, batch_loss_s: 0.0882, time:5.2348, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2840/3125], step: 12215, 7.948 samples/sec, batch_loss: 0.2193, batch_loss_c: 0.2256, batch_loss_s: 0.2047, time:5.0329, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2850/3125], step: 12225, 8.444 samples/sec, batch_loss: 0.4937, batch_loss_c: 0.4759, batch_loss_s: 0.5351, time:4.7370, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2860/3125], step: 12235, 8.495 samples/sec, batch_loss: 0.3330, batch_loss_c: 0.3399, batch_loss_s: 0.3167, time:4.7087, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2870/3125], step: 12245, 8.047 samples/sec, batch_loss: 0.0704, batch_loss_c: 0.0712, batch_loss_s: 0.0684, time:4.9707, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:47:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2880/3125], step: 12255, 8.289 samples/sec, batch_loss: 0.2853, batch_loss_c: 0.2819, batch_loss_s: 0.2932, time:4.8258, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2890/3125], step: 12265, 8.347 samples/sec, batch_loss: 0.0817, batch_loss_c: 0.0850, batch_loss_s: 0.0740, time:4.7921, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2900/3125], step: 12275, 7.377 samples/sec, batch_loss: 0.1384, batch_loss_c: 0.1449, batch_loss_s: 0.1231, time:5.4223, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2910/3125], step: 12285, 8.515 samples/sec, batch_loss: 0.0564, batch_loss_c: 0.0507, batch_loss_s: 0.0696, time:4.6977, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2920/3125], step: 12295, 8.669 samples/sec, batch_loss: 0.3357, batch_loss_c: 0.3311, batch_loss_s: 0.3466, time:4.6143, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2930/3125], step: 12305, 8.828 samples/sec, batch_loss: 0.1106, batch_loss_c: 0.1170, batch_loss_s: 0.0956, time:4.5308, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2940/3125], step: 12315, 8.326 samples/sec, batch_loss: 0.9758, batch_loss_c: 0.9654, batch_loss_s: 1.0000, time:4.8045, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2950/3125], step: 12325, 8.445 samples/sec, batch_loss: 0.1654, batch_loss_c: 0.1977, batch_loss_s: 0.0900, time:4.7364, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2960/3125], step: 12335, 7.819 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0704, batch_loss_s: 0.0749, time:5.1158, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2970/3125], step: 12345, 8.711 samples/sec, batch_loss: 0.2965, batch_loss_c: 0.2910, batch_loss_s: 0.3095, time:4.5917, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2980/3125], step: 12355, 8.635 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0796, batch_loss_s: 0.0934, time:4.6322, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2990/3125], step: 12365, 8.992 samples/sec, batch_loss: 0.2867, batch_loss_c: 0.2675, batch_loss_s: 0.3314, time:4.4486, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:48:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3000/3125], step: 12375, 8.793 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1114, batch_loss_s: 0.0853, time:4.5492, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3010/3125], step: 12385, 8.606 samples/sec, batch_loss: 0.2878, batch_loss_c: 0.2740, batch_loss_s: 0.3202, time:4.6480, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3020/3125], step: 12395, 8.941 samples/sec, batch_loss: 0.0689, batch_loss_c: 0.0705, batch_loss_s: 0.0652, time:4.4738, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3030/3125], step: 12405, 7.249 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0681, batch_loss_s: 0.0903, time:5.5180, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3040/3125], step: 12415, 7.443 samples/sec, batch_loss: 0.2903, batch_loss_c: 0.2793, batch_loss_s: 0.3159, time:5.3745, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3050/3125], step: 12425, 8.013 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0632, batch_loss_s: 0.0743, time:4.9917, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3060/3125], step: 12435, 8.834 samples/sec, batch_loss: 0.4243, batch_loss_c: 0.4798, batch_loss_s: 0.2948, time:4.5278, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3070/3125], step: 12445, 9.293 samples/sec, batch_loss: 0.1146, batch_loss_c: 0.1247, batch_loss_s: 0.0910, time:4.3043, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3080/3125], step: 12455, 8.464 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0856, batch_loss_s: 0.0730, time:4.7260, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3090/3125], step: 12465, 9.170 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.0936, batch_loss_s: 0.1132, time:4.3618, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3100/3125], step: 12475, 8.567 samples/sec, batch_loss: 0.3157, batch_loss_c: 0.3073, batch_loss_s: 0.3353, time:4.6693, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3110/3125], step: 12485, 10.159 samples/sec, batch_loss: 0.1263, batch_loss_c: 0.1514, batch_loss_s: 0.0678, time:3.9375, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3120/3125], step: 12495, 10.305 samples/sec, batch_loss: 0.2809, batch_loss_c: 0.2710, batch_loss_s: 0.3040, time:3.8815, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:49:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], train_loss: 0.1741, time: 1516.6322, lr: 0.0001\u001b[0m\n",
            "2019-11-24 10:49:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [0/3125], step: 12500, 6.852 samples/sec, batch_loss: 0.1611, batch_loss_c: 0.1518, batch_loss_s: 0.1829, time:5.8377, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [10/3125], step: 12510, 7.372 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0712, batch_loss_s: 0.0862, time:5.4257, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [20/3125], step: 12520, 7.152 samples/sec, batch_loss: 0.1539, batch_loss_c: 0.1624, batch_loss_s: 0.1342, time:5.5931, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [30/3125], step: 12530, 9.197 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0893, batch_loss_s: 0.0710, time:4.3493, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [40/3125], step: 12540, 9.070 samples/sec, batch_loss: 0.5780, batch_loss_c: 0.5812, batch_loss_s: 0.5707, time:4.4101, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [50/3125], step: 12550, 8.870 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.1082, batch_loss_s: 0.0860, time:4.5094, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [60/3125], step: 12560, 8.374 samples/sec, batch_loss: 0.2368, batch_loss_c: 0.2178, batch_loss_s: 0.2810, time:4.7770, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [70/3125], step: 12570, 8.788 samples/sec, batch_loss: 0.2945, batch_loss_c: 0.2927, batch_loss_s: 0.2987, time:4.5517, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [80/3125], step: 12580, 7.414 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1088, batch_loss_s: 0.1009, time:5.3951, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [90/3125], step: 12590, 7.356 samples/sec, batch_loss: 0.1123, batch_loss_c: 0.1171, batch_loss_s: 0.1013, time:5.4374, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [100/3125], step: 12600, 8.936 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.1115, batch_loss_s: 0.0716, time:4.4761, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [110/3125], step: 12610, 8.383 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1399, batch_loss_s: 0.1433, time:4.7716, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:50:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [120/3125], step: 12620, 8.613 samples/sec, batch_loss: 0.1328, batch_loss_c: 0.1188, batch_loss_s: 0.1656, time:4.6444, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [130/3125], step: 12630, 8.397 samples/sec, batch_loss: 0.3096, batch_loss_c: 0.3088, batch_loss_s: 0.3113, time:4.7636, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [140/3125], step: 12640, 8.004 samples/sec, batch_loss: 0.3177, batch_loss_c: 0.3033, batch_loss_s: 0.3512, time:4.9974, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [150/3125], step: 12650, 8.096 samples/sec, batch_loss: 0.0565, batch_loss_c: 0.0515, batch_loss_s: 0.0684, time:4.9405, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [160/3125], step: 12660, 8.315 samples/sec, batch_loss: 0.1263, batch_loss_c: 0.1308, batch_loss_s: 0.1156, time:4.8106, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [170/3125], step: 12670, 6.762 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0780, batch_loss_s: 0.0852, time:5.9151, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [180/3125], step: 12680, 7.237 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0638, batch_loss_s: 0.0725, time:5.5272, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [190/3125], step: 12690, 7.720 samples/sec, batch_loss: 0.3387, batch_loss_c: 0.3475, batch_loss_s: 0.3180, time:5.1817, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [200/3125], step: 12700, 8.397 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0829, batch_loss_s: 0.0848, time:4.7635, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [210/3125], step: 12710, 8.451 samples/sec, batch_loss: 0.1787, batch_loss_c: 0.2027, batch_loss_s: 0.1228, time:4.7332, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [220/3125], step: 12720, 8.287 samples/sec, batch_loss: 0.1411, batch_loss_c: 0.1628, batch_loss_s: 0.0905, time:4.8265, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [230/3125], step: 12730, 8.156 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1014, batch_loss_s: 0.0879, time:4.9045, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:51:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [240/3125], step: 12740, 7.905 samples/sec, batch_loss: 0.0648, batch_loss_c: 0.0626, batch_loss_s: 0.0697, time:5.0601, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [250/3125], step: 12750, 7.336 samples/sec, batch_loss: 0.1964, batch_loss_c: 0.2015, batch_loss_s: 0.1845, time:5.4525, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [260/3125], step: 12760, 7.488 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0665, batch_loss_s: 0.0880, time:5.3418, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [270/3125], step: 12770, 8.623 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1185, batch_loss_s: 0.1254, time:4.6389, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [280/3125], step: 12780, 8.852 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0664, batch_loss_s: 0.0759, time:4.5186, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [290/3125], step: 12790, 8.068 samples/sec, batch_loss: 0.1615, batch_loss_c: 0.1900, batch_loss_s: 0.0950, time:4.9578, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [300/3125], step: 12800, 7.819 samples/sec, batch_loss: 0.3713, batch_loss_c: 0.3865, batch_loss_s: 0.3358, time:5.1160, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [310/3125], step: 12810, 8.214 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0937, batch_loss_s: 0.0988, time:4.8696, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [320/3125], step: 12820, 8.234 samples/sec, batch_loss: 0.3250, batch_loss_c: 0.3265, batch_loss_s: 0.3214, time:4.8578, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [330/3125], step: 12830, 8.015 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0684, batch_loss_s: 0.0770, time:4.9904, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [340/3125], step: 12840, 8.448 samples/sec, batch_loss: 0.3386, batch_loss_c: 0.3419, batch_loss_s: 0.3310, time:4.7347, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [350/3125], step: 12850, 8.302 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1710, batch_loss_s: 0.1201, time:4.8179, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:52:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [360/3125], step: 12860, 8.328 samples/sec, batch_loss: 0.0680, batch_loss_c: 0.0671, batch_loss_s: 0.0702, time:4.8029, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [370/3125], step: 12870, 8.346 samples/sec, batch_loss: 0.2867, batch_loss_c: 0.2848, batch_loss_s: 0.2911, time:4.7925, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [380/3125], step: 12880, 8.123 samples/sec, batch_loss: 0.2953, batch_loss_c: 0.2970, batch_loss_s: 0.2913, time:4.9240, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [390/3125], step: 12890, 7.864 samples/sec, batch_loss: 0.0777, batch_loss_c: 0.0712, batch_loss_s: 0.0930, time:5.0864, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [400/3125], step: 12900, 7.605 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1134, batch_loss_s: 0.1004, time:5.2599, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [410/3125], step: 12910, 8.552 samples/sec, batch_loss: 0.3059, batch_loss_c: 0.3016, batch_loss_s: 0.3159, time:4.6773, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [420/3125], step: 12920, 8.729 samples/sec, batch_loss: 0.0643, batch_loss_c: 0.0598, batch_loss_s: 0.0746, time:4.5826, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [430/3125], step: 12930, 8.275 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0615, batch_loss_s: 0.0758, time:4.8338, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [440/3125], step: 12940, 7.922 samples/sec, batch_loss: 0.0832, batch_loss_c: 0.0819, batch_loss_s: 0.0860, time:5.0491, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [450/3125], step: 12950, 7.452 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1071, batch_loss_s: 0.1185, time:5.3677, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [460/3125], step: 12960, 8.555 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0869, batch_loss_s: 0.0781, time:4.6756, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [470/3125], step: 12970, 7.992 samples/sec, batch_loss: 0.0780, batch_loss_c: 0.0832, batch_loss_s: 0.0660, time:5.0051, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:53:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [480/3125], step: 12980, 8.326 samples/sec, batch_loss: 0.0782, batch_loss_c: 0.0772, batch_loss_s: 0.0806, time:4.8043, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [490/3125], step: 12990, 8.290 samples/sec, batch_loss: 0.1354, batch_loss_c: 0.1450, batch_loss_s: 0.1130, time:4.8253, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [500/3125], step: 13000, 8.172 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1015, batch_loss_s: 0.0957, time:4.8948, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [510/3125], step: 13010, 8.668 samples/sec, batch_loss: 0.0653, batch_loss_c: 0.0659, batch_loss_s: 0.0641, time:4.6147, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [520/3125], step: 13020, 8.859 samples/sec, batch_loss: 0.1563, batch_loss_c: 0.1749, batch_loss_s: 0.1128, time:4.5154, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [530/3125], step: 13030, 8.298 samples/sec, batch_loss: 0.0957, batch_loss_c: 0.0960, batch_loss_s: 0.0950, time:4.8205, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [540/3125], step: 13040, 8.316 samples/sec, batch_loss: 0.0432, batch_loss_c: 0.0380, batch_loss_s: 0.0552, time:4.8103, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [550/3125], step: 13050, 8.456 samples/sec, batch_loss: 0.3080, batch_loss_c: 0.3059, batch_loss_s: 0.3131, time:4.7305, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [560/3125], step: 13060, 9.131 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0855, batch_loss_s: 0.0948, time:4.3806, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [570/3125], step: 13070, 8.684 samples/sec, batch_loss: 0.1080, batch_loss_c: 0.1071, batch_loss_s: 0.1103, time:4.6062, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [580/3125], step: 13080, 9.277 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0599, batch_loss_s: 0.0653, time:4.3118, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [590/3125], step: 13090, 8.297 samples/sec, batch_loss: 0.3050, batch_loss_c: 0.3117, batch_loss_s: 0.2895, time:4.8213, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [600/3125], step: 13100, 8.863 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0835, batch_loss_s: 0.0927, time:4.5130, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:54:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [610/3125], step: 13110, 8.084 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0780, batch_loss_s: 0.0911, time:4.9479, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [620/3125], step: 13120, 8.537 samples/sec, batch_loss: 0.5273, batch_loss_c: 0.5264, batch_loss_s: 0.5293, time:4.6854, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [630/3125], step: 13130, 7.083 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0713, batch_loss_s: 0.0825, time:5.6472, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [640/3125], step: 13140, 7.479 samples/sec, batch_loss: 0.3521, batch_loss_c: 0.3651, batch_loss_s: 0.3218, time:5.3486, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [650/3125], step: 13150, 8.667 samples/sec, batch_loss: 0.0570, batch_loss_c: 0.0547, batch_loss_s: 0.0624, time:4.6153, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [660/3125], step: 13160, 8.540 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0849, batch_loss_s: 0.1003, time:4.6839, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [670/3125], step: 13170, 8.246 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0798, batch_loss_s: 0.1017, time:4.8510, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [680/3125], step: 13180, 8.549 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.1969, batch_loss_s: 0.1442, time:4.6790, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [690/3125], step: 13190, 9.005 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.0972, batch_loss_s: 0.0949, time:4.4419, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [700/3125], step: 13200, 8.610 samples/sec, batch_loss: 0.1797, batch_loss_c: 0.1876, batch_loss_s: 0.1612, time:4.6457, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [710/3125], step: 13210, 8.583 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0573, batch_loss_s: 0.0790, time:4.6602, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [720/3125], step: 13220, 7.569 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0540, batch_loss_s: 0.0707, time:5.2846, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:55:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [730/3125], step: 13230, 6.991 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1183, batch_loss_s: 0.0856, time:5.7214, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [740/3125], step: 13240, 7.380 samples/sec, batch_loss: 0.0470, batch_loss_c: 0.0467, batch_loss_s: 0.0477, time:5.4201, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [750/3125], step: 13250, 7.547 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0885, batch_loss_s: 0.1074, time:5.3003, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [760/3125], step: 13260, 9.088 samples/sec, batch_loss: 0.3318, batch_loss_c: 0.3295, batch_loss_s: 0.3371, time:4.4015, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [770/3125], step: 13270, 7.527 samples/sec, batch_loss: 0.0652, batch_loss_c: 0.0649, batch_loss_s: 0.0657, time:5.3144, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [780/3125], step: 13280, 9.169 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.1019, batch_loss_s: 0.0803, time:4.3624, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [790/3125], step: 13290, 8.194 samples/sec, batch_loss: 0.0844, batch_loss_c: 0.0815, batch_loss_s: 0.0912, time:4.8814, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [800/3125], step: 13300, 8.619 samples/sec, batch_loss: 0.0699, batch_loss_c: 0.0653, batch_loss_s: 0.0807, time:4.6408, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [810/3125], step: 13310, 8.466 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0977, batch_loss_s: 0.0866, time:4.7245, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [820/3125], step: 13320, 8.158 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1024, batch_loss_s: 0.1198, time:4.9033, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [830/3125], step: 13330, 7.952 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0758, batch_loss_s: 0.0845, time:5.0304, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [840/3125], step: 13340, 7.732 samples/sec, batch_loss: 0.3651, batch_loss_c: 0.3384, batch_loss_s: 0.4273, time:5.1736, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:56:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [850/3125], step: 13350, 8.504 samples/sec, batch_loss: 0.2766, batch_loss_c: 0.2566, batch_loss_s: 0.3232, time:4.7036, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [860/3125], step: 13360, 7.836 samples/sec, batch_loss: 0.3613, batch_loss_c: 0.3754, batch_loss_s: 0.3285, time:5.1047, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [870/3125], step: 13370, 7.603 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.1048, batch_loss_s: 0.0894, time:5.2609, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [880/3125], step: 13380, 7.441 samples/sec, batch_loss: 0.1087, batch_loss_c: 0.1130, batch_loss_s: 0.0986, time:5.3758, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [890/3125], step: 13390, 7.029 samples/sec, batch_loss: 0.1306, batch_loss_c: 0.1392, batch_loss_s: 0.1107, time:5.6907, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [900/3125], step: 13400, 8.294 samples/sec, batch_loss: 0.1487, batch_loss_c: 0.1760, batch_loss_s: 0.0850, time:4.8230, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [910/3125], step: 13410, 8.201 samples/sec, batch_loss: 0.5045, batch_loss_c: 0.4919, batch_loss_s: 0.5338, time:4.8773, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [920/3125], step: 13420, 9.054 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1277, batch_loss_s: 0.0884, time:4.4177, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [930/3125], step: 13430, 8.158 samples/sec, batch_loss: 0.3142, batch_loss_c: 0.3099, batch_loss_s: 0.3243, time:4.9029, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [940/3125], step: 13440, 8.611 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0681, batch_loss_s: 0.0807, time:4.6453, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [950/3125], step: 13450, 9.084 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0899, batch_loss_s: 0.0902, time:4.4033, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [960/3125], step: 13460, 8.998 samples/sec, batch_loss: 0.0919, batch_loss_c: 0.0882, batch_loss_s: 0.1008, time:4.4453, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [970/3125], step: 13470, 7.369 samples/sec, batch_loss: 0.3658, batch_loss_c: 0.3945, batch_loss_s: 0.2989, time:5.4283, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:57:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [980/3125], step: 13480, 8.770 samples/sec, batch_loss: 0.1109, batch_loss_c: 0.1167, batch_loss_s: 0.0973, time:4.5611, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [990/3125], step: 13490, 7.723 samples/sec, batch_loss: 0.3199, batch_loss_c: 0.3200, batch_loss_s: 0.3196, time:5.1792, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1000/3125], step: 13500, 8.774 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.1022, batch_loss_s: 0.0992, time:4.5591, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1010/3125], step: 13510, 8.744 samples/sec, batch_loss: 0.3519, batch_loss_c: 0.3558, batch_loss_s: 0.3427, time:4.5748, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1020/3125], step: 13520, 8.115 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1614, batch_loss_s: 0.1353, time:4.9291, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1030/3125], step: 13530, 8.157 samples/sec, batch_loss: 0.0577, batch_loss_c: 0.0543, batch_loss_s: 0.0656, time:4.9036, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1040/3125], step: 13540, 9.165 samples/sec, batch_loss: 0.0561, batch_loss_c: 0.0531, batch_loss_s: 0.0632, time:4.3642, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1050/3125], step: 13550, 8.136 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1180, batch_loss_s: 0.1065, time:4.9163, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1060/3125], step: 13560, 8.757 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1320, batch_loss_s: 0.0810, time:4.5677, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1070/3125], step: 13570, 7.065 samples/sec, batch_loss: 0.2088, batch_loss_c: 0.2000, batch_loss_s: 0.2293, time:5.6615, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1080/3125], step: 13580, 8.661 samples/sec, batch_loss: 0.3570, batch_loss_c: 0.3660, batch_loss_s: 0.3359, time:4.6182, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1090/3125], step: 13590, 8.217 samples/sec, batch_loss: 0.0523, batch_loss_c: 0.0479, batch_loss_s: 0.0625, time:4.8678, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:58:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1100/3125], step: 13600, 7.482 samples/sec, batch_loss: 0.5537, batch_loss_c: 0.5597, batch_loss_s: 0.5398, time:5.3461, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1110/3125], step: 13610, 8.426 samples/sec, batch_loss: 0.3249, batch_loss_c: 0.3271, batch_loss_s: 0.3197, time:4.7472, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1120/3125], step: 13620, 8.024 samples/sec, batch_loss: 0.2930, batch_loss_c: 0.2919, batch_loss_s: 0.2955, time:4.9853, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1130/3125], step: 13630, 7.781 samples/sec, batch_loss: 0.1672, batch_loss_c: 0.2024, batch_loss_s: 0.0852, time:5.1405, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1140/3125], step: 13640, 7.392 samples/sec, batch_loss: 0.2914, batch_loss_c: 0.2737, batch_loss_s: 0.3327, time:5.4113, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1150/3125], step: 13650, 8.059 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0893, batch_loss_s: 0.1018, time:4.9637, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1160/3125], step: 13660, 8.446 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.0990, batch_loss_s: 0.1075, time:4.7360, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1170/3125], step: 13670, 7.671 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3487, batch_loss_s: 0.3100, time:5.2145, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1180/3125], step: 13680, 8.387 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0774, batch_loss_s: 0.0635, time:4.7695, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1190/3125], step: 13690, 8.304 samples/sec, batch_loss: 0.2120, batch_loss_c: 0.1801, batch_loss_s: 0.2866, time:4.8168, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1200/3125], step: 13700, 8.294 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1184, batch_loss_s: 0.0690, time:4.8230, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1210/3125], step: 13710, 8.214 samples/sec, batch_loss: 0.1631, batch_loss_c: 0.1931, batch_loss_s: 0.0929, time:4.8698, lr:0.0001\u001b[0m\n",
            "2019-11-24 10:59:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1220/3125], step: 13720, 8.474 samples/sec, batch_loss: 0.1268, batch_loss_c: 0.1275, batch_loss_s: 0.1251, time:4.7202, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1230/3125], step: 13730, 8.601 samples/sec, batch_loss: 0.1352, batch_loss_c: 0.1285, batch_loss_s: 0.1510, time:4.6507, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1240/3125], step: 13740, 9.188 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0629, batch_loss_s: 0.0843, time:4.3533, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1250/3125], step: 13750, 8.690 samples/sec, batch_loss: 0.0542, batch_loss_c: 0.0528, batch_loss_s: 0.0575, time:4.6031, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1260/3125], step: 13760, 8.069 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0767, batch_loss_s: 0.0782, time:4.9570, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1270/3125], step: 13770, 8.789 samples/sec, batch_loss: 0.0547, batch_loss_c: 0.0502, batch_loss_s: 0.0651, time:4.5510, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1280/3125], step: 13780, 8.593 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0886, batch_loss_s: 0.0806, time:4.6549, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1290/3125], step: 13790, 8.406 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0813, batch_loss_s: 0.0978, time:4.7586, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1300/3125], step: 13800, 9.041 samples/sec, batch_loss: 0.1251, batch_loss_c: 0.1418, batch_loss_s: 0.0862, time:4.4243, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1310/3125], step: 13810, 8.621 samples/sec, batch_loss: 0.3346, batch_loss_c: 0.3325, batch_loss_s: 0.3397, time:4.6396, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1320/3125], step: 13820, 8.928 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1049, batch_loss_s: 0.1163, time:4.4804, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1330/3125], step: 13830, 8.837 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0682, batch_loss_s: 0.0697, time:4.5265, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1340/3125], step: 13840, 8.152 samples/sec, batch_loss: 0.2694, batch_loss_c: 0.2520, batch_loss_s: 0.3101, time:4.9066, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:00:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1350/3125], step: 13850, 8.712 samples/sec, batch_loss: 0.2771, batch_loss_c: 0.2728, batch_loss_s: 0.2872, time:4.5913, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1360/3125], step: 13860, 9.084 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1124, batch_loss_s: 0.1113, time:4.4034, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1370/3125], step: 13870, 8.483 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.0959, batch_loss_s: 0.0979, time:4.7154, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1380/3125], step: 13880, 7.211 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1503, batch_loss_s: 0.0622, time:5.5472, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1390/3125], step: 13890, 8.370 samples/sec, batch_loss: 0.3403, batch_loss_c: 0.3435, batch_loss_s: 0.3327, time:4.7792, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1400/3125], step: 13900, 8.789 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0604, batch_loss_s: 0.0762, time:4.5512, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1410/3125], step: 13910, 8.622 samples/sec, batch_loss: 0.1031, batch_loss_c: 0.1154, batch_loss_s: 0.0744, time:4.6392, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1420/3125], step: 13920, 9.238 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1709, batch_loss_s: 0.0909, time:4.3298, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1430/3125], step: 13930, 8.877 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0860, batch_loss_s: 0.0933, time:4.5060, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1440/3125], step: 13940, 7.844 samples/sec, batch_loss: 0.1093, batch_loss_c: 0.1215, batch_loss_s: 0.0809, time:5.0995, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1450/3125], step: 13950, 8.093 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0929, batch_loss_s: 0.1109, time:4.9425, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1460/3125], step: 13960, 9.150 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1117, batch_loss_s: 0.1263, time:4.3715, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1470/3125], step: 13970, 8.296 samples/sec, batch_loss: 0.5146, batch_loss_c: 0.5056, batch_loss_s: 0.5356, time:4.8215, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:01:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1480/3125], step: 13980, 8.196 samples/sec, batch_loss: 0.2624, batch_loss_c: 0.2500, batch_loss_s: 0.2913, time:4.8806, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1490/3125], step: 13990, 7.793 samples/sec, batch_loss: 0.3238, batch_loss_c: 0.3160, batch_loss_s: 0.3419, time:5.1327, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1500/3125], step: 14000, 8.885 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.1037, batch_loss_s: 0.0881, time:4.5019, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1510/3125], step: 14010, 8.256 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1251, batch_loss_s: 0.0942, time:4.8450, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1520/3125], step: 14020, 8.149 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.0979, batch_loss_s: 0.1016, time:4.9086, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1530/3125], step: 14030, 8.629 samples/sec, batch_loss: 0.1264, batch_loss_c: 0.1427, batch_loss_s: 0.0882, time:4.6358, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1540/3125], step: 14040, 8.494 samples/sec, batch_loss: 0.0566, batch_loss_c: 0.0535, batch_loss_s: 0.0637, time:4.7090, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1550/3125], step: 14050, 8.827 samples/sec, batch_loss: 0.1881, batch_loss_c: 0.2092, batch_loss_s: 0.1389, time:4.5318, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1560/3125], step: 14060, 9.100 samples/sec, batch_loss: 0.1235, batch_loss_c: 0.1255, batch_loss_s: 0.1188, time:4.3958, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1570/3125], step: 14070, 8.310 samples/sec, batch_loss: 0.0671, batch_loss_c: 0.0631, batch_loss_s: 0.0765, time:4.8135, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1580/3125], step: 14080, 8.319 samples/sec, batch_loss: 0.1420, batch_loss_c: 0.1650, batch_loss_s: 0.0883, time:4.8081, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1590/3125], step: 14090, 8.827 samples/sec, batch_loss: 0.3150, batch_loss_c: 0.3163, batch_loss_s: 0.3122, time:4.5316, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:02:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1600/3125], step: 14100, 8.188 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0935, batch_loss_s: 0.0816, time:4.8849, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1610/3125], step: 14110, 7.886 samples/sec, batch_loss: 0.2842, batch_loss_c: 0.2751, batch_loss_s: 0.3054, time:5.0725, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1620/3125], step: 14120, 8.488 samples/sec, batch_loss: 0.3264, batch_loss_c: 0.3217, batch_loss_s: 0.3375, time:4.7127, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1630/3125], step: 14130, 7.831 samples/sec, batch_loss: 0.3017, batch_loss_c: 0.2893, batch_loss_s: 0.3306, time:5.1076, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1640/3125], step: 14140, 8.586 samples/sec, batch_loss: 0.2767, batch_loss_c: 0.2616, batch_loss_s: 0.3120, time:4.6590, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1650/3125], step: 14150, 7.715 samples/sec, batch_loss: 0.0975, batch_loss_c: 0.0921, batch_loss_s: 0.1099, time:5.1849, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1660/3125], step: 14160, 7.624 samples/sec, batch_loss: 0.1620, batch_loss_c: 0.1870, batch_loss_s: 0.1037, time:5.2467, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1670/3125], step: 14170, 8.536 samples/sec, batch_loss: 0.0633, batch_loss_c: 0.0552, batch_loss_s: 0.0820, time:4.6860, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1680/3125], step: 14180, 9.124 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1159, batch_loss_s: 0.1088, time:4.3839, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1690/3125], step: 14190, 8.055 samples/sec, batch_loss: 0.4786, batch_loss_c: 0.4647, batch_loss_s: 0.5113, time:4.9661, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1700/3125], step: 14200, 8.232 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1155, batch_loss_s: 0.1357, time:4.8593, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1710/3125], step: 14210, 8.032 samples/sec, batch_loss: 0.0735, batch_loss_c: 0.0677, batch_loss_s: 0.0872, time:4.9799, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1720/3125], step: 14220, 7.894 samples/sec, batch_loss: 0.2952, batch_loss_c: 0.2884, batch_loss_s: 0.3111, time:5.0673, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:03:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1730/3125], step: 14230, 8.332 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1364, batch_loss_s: 0.1641, time:4.8007, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1740/3125], step: 14240, 8.060 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0812, batch_loss_s: 0.0893, time:4.9626, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1750/3125], step: 14250, 8.249 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0671, batch_loss_s: 0.0687, time:4.8492, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1760/3125], step: 14260, 8.420 samples/sec, batch_loss: 0.0620, batch_loss_c: 0.0647, batch_loss_s: 0.0557, time:4.7509, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1770/3125], step: 14270, 8.128 samples/sec, batch_loss: 0.3259, batch_loss_c: 0.3253, batch_loss_s: 0.3274, time:4.9211, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1780/3125], step: 14280, 8.392 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2947, batch_loss_s: 0.3028, time:4.7664, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1790/3125], step: 14290, 7.592 samples/sec, batch_loss: 0.2966, batch_loss_c: 0.2955, batch_loss_s: 0.2992, time:5.2685, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1800/3125], step: 14300, 7.698 samples/sec, batch_loss: 0.1110, batch_loss_c: 0.1070, batch_loss_s: 0.1202, time:5.1964, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1810/3125], step: 14310, 8.115 samples/sec, batch_loss: 0.0969, batch_loss_c: 0.0878, batch_loss_s: 0.1183, time:4.9293, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1820/3125], step: 14320, 8.098 samples/sec, batch_loss: 0.1317, batch_loss_c: 0.1403, batch_loss_s: 0.1116, time:4.9394, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1830/3125], step: 14330, 8.172 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0773, batch_loss_s: 0.1098, time:4.8948, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1840/3125], step: 14340, 8.847 samples/sec, batch_loss: 0.0620, batch_loss_c: 0.0577, batch_loss_s: 0.0718, time:4.5213, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:04:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1850/3125], step: 14350, 8.852 samples/sec, batch_loss: 0.3089, batch_loss_c: 0.3045, batch_loss_s: 0.3191, time:4.5189, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1860/3125], step: 14360, 7.530 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0742, batch_loss_s: 0.0758, time:5.3123, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1870/3125], step: 14370, 8.534 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0843, batch_loss_s: 0.0664, time:4.6869, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1880/3125], step: 14380, 8.491 samples/sec, batch_loss: 0.3170, batch_loss_c: 0.3231, batch_loss_s: 0.3029, time:4.7110, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1890/3125], step: 14390, 9.156 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1376, batch_loss_s: 0.1463, time:4.3687, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1900/3125], step: 14400, 8.142 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1269, batch_loss_s: 0.0885, time:4.9125, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1910/3125], step: 14410, 8.948 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0848, batch_loss_s: 0.0991, time:4.4704, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1920/3125], step: 14420, 8.777 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1039, batch_loss_s: 0.1161, time:4.5575, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1930/3125], step: 14430, 8.764 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0800, batch_loss_s: 0.0917, time:4.5641, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1940/3125], step: 14440, 8.374 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1407, batch_loss_s: 0.1045, time:4.7765, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1950/3125], step: 14450, 8.202 samples/sec, batch_loss: 0.3400, batch_loss_c: 0.3501, batch_loss_s: 0.3164, time:4.8770, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1960/3125], step: 14460, 8.665 samples/sec, batch_loss: 0.3137, batch_loss_c: 0.3060, batch_loss_s: 0.3316, time:4.6165, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1970/3125], step: 14470, 8.534 samples/sec, batch_loss: 0.1403, batch_loss_c: 0.1371, batch_loss_s: 0.1477, time:4.6869, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:05:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1980/3125], step: 14480, 7.808 samples/sec, batch_loss: 0.1374, batch_loss_c: 0.1451, batch_loss_s: 0.1194, time:5.1231, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1990/3125], step: 14490, 7.777 samples/sec, batch_loss: 0.0808, batch_loss_c: 0.0798, batch_loss_s: 0.0831, time:5.1437, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2000/3125], step: 14500, 7.783 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1055, batch_loss_s: 0.0992, time:5.1392, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2010/3125], step: 14510, 7.523 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3149, batch_loss_s: 0.3481, time:5.3170, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2020/3125], step: 14520, 8.372 samples/sec, batch_loss: 0.0696, batch_loss_c: 0.0672, batch_loss_s: 0.0752, time:4.7780, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2030/3125], step: 14530, 8.004 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0889, batch_loss_s: 0.0623, time:4.9973, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2040/3125], step: 14540, 8.216 samples/sec, batch_loss: 0.2984, batch_loss_c: 0.2935, batch_loss_s: 0.3098, time:4.8684, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2050/3125], step: 14550, 8.268 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0729, batch_loss_s: 0.0812, time:4.8380, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2060/3125], step: 14560, 8.625 samples/sec, batch_loss: 0.2056, batch_loss_c: 0.2473, batch_loss_s: 0.1083, time:4.6377, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2070/3125], step: 14570, 8.404 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2874, batch_loss_s: 0.3041, time:4.7599, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2080/3125], step: 14580, 8.594 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0746, batch_loss_s: 0.0810, time:4.6546, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2090/3125], step: 14590, 7.829 samples/sec, batch_loss: 0.0452, batch_loss_c: 0.0426, batch_loss_s: 0.0512, time:5.1093, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:06:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2100/3125], step: 14600, 8.591 samples/sec, batch_loss: 0.3080, batch_loss_c: 0.3092, batch_loss_s: 0.3053, time:4.6560, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2110/3125], step: 14610, 7.980 samples/sec, batch_loss: 0.1039, batch_loss_c: 0.1110, batch_loss_s: 0.0875, time:5.0126, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2120/3125], step: 14620, 8.814 samples/sec, batch_loss: 0.3626, batch_loss_c: 0.3651, batch_loss_s: 0.3566, time:4.5383, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2130/3125], step: 14630, 8.079 samples/sec, batch_loss: 0.1683, batch_loss_c: 0.1780, batch_loss_s: 0.1457, time:4.9514, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2140/3125], step: 14640, 8.117 samples/sec, batch_loss: 0.1082, batch_loss_c: 0.1064, batch_loss_s: 0.1125, time:4.9281, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2150/3125], step: 14650, 7.701 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1107, batch_loss_s: 0.1195, time:5.1941, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2160/3125], step: 14660, 9.113 samples/sec, batch_loss: 0.3022, batch_loss_c: 0.2993, batch_loss_s: 0.3090, time:4.3895, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2170/3125], step: 14670, 8.374 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0803, batch_loss_s: 0.0653, time:4.7768, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2180/3125], step: 14680, 8.834 samples/sec, batch_loss: 0.3019, batch_loss_c: 0.3014, batch_loss_s: 0.3031, time:4.5278, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2190/3125], step: 14690, 8.635 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0884, batch_loss_s: 0.0566, time:4.6324, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2200/3125], step: 14700, 7.719 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1318, batch_loss_s: 0.1257, time:5.1822, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2210/3125], step: 14710, 8.674 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.3047, batch_loss_s: 0.3005, time:4.6113, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:07:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2220/3125], step: 14720, 8.602 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0745, batch_loss_s: 0.0932, time:4.6500, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2230/3125], step: 14730, 8.552 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0948, batch_loss_s: 0.0496, time:4.6773, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2240/3125], step: 14740, 8.124 samples/sec, batch_loss: 0.2589, batch_loss_c: 0.2381, batch_loss_s: 0.3075, time:4.9235, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2250/3125], step: 14750, 7.473 samples/sec, batch_loss: 0.1719, batch_loss_c: 0.1760, batch_loss_s: 0.1623, time:5.3525, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2260/3125], step: 14760, 7.762 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.1050, batch_loss_s: 0.0649, time:5.1535, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2270/3125], step: 14770, 8.173 samples/sec, batch_loss: 0.1643, batch_loss_c: 0.1855, batch_loss_s: 0.1148, time:4.8942, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2280/3125], step: 14780, 9.073 samples/sec, batch_loss: 0.1313, batch_loss_c: 0.1509, batch_loss_s: 0.0856, time:4.4086, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2290/3125], step: 14790, 8.494 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0614, batch_loss_s: 0.0695, time:4.7094, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2300/3125], step: 14800, 8.601 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0792, batch_loss_s: 0.0738, time:4.6504, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2310/3125], step: 14810, 7.393 samples/sec, batch_loss: 0.3374, batch_loss_c: 0.3386, batch_loss_s: 0.3345, time:5.4104, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2320/3125], step: 14820, 8.113 samples/sec, batch_loss: 0.1260, batch_loss_c: 0.1327, batch_loss_s: 0.1104, time:4.9301, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2330/3125], step: 14830, 8.668 samples/sec, batch_loss: 0.5605, batch_loss_c: 0.5620, batch_loss_s: 0.5570, time:4.6146, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2340/3125], step: 14840, 7.899 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.1056, batch_loss_s: 0.0734, time:5.0638, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:08:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2350/3125], step: 14850, 8.406 samples/sec, batch_loss: 0.0623, batch_loss_c: 0.0563, batch_loss_s: 0.0761, time:4.7583, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2360/3125], step: 14860, 8.075 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0985, batch_loss_s: 0.0599, time:4.9535, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2370/3125], step: 14870, 8.653 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.1074, batch_loss_s: 0.0845, time:4.6227, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2380/3125], step: 14880, 7.527 samples/sec, batch_loss: 0.1116, batch_loss_c: 0.1122, batch_loss_s: 0.1101, time:5.3144, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2390/3125], step: 14890, 7.782 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0796, batch_loss_s: 0.0899, time:5.1403, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2400/3125], step: 14900, 7.371 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0717, batch_loss_s: 0.0741, time:5.4263, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2410/3125], step: 14910, 8.236 samples/sec, batch_loss: 0.0620, batch_loss_c: 0.0558, batch_loss_s: 0.0765, time:4.8569, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2420/3125], step: 14920, 8.496 samples/sec, batch_loss: 0.3101, batch_loss_c: 0.3113, batch_loss_s: 0.3073, time:4.7082, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2430/3125], step: 14930, 8.123 samples/sec, batch_loss: 0.1006, batch_loss_c: 0.1045, batch_loss_s: 0.0914, time:4.9242, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2440/3125], step: 14940, 8.105 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.0973, batch_loss_s: 0.1154, time:4.9353, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2450/3125], step: 14950, 8.104 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0718, batch_loss_s: 0.0924, time:4.9360, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2460/3125], step: 14960, 8.001 samples/sec, batch_loss: 0.1558, batch_loss_c: 0.1557, batch_loss_s: 0.1559, time:4.9994, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:09:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2470/3125], step: 14970, 8.097 samples/sec, batch_loss: 0.0691, batch_loss_c: 0.0628, batch_loss_s: 0.0838, time:4.9404, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2480/3125], step: 14980, 7.451 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0650, batch_loss_s: 0.0701, time:5.3683, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2490/3125], step: 14990, 8.232 samples/sec, batch_loss: 0.1420, batch_loss_c: 0.1582, batch_loss_s: 0.1042, time:4.8591, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2500/3125], step: 15000, 7.437 samples/sec, batch_loss: 0.3148, batch_loss_c: 0.3148, batch_loss_s: 0.3148, time:5.3783, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2510/3125], step: 15010, 8.665 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0637, batch_loss_s: 0.0744, time:4.6164, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2520/3125], step: 15020, 7.493 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0837, batch_loss_s: 0.0891, time:5.3383, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2530/3125], step: 15030, 8.970 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0749, batch_loss_s: 0.0808, time:4.4595, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2540/3125], step: 15040, 8.631 samples/sec, batch_loss: 0.5137, batch_loss_c: 0.5001, batch_loss_s: 0.5455, time:4.6343, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2550/3125], step: 15050, 7.909 samples/sec, batch_loss: 0.5289, batch_loss_c: 0.5236, batch_loss_s: 0.5414, time:5.0573, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2560/3125], step: 15060, 8.334 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0710, batch_loss_s: 0.0820, time:4.7997, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2570/3125], step: 15070, 8.598 samples/sec, batch_loss: 0.2910, batch_loss_c: 0.2878, batch_loss_s: 0.2985, time:4.6522, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2580/3125], step: 15080, 8.385 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1143, batch_loss_s: 0.0894, time:4.7705, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:10:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2590/3125], step: 15090, 7.948 samples/sec, batch_loss: 0.3431, batch_loss_c: 0.3398, batch_loss_s: 0.3507, time:5.0329, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2600/3125], step: 15100, 9.180 samples/sec, batch_loss: 0.1057, batch_loss_c: 0.1089, batch_loss_s: 0.0983, time:4.3574, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2610/3125], step: 15110, 8.650 samples/sec, batch_loss: 0.0794, batch_loss_c: 0.0808, batch_loss_s: 0.0761, time:4.6241, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2620/3125], step: 15120, 8.718 samples/sec, batch_loss: 0.1364, batch_loss_c: 0.1659, batch_loss_s: 0.0676, time:4.5882, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2630/3125], step: 15130, 8.650 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0679, batch_loss_s: 0.0842, time:4.6244, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2640/3125], step: 15140, 8.410 samples/sec, batch_loss: 0.1908, batch_loss_c: 0.2333, batch_loss_s: 0.0915, time:4.7561, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2650/3125], step: 15150, 8.642 samples/sec, batch_loss: 0.0567, batch_loss_c: 0.0554, batch_loss_s: 0.0597, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2660/3125], step: 15160, 8.722 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1213, batch_loss_s: 0.1068, time:4.5862, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2670/3125], step: 15170, 7.578 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0770, batch_loss_s: 0.0842, time:5.2786, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2680/3125], step: 15180, 7.599 samples/sec, batch_loss: 0.0706, batch_loss_c: 0.0721, batch_loss_s: 0.0672, time:5.2640, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2690/3125], step: 15190, 7.453 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0919, batch_loss_s: 0.0824, time:5.3669, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2700/3125], step: 15200, 8.149 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0697, batch_loss_s: 0.0848, time:4.9087, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:11:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2710/3125], step: 15210, 8.115 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0792, batch_loss_s: 0.0783, time:4.9292, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2720/3125], step: 15220, 8.412 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0909, batch_loss_s: 0.0813, time:4.7549, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2730/3125], step: 15230, 7.884 samples/sec, batch_loss: 0.2831, batch_loss_c: 0.2715, batch_loss_s: 0.3103, time:5.0738, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2740/3125], step: 15240, 8.597 samples/sec, batch_loss: 0.1243, batch_loss_c: 0.1244, batch_loss_s: 0.1241, time:4.6526, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2750/3125], step: 15250, 7.901 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0764, batch_loss_s: 0.0859, time:5.0628, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2760/3125], step: 15260, 9.102 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0894, batch_loss_s: 0.0817, time:4.3946, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2770/3125], step: 15270, 7.583 samples/sec, batch_loss: 0.2160, batch_loss_c: 0.2407, batch_loss_s: 0.1582, time:5.2749, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2780/3125], step: 15280, 7.598 samples/sec, batch_loss: 0.1503, batch_loss_c: 0.1453, batch_loss_s: 0.1622, time:5.2647, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2790/3125], step: 15290, 7.739 samples/sec, batch_loss: 0.3969, batch_loss_c: 0.4213, batch_loss_s: 0.3400, time:5.1686, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2800/3125], step: 15300, 7.989 samples/sec, batch_loss: 0.2807, batch_loss_c: 0.2790, batch_loss_s: 0.2846, time:5.0072, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2810/3125], step: 15310, 8.613 samples/sec, batch_loss: 0.1135, batch_loss_c: 0.1251, batch_loss_s: 0.0865, time:4.6444, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2820/3125], step: 15320, 7.511 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0762, batch_loss_s: 0.0699, time:5.3255, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:12:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2830/3125], step: 15330, 8.730 samples/sec, batch_loss: 0.3261, batch_loss_c: 0.3134, batch_loss_s: 0.3556, time:4.5820, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2840/3125], step: 15340, 8.432 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1240, batch_loss_s: 0.1111, time:4.7436, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2850/3125], step: 15350, 8.374 samples/sec, batch_loss: 0.0689, batch_loss_c: 0.0656, batch_loss_s: 0.0765, time:4.7766, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2860/3125], step: 15360, 8.179 samples/sec, batch_loss: 0.1102, batch_loss_c: 0.1231, batch_loss_s: 0.0801, time:4.8903, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2870/3125], step: 15370, 8.348 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0734, batch_loss_s: 0.0788, time:4.7913, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2880/3125], step: 15380, 8.368 samples/sec, batch_loss: 0.3367, batch_loss_c: 0.3401, batch_loss_s: 0.3288, time:4.7802, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2890/3125], step: 15390, 8.088 samples/sec, batch_loss: 0.1160, batch_loss_c: 0.1212, batch_loss_s: 0.1039, time:4.9457, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2900/3125], step: 15400, 7.215 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3175, batch_loss_s: 0.3184, time:5.5444, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2910/3125], step: 15410, 7.804 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1155, batch_loss_s: 0.0886, time:5.1254, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2920/3125], step: 15420, 9.017 samples/sec, batch_loss: 0.1538, batch_loss_c: 0.1626, batch_loss_s: 0.1333, time:4.4363, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2930/3125], step: 15430, 9.036 samples/sec, batch_loss: 0.2541, batch_loss_c: 0.2190, batch_loss_s: 0.3359, time:4.4270, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2940/3125], step: 15440, 9.243 samples/sec, batch_loss: 0.0506, batch_loss_c: 0.0481, batch_loss_s: 0.0563, time:4.3277, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2950/3125], step: 15450, 8.043 samples/sec, batch_loss: 0.1177, batch_loss_c: 0.1228, batch_loss_s: 0.1057, time:4.9734, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:13:57 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2960/3125], step: 15460, 9.197 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0754, batch_loss_s: 0.0970, time:4.3493, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2970/3125], step: 15470, 8.787 samples/sec, batch_loss: 0.3162, batch_loss_c: 0.3104, batch_loss_s: 0.3298, time:4.5520, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2980/3125], step: 15480, 8.146 samples/sec, batch_loss: 0.1272, batch_loss_c: 0.1417, batch_loss_s: 0.0932, time:4.9107, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2990/3125], step: 15490, 9.065 samples/sec, batch_loss: 0.3523, batch_loss_c: 0.3689, batch_loss_s: 0.3137, time:4.4126, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3000/3125], step: 15500, 8.719 samples/sec, batch_loss: 0.0690, batch_loss_c: 0.0631, batch_loss_s: 0.0829, time:4.5879, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3010/3125], step: 15510, 8.332 samples/sec, batch_loss: 0.2897, batch_loss_c: 0.2802, batch_loss_s: 0.3119, time:4.8009, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3020/3125], step: 15520, 8.233 samples/sec, batch_loss: 0.0787, batch_loss_c: 0.0756, batch_loss_s: 0.0859, time:4.8584, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3030/3125], step: 15530, 8.503 samples/sec, batch_loss: 0.1208, batch_loss_c: 0.0846, batch_loss_s: 0.2051, time:4.7041, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3040/3125], step: 15540, 8.440 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0833, batch_loss_s: 0.1026, time:4.7395, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3050/3125], step: 15550, 8.589 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0958, batch_loss_s: 0.0794, time:4.6572, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3060/3125], step: 15560, 6.929 samples/sec, batch_loss: 0.3057, batch_loss_c: 0.3030, batch_loss_s: 0.3120, time:5.7730, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3070/3125], step: 15570, 9.156 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0894, batch_loss_s: 0.0881, time:4.3685, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3080/3125], step: 15580, 8.295 samples/sec, batch_loss: 0.0626, batch_loss_c: 0.0598, batch_loss_s: 0.0691, time:4.8220, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:14:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3090/3125], step: 15590, 8.834 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0895, batch_loss_s: 0.0928, time:4.5282, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3100/3125], step: 15600, 7.458 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0772, batch_loss_s: 0.0927, time:5.3632, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3110/3125], step: 15610, 10.311 samples/sec, batch_loss: 0.3127, batch_loss_c: 0.3137, batch_loss_s: 0.3104, time:3.8795, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3120/3125], step: 15620, 10.242 samples/sec, batch_loss: 0.0902, batch_loss_c: 0.0869, batch_loss_s: 0.0979, time:3.9056, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], train_loss: 0.1712, time: 1520.3740, lr: 0.0001\u001b[0m\n",
            "2019-11-24 11:15:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [0/3125], step: 15625, 9.274 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1109, batch_loss_s: 0.1262, time:4.3130, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [10/3125], step: 15635, 5.224 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3142, batch_loss_s: 0.3132, time:7.6574, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [20/3125], step: 15645, 7.312 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0891, batch_loss_s: 0.0884, time:5.4703, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [30/3125], step: 15655, 8.359 samples/sec, batch_loss: 0.2599, batch_loss_c: 0.2370, batch_loss_s: 0.3133, time:4.7853, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [40/3125], step: 15665, 8.597 samples/sec, batch_loss: 0.0608, batch_loss_c: 0.0597, batch_loss_s: 0.0635, time:4.6528, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [50/3125], step: 15675, 8.741 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0774, batch_loss_s: 0.0850, time:4.5759, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [60/3125], step: 15685, 8.693 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0791, batch_loss_s: 0.0798, time:4.6014, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [70/3125], step: 15695, 8.334 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1170, batch_loss_s: 0.0720, time:4.7996, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:15:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [80/3125], step: 15705, 8.774 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1421, batch_loss_s: 0.0982, time:4.5592, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [90/3125], step: 15715, 8.121 samples/sec, batch_loss: 0.0771, batch_loss_c: 0.0747, batch_loss_s: 0.0827, time:4.9255, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [100/3125], step: 15725, 8.354 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1088, batch_loss_s: 0.0866, time:4.7881, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [110/3125], step: 15735, 8.851 samples/sec, batch_loss: 0.1510, batch_loss_c: 0.1750, batch_loss_s: 0.0951, time:4.5192, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [120/3125], step: 15745, 8.364 samples/sec, batch_loss: 0.2687, batch_loss_c: 0.2761, batch_loss_s: 0.2514, time:4.7821, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [130/3125], step: 15755, 7.690 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0625, batch_loss_s: 0.0774, time:5.2018, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [140/3125], step: 15765, 8.276 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0886, batch_loss_s: 0.0821, time:4.8335, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [150/3125], step: 15775, 7.611 samples/sec, batch_loss: 0.0483, batch_loss_c: 0.0442, batch_loss_s: 0.0580, time:5.2555, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [160/3125], step: 15785, 8.180 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0939, batch_loss_s: 0.0910, time:4.8898, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [170/3125], step: 15795, 7.936 samples/sec, batch_loss: 0.3714, batch_loss_c: 0.3749, batch_loss_s: 0.3632, time:5.0401, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [180/3125], step: 15805, 7.563 samples/sec, batch_loss: 0.1400, batch_loss_c: 0.1431, batch_loss_s: 0.1327, time:5.2889, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [190/3125], step: 15815, 7.392 samples/sec, batch_loss: 0.4738, batch_loss_c: 0.4634, batch_loss_s: 0.4979, time:5.4110, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:16:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [200/3125], step: 15825, 8.054 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1121, batch_loss_s: 0.0775, time:4.9662, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [210/3125], step: 15835, 7.498 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0851, batch_loss_s: 0.0910, time:5.3348, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [220/3125], step: 15845, 8.201 samples/sec, batch_loss: 0.2087, batch_loss_c: 0.2430, batch_loss_s: 0.1287, time:4.8775, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [230/3125], step: 15855, 7.406 samples/sec, batch_loss: 0.3241, batch_loss_c: 0.3278, batch_loss_s: 0.3157, time:5.4010, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [240/3125], step: 15865, 8.342 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0821, batch_loss_s: 0.0918, time:4.7952, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [250/3125], step: 15875, 8.231 samples/sec, batch_loss: 0.1830, batch_loss_c: 0.1905, batch_loss_s: 0.1653, time:4.8599, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [260/3125], step: 15885, 8.545 samples/sec, batch_loss: 0.0614, batch_loss_c: 0.0608, batch_loss_s: 0.0628, time:4.6811, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [270/3125], step: 15895, 8.140 samples/sec, batch_loss: 0.3469, batch_loss_c: 0.3620, batch_loss_s: 0.3117, time:4.9140, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [280/3125], step: 15905, 8.436 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.0939, batch_loss_s: 0.1111, time:4.7413, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [290/3125], step: 15915, 7.319 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1051, batch_loss_s: 0.1112, time:5.4651, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [300/3125], step: 15925, 8.331 samples/sec, batch_loss: 0.0567, batch_loss_c: 0.0521, batch_loss_s: 0.0676, time:4.8014, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [310/3125], step: 15935, 8.011 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0733, batch_loss_s: 0.0788, time:4.9930, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:17:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [320/3125], step: 15945, 8.155 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0883, batch_loss_s: 0.1014, time:4.9050, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [330/3125], step: 15955, 8.515 samples/sec, batch_loss: 0.5405, batch_loss_c: 0.5391, batch_loss_s: 0.5438, time:4.6973, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [340/3125], step: 15965, 7.660 samples/sec, batch_loss: 0.1682, batch_loss_c: 0.1665, batch_loss_s: 0.1721, time:5.2222, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [350/3125], step: 15975, 8.413 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0742, batch_loss_s: 0.0832, time:4.7544, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [360/3125], step: 15985, 8.001 samples/sec, batch_loss: 0.1363, batch_loss_c: 0.1659, batch_loss_s: 0.0673, time:4.9991, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [370/3125], step: 15995, 8.193 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0752, batch_loss_s: 0.0934, time:4.8821, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [380/3125], step: 16005, 8.155 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0889, batch_loss_s: 0.0759, time:4.9051, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [390/3125], step: 16015, 7.552 samples/sec, batch_loss: 0.0919, batch_loss_c: 0.0885, batch_loss_s: 0.0998, time:5.2967, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [400/3125], step: 16025, 8.385 samples/sec, batch_loss: 0.3267, batch_loss_c: 0.3340, batch_loss_s: 0.3095, time:4.7707, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [410/3125], step: 16035, 8.675 samples/sec, batch_loss: 0.3462, batch_loss_c: 0.3384, batch_loss_s: 0.3646, time:4.6108, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [420/3125], step: 16045, 7.823 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0770, batch_loss_s: 0.0623, time:5.1134, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [430/3125], step: 16055, 7.677 samples/sec, batch_loss: 0.2836, batch_loss_c: 0.2806, batch_loss_s: 0.2905, time:5.2103, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:18:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [440/3125], step: 16065, 8.495 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0768, batch_loss_s: 0.1005, time:4.7087, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [450/3125], step: 16075, 8.450 samples/sec, batch_loss: 0.0726, batch_loss_c: 0.0705, batch_loss_s: 0.0773, time:4.7339, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [460/3125], step: 16085, 8.226 samples/sec, batch_loss: 0.0685, batch_loss_c: 0.0646, batch_loss_s: 0.0776, time:4.8627, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [470/3125], step: 16095, 8.714 samples/sec, batch_loss: 0.1180, batch_loss_c: 0.1177, batch_loss_s: 0.1185, time:4.5904, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [480/3125], step: 16105, 8.298 samples/sec, batch_loss: 0.3164, batch_loss_c: 0.3126, batch_loss_s: 0.3254, time:4.8207, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [490/3125], step: 16115, 9.330 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0997, batch_loss_s: 0.1010, time:4.2873, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [500/3125], step: 16125, 8.118 samples/sec, batch_loss: 0.1378, batch_loss_c: 0.1529, batch_loss_s: 0.1026, time:4.9273, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [510/3125], step: 16135, 7.846 samples/sec, batch_loss: 0.5208, batch_loss_c: 0.5122, batch_loss_s: 0.5410, time:5.0984, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [520/3125], step: 16145, 7.304 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0926, batch_loss_s: 0.0986, time:5.4764, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [530/3125], step: 16155, 8.282 samples/sec, batch_loss: 0.1567, batch_loss_c: 0.1861, batch_loss_s: 0.0880, time:4.8298, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [540/3125], step: 16165, 7.535 samples/sec, batch_loss: 0.3483, batch_loss_c: 0.3558, batch_loss_s: 0.3308, time:5.3082, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [550/3125], step: 16175, 8.367 samples/sec, batch_loss: 0.1569, batch_loss_c: 0.1964, batch_loss_s: 0.0649, time:4.7807, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:19:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [560/3125], step: 16185, 8.895 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3455, batch_loss_s: 0.3437, time:4.4970, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [570/3125], step: 16195, 8.854 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0959, batch_loss_s: 0.0725, time:4.5180, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [580/3125], step: 16205, 8.766 samples/sec, batch_loss: 0.0822, batch_loss_c: 0.0860, batch_loss_s: 0.0735, time:4.5632, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [590/3125], step: 16215, 8.599 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1313, batch_loss_s: 0.0772, time:4.6515, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [600/3125], step: 16225, 9.096 samples/sec, batch_loss: 0.1430, batch_loss_c: 0.1576, batch_loss_s: 0.1088, time:4.3975, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [610/3125], step: 16235, 8.401 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1087, batch_loss_s: 0.1011, time:4.7616, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [620/3125], step: 16245, 9.223 samples/sec, batch_loss: 0.0786, batch_loss_c: 0.0822, batch_loss_s: 0.0702, time:4.3368, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [630/3125], step: 16255, 7.927 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0771, batch_loss_s: 0.0664, time:5.0459, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [640/3125], step: 16265, 8.222 samples/sec, batch_loss: 0.3181, batch_loss_c: 0.3138, batch_loss_s: 0.3279, time:4.8652, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [650/3125], step: 16275, 8.239 samples/sec, batch_loss: 0.1676, batch_loss_c: 0.1944, batch_loss_s: 0.1053, time:4.8548, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [660/3125], step: 16285, 8.429 samples/sec, batch_loss: 0.2807, batch_loss_c: 0.2711, batch_loss_s: 0.3030, time:4.7455, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [670/3125], step: 16295, 7.932 samples/sec, batch_loss: 0.2634, batch_loss_c: 0.2450, batch_loss_s: 0.3064, time:5.0426, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [680/3125], step: 16305, 7.806 samples/sec, batch_loss: 0.0980, batch_loss_c: 0.1076, batch_loss_s: 0.0756, time:5.1244, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:20:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [690/3125], step: 16315, 7.559 samples/sec, batch_loss: 0.1207, batch_loss_c: 0.1262, batch_loss_s: 0.1078, time:5.2920, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [700/3125], step: 16325, 8.878 samples/sec, batch_loss: 0.3828, batch_loss_c: 0.3959, batch_loss_s: 0.3525, time:4.5056, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [710/3125], step: 16335, 8.682 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2899, batch_loss_s: 0.2983, time:4.6073, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [720/3125], step: 16345, 8.343 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0788, batch_loss_s: 0.0714, time:4.7946, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [730/3125], step: 16355, 8.882 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1279, batch_loss_s: 0.1069, time:4.5033, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [740/3125], step: 16365, 8.333 samples/sec, batch_loss: 0.1678, batch_loss_c: 0.2007, batch_loss_s: 0.0912, time:4.8003, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [750/3125], step: 16375, 7.916 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1118, batch_loss_s: 0.0922, time:5.0530, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [760/3125], step: 16385, 7.926 samples/sec, batch_loss: 0.3122, batch_loss_c: 0.3097, batch_loss_s: 0.3181, time:5.0468, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [770/3125], step: 16395, 8.334 samples/sec, batch_loss: 0.3441, batch_loss_c: 0.3436, batch_loss_s: 0.3453, time:4.7997, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [780/3125], step: 16405, 7.856 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0572, batch_loss_s: 0.0718, time:5.0918, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [790/3125], step: 16415, 8.512 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0658, batch_loss_s: 0.0692, time:4.6995, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [800/3125], step: 16425, 7.806 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0811, batch_loss_s: 0.0857, time:5.1246, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:21:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [810/3125], step: 16435, 7.312 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0814, batch_loss_s: 0.0628, time:5.4706, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [820/3125], step: 16445, 7.837 samples/sec, batch_loss: 0.1874, batch_loss_c: 0.1981, batch_loss_s: 0.1625, time:5.1041, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [830/3125], step: 16455, 8.323 samples/sec, batch_loss: 0.3066, batch_loss_c: 0.3047, batch_loss_s: 0.3109, time:4.8060, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [840/3125], step: 16465, 7.751 samples/sec, batch_loss: 0.3040, batch_loss_c: 0.2962, batch_loss_s: 0.3221, time:5.1605, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [850/3125], step: 16475, 8.503 samples/sec, batch_loss: 0.3444, batch_loss_c: 0.3297, batch_loss_s: 0.3787, time:4.7041, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [860/3125], step: 16485, 9.232 samples/sec, batch_loss: 0.3127, batch_loss_c: 0.3124, batch_loss_s: 0.3133, time:4.3329, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [870/3125], step: 16495, 8.079 samples/sec, batch_loss: 0.0679, batch_loss_c: 0.0648, batch_loss_s: 0.0751, time:4.9509, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [880/3125], step: 16505, 7.758 samples/sec, batch_loss: 0.3157, batch_loss_c: 0.3156, batch_loss_s: 0.3159, time:5.1557, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [890/3125], step: 16515, 7.959 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1314, batch_loss_s: 0.1260, time:5.0259, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [900/3125], step: 16525, 8.177 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.2995, batch_loss_s: 0.3148, time:4.8918, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [910/3125], step: 16535, 8.314 samples/sec, batch_loss: 0.2973, batch_loss_c: 0.2927, batch_loss_s: 0.3079, time:4.8114, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [920/3125], step: 16545, 8.932 samples/sec, batch_loss: 0.3184, batch_loss_c: 0.3247, batch_loss_s: 0.3036, time:4.4783, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:22:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [930/3125], step: 16555, 9.130 samples/sec, batch_loss: 0.3227, batch_loss_c: 0.3244, batch_loss_s: 0.3189, time:4.3811, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [940/3125], step: 16565, 8.541 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0773, batch_loss_s: 0.0867, time:4.6831, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [950/3125], step: 16575, 8.368 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0873, batch_loss_s: 0.0860, time:4.7799, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [960/3125], step: 16585, 8.961 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0834, batch_loss_s: 0.0772, time:4.4636, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [970/3125], step: 16595, 7.923 samples/sec, batch_loss: 0.3077, batch_loss_c: 0.3075, batch_loss_s: 0.3080, time:5.0485, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [980/3125], step: 16605, 8.649 samples/sec, batch_loss: 0.7107, batch_loss_c: 0.6855, batch_loss_s: 0.7694, time:4.6249, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [990/3125], step: 16615, 8.738 samples/sec, batch_loss: 0.1682, batch_loss_c: 0.1858, batch_loss_s: 0.1271, time:4.5779, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1000/3125], step: 16625, 8.371 samples/sec, batch_loss: 0.1593, batch_loss_c: 0.1564, batch_loss_s: 0.1659, time:4.7786, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1010/3125], step: 16635, 8.324 samples/sec, batch_loss: 0.1283, batch_loss_c: 0.1435, batch_loss_s: 0.0929, time:4.8055, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1020/3125], step: 16645, 8.726 samples/sec, batch_loss: 0.3103, batch_loss_c: 0.3091, batch_loss_s: 0.3130, time:4.5838, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1030/3125], step: 16655, 7.698 samples/sec, batch_loss: 0.1794, batch_loss_c: 0.2200, batch_loss_s: 0.0846, time:5.1963, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1040/3125], step: 16665, 8.487 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.1114, batch_loss_s: 0.0697, time:4.7131, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1050/3125], step: 16675, 8.783 samples/sec, batch_loss: 0.0682, batch_loss_c: 0.0619, batch_loss_s: 0.0827, time:4.5540, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:23:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1060/3125], step: 16685, 8.141 samples/sec, batch_loss: 0.0964, batch_loss_c: 0.1051, batch_loss_s: 0.0763, time:4.9135, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1070/3125], step: 16695, 7.740 samples/sec, batch_loss: 0.0631, batch_loss_c: 0.0575, batch_loss_s: 0.0762, time:5.1678, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1080/3125], step: 16705, 7.387 samples/sec, batch_loss: 0.1143, batch_loss_c: 0.1366, batch_loss_s: 0.0622, time:5.4152, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1090/3125], step: 16715, 9.237 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0793, batch_loss_s: 0.1023, time:4.3306, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1100/3125], step: 16725, 7.821 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1127, batch_loss_s: 0.1109, time:5.1143, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1110/3125], step: 16735, 7.903 samples/sec, batch_loss: 0.3308, batch_loss_c: 0.3366, batch_loss_s: 0.3174, time:5.0616, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1120/3125], step: 16745, 6.473 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0922, batch_loss_s: 0.0815, time:6.1795, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1130/3125], step: 16755, 7.806 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0844, batch_loss_s: 0.0998, time:5.1240, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1140/3125], step: 16765, 7.813 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3019, batch_loss_s: 0.3354, time:5.1198, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1150/3125], step: 16775, 7.921 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1316, batch_loss_s: 0.1093, time:5.0499, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1160/3125], step: 16785, 7.689 samples/sec, batch_loss: 0.3342, batch_loss_c: 0.3303, batch_loss_s: 0.3433, time:5.2022, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1170/3125], step: 16795, 8.401 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0952, batch_loss_s: 0.0956, time:4.7612, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:24:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1180/3125], step: 16805, 8.050 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0738, batch_loss_s: 0.0716, time:4.9688, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1190/3125], step: 16815, 8.907 samples/sec, batch_loss: 0.1445, batch_loss_c: 0.1434, batch_loss_s: 0.1472, time:4.4911, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1200/3125], step: 16825, 8.686 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0620, batch_loss_s: 0.0842, time:4.6052, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1210/3125], step: 16835, 8.387 samples/sec, batch_loss: 0.1789, batch_loss_c: 0.2240, batch_loss_s: 0.0738, time:4.7692, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1220/3125], step: 16845, 8.147 samples/sec, batch_loss: 0.3282, batch_loss_c: 0.3408, batch_loss_s: 0.2988, time:4.9097, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1230/3125], step: 16855, 7.920 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0795, batch_loss_s: 0.0895, time:5.0506, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1240/3125], step: 16865, 8.341 samples/sec, batch_loss: 0.1450, batch_loss_c: 0.1501, batch_loss_s: 0.1332, time:4.7957, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1250/3125], step: 16875, 9.118 samples/sec, batch_loss: 0.2553, batch_loss_c: 0.2356, batch_loss_s: 0.3014, time:4.3867, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1260/3125], step: 16885, 8.487 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0898, batch_loss_s: 0.0837, time:4.7129, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1270/3125], step: 16895, 9.385 samples/sec, batch_loss: 0.1025, batch_loss_c: 0.1100, batch_loss_s: 0.0852, time:4.2622, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1280/3125], step: 16905, 9.319 samples/sec, batch_loss: 0.0655, batch_loss_c: 0.0612, batch_loss_s: 0.0754, time:4.2924, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1290/3125], step: 16915, 9.201 samples/sec, batch_loss: 0.1899, batch_loss_c: 0.2142, batch_loss_s: 0.1330, time:4.3475, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1300/3125], step: 16925, 8.365 samples/sec, batch_loss: 0.0667, batch_loss_c: 0.0661, batch_loss_s: 0.0680, time:4.7820, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:25:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1310/3125], step: 16935, 9.072 samples/sec, batch_loss: 0.1189, batch_loss_c: 0.1135, batch_loss_s: 0.1313, time:4.4091, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1320/3125], step: 16945, 7.550 samples/sec, batch_loss: 0.0848, batch_loss_c: 0.0813, batch_loss_s: 0.0929, time:5.2977, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1330/3125], step: 16955, 8.297 samples/sec, batch_loss: 0.1885, batch_loss_c: 0.1982, batch_loss_s: 0.1659, time:4.8210, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1340/3125], step: 16965, 8.699 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1201, batch_loss_s: 0.0933, time:4.5983, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1350/3125], step: 16975, 8.880 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0611, batch_loss_s: 0.0633, time:4.5044, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1360/3125], step: 16985, 8.215 samples/sec, batch_loss: 0.3379, batch_loss_c: 0.3422, batch_loss_s: 0.3278, time:4.8691, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1370/3125], step: 16995, 8.210 samples/sec, batch_loss: 0.2289, batch_loss_c: 0.2115, batch_loss_s: 0.2695, time:4.8723, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1380/3125], step: 17005, 8.993 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0660, batch_loss_s: 0.0786, time:4.4481, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1390/3125], step: 17015, 8.932 samples/sec, batch_loss: 0.4598, batch_loss_c: 0.4236, batch_loss_s: 0.5442, time:4.4785, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1400/3125], step: 17025, 8.396 samples/sec, batch_loss: 0.5381, batch_loss_c: 0.5274, batch_loss_s: 0.5630, time:4.7639, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1410/3125], step: 17035, 8.392 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0708, batch_loss_s: 0.0856, time:4.7667, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1420/3125], step: 17045, 8.845 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0932, batch_loss_s: 0.0753, time:4.5221, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:26:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1430/3125], step: 17055, 8.102 samples/sec, batch_loss: 0.3481, batch_loss_c: 0.3498, batch_loss_s: 0.3441, time:4.9370, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1440/3125], step: 17065, 7.978 samples/sec, batch_loss: 0.0800, batch_loss_c: 0.0765, batch_loss_s: 0.0882, time:5.0138, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1450/3125], step: 17075, 8.042 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1232, batch_loss_s: 0.1412, time:4.9740, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1460/3125], step: 17085, 7.641 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1238, batch_loss_s: 0.1018, time:5.2351, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1470/3125], step: 17095, 8.416 samples/sec, batch_loss: 0.0640, batch_loss_c: 0.0637, batch_loss_s: 0.0646, time:4.7528, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1480/3125], step: 17105, 8.020 samples/sec, batch_loss: 0.0753, batch_loss_c: 0.0729, batch_loss_s: 0.0809, time:4.9875, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1490/3125], step: 17115, 7.926 samples/sec, batch_loss: 0.3495, batch_loss_c: 0.3667, batch_loss_s: 0.3094, time:5.0469, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1500/3125], step: 17125, 7.747 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1033, batch_loss_s: 0.1018, time:5.1636, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1510/3125], step: 17135, 7.760 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0961, batch_loss_s: 0.0770, time:5.1545, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1520/3125], step: 17145, 8.565 samples/sec, batch_loss: 0.3021, batch_loss_c: 0.2973, batch_loss_s: 0.3134, time:4.6701, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1530/3125], step: 17155, 7.304 samples/sec, batch_loss: 0.0985, batch_loss_c: 0.0967, batch_loss_s: 0.1026, time:5.4764, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1540/3125], step: 17165, 7.548 samples/sec, batch_loss: 0.1285, batch_loss_c: 0.1378, batch_loss_s: 0.1066, time:5.2996, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:27:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1550/3125], step: 17175, 8.439 samples/sec, batch_loss: 0.1111, batch_loss_c: 0.1201, batch_loss_s: 0.0902, time:4.7401, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1560/3125], step: 17185, 8.257 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3362, batch_loss_s: 0.3391, time:4.8443, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1570/3125], step: 17195, 8.444 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.1028, batch_loss_s: 0.0802, time:4.7369, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1580/3125], step: 17205, 8.650 samples/sec, batch_loss: 0.3659, batch_loss_c: 0.3796, batch_loss_s: 0.3341, time:4.6242, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1590/3125], step: 17215, 8.094 samples/sec, batch_loss: 0.2819, batch_loss_c: 0.2741, batch_loss_s: 0.2999, time:4.9421, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1600/3125], step: 17225, 9.342 samples/sec, batch_loss: 0.5223, batch_loss_c: 0.5177, batch_loss_s: 0.5332, time:4.2816, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1610/3125], step: 17235, 8.267 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1112, batch_loss_s: 0.1228, time:4.8384, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1620/3125], step: 17245, 7.567 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0901, batch_loss_s: 0.0933, time:5.2864, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1630/3125], step: 17255, 8.388 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3128, batch_loss_s: 0.3450, time:4.7689, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1640/3125], step: 17265, 8.568 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0639, batch_loss_s: 0.0751, time:4.6688, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1650/3125], step: 17275, 8.642 samples/sec, batch_loss: 0.3100, batch_loss_c: 0.3076, batch_loss_s: 0.3155, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1660/3125], step: 17285, 7.694 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0885, batch_loss_s: 0.0841, time:5.1985, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1670/3125], step: 17295, 7.495 samples/sec, batch_loss: 0.2422, batch_loss_c: 0.2199, batch_loss_s: 0.2942, time:5.3368, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:28:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1680/3125], step: 17305, 7.559 samples/sec, batch_loss: 0.2633, batch_loss_c: 0.2460, batch_loss_s: 0.3037, time:5.2919, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1690/3125], step: 17315, 8.202 samples/sec, batch_loss: 0.0945, batch_loss_c: 0.0912, batch_loss_s: 0.1021, time:4.8766, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1700/3125], step: 17325, 8.283 samples/sec, batch_loss: 0.0837, batch_loss_c: 0.0806, batch_loss_s: 0.0911, time:4.8292, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1710/3125], step: 17335, 9.105 samples/sec, batch_loss: 0.0676, batch_loss_c: 0.0686, batch_loss_s: 0.0651, time:4.3930, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1720/3125], step: 17345, 8.752 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.2000, batch_loss_s: 0.0758, time:4.5702, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1730/3125], step: 17355, 7.857 samples/sec, batch_loss: 0.0497, batch_loss_c: 0.0459, batch_loss_s: 0.0586, time:5.0908, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1740/3125], step: 17365, 7.933 samples/sec, batch_loss: 0.3717, batch_loss_c: 0.3926, batch_loss_s: 0.3227, time:5.0422, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1750/3125], step: 17375, 8.189 samples/sec, batch_loss: 0.0851, batch_loss_c: 0.0856, batch_loss_s: 0.0839, time:4.8848, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1760/3125], step: 17385, 8.728 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0783, batch_loss_s: 0.0854, time:4.5829, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1770/3125], step: 17395, 7.778 samples/sec, batch_loss: 0.3735, batch_loss_c: 0.3659, batch_loss_s: 0.3913, time:5.1429, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1780/3125], step: 17405, 8.610 samples/sec, batch_loss: 0.0600, batch_loss_c: 0.0547, batch_loss_s: 0.0724, time:4.6458, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1790/3125], step: 17415, 8.544 samples/sec, batch_loss: 0.0937, batch_loss_c: 0.0950, batch_loss_s: 0.0907, time:4.6816, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:29:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1800/3125], step: 17425, 8.295 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0638, batch_loss_s: 0.0886, time:4.8224, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1810/3125], step: 17435, 8.415 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1575, batch_loss_s: 0.1181, time:4.7535, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1820/3125], step: 17445, 8.425 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1079, batch_loss_s: 0.1062, time:4.7478, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1830/3125], step: 17455, 8.363 samples/sec, batch_loss: 0.0985, batch_loss_c: 0.1028, batch_loss_s: 0.0887, time:4.7831, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1840/3125], step: 17465, 8.400 samples/sec, batch_loss: 0.3174, batch_loss_c: 0.3102, batch_loss_s: 0.3339, time:4.7619, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1850/3125], step: 17475, 7.972 samples/sec, batch_loss: 0.2417, batch_loss_c: 0.2383, batch_loss_s: 0.2496, time:5.0175, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1860/3125], step: 17485, 8.296 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0789, batch_loss_s: 0.0921, time:4.8215, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1870/3125], step: 17495, 8.564 samples/sec, batch_loss: 0.3212, batch_loss_c: 0.3227, batch_loss_s: 0.3176, time:4.6708, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1880/3125], step: 17505, 8.515 samples/sec, batch_loss: 0.3644, batch_loss_c: 0.3613, batch_loss_s: 0.3718, time:4.6975, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1890/3125], step: 17515, 8.484 samples/sec, batch_loss: 0.1413, batch_loss_c: 0.1378, batch_loss_s: 0.1496, time:4.7145, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1900/3125], step: 17525, 8.937 samples/sec, batch_loss: 0.0660, batch_loss_c: 0.0638, batch_loss_s: 0.0713, time:4.4756, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1910/3125], step: 17535, 8.173 samples/sec, batch_loss: 0.3254, batch_loss_c: 0.3193, batch_loss_s: 0.3398, time:4.8939, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1920/3125], step: 17545, 9.010 samples/sec, batch_loss: 0.1757, batch_loss_c: 0.1349, batch_loss_s: 0.2709, time:4.4393, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:30:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1930/3125], step: 17555, 8.305 samples/sec, batch_loss: 0.0612, batch_loss_c: 0.0586, batch_loss_s: 0.0671, time:4.8164, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1940/3125], step: 17565, 7.809 samples/sec, batch_loss: 0.3272, batch_loss_c: 0.3275, batch_loss_s: 0.3264, time:5.1224, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1950/3125], step: 17575, 8.657 samples/sec, batch_loss: 0.2854, batch_loss_c: 0.2836, batch_loss_s: 0.2894, time:4.6207, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1960/3125], step: 17585, 8.044 samples/sec, batch_loss: 0.3289, batch_loss_c: 0.3281, batch_loss_s: 0.3309, time:4.9730, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1970/3125], step: 17595, 8.156 samples/sec, batch_loss: 0.2530, batch_loss_c: 0.2721, batch_loss_s: 0.2083, time:4.9041, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1980/3125], step: 17605, 7.782 samples/sec, batch_loss: 0.1596, batch_loss_c: 0.1825, batch_loss_s: 0.1061, time:5.1399, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1990/3125], step: 17615, 8.283 samples/sec, batch_loss: 0.1861, batch_loss_c: 0.2024, batch_loss_s: 0.1482, time:4.8293, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2000/3125], step: 17625, 8.467 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3102, batch_loss_s: 0.3181, time:4.7242, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2010/3125], step: 17635, 6.991 samples/sec, batch_loss: 0.0742, batch_loss_c: 0.0750, batch_loss_s: 0.0723, time:5.7216, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2020/3125], step: 17645, 8.595 samples/sec, batch_loss: 0.1493, batch_loss_c: 0.1563, batch_loss_s: 0.1328, time:4.6541, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2030/3125], step: 17655, 7.659 samples/sec, batch_loss: 0.3218, batch_loss_c: 0.3317, batch_loss_s: 0.2989, time:5.2227, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2040/3125], step: 17665, 8.596 samples/sec, batch_loss: 0.0697, batch_loss_c: 0.0700, batch_loss_s: 0.0691, time:4.6532, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:31:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2050/3125], step: 17675, 7.952 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1384, batch_loss_s: 0.0910, time:5.0302, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2060/3125], step: 17685, 8.190 samples/sec, batch_loss: 0.0931, batch_loss_c: 0.0923, batch_loss_s: 0.0947, time:4.8841, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2070/3125], step: 17695, 7.964 samples/sec, batch_loss: 0.1779, batch_loss_c: 0.1796, batch_loss_s: 0.1738, time:5.0227, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2080/3125], step: 17705, 8.283 samples/sec, batch_loss: 0.1232, batch_loss_c: 0.1311, batch_loss_s: 0.1048, time:4.8290, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2090/3125], step: 17715, 8.473 samples/sec, batch_loss: 0.1644, batch_loss_c: 0.1857, batch_loss_s: 0.1147, time:4.7209, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2100/3125], step: 17725, 7.640 samples/sec, batch_loss: 0.1802, batch_loss_c: 0.1819, batch_loss_s: 0.1763, time:5.2358, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2110/3125], step: 17735, 7.917 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0918, batch_loss_s: 0.0858, time:5.0522, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2120/3125], step: 17745, 8.010 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0711, batch_loss_s: 0.0712, time:4.9937, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2130/3125], step: 17755, 8.676 samples/sec, batch_loss: 0.5096, batch_loss_c: 0.4927, batch_loss_s: 0.5491, time:4.6105, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2140/3125], step: 17765, 8.118 samples/sec, batch_loss: 0.2427, batch_loss_c: 0.2952, batch_loss_s: 0.1203, time:4.9270, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2150/3125], step: 17775, 8.971 samples/sec, batch_loss: 0.0725, batch_loss_c: 0.0653, batch_loss_s: 0.0892, time:4.4591, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2160/3125], step: 17785, 8.296 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1012, batch_loss_s: 0.0886, time:4.8216, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:32:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2170/3125], step: 17795, 8.779 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1033, batch_loss_s: 0.1045, time:4.5562, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2180/3125], step: 17805, 8.787 samples/sec, batch_loss: 0.0681, batch_loss_c: 0.0660, batch_loss_s: 0.0730, time:4.5521, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2190/3125], step: 17815, 7.300 samples/sec, batch_loss: 0.2495, batch_loss_c: 0.2787, batch_loss_s: 0.1813, time:5.4797, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2200/3125], step: 17825, 8.647 samples/sec, batch_loss: 0.3115, batch_loss_c: 0.3137, batch_loss_s: 0.3063, time:4.6256, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2210/3125], step: 17835, 8.764 samples/sec, batch_loss: 0.0534, batch_loss_c: 0.0542, batch_loss_s: 0.0514, time:4.5644, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2220/3125], step: 17845, 8.543 samples/sec, batch_loss: 0.3006, batch_loss_c: 0.2991, batch_loss_s: 0.3041, time:4.6820, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2230/3125], step: 17855, 8.376 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1455, batch_loss_s: 0.0768, time:4.7758, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2240/3125], step: 17865, 7.813 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0854, batch_loss_s: 0.0641, time:5.1195, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2250/3125], step: 17875, 9.184 samples/sec, batch_loss: 0.3008, batch_loss_c: 0.2983, batch_loss_s: 0.3067, time:4.3554, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2260/3125], step: 17885, 8.809 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1066, batch_loss_s: 0.0940, time:4.5406, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2270/3125], step: 17895, 8.185 samples/sec, batch_loss: 0.3083, batch_loss_c: 0.3096, batch_loss_s: 0.3053, time:4.8873, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2280/3125], step: 17905, 7.852 samples/sec, batch_loss: 0.0980, batch_loss_c: 0.1050, batch_loss_s: 0.0818, time:5.0943, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2290/3125], step: 17915, 8.772 samples/sec, batch_loss: 0.3000, batch_loss_c: 0.2956, batch_loss_s: 0.3102, time:4.5598, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:33:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2300/3125], step: 17925, 7.706 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0806, batch_loss_s: 0.0802, time:5.1906, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2310/3125], step: 17935, 8.557 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3124, batch_loss_s: 0.3171, time:4.6746, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2320/3125], step: 17945, 8.461 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0986, batch_loss_s: 0.0653, time:4.7277, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2330/3125], step: 17955, 8.045 samples/sec, batch_loss: 0.1322, batch_loss_c: 0.1483, batch_loss_s: 0.0946, time:4.9722, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2340/3125], step: 17965, 7.906 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0772, batch_loss_s: 0.0783, time:5.0595, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2350/3125], step: 17975, 7.596 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0938, batch_loss_s: 0.0923, time:5.2658, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2360/3125], step: 17985, 8.621 samples/sec, batch_loss: 0.3071, batch_loss_c: 0.2908, batch_loss_s: 0.3452, time:4.6399, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2370/3125], step: 17995, 9.332 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0825, batch_loss_s: 0.1018, time:4.2865, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2380/3125], step: 18005, 8.627 samples/sec, batch_loss: 0.0816, batch_loss_c: 0.0858, batch_loss_s: 0.0719, time:4.6367, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2390/3125], step: 18015, 9.314 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0675, batch_loss_s: 0.0897, time:4.2945, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2400/3125], step: 18025, 8.867 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.1104, batch_loss_s: 0.0722, time:4.5110, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2410/3125], step: 18035, 8.174 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0889, batch_loss_s: 0.0881, time:4.8933, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2420/3125], step: 18045, 8.539 samples/sec, batch_loss: 0.0597, batch_loss_c: 0.0558, batch_loss_s: 0.0689, time:4.6846, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:34:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2430/3125], step: 18055, 8.652 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0932, batch_loss_s: 0.0938, time:4.6230, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2440/3125], step: 18065, 8.363 samples/sec, batch_loss: 0.0711, batch_loss_c: 0.0695, batch_loss_s: 0.0746, time:4.7830, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2450/3125], step: 18075, 7.775 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0775, batch_loss_s: 0.0794, time:5.1450, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2460/3125], step: 18085, 7.167 samples/sec, batch_loss: 0.1480, batch_loss_c: 0.1496, batch_loss_s: 0.1444, time:5.5814, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2470/3125], step: 18095, 8.499 samples/sec, batch_loss: 0.0919, batch_loss_c: 0.0935, batch_loss_s: 0.0882, time:4.7065, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2480/3125], step: 18105, 7.704 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0770, batch_loss_s: 0.0760, time:5.1920, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2490/3125], step: 18115, 9.059 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1035, batch_loss_s: 0.1043, time:4.4153, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2500/3125], step: 18125, 8.925 samples/sec, batch_loss: 0.3148, batch_loss_c: 0.3061, batch_loss_s: 0.3351, time:4.4820, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2510/3125], step: 18135, 8.876 samples/sec, batch_loss: 0.1245, batch_loss_c: 0.1378, batch_loss_s: 0.0936, time:4.5067, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2520/3125], step: 18145, 8.502 samples/sec, batch_loss: 0.0652, batch_loss_c: 0.0606, batch_loss_s: 0.0760, time:4.7049, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2530/3125], step: 18155, 8.675 samples/sec, batch_loss: 0.0946, batch_loss_c: 0.0911, batch_loss_s: 0.1028, time:4.6111, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2540/3125], step: 18165, 8.674 samples/sec, batch_loss: 0.2795, batch_loss_c: 0.2671, batch_loss_s: 0.3085, time:4.6116, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:35:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2550/3125], step: 18175, 7.533 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0650, batch_loss_s: 0.0908, time:5.3101, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2560/3125], step: 18185, 8.188 samples/sec, batch_loss: 0.0988, batch_loss_c: 0.1072, batch_loss_s: 0.0791, time:4.8853, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2570/3125], step: 18195, 8.154 samples/sec, batch_loss: 0.0986, batch_loss_c: 0.1028, batch_loss_s: 0.0889, time:4.9055, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2580/3125], step: 18205, 8.661 samples/sec, batch_loss: 0.0547, batch_loss_c: 0.0506, batch_loss_s: 0.0643, time:4.6184, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2590/3125], step: 18215, 8.385 samples/sec, batch_loss: 0.0654, batch_loss_c: 0.0619, batch_loss_s: 0.0734, time:4.7703, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2600/3125], step: 18225, 8.177 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1231, batch_loss_s: 0.1422, time:4.8920, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2610/3125], step: 18235, 8.371 samples/sec, batch_loss: 0.3382, batch_loss_c: 0.3458, batch_loss_s: 0.3205, time:4.7783, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2620/3125], step: 18245, 8.779 samples/sec, batch_loss: 0.1662, batch_loss_c: 0.1582, batch_loss_s: 0.1847, time:4.5562, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2630/3125], step: 18255, 8.202 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0705, batch_loss_s: 0.0752, time:4.8770, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2640/3125], step: 18265, 8.204 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0854, batch_loss_s: 0.0951, time:4.8756, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2650/3125], step: 18275, 7.820 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0820, batch_loss_s: 0.0700, time:5.1150, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2660/3125], step: 18285, 7.928 samples/sec, batch_loss: 0.0531, batch_loss_c: 0.0514, batch_loss_s: 0.0572, time:5.0451, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:36:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2670/3125], step: 18295, 8.639 samples/sec, batch_loss: 0.0578, batch_loss_c: 0.0512, batch_loss_s: 0.0733, time:4.6300, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2680/3125], step: 18305, 8.109 samples/sec, batch_loss: 0.3121, batch_loss_c: 0.3050, batch_loss_s: 0.3286, time:4.9325, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2690/3125], step: 18315, 7.838 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0865, batch_loss_s: 0.0961, time:5.1034, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2700/3125], step: 18325, 7.974 samples/sec, batch_loss: 0.2664, batch_loss_c: 0.2358, batch_loss_s: 0.3378, time:5.0164, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2710/3125], step: 18335, 8.642 samples/sec, batch_loss: 0.1378, batch_loss_c: 0.1344, batch_loss_s: 0.1457, time:4.6285, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2720/3125], step: 18345, 7.820 samples/sec, batch_loss: 0.3078, batch_loss_c: 0.2923, batch_loss_s: 0.3440, time:5.1151, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2730/3125], step: 18355, 8.220 samples/sec, batch_loss: 0.3604, batch_loss_c: 0.3733, batch_loss_s: 0.3305, time:4.8662, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2740/3125], step: 18365, 6.830 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0882, batch_loss_s: 0.1054, time:5.8563, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:36 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2750/3125], step: 18375, 7.770 samples/sec, batch_loss: 0.1071, batch_loss_c: 0.1151, batch_loss_s: 0.0884, time:5.1479, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2760/3125], step: 18385, 8.371 samples/sec, batch_loss: 0.3007, batch_loss_c: 0.2949, batch_loss_s: 0.3144, time:4.7782, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:46 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2770/3125], step: 18395, 8.287 samples/sec, batch_loss: 0.3426, batch_loss_c: 0.3395, batch_loss_s: 0.3498, time:4.8267, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2780/3125], step: 18405, 8.485 samples/sec, batch_loss: 0.1028, batch_loss_c: 0.1116, batch_loss_s: 0.0821, time:4.7142, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:37:56 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2790/3125], step: 18415, 7.726 samples/sec, batch_loss: 0.3974, batch_loss_c: 0.4390, batch_loss_s: 0.3001, time:5.1773, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2800/3125], step: 18425, 8.953 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.0991, batch_loss_s: 0.0989, time:4.4677, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2810/3125], step: 18435, 7.979 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1025, batch_loss_s: 0.1075, time:5.0133, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2820/3125], step: 18445, 8.311 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0614, batch_loss_s: 0.0725, time:4.8128, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2830/3125], step: 18455, 8.277 samples/sec, batch_loss: 0.2341, batch_loss_c: 0.2660, batch_loss_s: 0.1598, time:4.8325, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2840/3125], step: 18465, 8.842 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.0982, batch_loss_s: 0.1083, time:4.5240, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2850/3125], step: 18475, 8.686 samples/sec, batch_loss: 0.1740, batch_loss_c: 0.1704, batch_loss_s: 0.1825, time:4.6049, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2860/3125], step: 18485, 8.736 samples/sec, batch_loss: 0.3241, batch_loss_c: 0.3264, batch_loss_s: 0.3188, time:4.5787, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2870/3125], step: 18495, 8.582 samples/sec, batch_loss: 0.0735, batch_loss_c: 0.0699, batch_loss_s: 0.0819, time:4.6607, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2880/3125], step: 18505, 8.473 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0805, batch_loss_s: 0.0825, time:4.7208, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2890/3125], step: 18515, 8.159 samples/sec, batch_loss: 0.3169, batch_loss_c: 0.3150, batch_loss_s: 0.3214, time:4.9023, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2900/3125], step: 18525, 8.520 samples/sec, batch_loss: 0.0647, batch_loss_c: 0.0621, batch_loss_s: 0.0709, time:4.6948, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2910/3125], step: 18535, 7.543 samples/sec, batch_loss: 0.1194, batch_loss_c: 0.1239, batch_loss_s: 0.1089, time:5.3030, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:38:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2920/3125], step: 18545, 8.013 samples/sec, batch_loss: 0.2804, batch_loss_c: 0.2699, batch_loss_s: 0.3051, time:4.9918, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2930/3125], step: 18555, 8.468 samples/sec, batch_loss: 0.1979, batch_loss_c: 0.2029, batch_loss_s: 0.1862, time:4.7235, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2940/3125], step: 18565, 8.821 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0864, batch_loss_s: 0.0808, time:4.5347, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2950/3125], step: 18575, 8.622 samples/sec, batch_loss: 0.3035, batch_loss_c: 0.2982, batch_loss_s: 0.3159, time:4.6392, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:16 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2960/3125], step: 18585, 8.965 samples/sec, batch_loss: 0.5442, batch_loss_c: 0.5403, batch_loss_s: 0.5532, time:4.4616, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2970/3125], step: 18595, 8.366 samples/sec, batch_loss: 0.2878, batch_loss_c: 0.2859, batch_loss_s: 0.2922, time:4.7813, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2980/3125], step: 18605, 8.769 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0673, batch_loss_s: 0.0774, time:4.5617, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [2990/3125], step: 18615, 8.619 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1133, batch_loss_s: 0.1363, time:4.6412, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3000/3125], step: 18625, 8.426 samples/sec, batch_loss: 0.3686, batch_loss_c: 0.3844, batch_loss_s: 0.3318, time:4.7470, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3010/3125], step: 18635, 7.674 samples/sec, batch_loss: 0.1090, batch_loss_c: 0.1186, batch_loss_s: 0.0867, time:5.2123, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3020/3125], step: 18645, 8.534 samples/sec, batch_loss: 0.3326, batch_loss_c: 0.3352, batch_loss_s: 0.3265, time:4.6874, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:49 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3030/3125], step: 18655, 8.665 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1871, batch_loss_s: 0.0880, time:4.6161, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3040/3125], step: 18665, 8.711 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0826, batch_loss_s: 0.0867, time:4.5921, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:39:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3050/3125], step: 18675, 8.377 samples/sec, batch_loss: 0.0623, batch_loss_c: 0.0589, batch_loss_s: 0.0703, time:4.7749, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3060/3125], step: 18685, 8.570 samples/sec, batch_loss: 0.3354, batch_loss_c: 0.3314, batch_loss_s: 0.3447, time:4.6674, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:09 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3070/3125], step: 18695, 7.770 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0982, batch_loss_s: 0.0895, time:5.1481, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3080/3125], step: 18705, 7.960 samples/sec, batch_loss: 0.3325, batch_loss_c: 0.3385, batch_loss_s: 0.3183, time:5.0248, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3090/3125], step: 18715, 8.364 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1185, batch_loss_s: 0.1012, time:4.7824, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3100/3125], step: 18725, 7.885 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1119, batch_loss_s: 0.0795, time:5.0731, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3110/3125], step: 18735, 10.531 samples/sec, batch_loss: 0.3473, batch_loss_c: 0.3581, batch_loss_s: 0.3220, time:3.7985, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [3120/3125], step: 18745, 10.256 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0695, batch_loss_s: 0.0903, time:3.9000, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], train_loss: 0.1697, time: 1519.1301, lr: 0.0001\u001b[0m\n",
            "2019-11-24 11:40:38 \u001b[32mINFO     \u001b[0m train.py: [6/10], [0/3125], step: 18750, 8.986 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1787, batch_loss_s: 0.1086, time:4.4513, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [10/3125], step: 18760, 6.391 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0776, batch_loss_s: 0.0841, time:6.2583, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [20/3125], step: 18770, 7.386 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0671, batch_loss_s: 0.0841, time:5.4158, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [30/3125], step: 18780, 8.675 samples/sec, batch_loss: 0.2429, batch_loss_c: 0.2689, batch_loss_s: 0.1820, time:4.6110, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:40:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [40/3125], step: 18790, 8.859 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1136, batch_loss_s: 0.1086, time:4.5150, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [50/3125], step: 18800, 9.066 samples/sec, batch_loss: 0.0546, batch_loss_c: 0.0520, batch_loss_s: 0.0608, time:4.4123, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [60/3125], step: 18810, 8.840 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0622, batch_loss_s: 0.0758, time:4.5250, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [70/3125], step: 18820, 8.369 samples/sec, batch_loss: 0.0684, batch_loss_c: 0.0629, batch_loss_s: 0.0811, time:4.7793, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [80/3125], step: 18830, 8.544 samples/sec, batch_loss: 0.1337, batch_loss_c: 0.1298, batch_loss_s: 0.1426, time:4.6818, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [90/3125], step: 18840, 7.546 samples/sec, batch_loss: 0.3561, batch_loss_c: 0.3669, batch_loss_s: 0.3309, time:5.3006, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [100/3125], step: 18850, 7.704 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0862, batch_loss_s: 0.0784, time:5.1924, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [110/3125], step: 18860, 8.017 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.0996, batch_loss_s: 0.1049, time:4.9893, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [120/3125], step: 18870, 8.196 samples/sec, batch_loss: 0.3295, batch_loss_c: 0.3278, batch_loss_s: 0.3334, time:4.8807, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [130/3125], step: 18880, 8.327 samples/sec, batch_loss: 0.0518, batch_loss_c: 0.0453, batch_loss_s: 0.0670, time:4.8035, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [140/3125], step: 18890, 8.570 samples/sec, batch_loss: 0.3074, batch_loss_c: 0.3064, batch_loss_s: 0.3096, time:4.6672, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [150/3125], step: 18900, 8.634 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1230, batch_loss_s: 0.0886, time:4.6327, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:41:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [160/3125], step: 18910, 7.649 samples/sec, batch_loss: 0.1741, batch_loss_c: 0.1299, batch_loss_s: 0.2771, time:5.2296, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [170/3125], step: 18920, 7.617 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0794, batch_loss_s: 0.0503, time:5.2514, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [180/3125], step: 18930, 7.940 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0669, batch_loss_s: 0.0839, time:5.0379, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [190/3125], step: 18940, 6.964 samples/sec, batch_loss: 0.1951, batch_loss_c: 0.2218, batch_loss_s: 0.1329, time:5.7437, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [200/3125], step: 18950, 7.977 samples/sec, batch_loss: 0.1198, batch_loss_c: 0.1134, batch_loss_s: 0.1348, time:5.0142, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [210/3125], step: 18960, 7.634 samples/sec, batch_loss: 0.3057, batch_loss_c: 0.2995, batch_loss_s: 0.3203, time:5.2396, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [220/3125], step: 18970, 8.429 samples/sec, batch_loss: 0.0893, batch_loss_c: 0.0775, batch_loss_s: 0.1168, time:4.7458, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [230/3125], step: 18980, 8.396 samples/sec, batch_loss: 0.1675, batch_loss_c: 0.2112, batch_loss_s: 0.0653, time:4.7643, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [240/3125], step: 18990, 7.806 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0854, batch_loss_s: 0.1085, time:5.1240, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [250/3125], step: 19000, 8.160 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0667, batch_loss_s: 0.0787, time:4.9020, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [260/3125], step: 19010, 8.368 samples/sec, batch_loss: 0.1467, batch_loss_c: 0.1644, batch_loss_s: 0.1054, time:4.7802, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [270/3125], step: 19020, 8.396 samples/sec, batch_loss: 0.0657, batch_loss_c: 0.0615, batch_loss_s: 0.0756, time:4.7642, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:42:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [280/3125], step: 19030, 8.770 samples/sec, batch_loss: 0.3168, batch_loss_c: 0.3121, batch_loss_s: 0.3278, time:4.5610, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [290/3125], step: 19040, 8.824 samples/sec, batch_loss: 0.2162, batch_loss_c: 0.1807, batch_loss_s: 0.2989, time:4.5332, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [300/3125], step: 19050, 7.836 samples/sec, batch_loss: 0.0913, batch_loss_c: 0.0849, batch_loss_s: 0.1062, time:5.1044, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [310/3125], step: 19060, 8.082 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0839, batch_loss_s: 0.0924, time:4.9495, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [320/3125], step: 19070, 8.124 samples/sec, batch_loss: 0.1274, batch_loss_c: 0.1412, batch_loss_s: 0.0952, time:4.9236, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [330/3125], step: 19080, 8.374 samples/sec, batch_loss: 0.3014, batch_loss_c: 0.3002, batch_loss_s: 0.3041, time:4.7766, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [340/3125], step: 19090, 7.972 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1126, batch_loss_s: 0.0938, time:5.0174, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [350/3125], step: 19100, 8.217 samples/sec, batch_loss: 0.2669, batch_loss_c: 0.2986, batch_loss_s: 0.1928, time:4.8682, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [360/3125], step: 19110, 7.615 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1593, batch_loss_s: 0.0979, time:5.2531, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [370/3125], step: 19120, 7.574 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0771, batch_loss_s: 0.0811, time:5.2815, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [380/3125], step: 19130, 8.861 samples/sec, batch_loss: 0.0687, batch_loss_c: 0.0684, batch_loss_s: 0.0695, time:4.5141, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [390/3125], step: 19140, 8.139 samples/sec, batch_loss: 0.0592, batch_loss_c: 0.0518, batch_loss_s: 0.0762, time:4.9149, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:43:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [400/3125], step: 19150, 7.810 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1658, batch_loss_s: 0.0923, time:5.1213, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [410/3125], step: 19160, 9.441 samples/sec, batch_loss: 0.2001, batch_loss_c: 0.1932, batch_loss_s: 0.2161, time:4.2367, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [420/3125], step: 19170, 7.574 samples/sec, batch_loss: 0.2915, batch_loss_c: 0.2684, batch_loss_s: 0.3453, time:5.2810, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [430/3125], step: 19180, 8.499 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1109, batch_loss_s: 0.1058, time:4.7064, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [440/3125], step: 19190, 8.172 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0886, batch_loss_s: 0.0888, time:4.8949, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [450/3125], step: 19200, 8.566 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3665, batch_loss_s: 0.3089, time:4.6696, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [460/3125], step: 19210, 8.224 samples/sec, batch_loss: 0.0603, batch_loss_c: 0.0560, batch_loss_s: 0.0704, time:4.8638, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [470/3125], step: 19220, 8.499 samples/sec, batch_loss: 0.0587, batch_loss_c: 0.0572, batch_loss_s: 0.0622, time:4.7066, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [480/3125], step: 19230, 8.514 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1297, batch_loss_s: 0.0994, time:4.6979, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:38 \u001b[32mINFO     \u001b[0m train.py: [6/10], [490/3125], step: 19240, 8.805 samples/sec, batch_loss: 0.4249, batch_loss_c: 0.4310, batch_loss_s: 0.4106, time:4.5431, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:43 \u001b[32mINFO     \u001b[0m train.py: [6/10], [500/3125], step: 19250, 8.325 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0815, batch_loss_s: 0.0979, time:4.8050, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:48 \u001b[32mINFO     \u001b[0m train.py: [6/10], [510/3125], step: 19260, 7.524 samples/sec, batch_loss: 0.0736, batch_loss_c: 0.0716, batch_loss_s: 0.0782, time:5.3164, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [520/3125], step: 19270, 8.550 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1137, batch_loss_s: 0.1084, time:4.6785, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:44:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [530/3125], step: 19280, 8.230 samples/sec, batch_loss: 0.0640, batch_loss_c: 0.0591, batch_loss_s: 0.0755, time:4.8604, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [540/3125], step: 19290, 8.028 samples/sec, batch_loss: 0.0725, batch_loss_c: 0.0675, batch_loss_s: 0.0840, time:4.9826, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [550/3125], step: 19300, 8.891 samples/sec, batch_loss: 0.0606, batch_loss_c: 0.0572, batch_loss_s: 0.0685, time:4.4990, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [560/3125], step: 19310, 8.488 samples/sec, batch_loss: 0.3803, batch_loss_c: 0.3720, batch_loss_s: 0.3995, time:4.7123, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [570/3125], step: 19320, 8.722 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0620, batch_loss_s: 0.0747, time:4.5862, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [580/3125], step: 19330, 8.017 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1300, batch_loss_s: 0.0953, time:4.9895, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [590/3125], step: 19340, 8.587 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.0993, batch_loss_s: 0.0920, time:4.6583, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [600/3125], step: 19350, 8.443 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.0990, batch_loss_s: 0.0881, time:4.7379, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [610/3125], step: 19360, 9.088 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0691, batch_loss_s: 0.0775, time:4.4016, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [620/3125], step: 19370, 8.201 samples/sec, batch_loss: 0.0702, batch_loss_c: 0.0617, batch_loss_s: 0.0903, time:4.8773, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [630/3125], step: 19380, 8.537 samples/sec, batch_loss: 0.1476, batch_loss_c: 0.1726, batch_loss_s: 0.0892, time:4.6855, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [640/3125], step: 19390, 8.404 samples/sec, batch_loss: 0.4362, batch_loss_c: 0.4202, batch_loss_s: 0.4735, time:4.7597, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:45:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [650/3125], step: 19400, 8.043 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0970, batch_loss_s: 0.0905, time:4.9731, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [660/3125], step: 19410, 7.461 samples/sec, batch_loss: 0.2713, batch_loss_c: 0.2539, batch_loss_s: 0.3120, time:5.3609, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [670/3125], step: 19420, 7.278 samples/sec, batch_loss: 0.1087, batch_loss_c: 0.1179, batch_loss_s: 0.0872, time:5.4961, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [680/3125], step: 19430, 8.253 samples/sec, batch_loss: 0.1111, batch_loss_c: 0.1073, batch_loss_s: 0.1201, time:4.8465, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [690/3125], step: 19440, 8.139 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0794, batch_loss_s: 0.0833, time:4.9147, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [700/3125], step: 19450, 8.804 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0628, batch_loss_s: 0.0777, time:4.5434, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [710/3125], step: 19460, 7.602 samples/sec, batch_loss: 0.0578, batch_loss_c: 0.0545, batch_loss_s: 0.0655, time:5.2616, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [720/3125], step: 19470, 9.051 samples/sec, batch_loss: 0.3275, batch_loss_c: 0.3262, batch_loss_s: 0.3305, time:4.4193, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [730/3125], step: 19480, 7.801 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0868, batch_loss_s: 0.0936, time:5.1277, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [740/3125], step: 19490, 7.794 samples/sec, batch_loss: 0.1128, batch_loss_c: 0.1204, batch_loss_s: 0.0951, time:5.1322, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [750/3125], step: 19500, 8.341 samples/sec, batch_loss: 0.2685, batch_loss_c: 0.2498, batch_loss_s: 0.3121, time:4.7957, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [760/3125], step: 19510, 7.528 samples/sec, batch_loss: 0.0978, batch_loss_c: 0.0978, batch_loss_s: 0.0978, time:5.3134, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:46:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [770/3125], step: 19520, 8.071 samples/sec, batch_loss: 0.1421, batch_loss_c: 0.1502, batch_loss_s: 0.1231, time:4.9560, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [780/3125], step: 19530, 7.488 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1174, batch_loss_s: 0.0993, time:5.3418, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [790/3125], step: 19540, 8.099 samples/sec, batch_loss: 0.0749, batch_loss_c: 0.0667, batch_loss_s: 0.0940, time:4.9386, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [800/3125], step: 19550, 7.068 samples/sec, batch_loss: 0.0927, batch_loss_c: 0.1019, batch_loss_s: 0.0710, time:5.6593, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [810/3125], step: 19560, 7.944 samples/sec, batch_loss: 0.3038, batch_loss_c: 0.2824, batch_loss_s: 0.3538, time:5.0355, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [820/3125], step: 19570, 6.928 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0837, batch_loss_s: 0.0709, time:5.7735, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [830/3125], step: 19580, 7.850 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1345, batch_loss_s: 0.0829, time:5.0957, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [840/3125], step: 19590, 9.027 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1103, batch_loss_s: 0.1229, time:4.4311, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [850/3125], step: 19600, 7.256 samples/sec, batch_loss: 0.2079, batch_loss_c: 0.1759, batch_loss_s: 0.2824, time:5.5127, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [860/3125], step: 19610, 8.969 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3067, batch_loss_s: 0.3325, time:4.4596, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [870/3125], step: 19620, 8.470 samples/sec, batch_loss: 0.2901, batch_loss_c: 0.2838, batch_loss_s: 0.3048, time:4.7226, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [880/3125], step: 19630, 7.678 samples/sec, batch_loss: 0.2119, batch_loss_c: 0.2162, batch_loss_s: 0.2019, time:5.2094, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:47:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [890/3125], step: 19640, 8.535 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0857, batch_loss_s: 0.0751, time:4.6864, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [900/3125], step: 19650, 7.049 samples/sec, batch_loss: 0.2870, batch_loss_c: 0.2737, batch_loss_s: 0.3179, time:5.6749, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [910/3125], step: 19660, 7.323 samples/sec, batch_loss: 0.0738, batch_loss_c: 0.0751, batch_loss_s: 0.0707, time:5.4619, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [920/3125], step: 19670, 8.071 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0894, batch_loss_s: 0.1014, time:4.9557, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [930/3125], step: 19680, 7.715 samples/sec, batch_loss: 0.2619, batch_loss_c: 0.3012, batch_loss_s: 0.1703, time:5.1846, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [940/3125], step: 19690, 8.573 samples/sec, batch_loss: 0.3433, batch_loss_c: 0.3427, batch_loss_s: 0.3447, time:4.6657, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [950/3125], step: 19700, 7.813 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0657, batch_loss_s: 0.0637, time:5.1195, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [960/3125], step: 19710, 8.829 samples/sec, batch_loss: 0.0987, batch_loss_c: 0.0934, batch_loss_s: 0.1109, time:4.5304, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [970/3125], step: 19720, 8.798 samples/sec, batch_loss: 0.4055, batch_loss_c: 0.4489, batch_loss_s: 0.3042, time:4.5463, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [980/3125], step: 19730, 8.551 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.0952, batch_loss_s: 0.0993, time:4.6779, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [990/3125], step: 19740, 7.889 samples/sec, batch_loss: 0.1223, batch_loss_c: 0.1425, batch_loss_s: 0.0752, time:5.0707, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1000/3125], step: 19750, 8.775 samples/sec, batch_loss: 0.3827, batch_loss_c: 0.3981, batch_loss_s: 0.3466, time:4.5584, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:48:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1010/3125], step: 19760, 8.481 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1038, batch_loss_s: 0.0944, time:4.7162, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1020/3125], step: 19770, 8.283 samples/sec, batch_loss: 0.3115, batch_loss_c: 0.3094, batch_loss_s: 0.3163, time:4.8290, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1030/3125], step: 19780, 8.490 samples/sec, batch_loss: 0.2821, batch_loss_c: 0.2709, batch_loss_s: 0.3082, time:4.7115, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1040/3125], step: 19790, 7.640 samples/sec, batch_loss: 0.0729, batch_loss_c: 0.0707, batch_loss_s: 0.0780, time:5.2359, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1050/3125], step: 19800, 7.726 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0751, batch_loss_s: 0.0691, time:5.1775, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1060/3125], step: 19810, 8.197 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.0966, batch_loss_s: 0.1152, time:4.8796, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1070/3125], step: 19820, 7.851 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.3057, batch_loss_s: 0.2981, time:5.0951, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1080/3125], step: 19830, 8.295 samples/sec, batch_loss: 0.1837, batch_loss_c: 0.1774, batch_loss_s: 0.1983, time:4.8224, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1090/3125], step: 19840, 7.645 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0898, batch_loss_s: 0.0938, time:5.2324, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1100/3125], step: 19850, 7.920 samples/sec, batch_loss: 0.1093, batch_loss_c: 0.0902, batch_loss_s: 0.1539, time:5.0503, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1110/3125], step: 19860, 6.931 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0877, batch_loss_s: 0.0937, time:5.7716, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1120/3125], step: 19870, 8.256 samples/sec, batch_loss: 0.2867, batch_loss_c: 0.2939, batch_loss_s: 0.2699, time:4.8449, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:49:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1130/3125], step: 19880, 8.394 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0714, batch_loss_s: 0.0748, time:4.7652, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1140/3125], step: 19890, 6.713 samples/sec, batch_loss: 0.1635, batch_loss_c: 0.1769, batch_loss_s: 0.1322, time:5.9583, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1150/3125], step: 19900, 8.088 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0988, batch_loss_s: 0.0881, time:4.9453, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1160/3125], step: 19910, 8.712 samples/sec, batch_loss: 0.2957, batch_loss_c: 0.2950, batch_loss_s: 0.2973, time:4.5912, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1170/3125], step: 19920, 8.389 samples/sec, batch_loss: 0.2674, batch_loss_c: 0.2509, batch_loss_s: 0.3061, time:4.7682, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1180/3125], step: 19930, 7.871 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.0901, batch_loss_s: 0.1018, time:5.0819, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1190/3125], step: 19940, 8.590 samples/sec, batch_loss: 0.3093, batch_loss_c: 0.2903, batch_loss_s: 0.3538, time:4.6566, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1200/3125], step: 19950, 8.787 samples/sec, batch_loss: 0.2001, batch_loss_c: 0.2269, batch_loss_s: 0.1374, time:4.5522, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1210/3125], step: 19960, 8.461 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0913, batch_loss_s: 0.1090, time:4.7276, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1220/3125], step: 19970, 8.441 samples/sec, batch_loss: 0.0514, batch_loss_c: 0.0485, batch_loss_s: 0.0582, time:4.7387, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1230/3125], step: 19980, 8.340 samples/sec, batch_loss: 0.2794, batch_loss_c: 0.2672, batch_loss_s: 0.3080, time:4.7964, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1240/3125], step: 19990, 8.423 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.0959, batch_loss_s: 0.1026, time:4.7491, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1250/3125], step: 20000, 8.821 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0931, batch_loss_s: 0.1012, time:4.5346, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:50:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1260/3125], step: 20010, 9.325 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1457, batch_loss_s: 0.1173, time:4.2895, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1270/3125], step: 20020, 8.648 samples/sec, batch_loss: 0.0977, batch_loss_c: 0.0898, batch_loss_s: 0.1162, time:4.6251, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1280/3125], step: 20030, 9.351 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0815, batch_loss_s: 0.0876, time:4.2774, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1290/3125], step: 20040, 7.676 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1520, batch_loss_s: 0.0810, time:5.2108, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1300/3125], step: 20050, 8.642 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0719, batch_loss_s: 0.0788, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1310/3125], step: 20060, 8.773 samples/sec, batch_loss: 0.3325, batch_loss_c: 0.3271, batch_loss_s: 0.3452, time:4.5595, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1320/3125], step: 20070, 8.567 samples/sec, batch_loss: 0.3099, batch_loss_c: 0.3085, batch_loss_s: 0.3131, time:4.6691, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1330/3125], step: 20080, 8.416 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1061, batch_loss_s: 0.1014, time:4.7526, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1340/3125], step: 20090, 8.183 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0893, batch_loss_s: 0.1050, time:4.8881, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1350/3125], step: 20100, 8.800 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0989, batch_loss_s: 0.0877, time:4.5453, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1360/3125], step: 20110, 8.813 samples/sec, batch_loss: 0.4202, batch_loss_c: 0.4354, batch_loss_s: 0.3848, time:4.5389, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1370/3125], step: 20120, 8.268 samples/sec, batch_loss: 0.5100, batch_loss_c: 0.4966, batch_loss_s: 0.5411, time:4.8378, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1380/3125], step: 20130, 8.752 samples/sec, batch_loss: 0.1350, batch_loss_c: 0.1586, batch_loss_s: 0.0801, time:4.5702, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:51:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1390/3125], step: 20140, 7.733 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1384, batch_loss_s: 0.0976, time:5.1727, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:04 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1400/3125], step: 20150, 7.937 samples/sec, batch_loss: 0.0483, batch_loss_c: 0.0452, batch_loss_s: 0.0556, time:5.0394, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:09 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1410/3125], step: 20160, 7.687 samples/sec, batch_loss: 0.1699, batch_loss_c: 0.2087, batch_loss_s: 0.0791, time:5.2036, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1420/3125], step: 20170, 8.246 samples/sec, batch_loss: 0.1247, batch_loss_c: 0.1281, batch_loss_s: 0.1167, time:4.8510, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1430/3125], step: 20180, 8.160 samples/sec, batch_loss: 0.3529, batch_loss_c: 0.3695, batch_loss_s: 0.3140, time:4.9020, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1440/3125], step: 20190, 9.503 samples/sec, batch_loss: 0.1318, batch_loss_c: 0.1235, batch_loss_s: 0.1512, time:4.2090, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1450/3125], step: 20200, 8.042 samples/sec, batch_loss: 0.0633, batch_loss_c: 0.0643, batch_loss_s: 0.0610, time:4.9741, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:33 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1460/3125], step: 20210, 8.223 samples/sec, batch_loss: 0.0722, batch_loss_c: 0.0713, batch_loss_s: 0.0743, time:4.8641, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:38 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1470/3125], step: 20220, 8.604 samples/sec, batch_loss: 0.0781, batch_loss_c: 0.0826, batch_loss_s: 0.0677, time:4.6489, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1480/3125], step: 20230, 8.873 samples/sec, batch_loss: 0.3428, batch_loss_c: 0.3410, batch_loss_s: 0.3470, time:4.5081, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1490/3125], step: 20240, 8.383 samples/sec, batch_loss: 0.0537, batch_loss_c: 0.0526, batch_loss_s: 0.0564, time:4.7715, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1500/3125], step: 20250, 8.835 samples/sec, batch_loss: 0.1453, batch_loss_c: 0.1654, batch_loss_s: 0.0983, time:4.5273, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:52:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1510/3125], step: 20260, 8.779 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.0994, batch_loss_s: 0.1099, time:4.5563, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1520/3125], step: 20270, 8.336 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0753, batch_loss_s: 0.0642, time:4.7982, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1530/3125], step: 20280, 8.181 samples/sec, batch_loss: 0.1089, batch_loss_c: 0.1054, batch_loss_s: 0.1170, time:4.8895, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1540/3125], step: 20290, 9.252 samples/sec, batch_loss: 0.3011, batch_loss_c: 0.2984, batch_loss_s: 0.3072, time:4.3235, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1550/3125], step: 20300, 7.936 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1296, batch_loss_s: 0.0592, time:5.0406, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1560/3125], step: 20310, 8.922 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0599, batch_loss_s: 0.0697, time:4.4832, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1570/3125], step: 20320, 8.622 samples/sec, batch_loss: 0.1320, batch_loss_c: 0.1336, batch_loss_s: 0.1282, time:4.6393, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1580/3125], step: 20330, 8.370 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1125, batch_loss_s: 0.1313, time:4.7792, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1590/3125], step: 20340, 9.038 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0978, batch_loss_s: 0.1055, time:4.4257, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:38 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1600/3125], step: 20350, 8.661 samples/sec, batch_loss: 0.1320, batch_loss_c: 0.1470, batch_loss_s: 0.0970, time:4.6183, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:43 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1610/3125], step: 20360, 8.846 samples/sec, batch_loss: 0.3407, batch_loss_c: 0.3410, batch_loss_s: 0.3400, time:4.5218, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1620/3125], step: 20370, 8.570 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0648, batch_loss_s: 0.0701, time:4.6672, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1630/3125], step: 20380, 9.032 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1204, batch_loss_s: 0.0926, time:4.4286, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:53:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1640/3125], step: 20390, 8.112 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0640, batch_loss_s: 0.0866, time:4.9312, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1650/3125], step: 20400, 8.075 samples/sec, batch_loss: 0.2180, batch_loss_c: 0.2342, batch_loss_s: 0.1801, time:4.9539, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1660/3125], step: 20410, 8.562 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0782, batch_loss_s: 0.0661, time:4.6721, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1670/3125], step: 20420, 8.795 samples/sec, batch_loss: 0.2976, batch_loss_c: 0.2971, batch_loss_s: 0.2989, time:4.5479, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1680/3125], step: 20430, 8.455 samples/sec, batch_loss: 0.0725, batch_loss_c: 0.0660, batch_loss_s: 0.0879, time:4.7307, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1690/3125], step: 20440, 8.110 samples/sec, batch_loss: 0.0599, batch_loss_c: 0.0567, batch_loss_s: 0.0673, time:4.9323, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1700/3125], step: 20450, 7.588 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0807, batch_loss_s: 0.0787, time:5.2716, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1710/3125], step: 20460, 8.074 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1345, batch_loss_s: 0.1190, time:4.9539, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1720/3125], step: 20470, 7.477 samples/sec, batch_loss: 0.2770, batch_loss_c: 0.2737, batch_loss_s: 0.2848, time:5.3499, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1730/3125], step: 20480, 8.290 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.2934, batch_loss_s: 0.3267, time:4.8253, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1740/3125], step: 20490, 8.243 samples/sec, batch_loss: 0.0780, batch_loss_c: 0.0767, batch_loss_s: 0.0812, time:4.8528, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1750/3125], step: 20500, 8.334 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0799, batch_loss_s: 0.0921, time:4.7994, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:54:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1760/3125], step: 20510, 8.816 samples/sec, batch_loss: 0.0959, batch_loss_c: 0.1081, batch_loss_s: 0.0672, time:4.5371, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1770/3125], step: 20520, 8.260 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0818, batch_loss_s: 0.1003, time:4.8424, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1780/3125], step: 20530, 8.434 samples/sec, batch_loss: 0.2841, batch_loss_c: 0.2653, batch_loss_s: 0.3279, time:4.7427, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1790/3125], step: 20540, 8.083 samples/sec, batch_loss: 0.0880, batch_loss_c: 0.0838, batch_loss_s: 0.0976, time:4.9489, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:15 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1800/3125], step: 20550, 8.213 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0817, batch_loss_s: 0.0842, time:4.8705, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1810/3125], step: 20560, 7.789 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1048, batch_loss_s: 0.1142, time:5.1352, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1820/3125], step: 20570, 8.001 samples/sec, batch_loss: 0.3871, batch_loss_c: 0.4126, batch_loss_s: 0.3277, time:4.9994, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1830/3125], step: 20580, 8.636 samples/sec, batch_loss: 0.3124, batch_loss_c: 0.3128, batch_loss_s: 0.3116, time:4.6320, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1840/3125], step: 20590, 8.429 samples/sec, batch_loss: 0.1559, batch_loss_c: 0.1684, batch_loss_s: 0.1267, time:4.7452, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1850/3125], step: 20600, 8.073 samples/sec, batch_loss: 0.1127, batch_loss_c: 0.1285, batch_loss_s: 0.0757, time:4.9550, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1860/3125], step: 20610, 7.819 samples/sec, batch_loss: 0.2839, batch_loss_c: 0.2814, batch_loss_s: 0.2897, time:5.1159, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1870/3125], step: 20620, 9.091 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1476, batch_loss_s: 0.0762, time:4.3999, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1880/3125], step: 20630, 8.465 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0826, batch_loss_s: 0.0856, time:4.7252, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:55:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1890/3125], step: 20640, 7.636 samples/sec, batch_loss: 0.1174, batch_loss_c: 0.1353, batch_loss_s: 0.0756, time:5.2384, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1900/3125], step: 20650, 8.635 samples/sec, batch_loss: 0.3279, batch_loss_c: 0.3256, batch_loss_s: 0.3333, time:4.6325, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:08 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1910/3125], step: 20660, 8.279 samples/sec, batch_loss: 0.0581, batch_loss_c: 0.0537, batch_loss_s: 0.0683, time:4.8314, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:13 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1920/3125], step: 20670, 8.675 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0839, batch_loss_s: 0.0914, time:4.6110, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:18 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1930/3125], step: 20680, 7.891 samples/sec, batch_loss: 0.2918, batch_loss_c: 0.2870, batch_loss_s: 0.3030, time:5.0690, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1940/3125], step: 20690, 7.570 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1185, batch_loss_s: 0.2015, time:5.2843, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1950/3125], step: 20700, 8.374 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0638, batch_loss_s: 0.0680, time:4.7767, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:33 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1960/3125], step: 20710, 8.455 samples/sec, batch_loss: 0.0772, batch_loss_c: 0.0751, batch_loss_s: 0.0819, time:4.7310, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1970/3125], step: 20720, 8.284 samples/sec, batch_loss: 0.1513, batch_loss_c: 0.1806, batch_loss_s: 0.0830, time:4.8286, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1980/3125], step: 20730, 8.093 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0698, batch_loss_s: 0.0800, time:4.9427, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [1990/3125], step: 20740, 8.297 samples/sec, batch_loss: 0.0601, batch_loss_c: 0.0571, batch_loss_s: 0.0671, time:4.8209, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2000/3125], step: 20750, 7.658 samples/sec, batch_loss: 0.0553, batch_loss_c: 0.0533, batch_loss_s: 0.0600, time:5.2236, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:56:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2010/3125], step: 20760, 8.315 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0654, batch_loss_s: 0.0712, time:4.8105, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2020/3125], step: 20770, 7.438 samples/sec, batch_loss: 0.3197, batch_loss_c: 0.3329, batch_loss_s: 0.2888, time:5.3780, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2030/3125], step: 20780, 8.563 samples/sec, batch_loss: 0.3104, batch_loss_c: 0.3095, batch_loss_s: 0.3125, time:4.6712, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2040/3125], step: 20790, 8.010 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0838, batch_loss_s: 0.1233, time:4.9940, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2050/3125], step: 20800, 7.852 samples/sec, batch_loss: 0.1544, batch_loss_c: 0.1758, batch_loss_s: 0.1045, time:5.0942, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2060/3125], step: 20810, 8.346 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.0966, batch_loss_s: 0.1119, time:4.7930, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2070/3125], step: 20820, 8.263 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1158, batch_loss_s: 0.0823, time:4.8406, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2080/3125], step: 20830, 8.423 samples/sec, batch_loss: 0.0852, batch_loss_c: 0.0810, batch_loss_s: 0.0950, time:4.7487, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2090/3125], step: 20840, 9.025 samples/sec, batch_loss: 0.1537, batch_loss_c: 0.1547, batch_loss_s: 0.1514, time:4.4320, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2100/3125], step: 20850, 8.052 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0872, batch_loss_s: 0.0938, time:4.9679, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2110/3125], step: 20860, 8.099 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1192, batch_loss_s: 0.1219, time:4.9391, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2120/3125], step: 20870, 9.015 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1510, batch_loss_s: 0.1115, time:4.4373, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:57:55 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2130/3125], step: 20880, 8.006 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3458, batch_loss_s: 0.3570, time:4.9965, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:00 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2140/3125], step: 20890, 8.412 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0712, batch_loss_s: 0.0732, time:4.7552, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2150/3125], step: 20900, 9.084 samples/sec, batch_loss: 0.1471, batch_loss_c: 0.1619, batch_loss_s: 0.1125, time:4.4033, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2160/3125], step: 20910, 7.978 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0883, batch_loss_s: 0.0808, time:5.0139, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2170/3125], step: 20920, 8.280 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1504, batch_loss_s: 0.0563, time:4.8311, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2180/3125], step: 20930, 7.949 samples/sec, batch_loss: 0.0906, batch_loss_c: 0.0890, batch_loss_s: 0.0944, time:5.0319, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:24 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2190/3125], step: 20940, 8.608 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0657, batch_loss_s: 0.1023, time:4.6467, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:29 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2200/3125], step: 20950, 8.359 samples/sec, batch_loss: 0.1445, batch_loss_c: 0.1628, batch_loss_s: 0.1018, time:4.7855, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:34 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2210/3125], step: 20960, 8.580 samples/sec, batch_loss: 0.1367, batch_loss_c: 0.1338, batch_loss_s: 0.1434, time:4.6619, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:38 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2220/3125], step: 20970, 8.574 samples/sec, batch_loss: 0.1298, batch_loss_c: 0.1339, batch_loss_s: 0.1201, time:4.6651, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:43 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2230/3125], step: 20980, 8.766 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2242, batch_loss_s: 0.1544, time:4.5633, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2240/3125], step: 20990, 9.206 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0898, batch_loss_s: 0.0575, time:4.3449, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2250/3125], step: 21000, 8.902 samples/sec, batch_loss: 0.1429, batch_loss_c: 0.1643, batch_loss_s: 0.0930, time:4.4933, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:58:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2260/3125], step: 21010, 8.000 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0732, batch_loss_s: 0.0822, time:5.0000, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2270/3125], step: 21020, 8.348 samples/sec, batch_loss: 0.0572, batch_loss_c: 0.0528, batch_loss_s: 0.0676, time:4.7916, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2280/3125], step: 21030, 8.169 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1257, batch_loss_s: 0.1021, time:4.8965, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2290/3125], step: 21040, 8.763 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0929, batch_loss_s: 0.0642, time:4.5649, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2300/3125], step: 21050, 8.119 samples/sec, batch_loss: 0.2211, batch_loss_c: 0.2385, batch_loss_s: 0.1805, time:4.9266, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:20 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2310/3125], step: 21060, 8.644 samples/sec, batch_loss: 0.5454, batch_loss_c: 0.5480, batch_loss_s: 0.5394, time:4.6273, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2320/3125], step: 21070, 8.094 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0906, batch_loss_s: 0.0946, time:4.9416, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:30 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2330/3125], step: 21080, 8.895 samples/sec, batch_loss: 0.2028, batch_loss_c: 0.1998, batch_loss_s: 0.2097, time:4.4969, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2340/3125], step: 21090, 8.629 samples/sec, batch_loss: 0.0498, batch_loss_c: 0.0471, batch_loss_s: 0.0562, time:4.6353, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:39 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2350/3125], step: 21100, 9.039 samples/sec, batch_loss: 0.1285, batch_loss_c: 0.1473, batch_loss_s: 0.0846, time:4.4254, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:44 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2360/3125], step: 21110, 8.486 samples/sec, batch_loss: 0.0682, batch_loss_c: 0.0608, batch_loss_s: 0.0856, time:4.7139, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2370/3125], step: 21120, 8.207 samples/sec, batch_loss: 0.1691, batch_loss_c: 0.2029, batch_loss_s: 0.0904, time:4.8737, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:53 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2380/3125], step: 21130, 8.274 samples/sec, batch_loss: 0.3220, batch_loss_c: 0.3266, batch_loss_s: 0.3114, time:4.8347, lr:0.0001\u001b[0m\n",
            "2019-11-24 11:59:58 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2390/3125], step: 21140, 9.067 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1168, batch_loss_s: 0.1021, time:4.4116, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2400/3125], step: 21150, 9.462 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0958, batch_loss_s: 0.0779, time:4.2273, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2410/3125], step: 21160, 8.283 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0731, batch_loss_s: 0.0780, time:4.8294, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2420/3125], step: 21170, 8.335 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1471, batch_loss_s: 0.0826, time:4.7989, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2430/3125], step: 21180, 9.118 samples/sec, batch_loss: 0.0982, batch_loss_c: 0.1149, batch_loss_s: 0.0592, time:4.3868, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2440/3125], step: 21190, 8.294 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0759, batch_loss_s: 0.0971, time:4.8229, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:25 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2450/3125], step: 21200, 8.714 samples/sec, batch_loss: 0.3406, batch_loss_c: 0.3455, batch_loss_s: 0.3293, time:4.5904, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2460/3125], step: 21210, 7.818 samples/sec, batch_loss: 0.1027, batch_loss_c: 0.1166, batch_loss_s: 0.0701, time:5.1163, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:35 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2470/3125], step: 21220, 8.272 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0865, batch_loss_s: 0.1115, time:4.8356, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2480/3125], step: 21230, 8.407 samples/sec, batch_loss: 0.0662, batch_loss_c: 0.0690, batch_loss_s: 0.0597, time:4.7582, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2490/3125], step: 21240, 8.394 samples/sec, batch_loss: 0.0852, batch_loss_c: 0.0905, batch_loss_s: 0.0729, time:4.7651, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2500/3125], step: 21250, 8.533 samples/sec, batch_loss: 0.1582, batch_loss_c: 0.1725, batch_loss_s: 0.1249, time:4.6878, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:54 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2510/3125], step: 21260, 9.190 samples/sec, batch_loss: 0.1104, batch_loss_c: 0.1120, batch_loss_s: 0.1066, time:4.3524, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:00:59 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2520/3125], step: 21270, 8.268 samples/sec, batch_loss: 0.1681, batch_loss_c: 0.1682, batch_loss_s: 0.1679, time:4.8382, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:03 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2530/3125], step: 21280, 9.226 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0694, batch_loss_s: 0.0780, time:4.3356, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:08 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2540/3125], step: 21290, 8.386 samples/sec, batch_loss: 0.3229, batch_loss_c: 0.3167, batch_loss_s: 0.3372, time:4.7697, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:13 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2550/3125], step: 21300, 8.208 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0805, batch_loss_s: 0.0769, time:4.8731, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2560/3125], step: 21310, 8.736 samples/sec, batch_loss: 0.3465, batch_loss_c: 0.3480, batch_loss_s: 0.3431, time:4.5789, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2570/3125], step: 21320, 8.096 samples/sec, batch_loss: 0.1847, batch_loss_c: 0.2164, batch_loss_s: 0.1107, time:4.9407, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2580/3125], step: 21330, 8.886 samples/sec, batch_loss: 0.0704, batch_loss_c: 0.0704, batch_loss_s: 0.0704, time:4.5014, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2590/3125], step: 21340, 8.102 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.1021, batch_loss_s: 0.0920, time:4.9370, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2600/3125], step: 21350, 8.038 samples/sec, batch_loss: 0.4271, batch_loss_c: 0.4748, batch_loss_s: 0.3160, time:4.9766, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2610/3125], step: 21360, 8.077 samples/sec, batch_loss: 0.0893, batch_loss_c: 0.0906, batch_loss_s: 0.0862, time:4.9526, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2620/3125], step: 21370, 8.078 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0845, batch_loss_s: 0.0719, time:4.9517, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2630/3125], step: 21380, 7.645 samples/sec, batch_loss: 0.0615, batch_loss_c: 0.0596, batch_loss_s: 0.0661, time:5.2319, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:01:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2640/3125], step: 21390, 8.058 samples/sec, batch_loss: 0.1609, batch_loss_c: 0.1693, batch_loss_s: 0.1412, time:4.9641, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2650/3125], step: 21400, 8.092 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1266, batch_loss_s: 0.1098, time:4.9431, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2660/3125], step: 21410, 7.793 samples/sec, batch_loss: 0.1244, batch_loss_c: 0.1376, batch_loss_s: 0.0936, time:5.1328, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2670/3125], step: 21420, 7.677 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1009, batch_loss_s: 0.1065, time:5.2100, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2680/3125], step: 21430, 8.673 samples/sec, batch_loss: 0.3643, batch_loss_c: 0.3850, batch_loss_s: 0.3162, time:4.6122, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:22 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2690/3125], step: 21440, 7.456 samples/sec, batch_loss: 0.3218, batch_loss_c: 0.3169, batch_loss_s: 0.3333, time:5.3649, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:27 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2700/3125], step: 21450, 7.726 samples/sec, batch_loss: 0.2351, batch_loss_c: 0.2302, batch_loss_s: 0.2465, time:5.1773, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2710/3125], step: 21460, 8.249 samples/sec, batch_loss: 0.1633, batch_loss_c: 0.1772, batch_loss_s: 0.1310, time:4.8490, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2720/3125], step: 21470, 8.115 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0810, batch_loss_s: 0.0780, time:4.9291, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2730/3125], step: 21480, 8.039 samples/sec, batch_loss: 0.2945, batch_loss_c: 0.2772, batch_loss_s: 0.3349, time:4.9756, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2740/3125], step: 21490, 7.410 samples/sec, batch_loss: 0.2784, batch_loss_c: 0.2622, batch_loss_s: 0.3161, time:5.3984, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2750/3125], step: 21500, 8.260 samples/sec, batch_loss: 0.6603, batch_loss_c: 0.6380, batch_loss_s: 0.7126, time:4.8428, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:02:57 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2760/3125], step: 21510, 7.845 samples/sec, batch_loss: 0.5301, batch_loss_c: 0.5178, batch_loss_s: 0.5588, time:5.0987, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:02 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2770/3125], step: 21520, 8.055 samples/sec, batch_loss: 0.1808, batch_loss_c: 0.1987, batch_loss_s: 0.1392, time:4.9659, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:07 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2780/3125], step: 21530, 8.054 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0809, batch_loss_s: 0.0786, time:4.9665, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:12 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2790/3125], step: 21540, 8.433 samples/sec, batch_loss: 0.2625, batch_loss_c: 0.2406, batch_loss_s: 0.3137, time:4.7431, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:17 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2800/3125], step: 21550, 8.849 samples/sec, batch_loss: 0.0577, batch_loss_c: 0.0572, batch_loss_s: 0.0589, time:4.5202, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2810/3125], step: 21560, 8.406 samples/sec, batch_loss: 0.1152, batch_loss_c: 0.1344, batch_loss_s: 0.0704, time:4.7586, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2820/3125], step: 21570, 8.829 samples/sec, batch_loss: 0.5502, batch_loss_c: 0.5552, batch_loss_s: 0.5385, time:4.5307, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2830/3125], step: 21580, 8.104 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0861, batch_loss_s: 0.0823, time:4.9359, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2840/3125], step: 21590, 7.758 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.0924, batch_loss_s: 0.1184, time:5.1560, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:40 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2850/3125], step: 21600, 8.932 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0689, batch_loss_s: 0.0770, time:4.4785, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:46 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2860/3125], step: 21610, 7.709 samples/sec, batch_loss: 0.0720, batch_loss_c: 0.0707, batch_loss_s: 0.0749, time:5.1890, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:51 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2870/3125], step: 21620, 7.740 samples/sec, batch_loss: 0.2549, batch_loss_c: 0.2303, batch_loss_s: 0.3126, time:5.1680, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:03:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2880/3125], step: 21630, 8.256 samples/sec, batch_loss: 0.3124, batch_loss_c: 0.3093, batch_loss_s: 0.3195, time:4.8448, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2890/3125], step: 21640, 8.024 samples/sec, batch_loss: 0.2471, batch_loss_c: 0.2482, batch_loss_s: 0.2444, time:4.9851, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:05 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2900/3125], step: 21650, 8.396 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0728, batch_loss_s: 0.0851, time:4.7640, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:10 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2910/3125], step: 21660, 9.343 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3123, batch_loss_s: 0.3178, time:4.2812, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:14 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2920/3125], step: 21670, 8.884 samples/sec, batch_loss: 0.1255, batch_loss_c: 0.1250, batch_loss_s: 0.1265, time:4.5024, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:19 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2930/3125], step: 21680, 8.933 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1071, batch_loss_s: 0.1162, time:4.4778, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:23 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2940/3125], step: 21690, 8.551 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1099, batch_loss_s: 0.0827, time:4.6780, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:28 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2950/3125], step: 21700, 8.644 samples/sec, batch_loss: 0.3593, batch_loss_c: 0.3670, batch_loss_s: 0.3413, time:4.6272, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:32 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2960/3125], step: 21710, 8.939 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0764, batch_loss_s: 0.0875, time:4.4746, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:37 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2970/3125], step: 21720, 8.812 samples/sec, batch_loss: 0.1110, batch_loss_c: 0.1077, batch_loss_s: 0.1187, time:4.5390, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:42 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2980/3125], step: 21730, 7.915 samples/sec, batch_loss: 0.1183, batch_loss_c: 0.1266, batch_loss_s: 0.0991, time:5.0536, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:47 \u001b[32mINFO     \u001b[0m train.py: [6/10], [2990/3125], step: 21740, 7.880 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0643, batch_loss_s: 0.0826, time:5.0759, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:52 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3000/3125], step: 21750, 8.824 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0923, batch_loss_s: 0.0897, time:4.5331, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:04:56 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3010/3125], step: 21760, 8.810 samples/sec, batch_loss: 0.0683, batch_loss_c: 0.0699, batch_loss_s: 0.0644, time:4.5404, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:01 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3020/3125], step: 21770, 7.759 samples/sec, batch_loss: 0.1068, batch_loss_c: 0.1073, batch_loss_s: 0.1056, time:5.1551, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:06 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3030/3125], step: 21780, 8.224 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.0992, batch_loss_s: 0.1273, time:4.8637, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:11 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3040/3125], step: 21790, 8.083 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0796, batch_loss_s: 0.0794, time:4.9485, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:16 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3050/3125], step: 21800, 8.784 samples/sec, batch_loss: 0.0831, batch_loss_c: 0.0867, batch_loss_s: 0.0746, time:4.5536, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:21 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3060/3125], step: 21810, 7.278 samples/sec, batch_loss: 0.0858, batch_loss_c: 0.0876, batch_loss_s: 0.0814, time:5.4959, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:26 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3070/3125], step: 21820, 7.936 samples/sec, batch_loss: 0.3480, batch_loss_c: 0.3626, batch_loss_s: 0.3141, time:5.0405, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:31 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3080/3125], step: 21830, 8.532 samples/sec, batch_loss: 0.3213, batch_loss_c: 0.3112, batch_loss_s: 0.3450, time:4.6884, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:36 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3090/3125], step: 21840, 8.055 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0854, batch_loss_s: 0.1030, time:4.9662, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:41 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3100/3125], step: 21850, 8.245 samples/sec, batch_loss: 0.0816, batch_loss_c: 0.0821, batch_loss_s: 0.0803, time:4.8515, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:45 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3110/3125], step: 21860, 10.257 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0878, batch_loss_s: 0.0627, time:3.8996, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:49 \u001b[32mINFO     \u001b[0m train.py: [6/10], [3120/3125], step: 21870, 10.347 samples/sec, batch_loss: 0.1315, batch_loss_c: 0.1528, batch_loss_s: 0.0818, time:3.8657, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:05:50 \u001b[32mINFO     \u001b[0m train.py: [6/10], train_loss: 0.1669, time: 1517.2592, lr: 0.0001\u001b[0m\n",
            "2019-11-24 12:05:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [0/3125], step: 21875, 9.925 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1149, batch_loss_s: 0.1170, time:4.0301, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [10/3125], step: 21885, 5.485 samples/sec, batch_loss: 0.0947, batch_loss_c: 0.0936, batch_loss_s: 0.0975, time:7.2920, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [20/3125], step: 21895, 7.845 samples/sec, batch_loss: 0.3113, batch_loss_c: 0.3157, batch_loss_s: 0.3010, time:5.0990, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [30/3125], step: 21905, 7.422 samples/sec, batch_loss: 0.0610, batch_loss_c: 0.0545, batch_loss_s: 0.0762, time:5.3897, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [40/3125], step: 21915, 8.881 samples/sec, batch_loss: 0.0619, batch_loss_c: 0.0592, batch_loss_s: 0.0684, time:4.5038, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [50/3125], step: 21925, 8.739 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1455, batch_loss_s: 0.1178, time:4.5773, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [60/3125], step: 21935, 7.878 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0662, batch_loss_s: 0.0810, time:5.0775, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [70/3125], step: 21945, 8.703 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0666, batch_loss_s: 0.0821, time:4.5959, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [80/3125], step: 21955, 7.837 samples/sec, batch_loss: 0.0859, batch_loss_c: 0.0834, batch_loss_s: 0.0918, time:5.1042, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [90/3125], step: 21965, 7.505 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1217, batch_loss_s: 0.1009, time:5.3296, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [100/3125], step: 21975, 8.005 samples/sec, batch_loss: 0.1039, batch_loss_c: 0.1080, batch_loss_s: 0.0943, time:4.9967, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [110/3125], step: 21985, 8.999 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0839, batch_loss_s: 0.0969, time:4.4451, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:06:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [120/3125], step: 21995, 9.175 samples/sec, batch_loss: 0.3597, batch_loss_c: 0.3732, batch_loss_s: 0.3281, time:4.3598, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [130/3125], step: 22005, 8.333 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0806, batch_loss_s: 0.0771, time:4.8003, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [140/3125], step: 22015, 8.481 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0734, batch_loss_s: 0.0816, time:4.7165, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [150/3125], step: 22025, 7.246 samples/sec, batch_loss: 0.0833, batch_loss_c: 0.0775, batch_loss_s: 0.0966, time:5.5203, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [160/3125], step: 22035, 8.801 samples/sec, batch_loss: 0.2831, batch_loss_c: 0.2629, batch_loss_s: 0.3302, time:4.5449, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [170/3125], step: 22045, 7.927 samples/sec, batch_loss: 0.1246, batch_loss_c: 0.1333, batch_loss_s: 0.1043, time:5.0460, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [180/3125], step: 22055, 7.362 samples/sec, batch_loss: 0.1693, batch_loss_c: 0.1832, batch_loss_s: 0.1369, time:5.4332, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [190/3125], step: 22065, 7.358 samples/sec, batch_loss: 0.3093, batch_loss_c: 0.3087, batch_loss_s: 0.3109, time:5.4361, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [200/3125], step: 22075, 7.880 samples/sec, batch_loss: 0.0514, batch_loss_c: 0.0475, batch_loss_s: 0.0605, time:5.0765, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [210/3125], step: 22085, 7.857 samples/sec, batch_loss: 0.0919, batch_loss_c: 0.0797, batch_loss_s: 0.1205, time:5.0912, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [220/3125], step: 22095, 8.483 samples/sec, batch_loss: 0.2682, batch_loss_c: 0.2462, batch_loss_s: 0.3194, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [230/3125], step: 22105, 8.061 samples/sec, batch_loss: 0.3096, batch_loss_c: 0.3098, batch_loss_s: 0.3091, time:4.9623, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:07:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [240/3125], step: 22115, 8.391 samples/sec, batch_loss: 0.1461, batch_loss_c: 0.1713, batch_loss_s: 0.0873, time:4.7671, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [250/3125], step: 22125, 8.658 samples/sec, batch_loss: 0.1738, batch_loss_c: 0.1858, batch_loss_s: 0.1458, time:4.6201, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [260/3125], step: 22135, 8.721 samples/sec, batch_loss: 0.1053, batch_loss_c: 0.1262, batch_loss_s: 0.0565, time:4.5864, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [270/3125], step: 22145, 8.110 samples/sec, batch_loss: 0.1663, batch_loss_c: 0.1633, batch_loss_s: 0.1733, time:4.9323, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [280/3125], step: 22155, 7.921 samples/sec, batch_loss: 0.0874, batch_loss_c: 0.0825, batch_loss_s: 0.0989, time:5.0500, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [290/3125], step: 22165, 8.425 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.3095, batch_loss_s: 0.2938, time:4.7480, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [300/3125], step: 22175, 7.930 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0684, batch_loss_s: 0.0926, time:5.0441, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [310/3125], step: 22185, 8.317 samples/sec, batch_loss: 0.5249, batch_loss_c: 0.5142, batch_loss_s: 0.5500, time:4.8094, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [320/3125], step: 22195, 7.750 samples/sec, batch_loss: 0.3073, batch_loss_c: 0.3041, batch_loss_s: 0.3148, time:5.1614, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [330/3125], step: 22205, 8.522 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0783, batch_loss_s: 0.0618, time:4.6937, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [340/3125], step: 22215, 8.649 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0901, batch_loss_s: 0.0871, time:4.6249, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [350/3125], step: 22225, 7.469 samples/sec, batch_loss: 0.1984, batch_loss_c: 0.2473, batch_loss_s: 0.0843, time:5.3555, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [360/3125], step: 22235, 7.657 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0739, batch_loss_s: 0.0737, time:5.2236, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:08:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [370/3125], step: 22245, 7.703 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1265, batch_loss_s: 0.0840, time:5.1925, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [380/3125], step: 22255, 7.397 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.3044, batch_loss_s: 0.3136, time:5.4075, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [390/3125], step: 22265, 7.585 samples/sec, batch_loss: 0.2893, batch_loss_c: 0.2852, batch_loss_s: 0.2989, time:5.2736, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [400/3125], step: 22275, 8.494 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1043, batch_loss_s: 0.0929, time:4.7092, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [410/3125], step: 22285, 8.081 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0785, batch_loss_s: 0.0762, time:4.9497, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [420/3125], step: 22295, 8.916 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0673, batch_loss_s: 0.0773, time:4.4865, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [430/3125], step: 22305, 7.821 samples/sec, batch_loss: 0.2906, batch_loss_c: 0.2905, batch_loss_s: 0.2908, time:5.1147, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [440/3125], step: 22315, 8.201 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0713, batch_loss_s: 0.0872, time:4.8776, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [450/3125], step: 22325, 8.990 samples/sec, batch_loss: 0.2928, batch_loss_c: 0.2872, batch_loss_s: 0.3057, time:4.4496, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [460/3125], step: 22335, 8.369 samples/sec, batch_loss: 0.0670, batch_loss_c: 0.0610, batch_loss_s: 0.0809, time:4.7796, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [470/3125], step: 22345, 7.927 samples/sec, batch_loss: 0.0912, batch_loss_c: 0.0956, batch_loss_s: 0.0811, time:5.0462, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [480/3125], step: 22355, 7.695 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0940, batch_loss_s: 0.0925, time:5.1983, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:09:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [490/3125], step: 22365, 8.513 samples/sec, batch_loss: 0.1257, batch_loss_c: 0.1354, batch_loss_s: 0.1030, time:4.6988, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [500/3125], step: 22375, 8.318 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0866, batch_loss_s: 0.0732, time:4.8090, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [510/3125], step: 22385, 8.128 samples/sec, batch_loss: 0.0715, batch_loss_c: 0.0717, batch_loss_s: 0.0709, time:4.9214, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [520/3125], step: 22395, 9.032 samples/sec, batch_loss: 0.0793, batch_loss_c: 0.0770, batch_loss_s: 0.0849, time:4.4285, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [530/3125], step: 22405, 7.312 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0632, batch_loss_s: 0.0757, time:5.4704, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [540/3125], step: 22415, 8.871 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1180, batch_loss_s: 0.0910, time:4.5092, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [550/3125], step: 22425, 8.360 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3525, batch_loss_s: 0.3276, time:4.7850, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [560/3125], step: 22435, 7.730 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3149, batch_loss_s: 0.3224, time:5.1744, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [570/3125], step: 22445, 8.930 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0901, batch_loss_s: 0.0843, time:4.4793, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [580/3125], step: 22455, 8.635 samples/sec, batch_loss: 0.3520, batch_loss_c: 0.3646, batch_loss_s: 0.3228, time:4.6323, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [590/3125], step: 22465, 8.974 samples/sec, batch_loss: 0.2044, batch_loss_c: 0.2383, batch_loss_s: 0.1253, time:4.4575, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [600/3125], step: 22475, 9.313 samples/sec, batch_loss: 0.0727, batch_loss_c: 0.0703, batch_loss_s: 0.0783, time:4.2951, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:10:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [610/3125], step: 22485, 8.664 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1024, batch_loss_s: 0.0936, time:4.6168, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [620/3125], step: 22495, 8.118 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0997, batch_loss_s: 0.0856, time:4.9273, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [630/3125], step: 22505, 7.953 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.0971, batch_loss_s: 0.1061, time:5.0295, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [640/3125], step: 22515, 7.097 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1063, batch_loss_s: 0.1046, time:5.6364, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [650/3125], step: 22525, 7.949 samples/sec, batch_loss: 0.2707, batch_loss_c: 0.2537, batch_loss_s: 0.3102, time:5.0318, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [660/3125], step: 22535, 8.361 samples/sec, batch_loss: 0.3188, batch_loss_c: 0.3161, batch_loss_s: 0.3252, time:4.7839, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [670/3125], step: 22545, 8.132 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1067, batch_loss_s: 0.0969, time:4.9188, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [680/3125], step: 22555, 8.292 samples/sec, batch_loss: 0.3779, batch_loss_c: 0.3858, batch_loss_s: 0.3596, time:4.8240, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [690/3125], step: 22565, 7.871 samples/sec, batch_loss: 0.0823, batch_loss_c: 0.0768, batch_loss_s: 0.0953, time:5.0819, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [700/3125], step: 22575, 8.233 samples/sec, batch_loss: 0.3304, batch_loss_c: 0.3240, batch_loss_s: 0.3453, time:4.8585, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [710/3125], step: 22585, 8.153 samples/sec, batch_loss: 0.0573, batch_loss_c: 0.0519, batch_loss_s: 0.0697, time:4.9063, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [720/3125], step: 22595, 8.699 samples/sec, batch_loss: 0.2791, batch_loss_c: 0.2703, batch_loss_s: 0.2997, time:4.5982, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [730/3125], step: 22605, 8.069 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0625, batch_loss_s: 0.0783, time:4.9572, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:11:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [740/3125], step: 22615, 8.528 samples/sec, batch_loss: 0.2936, batch_loss_c: 0.2929, batch_loss_s: 0.2950, time:4.6907, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [750/3125], step: 22625, 8.039 samples/sec, batch_loss: 0.2712, batch_loss_c: 0.2502, batch_loss_s: 0.3200, time:4.9756, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [760/3125], step: 22635, 7.309 samples/sec, batch_loss: 0.2339, batch_loss_c: 0.2650, batch_loss_s: 0.1615, time:5.4726, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [770/3125], step: 22645, 7.734 samples/sec, batch_loss: 0.2727, batch_loss_c: 0.2595, batch_loss_s: 0.3036, time:5.1719, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [780/3125], step: 22655, 7.889 samples/sec, batch_loss: 0.1341, batch_loss_c: 0.1317, batch_loss_s: 0.1396, time:5.0706, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [790/3125], step: 22665, 7.608 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0760, batch_loss_s: 0.0718, time:5.2578, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [800/3125], step: 22675, 7.527 samples/sec, batch_loss: 0.3676, batch_loss_c: 0.3798, batch_loss_s: 0.3393, time:5.3141, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [810/3125], step: 22685, 8.478 samples/sec, batch_loss: 0.0492, batch_loss_c: 0.0475, batch_loss_s: 0.0530, time:4.7184, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [820/3125], step: 22695, 8.046 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3158, batch_loss_s: 0.3227, time:4.9713, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [830/3125], step: 22705, 7.894 samples/sec, batch_loss: 0.2749, batch_loss_c: 0.2675, batch_loss_s: 0.2920, time:5.0674, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [840/3125], step: 22715, 8.796 samples/sec, batch_loss: 0.2609, batch_loss_c: 0.3092, batch_loss_s: 0.1482, time:4.5477, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:12:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [850/3125], step: 22725, 8.241 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1702, batch_loss_s: 0.1036, time:4.8535, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [860/3125], step: 22735, 8.097 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0871, batch_loss_s: 0.0964, time:4.9398, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [870/3125], step: 22745, 7.270 samples/sec, batch_loss: 0.1081, batch_loss_c: 0.1052, batch_loss_s: 0.1149, time:5.5022, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [880/3125], step: 22755, 8.359 samples/sec, batch_loss: 0.0661, batch_loss_c: 0.0621, batch_loss_s: 0.0753, time:4.7851, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [890/3125], step: 22765, 8.506 samples/sec, batch_loss: 0.2753, batch_loss_c: 0.2620, batch_loss_s: 0.3062, time:4.7026, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [900/3125], step: 22775, 7.316 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0635, batch_loss_s: 0.0907, time:5.4676, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [910/3125], step: 22785, 8.898 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1116, batch_loss_s: 0.0925, time:4.4955, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [920/3125], step: 22795, 8.581 samples/sec, batch_loss: 0.3037, batch_loss_c: 0.2966, batch_loss_s: 0.3202, time:4.6614, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [930/3125], step: 22805, 8.884 samples/sec, batch_loss: 0.1392, batch_loss_c: 0.1609, batch_loss_s: 0.0885, time:4.5023, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [940/3125], step: 22815, 8.488 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1070, batch_loss_s: 0.1069, time:4.7123, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [950/3125], step: 22825, 8.560 samples/sec, batch_loss: 0.2917, batch_loss_c: 0.2883, batch_loss_s: 0.2995, time:4.6727, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [960/3125], step: 22835, 9.095 samples/sec, batch_loss: 0.0733, batch_loss_c: 0.0719, batch_loss_s: 0.0766, time:4.3980, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [970/3125], step: 22845, 8.498 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0666, batch_loss_s: 0.0663, time:4.7069, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:13:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [980/3125], step: 22855, 7.787 samples/sec, batch_loss: 0.1162, batch_loss_c: 0.1197, batch_loss_s: 0.1081, time:5.1365, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [990/3125], step: 22865, 8.465 samples/sec, batch_loss: 0.0665, batch_loss_c: 0.0625, batch_loss_s: 0.0757, time:4.7252, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1000/3125], step: 22875, 8.639 samples/sec, batch_loss: 0.3182, batch_loss_c: 0.3216, batch_loss_s: 0.3105, time:4.6303, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1010/3125], step: 22885, 8.706 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0869, batch_loss_s: 0.0938, time:4.5945, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1020/3125], step: 22895, 8.908 samples/sec, batch_loss: 0.1606, batch_loss_c: 0.1806, batch_loss_s: 0.1139, time:4.4903, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1030/3125], step: 22905, 7.402 samples/sec, batch_loss: 0.0504, batch_loss_c: 0.0463, batch_loss_s: 0.0600, time:5.4041, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1040/3125], step: 22915, 8.364 samples/sec, batch_loss: 0.2854, batch_loss_c: 0.2813, batch_loss_s: 0.2949, time:4.7824, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1050/3125], step: 22925, 8.326 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0802, batch_loss_s: 0.0490, time:4.8041, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1060/3125], step: 22935, 8.402 samples/sec, batch_loss: 0.0659, batch_loss_c: 0.0675, batch_loss_s: 0.0621, time:4.7609, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1070/3125], step: 22945, 8.023 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0754, batch_loss_s: 0.0867, time:4.9860, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1080/3125], step: 22955, 8.046 samples/sec, batch_loss: 0.2758, batch_loss_c: 0.2686, batch_loss_s: 0.2924, time:4.9712, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1090/3125], step: 22965, 7.795 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0919, batch_loss_s: 0.1032, time:5.1314, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:14:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1100/3125], step: 22975, 7.191 samples/sec, batch_loss: 0.3038, batch_loss_c: 0.3043, batch_loss_s: 0.3024, time:5.5622, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1110/3125], step: 22985, 7.002 samples/sec, batch_loss: 0.0881, batch_loss_c: 0.0897, batch_loss_s: 0.0843, time:5.7123, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1120/3125], step: 22995, 8.114 samples/sec, batch_loss: 0.5321, batch_loss_c: 0.5287, batch_loss_s: 0.5402, time:4.9300, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1130/3125], step: 23005, 8.301 samples/sec, batch_loss: 0.2876, batch_loss_c: 0.2763, batch_loss_s: 0.3139, time:4.8187, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1140/3125], step: 23015, 8.044 samples/sec, batch_loss: 0.1162, batch_loss_c: 0.1134, batch_loss_s: 0.1228, time:4.9729, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1150/3125], step: 23025, 8.327 samples/sec, batch_loss: 0.0595, batch_loss_c: 0.0574, batch_loss_s: 0.0645, time:4.8034, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1160/3125], step: 23035, 8.288 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0901, batch_loss_s: 0.0923, time:4.8264, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1170/3125], step: 23045, 8.338 samples/sec, batch_loss: 0.0924, batch_loss_c: 0.0898, batch_loss_s: 0.0984, time:4.7973, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1180/3125], step: 23055, 8.341 samples/sec, batch_loss: 0.0974, batch_loss_c: 0.1064, batch_loss_s: 0.0763, time:4.7956, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1190/3125], step: 23065, 8.467 samples/sec, batch_loss: 0.1805, batch_loss_c: 0.1832, batch_loss_s: 0.1742, time:4.7244, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1200/3125], step: 23075, 8.980 samples/sec, batch_loss: 0.1345, batch_loss_c: 0.1383, batch_loss_s: 0.1256, time:4.4544, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1210/3125], step: 23085, 8.997 samples/sec, batch_loss: 0.3083, batch_loss_c: 0.3049, batch_loss_s: 0.3163, time:4.4458, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1220/3125], step: 23095, 8.737 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0828, batch_loss_s: 0.0978, time:4.5785, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:15:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1230/3125], step: 23105, 8.657 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0654, batch_loss_s: 0.0888, time:4.6203, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1240/3125], step: 23115, 8.064 samples/sec, batch_loss: 0.1135, batch_loss_c: 0.1235, batch_loss_s: 0.0900, time:4.9603, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1250/3125], step: 23125, 9.454 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2865, batch_loss_s: 0.3010, time:4.2310, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1260/3125], step: 23135, 8.729 samples/sec, batch_loss: 0.0616, batch_loss_c: 0.0559, batch_loss_s: 0.0751, time:4.5825, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1270/3125], step: 23145, 9.101 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1136, batch_loss_s: 0.0934, time:4.3952, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1280/3125], step: 23155, 9.107 samples/sec, batch_loss: 0.3348, batch_loss_c: 0.3335, batch_loss_s: 0.3378, time:4.3920, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1290/3125], step: 23165, 8.967 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0604, batch_loss_s: 0.0722, time:4.4608, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1300/3125], step: 23175, 8.935 samples/sec, batch_loss: 0.3726, batch_loss_c: 0.3742, batch_loss_s: 0.3687, time:4.4768, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1310/3125], step: 23185, 8.522 samples/sec, batch_loss: 0.0939, batch_loss_c: 0.0998, batch_loss_s: 0.0802, time:4.6938, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1320/3125], step: 23195, 8.601 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0708, batch_loss_s: 0.0816, time:4.6507, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1330/3125], step: 23205, 8.364 samples/sec, batch_loss: 0.0922, batch_loss_c: 0.0857, batch_loss_s: 0.1074, time:4.7822, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1340/3125], step: 23215, 9.397 samples/sec, batch_loss: 0.3638, batch_loss_c: 0.3812, batch_loss_s: 0.3234, time:4.2565, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1350/3125], step: 23225, 8.741 samples/sec, batch_loss: 0.0829, batch_loss_c: 0.0759, batch_loss_s: 0.0992, time:4.5762, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:16:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1360/3125], step: 23235, 8.699 samples/sec, batch_loss: 0.1415, batch_loss_c: 0.1539, batch_loss_s: 0.1125, time:4.5981, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1370/3125], step: 23245, 9.175 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0951, batch_loss_s: 0.0737, time:4.3597, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1380/3125], step: 23255, 8.640 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1067, batch_loss_s: 0.1003, time:4.6296, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1390/3125], step: 23265, 7.821 samples/sec, batch_loss: 0.0904, batch_loss_c: 0.0914, batch_loss_s: 0.0879, time:5.1143, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1400/3125], step: 23275, 8.418 samples/sec, batch_loss: 0.1025, batch_loss_c: 0.0825, batch_loss_s: 0.1492, time:4.7520, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1410/3125], step: 23285, 8.445 samples/sec, batch_loss: 0.3320, batch_loss_c: 0.3277, batch_loss_s: 0.3421, time:4.7366, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1420/3125], step: 23295, 8.400 samples/sec, batch_loss: 0.0608, batch_loss_c: 0.0589, batch_loss_s: 0.0653, time:4.7620, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1430/3125], step: 23305, 7.799 samples/sec, batch_loss: 0.0534, batch_loss_c: 0.0498, batch_loss_s: 0.0618, time:5.1287, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1440/3125], step: 23315, 8.012 samples/sec, batch_loss: 0.2980, batch_loss_c: 0.2949, batch_loss_s: 0.3052, time:4.9924, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1450/3125], step: 23325, 7.363 samples/sec, batch_loss: 0.0675, batch_loss_c: 0.0628, batch_loss_s: 0.0782, time:5.4322, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1460/3125], step: 23335, 8.656 samples/sec, batch_loss: 0.3400, batch_loss_c: 0.3431, batch_loss_s: 0.3329, time:4.6210, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1470/3125], step: 23345, 7.189 samples/sec, batch_loss: 0.0656, batch_loss_c: 0.0641, batch_loss_s: 0.0692, time:5.5642, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:17:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1480/3125], step: 23355, 8.163 samples/sec, batch_loss: 0.0693, batch_loss_c: 0.0638, batch_loss_s: 0.0820, time:4.9001, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:01 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1490/3125], step: 23365, 9.072 samples/sec, batch_loss: 0.2990, batch_loss_c: 0.2971, batch_loss_s: 0.3034, time:4.4090, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1500/3125], step: 23375, 8.099 samples/sec, batch_loss: 0.3396, batch_loss_c: 0.3462, batch_loss_s: 0.3242, time:4.9387, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1510/3125], step: 23385, 8.051 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1333, batch_loss_s: 0.0885, time:4.9681, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1520/3125], step: 23395, 8.942 samples/sec, batch_loss: 0.0548, batch_loss_c: 0.0512, batch_loss_s: 0.0631, time:4.4733, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1530/3125], step: 23405, 8.857 samples/sec, batch_loss: 0.0857, batch_loss_c: 0.0901, batch_loss_s: 0.0756, time:4.5163, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1540/3125], step: 23415, 8.552 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0765, batch_loss_s: 0.0851, time:4.6771, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1550/3125], step: 23425, 8.784 samples/sec, batch_loss: 0.0734, batch_loss_c: 0.0760, batch_loss_s: 0.0674, time:4.5535, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1560/3125], step: 23435, 8.132 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1070, batch_loss_s: 0.0982, time:4.9188, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:39 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1570/3125], step: 23445, 8.552 samples/sec, batch_loss: 0.0772, batch_loss_c: 0.0764, batch_loss_s: 0.0790, time:4.6771, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1580/3125], step: 23455, 8.205 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0614, batch_loss_s: 0.0673, time:4.8752, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1590/3125], step: 23465, 9.196 samples/sec, batch_loss: 0.0980, batch_loss_c: 0.1063, batch_loss_s: 0.0785, time:4.3495, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1600/3125], step: 23475, 8.923 samples/sec, batch_loss: 0.0537, batch_loss_c: 0.0501, batch_loss_s: 0.0622, time:4.4827, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:18:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1610/3125], step: 23485, 7.767 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0658, batch_loss_s: 0.0782, time:5.1501, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1620/3125], step: 23495, 8.201 samples/sec, batch_loss: 0.0846, batch_loss_c: 0.0860, batch_loss_s: 0.0812, time:4.8773, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1630/3125], step: 23505, 7.950 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0904, batch_loss_s: 0.0795, time:5.0315, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1640/3125], step: 23515, 7.580 samples/sec, batch_loss: 0.0731, batch_loss_c: 0.0646, batch_loss_s: 0.0928, time:5.2767, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1650/3125], step: 23525, 7.756 samples/sec, batch_loss: 0.1648, batch_loss_c: 0.1680, batch_loss_s: 0.1573, time:5.1573, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1660/3125], step: 23535, 8.771 samples/sec, batch_loss: 0.0792, batch_loss_c: 0.0744, batch_loss_s: 0.0902, time:4.5604, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1670/3125], step: 23545, 8.502 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1067, batch_loss_s: 0.1048, time:4.7047, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1680/3125], step: 23555, 8.593 samples/sec, batch_loss: 0.0907, batch_loss_c: 0.0889, batch_loss_s: 0.0949, time:4.6551, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1690/3125], step: 23565, 8.686 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0835, batch_loss_s: 0.1044, time:4.6052, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1700/3125], step: 23575, 8.205 samples/sec, batch_loss: 0.3437, batch_loss_c: 0.3314, batch_loss_s: 0.3726, time:4.8751, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1710/3125], step: 23585, 8.349 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0901, batch_loss_s: 0.0779, time:4.7907, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1720/3125], step: 23595, 8.312 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0872, batch_loss_s: 0.0753, time:4.8125, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:19:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1730/3125], step: 23605, 8.919 samples/sec, batch_loss: 0.3684, batch_loss_c: 0.3812, batch_loss_s: 0.3386, time:4.4849, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1740/3125], step: 23615, 8.876 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0971, batch_loss_s: 0.0909, time:4.5068, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1750/3125], step: 23625, 7.654 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0750, batch_loss_s: 0.0862, time:5.2263, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:10 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1760/3125], step: 23635, 8.260 samples/sec, batch_loss: 0.5283, batch_loss_c: 0.5239, batch_loss_s: 0.5387, time:4.8424, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1770/3125], step: 23645, 8.542 samples/sec, batch_loss: 0.2346, batch_loss_c: 0.1995, batch_loss_s: 0.3166, time:4.6825, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1780/3125], step: 23655, 8.798 samples/sec, batch_loss: 0.4831, batch_loss_c: 0.4551, batch_loss_s: 0.5485, time:4.5467, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1790/3125], step: 23665, 7.976 samples/sec, batch_loss: 0.1612, batch_loss_c: 0.1506, batch_loss_s: 0.1860, time:5.0150, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1800/3125], step: 23675, 7.749 samples/sec, batch_loss: 0.2982, batch_loss_c: 0.2972, batch_loss_s: 0.3003, time:5.1619, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1810/3125], step: 23685, 7.884 samples/sec, batch_loss: 0.0739, batch_loss_c: 0.0673, batch_loss_s: 0.0895, time:5.0735, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1820/3125], step: 23695, 8.450 samples/sec, batch_loss: 0.3031, batch_loss_c: 0.3064, batch_loss_s: 0.2956, time:4.7338, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:44 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1830/3125], step: 23705, 8.400 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1053, batch_loss_s: 0.1159, time:4.7619, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1840/3125], step: 23715, 9.357 samples/sec, batch_loss: 0.1415, batch_loss_c: 0.1640, batch_loss_s: 0.0892, time:4.2749, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1850/3125], step: 23725, 7.920 samples/sec, batch_loss: 0.3918, batch_loss_c: 0.3781, batch_loss_s: 0.4239, time:5.0504, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:20:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1860/3125], step: 23735, 8.204 samples/sec, batch_loss: 0.1089, batch_loss_c: 0.0913, batch_loss_s: 0.1499, time:4.8755, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1870/3125], step: 23745, 8.318 samples/sec, batch_loss: 0.3617, batch_loss_c: 0.3808, batch_loss_s: 0.3171, time:4.8086, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1880/3125], step: 23755, 9.159 samples/sec, batch_loss: 0.1119, batch_loss_c: 0.1345, batch_loss_s: 0.0590, time:4.3675, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1890/3125], step: 23765, 8.965 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1277, batch_loss_s: 0.1012, time:4.4616, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1900/3125], step: 23775, 7.931 samples/sec, batch_loss: 0.0967, batch_loss_c: 0.0907, batch_loss_s: 0.1109, time:5.0432, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1910/3125], step: 23785, 8.761 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0567, batch_loss_s: 0.0712, time:4.5655, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1920/3125], step: 23795, 7.260 samples/sec, batch_loss: 0.1429, batch_loss_c: 0.1487, batch_loss_s: 0.1292, time:5.5099, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:32 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1930/3125], step: 23805, 8.033 samples/sec, batch_loss: 0.3622, batch_loss_c: 0.3749, batch_loss_s: 0.3327, time:4.9795, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1940/3125], step: 23815, 7.671 samples/sec, batch_loss: 0.2891, batch_loss_c: 0.2836, batch_loss_s: 0.3019, time:5.2143, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1950/3125], step: 23825, 8.025 samples/sec, batch_loss: 0.0555, batch_loss_c: 0.0532, batch_loss_s: 0.0608, time:4.9847, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1960/3125], step: 23835, 8.232 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0949, batch_loss_s: 0.0766, time:4.8590, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1970/3125], step: 23845, 8.903 samples/sec, batch_loss: 0.0837, batch_loss_c: 0.0942, batch_loss_s: 0.0593, time:4.4930, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:21:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1980/3125], step: 23855, 7.990 samples/sec, batch_loss: 0.1011, batch_loss_c: 0.1062, batch_loss_s: 0.0894, time:5.0059, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:02 \u001b[32mINFO     \u001b[0m train.py: [7/10], [1990/3125], step: 23865, 8.429 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.1000, batch_loss_s: 0.0704, time:4.7458, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:06 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2000/3125], step: 23875, 8.732 samples/sec, batch_loss: 0.0892, batch_loss_c: 0.0906, batch_loss_s: 0.0858, time:4.5807, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2010/3125], step: 23885, 8.081 samples/sec, batch_loss: 0.1560, batch_loss_c: 0.1810, batch_loss_s: 0.0976, time:4.9496, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2020/3125], step: 23895, 8.210 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0982, batch_loss_s: 0.0949, time:4.8720, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2030/3125], step: 23905, 8.706 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1353, batch_loss_s: 0.0844, time:4.5946, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2040/3125], step: 23915, 8.895 samples/sec, batch_loss: 0.1642, batch_loss_c: 0.1962, batch_loss_s: 0.0893, time:4.4970, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:30 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2050/3125], step: 23925, 8.263 samples/sec, batch_loss: 0.1188, batch_loss_c: 0.1183, batch_loss_s: 0.1198, time:4.8407, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2060/3125], step: 23935, 7.613 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1014, batch_loss_s: 0.1249, time:5.2542, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2070/3125], step: 23945, 7.954 samples/sec, batch_loss: 0.1541, batch_loss_c: 0.1933, batch_loss_s: 0.0626, time:5.0290, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2080/3125], step: 23955, 8.155 samples/sec, batch_loss: 0.3343, batch_loss_c: 0.3319, batch_loss_s: 0.3399, time:4.9047, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2090/3125], step: 23965, 7.852 samples/sec, batch_loss: 0.1508, batch_loss_c: 0.1635, batch_loss_s: 0.1210, time:5.0941, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:22:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2100/3125], step: 23975, 8.708 samples/sec, batch_loss: 0.1274, batch_loss_c: 0.0923, batch_loss_s: 0.2094, time:4.5933, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2110/3125], step: 23985, 7.410 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3532, batch_loss_s: 0.3373, time:5.3980, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2120/3125], step: 23995, 8.060 samples/sec, batch_loss: 0.1367, batch_loss_c: 0.1359, batch_loss_s: 0.1386, time:4.9625, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:11 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2130/3125], step: 24005, 7.143 samples/sec, batch_loss: 0.1726, batch_loss_c: 0.1787, batch_loss_s: 0.1584, time:5.5998, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:16 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2140/3125], step: 24015, 7.809 samples/sec, batch_loss: 0.0518, batch_loss_c: 0.0491, batch_loss_s: 0.0582, time:5.1225, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2150/3125], step: 24025, 9.054 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0689, batch_loss_s: 0.0780, time:4.4179, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2160/3125], step: 24035, 9.300 samples/sec, batch_loss: 0.2904, batch_loss_c: 0.2842, batch_loss_s: 0.3049, time:4.3012, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:29 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2170/3125], step: 24045, 9.076 samples/sec, batch_loss: 0.0604, batch_loss_c: 0.0565, batch_loss_s: 0.0695, time:4.4074, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:34 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2180/3125], step: 24055, 8.463 samples/sec, batch_loss: 0.0624, batch_loss_c: 0.0591, batch_loss_s: 0.0699, time:4.7263, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2190/3125], step: 24065, 8.990 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2848, batch_loss_s: 0.3049, time:4.4494, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2200/3125], step: 24075, 8.973 samples/sec, batch_loss: 0.2942, batch_loss_c: 0.2918, batch_loss_s: 0.2996, time:4.4576, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:47 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2210/3125], step: 24085, 8.839 samples/sec, batch_loss: 0.1295, batch_loss_c: 0.1338, batch_loss_s: 0.1194, time:4.5255, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:52 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2220/3125], step: 24095, 7.571 samples/sec, batch_loss: 0.0679, batch_loss_c: 0.0692, batch_loss_s: 0.0648, time:5.2833, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:23:57 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2230/3125], step: 24105, 8.036 samples/sec, batch_loss: 0.1057, batch_loss_c: 0.1166, batch_loss_s: 0.0804, time:4.9779, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2240/3125], step: 24115, 7.706 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0885, batch_loss_s: 0.0731, time:5.1906, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2250/3125], step: 24125, 8.742 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0853, batch_loss_s: 0.0766, time:4.5755, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2260/3125], step: 24135, 8.224 samples/sec, batch_loss: 0.2918, batch_loss_c: 0.2883, batch_loss_s: 0.3001, time:4.8637, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2270/3125], step: 24145, 8.081 samples/sec, batch_loss: 0.0955, batch_loss_c: 0.0909, batch_loss_s: 0.1062, time:4.9496, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2280/3125], step: 24155, 8.582 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0921, batch_loss_s: 0.0837, time:4.6607, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2290/3125], step: 24165, 8.700 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.1945, batch_loss_s: 0.0886, time:4.5978, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2300/3125], step: 24175, 8.510 samples/sec, batch_loss: 0.2589, batch_loss_c: 0.2414, batch_loss_s: 0.2997, time:4.7006, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2310/3125], step: 24185, 9.015 samples/sec, batch_loss: 0.1405, batch_loss_c: 0.1417, batch_loss_s: 0.1379, time:4.4373, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2320/3125], step: 24195, 8.095 samples/sec, batch_loss: 0.1534, batch_loss_c: 0.1665, batch_loss_s: 0.1229, time:4.9416, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2330/3125], step: 24205, 7.867 samples/sec, batch_loss: 0.1500, batch_loss_c: 0.1643, batch_loss_s: 0.1165, time:5.0847, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:50 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2340/3125], step: 24215, 8.623 samples/sec, batch_loss: 0.2942, batch_loss_c: 0.2875, batch_loss_s: 0.3098, time:4.6388, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:24:55 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2350/3125], step: 24225, 8.560 samples/sec, batch_loss: 0.2708, batch_loss_c: 0.3429, batch_loss_s: 0.1026, time:4.6726, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2360/3125], step: 24235, 8.424 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0888, batch_loss_s: 0.0817, time:4.7483, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2370/3125], step: 24245, 9.008 samples/sec, batch_loss: 0.0778, batch_loss_c: 0.0779, batch_loss_s: 0.0778, time:4.4407, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2380/3125], step: 24255, 8.369 samples/sec, batch_loss: 0.3935, batch_loss_c: 0.4184, batch_loss_s: 0.3353, time:4.7794, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2390/3125], step: 24265, 7.274 samples/sec, batch_loss: 0.1774, batch_loss_c: 0.1761, batch_loss_s: 0.1803, time:5.4992, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:19 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2400/3125], step: 24275, 8.484 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.1014, batch_loss_s: 0.0873, time:4.7145, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:24 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2410/3125], step: 24285, 8.610 samples/sec, batch_loss: 0.0759, batch_loss_c: 0.0685, batch_loss_s: 0.0930, time:4.6459, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2420/3125], step: 24295, 8.289 samples/sec, batch_loss: 0.1822, batch_loss_c: 0.2040, batch_loss_s: 0.1312, time:4.8259, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2430/3125], step: 24305, 7.955 samples/sec, batch_loss: 0.0884, batch_loss_c: 0.0814, batch_loss_s: 0.1047, time:5.0285, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2440/3125], step: 24315, 8.286 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0959, batch_loss_s: 0.0858, time:4.8276, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2450/3125], step: 24325, 8.104 samples/sec, batch_loss: 0.3421, batch_loss_c: 0.3415, batch_loss_s: 0.3433, time:4.9358, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2460/3125], step: 24335, 7.931 samples/sec, batch_loss: 0.1444, batch_loss_c: 0.1423, batch_loss_s: 0.1494, time:5.0432, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2470/3125], step: 24345, 8.309 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0817, batch_loss_s: 0.0906, time:4.8143, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:25:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2480/3125], step: 24355, 8.603 samples/sec, batch_loss: 0.5403, batch_loss_c: 0.5410, batch_loss_s: 0.5386, time:4.6495, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2490/3125], step: 24365, 8.246 samples/sec, batch_loss: 0.3334, batch_loss_c: 0.3408, batch_loss_s: 0.3162, time:4.8507, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2500/3125], step: 24375, 8.149 samples/sec, batch_loss: 0.0589, batch_loss_c: 0.0560, batch_loss_s: 0.0654, time:4.9083, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:12 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2510/3125], step: 24385, 8.337 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1451, batch_loss_s: 0.0872, time:4.7976, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:17 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2520/3125], step: 24395, 8.994 samples/sec, batch_loss: 0.0763, batch_loss_c: 0.0715, batch_loss_s: 0.0874, time:4.4473, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:21 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2530/3125], step: 24405, 9.018 samples/sec, batch_loss: 0.3261, batch_loss_c: 0.3257, batch_loss_s: 0.3269, time:4.4354, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:26 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2540/3125], step: 24415, 7.914 samples/sec, batch_loss: 0.1125, batch_loss_c: 0.1298, batch_loss_s: 0.0720, time:5.0545, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2550/3125], step: 24425, 8.667 samples/sec, batch_loss: 0.2897, batch_loss_c: 0.2882, batch_loss_s: 0.2931, time:4.6152, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:36 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2560/3125], step: 24435, 7.901 samples/sec, batch_loss: 0.1936, batch_loss_c: 0.1914, batch_loss_s: 0.1985, time:5.0629, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2570/3125], step: 24445, 8.789 samples/sec, batch_loss: 0.2737, batch_loss_c: 0.2422, batch_loss_s: 0.3471, time:4.5510, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2580/3125], step: 24455, 8.896 samples/sec, batch_loss: 0.0741, batch_loss_c: 0.0711, batch_loss_s: 0.0812, time:4.4966, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2590/3125], step: 24465, 8.977 samples/sec, batch_loss: 0.7442, batch_loss_c: 0.7349, batch_loss_s: 0.7660, time:4.4560, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2600/3125], step: 24475, 7.950 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0860, batch_loss_s: 0.1200, time:5.0313, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:26:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2610/3125], step: 24485, 8.734 samples/sec, batch_loss: 0.0687, batch_loss_c: 0.0654, batch_loss_s: 0.0766, time:4.5800, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:04 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2620/3125], step: 24495, 8.183 samples/sec, batch_loss: 0.1217, batch_loss_c: 0.1174, batch_loss_s: 0.1316, time:4.8884, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2630/3125], step: 24505, 7.876 samples/sec, batch_loss: 0.2645, batch_loss_c: 0.2531, batch_loss_s: 0.2909, time:5.0786, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2640/3125], step: 24515, 8.374 samples/sec, batch_loss: 0.1453, batch_loss_c: 0.1653, batch_loss_s: 0.0986, time:4.7767, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2650/3125], step: 24525, 8.930 samples/sec, batch_loss: 0.0506, batch_loss_c: 0.0484, batch_loss_s: 0.0558, time:4.4795, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:23 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2660/3125], step: 24535, 8.199 samples/sec, batch_loss: 0.3029, batch_loss_c: 0.2881, batch_loss_s: 0.3376, time:4.8784, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2670/3125], step: 24545, 8.687 samples/sec, batch_loss: 0.0645, batch_loss_c: 0.0571, batch_loss_s: 0.0816, time:4.6045, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2680/3125], step: 24555, 7.968 samples/sec, batch_loss: 0.5374, batch_loss_c: 0.5319, batch_loss_s: 0.5504, time:5.0202, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2690/3125], step: 24565, 7.838 samples/sec, batch_loss: 0.1318, batch_loss_c: 0.1436, batch_loss_s: 0.1044, time:5.1035, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:43 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2700/3125], step: 24575, 8.408 samples/sec, batch_loss: 0.3091, batch_loss_c: 0.3078, batch_loss_s: 0.3122, time:4.7571, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2710/3125], step: 24585, 7.787 samples/sec, batch_loss: 0.0620, batch_loss_c: 0.0599, batch_loss_s: 0.0670, time:5.1364, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2720/3125], step: 24595, 7.832 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0869, batch_loss_s: 0.1003, time:5.1072, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:27:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2730/3125], step: 24605, 7.403 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0778, batch_loss_s: 0.0864, time:5.4029, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2740/3125], step: 24615, 7.934 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0731, batch_loss_s: 0.0682, time:5.0418, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2750/3125], step: 24625, 7.949 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0661, batch_loss_s: 0.0816, time:5.0322, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:14 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2760/3125], step: 24635, 7.758 samples/sec, batch_loss: 0.2901, batch_loss_c: 0.2912, batch_loss_s: 0.2877, time:5.1558, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2770/3125], step: 24645, 9.089 samples/sec, batch_loss: 0.1198, batch_loss_c: 0.1271, batch_loss_s: 0.1030, time:4.4011, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2780/3125], step: 24655, 8.720 samples/sec, batch_loss: 0.0499, batch_loss_c: 0.0451, batch_loss_s: 0.0610, time:4.5870, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:28 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2790/3125], step: 24665, 7.426 samples/sec, batch_loss: 0.1129, batch_loss_c: 0.1344, batch_loss_s: 0.0629, time:5.3863, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:33 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2800/3125], step: 24675, 7.895 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1164, batch_loss_s: 0.1065, time:5.0667, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:38 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2810/3125], step: 24685, 8.079 samples/sec, batch_loss: 0.0855, batch_loss_c: 0.0870, batch_loss_s: 0.0818, time:4.9509, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:42 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2820/3125], step: 24695, 9.187 samples/sec, batch_loss: 0.0577, batch_loss_c: 0.0546, batch_loss_s: 0.0649, time:4.3539, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:48 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2830/3125], step: 24705, 7.326 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.0904, batch_loss_s: 0.1198, time:5.4598, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:53 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2840/3125], step: 24715, 8.250 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0683, batch_loss_s: 0.0614, time:4.8486, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:28:58 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2850/3125], step: 24725, 7.218 samples/sec, batch_loss: 0.0946, batch_loss_c: 0.0902, batch_loss_s: 0.1049, time:5.5419, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2860/3125], step: 24735, 7.702 samples/sec, batch_loss: 0.3686, batch_loss_c: 0.3851, batch_loss_s: 0.3301, time:5.1935, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:08 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2870/3125], step: 24745, 8.471 samples/sec, batch_loss: 0.3666, batch_loss_c: 0.3843, batch_loss_s: 0.3254, time:4.7222, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:13 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2880/3125], step: 24755, 8.281 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0937, batch_loss_s: 0.0988, time:4.8301, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:18 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2890/3125], step: 24765, 8.589 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0682, batch_loss_s: 0.0783, time:4.6573, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:22 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2900/3125], step: 24775, 8.705 samples/sec, batch_loss: 0.1024, batch_loss_c: 0.1081, batch_loss_s: 0.0891, time:4.5952, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:27 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2910/3125], step: 24785, 9.018 samples/sec, batch_loss: 0.1545, batch_loss_c: 0.1418, batch_loss_s: 0.1842, time:4.4358, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2920/3125], step: 24795, 8.268 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1027, batch_loss_s: 0.1085, time:4.8378, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:37 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2930/3125], step: 24805, 7.783 samples/sec, batch_loss: 0.1459, batch_loss_c: 0.1555, batch_loss_s: 0.1236, time:5.1395, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:41 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2940/3125], step: 24815, 8.240 samples/sec, batch_loss: 0.1619, batch_loss_c: 0.1792, batch_loss_s: 0.1214, time:4.8546, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:46 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2950/3125], step: 24825, 8.554 samples/sec, batch_loss: 0.3857, batch_loss_c: 0.4098, batch_loss_s: 0.3296, time:4.6764, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:51 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2960/3125], step: 24835, 8.271 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.1070, batch_loss_s: 0.0744, time:4.8362, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:29:56 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2970/3125], step: 24845, 8.210 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1588, batch_loss_s: 0.1103, time:4.8720, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:00 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2980/3125], step: 24855, 8.965 samples/sec, batch_loss: 0.0975, batch_loss_c: 0.0931, batch_loss_s: 0.1080, time:4.4616, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:05 \u001b[32mINFO     \u001b[0m train.py: [7/10], [2990/3125], step: 24865, 8.744 samples/sec, batch_loss: 0.0494, batch_loss_c: 0.0450, batch_loss_s: 0.0597, time:4.5746, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3000/3125], step: 24875, 8.612 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0721, batch_loss_s: 0.0930, time:4.6449, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:15 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3010/3125], step: 24885, 7.384 samples/sec, batch_loss: 0.3704, batch_loss_c: 0.3961, batch_loss_s: 0.3104, time:5.4169, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:20 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3020/3125], step: 24895, 7.455 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0606, batch_loss_s: 0.0834, time:5.3654, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:25 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3030/3125], step: 24905, 7.647 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.1021, batch_loss_s: 0.0850, time:5.2305, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:31 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3040/3125], step: 24915, 7.704 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1092, batch_loss_s: 0.1110, time:5.1924, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:35 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3050/3125], step: 24925, 8.430 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1073, batch_loss_s: 0.1063, time:4.7447, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:40 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3060/3125], step: 24935, 8.546 samples/sec, batch_loss: 0.5505, batch_loss_c: 0.5484, batch_loss_s: 0.5555, time:4.6807, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:45 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3070/3125], step: 24945, 9.007 samples/sec, batch_loss: 0.0980, batch_loss_c: 0.1098, batch_loss_s: 0.0706, time:4.4410, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:49 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3080/3125], step: 24955, 8.697 samples/sec, batch_loss: 0.1342, batch_loss_c: 0.1306, batch_loss_s: 0.1426, time:4.5992, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:54 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3090/3125], step: 24965, 8.066 samples/sec, batch_loss: 0.2638, batch_loss_c: 0.2565, batch_loss_s: 0.2810, time:4.9593, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:30:59 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3100/3125], step: 24975, 8.223 samples/sec, batch_loss: 0.2910, batch_loss_c: 0.2892, batch_loss_s: 0.2951, time:4.8646, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:03 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3110/3125], step: 24985, 10.178 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3277, batch_loss_s: 0.3214, time:3.9302, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:07 \u001b[32mINFO     \u001b[0m train.py: [7/10], [3120/3125], step: 24995, 10.198 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.2980, batch_loss_s: 0.3202, time:3.9223, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:09 \u001b[32mINFO     \u001b[0m train.py: [7/10], train_loss: 0.1660, time: 1518.1607, lr: 0.0001\u001b[0m\n",
            "2019-11-24 12:31:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [0/3125], step: 25000, 7.993 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1242, batch_loss_s: 0.1403, time:5.0044, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [10/3125], step: 25010, 6.703 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1130, batch_loss_s: 0.0947, time:5.9679, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [20/3125], step: 25020, 7.698 samples/sec, batch_loss: 0.1132, batch_loss_c: 0.1189, batch_loss_s: 0.0998, time:5.1961, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [30/3125], step: 25030, 7.820 samples/sec, batch_loss: 0.2834, batch_loss_c: 0.2752, batch_loss_s: 0.3025, time:5.1152, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:35 \u001b[32mINFO     \u001b[0m train.py: [8/10], [40/3125], step: 25040, 8.104 samples/sec, batch_loss: 0.1957, batch_loss_c: 0.2298, batch_loss_s: 0.1163, time:4.9358, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [50/3125], step: 25050, 8.452 samples/sec, batch_loss: 0.0908, batch_loss_c: 0.0965, batch_loss_s: 0.0774, time:4.7326, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [60/3125], step: 25060, 8.942 samples/sec, batch_loss: 0.1533, batch_loss_c: 0.1669, batch_loss_s: 0.1215, time:4.4731, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [70/3125], step: 25070, 8.416 samples/sec, batch_loss: 0.0439, batch_loss_c: 0.0371, batch_loss_s: 0.0597, time:4.7526, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [80/3125], step: 25080, 8.372 samples/sec, batch_loss: 0.1303, batch_loss_c: 0.1469, batch_loss_s: 0.0915, time:4.7779, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:31:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [90/3125], step: 25090, 8.568 samples/sec, batch_loss: 0.1691, batch_loss_c: 0.1851, batch_loss_s: 0.1319, time:4.6683, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [100/3125], step: 25100, 7.661 samples/sec, batch_loss: 0.1334, batch_loss_c: 0.1565, batch_loss_s: 0.0793, time:5.2214, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [110/3125], step: 25110, 8.358 samples/sec, batch_loss: 0.0470, batch_loss_c: 0.0406, batch_loss_s: 0.0619, time:4.7860, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [120/3125], step: 25120, 8.142 samples/sec, batch_loss: 0.2858, batch_loss_c: 0.2538, batch_loss_s: 0.3604, time:4.9126, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [130/3125], step: 25130, 8.376 samples/sec, batch_loss: 0.1048, batch_loss_c: 0.1016, batch_loss_s: 0.1122, time:4.7754, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [140/3125], step: 25140, 7.301 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0795, batch_loss_s: 0.0970, time:5.4787, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [150/3125], step: 25150, 7.853 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0736, batch_loss_s: 0.0796, time:5.0933, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [160/3125], step: 25160, 7.702 samples/sec, batch_loss: 0.1929, batch_loss_c: 0.2260, batch_loss_s: 0.1155, time:5.1933, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [170/3125], step: 25170, 6.795 samples/sec, batch_loss: 0.1812, batch_loss_c: 0.2036, batch_loss_s: 0.1288, time:5.8863, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [180/3125], step: 25180, 7.499 samples/sec, batch_loss: 0.2953, batch_loss_c: 0.3087, batch_loss_s: 0.2640, time:5.3340, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [190/3125], step: 25190, 9.045 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0679, batch_loss_s: 0.0910, time:4.4225, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [200/3125], step: 25200, 8.056 samples/sec, batch_loss: 0.0628, batch_loss_c: 0.0570, batch_loss_s: 0.0762, time:4.9652, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:32:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [210/3125], step: 25210, 8.173 samples/sec, batch_loss: 0.0769, batch_loss_c: 0.0731, batch_loss_s: 0.0860, time:4.8941, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [220/3125], step: 25220, 8.618 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.1049, batch_loss_s: 0.0905, time:4.6416, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [230/3125], step: 25230, 8.532 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1394, batch_loss_s: 0.0872, time:4.6883, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [240/3125], step: 25240, 8.775 samples/sec, batch_loss: 0.3194, batch_loss_c: 0.3284, batch_loss_s: 0.2986, time:4.5582, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [250/3125], step: 25250, 8.269 samples/sec, batch_loss: 0.0603, batch_loss_c: 0.0585, batch_loss_s: 0.0645, time:4.8372, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [260/3125], step: 25260, 7.184 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0803, batch_loss_s: 0.0908, time:5.5683, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [270/3125], step: 25270, 8.100 samples/sec, batch_loss: 0.0861, batch_loss_c: 0.0835, batch_loss_s: 0.0922, time:4.9386, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [280/3125], step: 25280, 8.334 samples/sec, batch_loss: 0.0597, batch_loss_c: 0.0544, batch_loss_s: 0.0721, time:4.7997, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [290/3125], step: 25290, 8.168 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0840, batch_loss_s: 0.0794, time:4.8971, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [300/3125], step: 25300, 8.366 samples/sec, batch_loss: 0.0995, batch_loss_c: 0.1111, batch_loss_s: 0.0725, time:4.7811, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [310/3125], step: 25310, 6.948 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0948, batch_loss_s: 0.0958, time:5.7570, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [320/3125], step: 25320, 8.239 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0572, batch_loss_s: 0.0719, time:4.8548, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:33:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [330/3125], step: 25330, 8.267 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0761, batch_loss_s: 0.0750, time:4.8385, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [340/3125], step: 25340, 8.577 samples/sec, batch_loss: 0.1152, batch_loss_c: 0.1120, batch_loss_s: 0.1228, time:4.6635, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [350/3125], step: 25350, 8.023 samples/sec, batch_loss: 0.0766, batch_loss_c: 0.0660, batch_loss_s: 0.1011, time:4.9857, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [360/3125], step: 25360, 8.077 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.0997, batch_loss_s: 0.1108, time:4.9525, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [370/3125], step: 25370, 7.089 samples/sec, batch_loss: 0.1769, batch_loss_c: 0.2038, batch_loss_s: 0.1143, time:5.6426, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [380/3125], step: 25380, 8.049 samples/sec, batch_loss: 0.0802, batch_loss_c: 0.0780, batch_loss_s: 0.0854, time:4.9693, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [390/3125], step: 25390, 7.901 samples/sec, batch_loss: 0.1746, batch_loss_c: 0.1688, batch_loss_s: 0.1880, time:5.0625, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [400/3125], step: 25400, 7.470 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1151, batch_loss_s: 0.1152, time:5.3544, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [410/3125], step: 25410, 7.021 samples/sec, batch_loss: 0.1309, batch_loss_c: 0.1462, batch_loss_s: 0.0953, time:5.6970, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [420/3125], step: 25420, 8.551 samples/sec, batch_loss: 0.3429, batch_loss_c: 0.3577, batch_loss_s: 0.3082, time:4.6778, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [430/3125], step: 25430, 8.584 samples/sec, batch_loss: 0.3481, batch_loss_c: 0.3584, batch_loss_s: 0.3240, time:4.6596, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [440/3125], step: 25440, 8.233 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0746, batch_loss_s: 0.0949, time:4.8587, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:34:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [450/3125], step: 25450, 8.672 samples/sec, batch_loss: 0.0890, batch_loss_c: 0.0937, batch_loss_s: 0.0780, time:4.6127, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [460/3125], step: 25460, 8.098 samples/sec, batch_loss: 0.3632, batch_loss_c: 0.3700, batch_loss_s: 0.3474, time:4.9394, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [470/3125], step: 25470, 8.477 samples/sec, batch_loss: 0.5419, batch_loss_c: 0.5428, batch_loss_s: 0.5398, time:4.7188, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [480/3125], step: 25480, 7.852 samples/sec, batch_loss: 0.0653, batch_loss_c: 0.0632, batch_loss_s: 0.0701, time:5.0942, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [490/3125], step: 25490, 7.969 samples/sec, batch_loss: 0.2277, batch_loss_c: 0.2670, batch_loss_s: 0.1360, time:5.0195, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [500/3125], step: 25500, 8.200 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1048, batch_loss_s: 0.1288, time:4.8782, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [510/3125], step: 25510, 8.513 samples/sec, batch_loss: 0.3133, batch_loss_c: 0.3117, batch_loss_s: 0.3170, time:4.6985, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [520/3125], step: 25520, 7.943 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.2994, batch_loss_s: 0.3600, time:5.0360, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [530/3125], step: 25530, 9.370 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1570, batch_loss_s: 0.1453, time:4.2688, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [540/3125], step: 25540, 8.643 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1307, batch_loss_s: 0.0812, time:4.6282, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [550/3125], step: 25550, 8.415 samples/sec, batch_loss: 0.0814, batch_loss_c: 0.0789, batch_loss_s: 0.0873, time:4.7533, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [560/3125], step: 25560, 8.966 samples/sec, batch_loss: 0.1500, batch_loss_c: 0.1583, batch_loss_s: 0.1306, time:4.4612, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:35:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [570/3125], step: 25570, 8.310 samples/sec, batch_loss: 0.1244, batch_loss_c: 0.1327, batch_loss_s: 0.1051, time:4.8136, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [580/3125], step: 25580, 8.725 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0842, batch_loss_s: 0.0942, time:4.5843, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [590/3125], step: 25590, 8.470 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.1570, batch_loss_s: 0.2373, time:4.7227, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [600/3125], step: 25600, 8.626 samples/sec, batch_loss: 0.0757, batch_loss_c: 0.0723, batch_loss_s: 0.0836, time:4.6369, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [610/3125], step: 25610, 8.703 samples/sec, batch_loss: 0.0828, batch_loss_c: 0.0822, batch_loss_s: 0.0841, time:4.5960, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [620/3125], step: 25620, 8.810 samples/sec, batch_loss: 0.0925, batch_loss_c: 0.0943, batch_loss_s: 0.0883, time:4.5402, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [630/3125], step: 25630, 8.329 samples/sec, batch_loss: 0.1101, batch_loss_c: 0.1111, batch_loss_s: 0.1078, time:4.8024, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [640/3125], step: 25640, 8.540 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0983, batch_loss_s: 0.0693, time:4.6840, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [650/3125], step: 25650, 8.118 samples/sec, batch_loss: 0.2844, batch_loss_c: 0.2793, batch_loss_s: 0.2963, time:4.9272, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [660/3125], step: 25660, 8.381 samples/sec, batch_loss: 0.0658, batch_loss_c: 0.0635, batch_loss_s: 0.0713, time:4.7727, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [670/3125], step: 25670, 7.585 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1276, batch_loss_s: 0.1152, time:5.2737, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [680/3125], step: 25680, 8.795 samples/sec, batch_loss: 0.2046, batch_loss_c: 0.2106, batch_loss_s: 0.1906, time:4.5481, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [690/3125], step: 25690, 7.678 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0806, batch_loss_s: 0.0810, time:5.2100, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:36:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [700/3125], step: 25700, 8.308 samples/sec, batch_loss: 0.1111, batch_loss_c: 0.1357, batch_loss_s: 0.0536, time:4.8146, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [710/3125], step: 25710, 7.866 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0964, batch_loss_s: 0.0897, time:5.0853, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [720/3125], step: 25720, 8.623 samples/sec, batch_loss: 0.4567, batch_loss_c: 0.4250, batch_loss_s: 0.5308, time:4.6388, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [730/3125], step: 25730, 7.953 samples/sec, batch_loss: 0.0470, batch_loss_c: 0.0435, batch_loss_s: 0.0553, time:5.0294, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [740/3125], step: 25740, 7.895 samples/sec, batch_loss: 0.3091, batch_loss_c: 0.3107, batch_loss_s: 0.3056, time:5.0663, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:23 \u001b[32mINFO     \u001b[0m train.py: [8/10], [750/3125], step: 25750, 8.577 samples/sec, batch_loss: 0.1244, batch_loss_c: 0.1265, batch_loss_s: 0.1195, time:4.6636, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [760/3125], step: 25760, 8.456 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0936, batch_loss_s: 0.0992, time:4.7305, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [770/3125], step: 25770, 8.200 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.0960, batch_loss_s: 0.1131, time:4.8781, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [780/3125], step: 25780, 8.450 samples/sec, batch_loss: 0.3103, batch_loss_c: 0.3024, batch_loss_s: 0.3287, time:4.7337, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [790/3125], step: 25790, 8.527 samples/sec, batch_loss: 0.3178, batch_loss_c: 0.3118, batch_loss_s: 0.3318, time:4.6912, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [800/3125], step: 25800, 7.756 samples/sec, batch_loss: 0.1167, batch_loss_c: 0.1152, batch_loss_s: 0.1200, time:5.1576, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [810/3125], step: 25810, 7.871 samples/sec, batch_loss: 0.2738, batch_loss_c: 0.2562, batch_loss_s: 0.3148, time:5.0817, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:37:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [820/3125], step: 25820, 7.660 samples/sec, batch_loss: 0.1194, batch_loss_c: 0.1121, batch_loss_s: 0.1366, time:5.2216, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [830/3125], step: 25830, 8.911 samples/sec, batch_loss: 0.0660, batch_loss_c: 0.0667, batch_loss_s: 0.0646, time:4.4890, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [840/3125], step: 25840, 8.286 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3263, batch_loss_s: 0.3107, time:4.8277, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [850/3125], step: 25850, 7.601 samples/sec, batch_loss: 0.0954, batch_loss_c: 0.1088, batch_loss_s: 0.0639, time:5.2626, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [860/3125], step: 25860, 7.127 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1304, batch_loss_s: 0.0952, time:5.6126, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [870/3125], step: 25870, 8.078 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.2978, batch_loss_s: 0.3164, time:4.9516, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [880/3125], step: 25880, 9.303 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1341, batch_loss_s: 0.0756, time:4.2997, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [890/3125], step: 25890, 8.736 samples/sec, batch_loss: 0.4033, batch_loss_c: 0.4184, batch_loss_s: 0.3683, time:4.5790, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:37 \u001b[32mINFO     \u001b[0m train.py: [8/10], [900/3125], step: 25900, 7.167 samples/sec, batch_loss: 0.3170, batch_loss_c: 0.3168, batch_loss_s: 0.3174, time:5.5810, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [910/3125], step: 25910, 8.882 samples/sec, batch_loss: 0.1911, batch_loss_c: 0.1543, batch_loss_s: 0.2770, time:4.5035, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [920/3125], step: 25920, 8.311 samples/sec, batch_loss: 0.3159, batch_loss_c: 0.3116, batch_loss_s: 0.3260, time:4.8132, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:51 \u001b[32mINFO     \u001b[0m train.py: [8/10], [930/3125], step: 25930, 7.705 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0572, batch_loss_s: 0.0633, time:5.1913, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:38:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [940/3125], step: 25940, 8.956 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3075, batch_loss_s: 0.3225, time:4.4661, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [950/3125], step: 25950, 7.762 samples/sec, batch_loss: 0.0500, batch_loss_c: 0.0469, batch_loss_s: 0.0572, time:5.1531, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:06 \u001b[32mINFO     \u001b[0m train.py: [8/10], [960/3125], step: 25960, 8.107 samples/sec, batch_loss: 0.0583, batch_loss_c: 0.0527, batch_loss_s: 0.0713, time:4.9337, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [970/3125], step: 25970, 8.738 samples/sec, batch_loss: 0.2131, batch_loss_c: 0.2435, batch_loss_s: 0.1421, time:4.5776, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [980/3125], step: 25980, 8.647 samples/sec, batch_loss: 0.1195, batch_loss_c: 0.1312, batch_loss_s: 0.0921, time:4.6259, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [990/3125], step: 25990, 8.202 samples/sec, batch_loss: 0.3017, batch_loss_c: 0.2960, batch_loss_s: 0.3150, time:4.8768, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:25 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1000/3125], step: 26000, 8.691 samples/sec, batch_loss: 0.0600, batch_loss_c: 0.0620, batch_loss_s: 0.0554, time:4.6024, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1010/3125], step: 26010, 8.272 samples/sec, batch_loss: 0.0573, batch_loss_c: 0.0622, batch_loss_s: 0.0461, time:4.8356, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1020/3125], step: 26020, 8.372 samples/sec, batch_loss: 0.3016, batch_loss_c: 0.2999, batch_loss_s: 0.3053, time:4.7778, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1030/3125], step: 26030, 7.808 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.0995, batch_loss_s: 0.1269, time:5.1228, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1040/3125], step: 26040, 7.492 samples/sec, batch_loss: 0.1191, batch_loss_c: 0.1344, batch_loss_s: 0.0835, time:5.3390, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1050/3125], step: 26050, 8.931 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3065, batch_loss_s: 0.3328, time:4.4786, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1060/3125], step: 26060, 7.996 samples/sec, batch_loss: 0.0724, batch_loss_c: 0.0785, batch_loss_s: 0.0583, time:5.0028, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:39:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1070/3125], step: 26070, 9.049 samples/sec, batch_loss: 0.3234, batch_loss_c: 0.3210, batch_loss_s: 0.3293, time:4.4204, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1080/3125], step: 26080, 8.714 samples/sec, batch_loss: 0.0470, batch_loss_c: 0.0459, batch_loss_s: 0.0496, time:4.5905, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1090/3125], step: 26090, 7.091 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0823, batch_loss_s: 0.0954, time:5.6409, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1100/3125], step: 26100, 8.442 samples/sec, batch_loss: 0.0578, batch_loss_c: 0.0549, batch_loss_s: 0.0644, time:4.7383, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:18 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1110/3125], step: 26110, 8.164 samples/sec, batch_loss: 0.3345, batch_loss_c: 0.3443, batch_loss_s: 0.3116, time:4.8994, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1120/3125], step: 26120, 7.648 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3162, batch_loss_s: 0.3191, time:5.2304, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1130/3125], step: 26130, 7.873 samples/sec, batch_loss: 0.3273, batch_loss_c: 0.3162, batch_loss_s: 0.3534, time:5.0808, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1140/3125], step: 26140, 7.817 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1294, batch_loss_s: 0.0976, time:5.1171, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1150/3125], step: 26150, 8.644 samples/sec, batch_loss: 0.3079, batch_loss_c: 0.3071, batch_loss_s: 0.3098, time:4.6276, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1160/3125], step: 26160, 8.392 samples/sec, batch_loss: 0.3231, batch_loss_c: 0.3295, batch_loss_s: 0.3081, time:4.7665, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1170/3125], step: 26170, 8.357 samples/sec, batch_loss: 0.0626, batch_loss_c: 0.0592, batch_loss_s: 0.0705, time:4.7867, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1180/3125], step: 26180, 7.657 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0783, batch_loss_s: 0.0878, time:5.2242, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:40:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1190/3125], step: 26190, 8.337 samples/sec, batch_loss: 0.2605, batch_loss_c: 0.2415, batch_loss_s: 0.3047, time:4.7980, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1200/3125], step: 26200, 8.099 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.3039, batch_loss_s: 0.2603, time:4.9391, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1210/3125], step: 26210, 7.909 samples/sec, batch_loss: 0.1617, batch_loss_c: 0.1788, batch_loss_s: 0.1217, time:5.0575, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1220/3125], step: 26220, 8.690 samples/sec, batch_loss: 0.3119, batch_loss_c: 0.3141, batch_loss_s: 0.3068, time:4.6028, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1230/3125], step: 26230, 9.327 samples/sec, batch_loss: 0.1819, batch_loss_c: 0.2115, batch_loss_s: 0.1129, time:4.2885, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1240/3125], step: 26240, 8.172 samples/sec, batch_loss: 0.0528, batch_loss_c: 0.0480, batch_loss_s: 0.0641, time:4.8947, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1250/3125], step: 26250, 8.099 samples/sec, batch_loss: 0.3406, batch_loss_c: 0.3508, batch_loss_s: 0.3169, time:4.9387, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1260/3125], step: 26260, 8.914 samples/sec, batch_loss: 0.0641, batch_loss_c: 0.0644, batch_loss_s: 0.0636, time:4.4872, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1270/3125], step: 26270, 9.191 samples/sec, batch_loss: 0.1263, batch_loss_c: 0.1426, batch_loss_s: 0.0882, time:4.3522, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1280/3125], step: 26280, 8.809 samples/sec, batch_loss: 0.3344, batch_loss_c: 0.3508, batch_loss_s: 0.2961, time:4.5407, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1290/3125], step: 26290, 8.953 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.1047, batch_loss_s: 0.0656, time:4.4678, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1300/3125], step: 26300, 9.224 samples/sec, batch_loss: 0.0889, batch_loss_c: 0.0879, batch_loss_s: 0.0912, time:4.3367, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1310/3125], step: 26310, 8.264 samples/sec, batch_loss: 0.3047, batch_loss_c: 0.2988, batch_loss_s: 0.3183, time:4.8401, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:41:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1320/3125], step: 26320, 9.104 samples/sec, batch_loss: 0.0763, batch_loss_c: 0.0735, batch_loss_s: 0.0829, time:4.3938, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1330/3125], step: 26330, 8.280 samples/sec, batch_loss: 0.2949, batch_loss_c: 0.2810, batch_loss_s: 0.3272, time:4.8307, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1340/3125], step: 26340, 9.002 samples/sec, batch_loss: 0.0784, batch_loss_c: 0.0765, batch_loss_s: 0.0827, time:4.4434, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1350/3125], step: 26350, 9.331 samples/sec, batch_loss: 0.0718, batch_loss_c: 0.0699, batch_loss_s: 0.0761, time:4.2870, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1360/3125], step: 26360, 8.332 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0688, batch_loss_s: 0.0523, time:4.8007, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1370/3125], step: 26370, 9.097 samples/sec, batch_loss: 0.3069, batch_loss_c: 0.3053, batch_loss_s: 0.3107, time:4.3970, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1380/3125], step: 26380, 8.828 samples/sec, batch_loss: 0.2580, batch_loss_c: 0.2461, batch_loss_s: 0.2858, time:4.5312, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1390/3125], step: 26390, 8.825 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1181, batch_loss_s: 0.0981, time:4.5326, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:35 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1400/3125], step: 26400, 8.120 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1119, batch_loss_s: 0.1441, time:4.9261, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1410/3125], step: 26410, 8.195 samples/sec, batch_loss: 0.3750, batch_loss_c: 0.3726, batch_loss_s: 0.3806, time:4.8813, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1420/3125], step: 26420, 9.317 samples/sec, batch_loss: 0.0847, batch_loss_c: 0.0835, batch_loss_s: 0.0875, time:4.2931, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1430/3125], step: 26430, 8.328 samples/sec, batch_loss: 0.3578, batch_loss_c: 0.3766, batch_loss_s: 0.3140, time:4.8032, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1440/3125], step: 26440, 7.343 samples/sec, batch_loss: 0.3052, batch_loss_c: 0.2933, batch_loss_s: 0.3332, time:5.4476, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:42:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1450/3125], step: 26450, 8.046 samples/sec, batch_loss: 0.0990, batch_loss_c: 0.0546, batch_loss_s: 0.2025, time:4.9711, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1460/3125], step: 26460, 7.852 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.0980, batch_loss_s: 0.0949, time:5.0943, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1470/3125], step: 26470, 7.980 samples/sec, batch_loss: 0.1084, batch_loss_c: 0.1112, batch_loss_s: 0.1019, time:5.0127, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1480/3125], step: 26480, 8.043 samples/sec, batch_loss: 0.0756, batch_loss_c: 0.0695, batch_loss_s: 0.0896, time:4.9735, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1490/3125], step: 26490, 7.940 samples/sec, batch_loss: 0.2898, batch_loss_c: 0.2790, batch_loss_s: 0.3148, time:5.0375, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1500/3125], step: 26500, 8.751 samples/sec, batch_loss: 0.1387, batch_loss_c: 0.1566, batch_loss_s: 0.0968, time:4.5709, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1510/3125], step: 26510, 8.019 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0695, batch_loss_s: 0.0847, time:4.9882, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1520/3125], step: 26520, 7.953 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0618, batch_loss_s: 0.0728, time:5.0295, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1530/3125], step: 26530, 9.004 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1050, batch_loss_s: 0.1067, time:4.4424, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1540/3125], step: 26540, 8.393 samples/sec, batch_loss: 0.5678, batch_loss_c: 0.5695, batch_loss_s: 0.5637, time:4.7662, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1550/3125], step: 26550, 7.700 samples/sec, batch_loss: 0.7552, batch_loss_c: 0.7469, batch_loss_s: 0.7747, time:5.1951, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1560/3125], step: 26560, 8.762 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0855, batch_loss_s: 0.0791, time:4.5653, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:43:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1570/3125], step: 26570, 8.017 samples/sec, batch_loss: 0.1629, batch_loss_c: 0.1864, batch_loss_s: 0.1080, time:4.9896, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1580/3125], step: 26580, 8.773 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0811, batch_loss_s: 0.1018, time:4.5593, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1590/3125], step: 26590, 8.550 samples/sec, batch_loss: 0.3436, batch_loss_c: 0.3415, batch_loss_s: 0.3482, time:4.6783, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1600/3125], step: 26600, 7.804 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1137, batch_loss_s: 0.0673, time:5.1254, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1610/3125], step: 26610, 8.173 samples/sec, batch_loss: 0.0677, batch_loss_c: 0.0670, batch_loss_s: 0.0694, time:4.8941, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1620/3125], step: 26620, 8.313 samples/sec, batch_loss: 0.5482, batch_loss_c: 0.5508, batch_loss_s: 0.5422, time:4.8118, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1630/3125], step: 26630, 8.135 samples/sec, batch_loss: 0.1881, batch_loss_c: 0.2062, batch_loss_s: 0.1459, time:4.9172, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1640/3125], step: 26640, 9.046 samples/sec, batch_loss: 0.1807, batch_loss_c: 0.1839, batch_loss_s: 0.1731, time:4.4220, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1650/3125], step: 26650, 8.577 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.0978, batch_loss_s: 0.1168, time:4.6637, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1660/3125], step: 26660, 9.214 samples/sec, batch_loss: 0.0899, batch_loss_c: 0.0887, batch_loss_s: 0.0926, time:4.3412, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1670/3125], step: 26670, 8.094 samples/sec, batch_loss: 0.0936, batch_loss_c: 0.0952, batch_loss_s: 0.0898, time:4.9421, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1680/3125], step: 26680, 9.249 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1224, batch_loss_s: 0.1216, time:4.3248, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:44:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1690/3125], step: 26690, 7.434 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0839, batch_loss_s: 0.0798, time:5.3809, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:00 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1700/3125], step: 26700, 7.991 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0659, batch_loss_s: 0.0750, time:5.0055, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1710/3125], step: 26710, 8.933 samples/sec, batch_loss: 0.3538, batch_loss_c: 0.3578, batch_loss_s: 0.3444, time:4.4779, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1720/3125], step: 26720, 8.388 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1044, batch_loss_s: 0.0832, time:4.7688, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1730/3125], step: 26730, 7.964 samples/sec, batch_loss: 0.0787, batch_loss_c: 0.0752, batch_loss_s: 0.0868, time:5.0228, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1740/3125], step: 26740, 7.648 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0982, batch_loss_s: 0.0952, time:5.2303, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1750/3125], step: 26750, 8.446 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0997, batch_loss_s: 0.0983, time:4.7358, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1760/3125], step: 26760, 8.522 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1248, batch_loss_s: 0.0867, time:4.6936, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1770/3125], step: 26770, 8.697 samples/sec, batch_loss: 0.2165, batch_loss_c: 0.2276, batch_loss_s: 0.1906, time:4.5992, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1780/3125], step: 26780, 8.898 samples/sec, batch_loss: 0.2959, batch_loss_c: 0.2826, batch_loss_s: 0.3269, time:4.4953, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1790/3125], step: 26790, 7.829 samples/sec, batch_loss: 0.2028, batch_loss_c: 0.2276, batch_loss_s: 0.1448, time:5.1090, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1800/3125], step: 26800, 8.549 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0744, batch_loss_s: 0.0624, time:4.6790, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1810/3125], step: 26810, 8.992 samples/sec, batch_loss: 0.5485, batch_loss_c: 0.5507, batch_loss_s: 0.5434, time:4.4484, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:45:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1820/3125], step: 26820, 8.618 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0967, batch_loss_s: 0.0985, time:4.6415, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1830/3125], step: 26830, 8.245 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0735, batch_loss_s: 0.0601, time:4.8513, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1840/3125], step: 26840, 8.480 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0731, batch_loss_s: 0.0881, time:4.7172, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1850/3125], step: 26850, 8.194 samples/sec, batch_loss: 0.3659, batch_loss_c: 0.3708, batch_loss_s: 0.3546, time:4.8814, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1860/3125], step: 26860, 8.395 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.0852, batch_loss_s: 0.1061, time:4.7648, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1870/3125], step: 26870, 7.719 samples/sec, batch_loss: 0.1102, batch_loss_c: 0.1188, batch_loss_s: 0.0901, time:5.1822, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1880/3125], step: 26880, 8.536 samples/sec, batch_loss: 0.2583, batch_loss_c: 0.2587, batch_loss_s: 0.2574, time:4.6861, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1890/3125], step: 26890, 9.002 samples/sec, batch_loss: 0.3033, batch_loss_c: 0.2969, batch_loss_s: 0.3183, time:4.4435, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1900/3125], step: 26900, 7.784 samples/sec, batch_loss: 0.3085, batch_loss_c: 0.3067, batch_loss_s: 0.3128, time:5.1385, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1910/3125], step: 26910, 7.982 samples/sec, batch_loss: 0.1005, batch_loss_c: 0.0998, batch_loss_s: 0.1019, time:5.0113, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1920/3125], step: 26920, 8.626 samples/sec, batch_loss: 0.1782, batch_loss_c: 0.1907, batch_loss_s: 0.1492, time:4.6370, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1930/3125], step: 26930, 8.081 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0960, batch_loss_s: 0.0743, time:4.9496, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:46:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1940/3125], step: 26940, 8.512 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.0970, batch_loss_s: 0.0787, time:4.6992, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:00 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1950/3125], step: 26950, 8.043 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0719, batch_loss_s: 0.0814, time:4.9730, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1960/3125], step: 26960, 8.900 samples/sec, batch_loss: 0.3099, batch_loss_c: 0.3101, batch_loss_s: 0.3095, time:4.4942, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1970/3125], step: 26970, 8.174 samples/sec, batch_loss: 0.1318, batch_loss_c: 0.1346, batch_loss_s: 0.1254, time:4.8937, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1980/3125], step: 26980, 8.580 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0725, batch_loss_s: 0.0836, time:4.6619, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [1990/3125], step: 26990, 7.382 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0672, batch_loss_s: 0.0790, time:5.4183, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2000/3125], step: 27000, 8.352 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.1038, batch_loss_s: 0.0893, time:4.7894, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2010/3125], step: 27010, 8.304 samples/sec, batch_loss: 0.0812, batch_loss_c: 0.0810, batch_loss_s: 0.0815, time:4.8168, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2020/3125], step: 27020, 8.256 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0847, batch_loss_s: 0.0923, time:4.8447, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2030/3125], step: 27030, 8.590 samples/sec, batch_loss: 0.1294, batch_loss_c: 0.1430, batch_loss_s: 0.0978, time:4.6567, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2040/3125], step: 27040, 8.593 samples/sec, batch_loss: 0.0865, batch_loss_c: 0.0810, batch_loss_s: 0.0993, time:4.6551, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2050/3125], step: 27050, 7.826 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1104, batch_loss_s: 0.1204, time:5.1109, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2060/3125], step: 27060, 8.328 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1223, batch_loss_s: 0.1114, time:4.8030, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:47:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2070/3125], step: 27070, 8.538 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3266, batch_loss_s: 0.3206, time:4.6847, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2080/3125], step: 27080, 8.236 samples/sec, batch_loss: 0.0815, batch_loss_c: 0.0757, batch_loss_s: 0.0952, time:4.8569, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:08 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2090/3125], step: 27090, 7.891 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1150, batch_loss_s: 0.1049, time:5.0693, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2100/3125], step: 27100, 8.138 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.0809, batch_loss_s: 0.1392, time:4.9155, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2110/3125], step: 27110, 8.438 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0631, batch_loss_s: 0.0902, time:4.7406, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2120/3125], step: 27120, 8.418 samples/sec, batch_loss: 0.0663, batch_loss_c: 0.0625, batch_loss_s: 0.0752, time:4.7520, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2130/3125], step: 27130, 7.953 samples/sec, batch_loss: 0.1165, batch_loss_c: 0.1101, batch_loss_s: 0.1316, time:5.0297, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2140/3125], step: 27140, 8.660 samples/sec, batch_loss: 0.0888, batch_loss_c: 0.0826, batch_loss_s: 0.1033, time:4.6192, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2150/3125], step: 27150, 8.805 samples/sec, batch_loss: 0.3063, batch_loss_c: 0.3053, batch_loss_s: 0.3088, time:4.5430, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2160/3125], step: 27160, 8.561 samples/sec, batch_loss: 0.0549, batch_loss_c: 0.0519, batch_loss_s: 0.0618, time:4.6723, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2170/3125], step: 27170, 8.493 samples/sec, batch_loss: 0.2885, batch_loss_c: 0.2818, batch_loss_s: 0.3043, time:4.7098, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2180/3125], step: 27180, 9.042 samples/sec, batch_loss: 0.5016, batch_loss_c: 0.4867, batch_loss_s: 0.5363, time:4.4240, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:48:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2190/3125], step: 27190, 8.427 samples/sec, batch_loss: 0.1001, batch_loss_c: 0.0961, batch_loss_s: 0.1094, time:4.7469, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:00 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2200/3125], step: 27200, 8.414 samples/sec, batch_loss: 0.1176, batch_loss_c: 0.1182, batch_loss_s: 0.1162, time:4.7541, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2210/3125], step: 27210, 8.172 samples/sec, batch_loss: 0.0849, batch_loss_c: 0.0875, batch_loss_s: 0.0790, time:4.8950, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2220/3125], step: 27220, 8.051 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0928, batch_loss_s: 0.0934, time:4.9685, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2230/3125], step: 27230, 8.113 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.0983, batch_loss_s: 0.1103, time:4.9301, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2240/3125], step: 27240, 8.914 samples/sec, batch_loss: 0.1480, batch_loss_c: 0.1618, batch_loss_s: 0.1158, time:4.4874, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2250/3125], step: 27250, 7.697 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0838, batch_loss_s: 0.0700, time:5.1970, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2260/3125], step: 27260, 8.687 samples/sec, batch_loss: 0.3125, batch_loss_c: 0.3122, batch_loss_s: 0.3132, time:4.6044, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2270/3125], step: 27270, 8.909 samples/sec, batch_loss: 0.0941, batch_loss_c: 0.0925, batch_loss_s: 0.0980, time:4.4897, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2280/3125], step: 27280, 8.680 samples/sec, batch_loss: 0.3151, batch_loss_c: 0.3254, batch_loss_s: 0.2909, time:4.6084, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:42 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2290/3125], step: 27290, 9.295 samples/sec, batch_loss: 0.3063, batch_loss_c: 0.3042, batch_loss_s: 0.3110, time:4.3033, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:47 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2300/3125], step: 27300, 8.868 samples/sec, batch_loss: 0.0689, batch_loss_c: 0.0647, batch_loss_s: 0.0788, time:4.5107, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:52 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2310/3125], step: 27310, 8.295 samples/sec, batch_loss: 0.3135, batch_loss_c: 0.3067, batch_loss_s: 0.3296, time:4.8222, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:49:56 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2320/3125], step: 27320, 8.559 samples/sec, batch_loss: 0.1709, batch_loss_c: 0.1862, batch_loss_s: 0.1350, time:4.6737, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2330/3125], step: 27330, 8.150 samples/sec, batch_loss: 0.0509, batch_loss_c: 0.0482, batch_loss_s: 0.0574, time:4.9079, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:06 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2340/3125], step: 27340, 7.815 samples/sec, batch_loss: 0.1392, batch_loss_c: 0.1412, batch_loss_s: 0.1347, time:5.1184, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:11 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2350/3125], step: 27350, 8.857 samples/sec, batch_loss: 0.3575, batch_loss_c: 0.3637, batch_loss_s: 0.3430, time:4.5160, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2360/3125], step: 27360, 7.699 samples/sec, batch_loss: 0.1609, batch_loss_c: 0.1453, batch_loss_s: 0.1974, time:5.1955, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:21 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2370/3125], step: 27370, 8.466 samples/sec, batch_loss: 0.6845, batch_loss_c: 0.6490, batch_loss_s: 0.7674, time:4.7247, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:26 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2380/3125], step: 27380, 8.321 samples/sec, batch_loss: 0.0999, batch_loss_c: 0.1008, batch_loss_s: 0.0978, time:4.8071, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:30 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2390/3125], step: 27390, 8.206 samples/sec, batch_loss: 0.0694, batch_loss_c: 0.0610, batch_loss_s: 0.0891, time:4.8744, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:35 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2400/3125], step: 27400, 7.818 samples/sec, batch_loss: 0.0767, batch_loss_c: 0.0799, batch_loss_s: 0.0695, time:5.1166, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:40 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2410/3125], step: 27410, 8.763 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0634, batch_loss_s: 0.0862, time:4.5647, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:45 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2420/3125], step: 27420, 8.513 samples/sec, batch_loss: 0.3392, batch_loss_c: 0.3465, batch_loss_s: 0.3220, time:4.6988, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2430/3125], step: 27430, 8.003 samples/sec, batch_loss: 0.1566, batch_loss_c: 0.1680, batch_loss_s: 0.1298, time:4.9981, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2440/3125], step: 27440, 8.512 samples/sec, batch_loss: 0.1587, batch_loss_c: 0.1873, batch_loss_s: 0.0921, time:4.6991, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:50:59 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2450/3125], step: 27450, 8.363 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1410, batch_loss_s: 0.1067, time:4.7827, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:04 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2460/3125], step: 27460, 7.867 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3222, batch_loss_s: 0.3203, time:5.0843, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2470/3125], step: 27470, 7.295 samples/sec, batch_loss: 0.2019, batch_loss_c: 0.2066, batch_loss_s: 0.1910, time:5.4835, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2480/3125], step: 27480, 7.897 samples/sec, batch_loss: 0.1208, batch_loss_c: 0.1274, batch_loss_s: 0.1054, time:5.0654, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2490/3125], step: 27490, 8.645 samples/sec, batch_loss: 0.2415, batch_loss_c: 0.2514, batch_loss_s: 0.2183, time:4.6268, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2500/3125], step: 27500, 9.079 samples/sec, batch_loss: 0.1044, batch_loss_c: 0.1119, batch_loss_s: 0.0867, time:4.4056, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:28 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2510/3125], step: 27510, 8.946 samples/sec, batch_loss: 0.3008, batch_loss_c: 0.2975, batch_loss_s: 0.3086, time:4.4712, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:33 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2520/3125], step: 27520, 8.224 samples/sec, batch_loss: 0.3077, batch_loss_c: 0.2910, batch_loss_s: 0.3466, time:4.8636, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:38 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2530/3125], step: 27530, 8.594 samples/sec, batch_loss: 0.1130, batch_loss_c: 0.1210, batch_loss_s: 0.0942, time:4.6542, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2540/3125], step: 27540, 8.204 samples/sec, batch_loss: 0.0686, batch_loss_c: 0.0672, batch_loss_s: 0.0719, time:4.8759, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2550/3125], step: 27550, 7.902 samples/sec, batch_loss: 0.1474, batch_loss_c: 0.1751, batch_loss_s: 0.0828, time:5.0618, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2560/3125], step: 27560, 8.139 samples/sec, batch_loss: 0.3327, batch_loss_c: 0.3354, batch_loss_s: 0.3263, time:4.9149, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:51:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2570/3125], step: 27570, 7.686 samples/sec, batch_loss: 0.1019, batch_loss_c: 0.1142, batch_loss_s: 0.0731, time:5.2044, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2580/3125], step: 27580, 8.526 samples/sec, batch_loss: 0.0611, batch_loss_c: 0.0592, batch_loss_s: 0.0654, time:4.6917, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2590/3125], step: 27590, 8.380 samples/sec, batch_loss: 0.2043, batch_loss_c: 0.2646, batch_loss_s: 0.0635, time:4.7731, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2600/3125], step: 27600, 8.715 samples/sec, batch_loss: 0.1113, batch_loss_c: 0.1176, batch_loss_s: 0.0966, time:4.5899, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2610/3125], step: 27610, 8.642 samples/sec, batch_loss: 0.4127, batch_loss_c: 0.4045, batch_loss_s: 0.4321, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2620/3125], step: 27620, 8.030 samples/sec, batch_loss: 0.0617, batch_loss_c: 0.0601, batch_loss_s: 0.0654, time:4.9813, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2630/3125], step: 27630, 8.226 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.0969, batch_loss_s: 0.1053, time:4.8626, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:31 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2640/3125], step: 27640, 8.791 samples/sec, batch_loss: 0.0872, batch_loss_c: 0.0940, batch_loss_s: 0.0712, time:4.5501, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2650/3125], step: 27650, 8.758 samples/sec, batch_loss: 0.0958, batch_loss_c: 0.1022, batch_loss_s: 0.0809, time:4.5672, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2660/3125], step: 27660, 7.380 samples/sec, batch_loss: 0.3145, batch_loss_c: 0.3158, batch_loss_s: 0.3114, time:5.4198, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2670/3125], step: 27670, 8.919 samples/sec, batch_loss: 0.4205, batch_loss_c: 0.4483, batch_loss_s: 0.3557, time:4.4848, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2680/3125], step: 27680, 8.837 samples/sec, batch_loss: 0.3416, batch_loss_c: 0.3429, batch_loss_s: 0.3386, time:4.5266, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:52:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2690/3125], step: 27690, 7.665 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0783, batch_loss_s: 0.0932, time:5.2186, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:00 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2700/3125], step: 27700, 8.562 samples/sec, batch_loss: 0.0841, batch_loss_c: 0.0833, batch_loss_s: 0.0860, time:4.6718, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2710/3125], step: 27710, 8.023 samples/sec, batch_loss: 0.3085, batch_loss_c: 0.3020, batch_loss_s: 0.3238, time:4.9858, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:09 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2720/3125], step: 27720, 8.877 samples/sec, batch_loss: 0.0838, batch_loss_c: 0.0841, batch_loss_s: 0.0830, time:4.5061, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:14 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2730/3125], step: 27730, 8.803 samples/sec, batch_loss: 0.0638, batch_loss_c: 0.0628, batch_loss_s: 0.0662, time:4.5437, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2740/3125], step: 27740, 7.412 samples/sec, batch_loss: 0.3068, batch_loss_c: 0.3030, batch_loss_s: 0.3156, time:5.3966, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2750/3125], step: 27750, 7.934 samples/sec, batch_loss: 0.0584, batch_loss_c: 0.0555, batch_loss_s: 0.0652, time:5.0417, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2760/3125], step: 27760, 7.933 samples/sec, batch_loss: 0.0641, batch_loss_c: 0.0613, batch_loss_s: 0.0706, time:5.0422, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2770/3125], step: 27770, 8.075 samples/sec, batch_loss: 0.4632, batch_loss_c: 0.4315, batch_loss_s: 0.5372, time:4.9536, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2780/3125], step: 27780, 8.090 samples/sec, batch_loss: 0.0606, batch_loss_c: 0.0554, batch_loss_s: 0.0725, time:4.9441, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:44 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2790/3125], step: 27790, 8.650 samples/sec, batch_loss: 0.0794, batch_loss_c: 0.0821, batch_loss_s: 0.0731, time:4.6245, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:49 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2800/3125], step: 27800, 8.494 samples/sec, batch_loss: 0.3098, batch_loss_c: 0.3067, batch_loss_s: 0.3169, time:4.7090, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:54 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2810/3125], step: 27810, 8.252 samples/sec, batch_loss: 0.0532, batch_loss_c: 0.0499, batch_loss_s: 0.0609, time:4.8471, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:53:58 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2820/3125], step: 27820, 8.692 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1176, batch_loss_s: 0.0917, time:4.6018, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:03 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2830/3125], step: 27830, 8.885 samples/sec, batch_loss: 0.1712, batch_loss_c: 0.1809, batch_loss_s: 0.1485, time:4.5019, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2840/3125], step: 27840, 8.537 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1028, batch_loss_s: 0.1069, time:4.6857, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:12 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2850/3125], step: 27850, 8.083 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0773, batch_loss_s: 0.0828, time:4.9487, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:17 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2860/3125], step: 27860, 8.409 samples/sec, batch_loss: 0.2862, batch_loss_c: 0.2846, batch_loss_s: 0.2898, time:4.7569, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2870/3125], step: 27870, 8.623 samples/sec, batch_loss: 0.0940, batch_loss_c: 0.0994, batch_loss_s: 0.0813, time:4.6387, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:27 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2880/3125], step: 27880, 8.111 samples/sec, batch_loss: 0.0791, batch_loss_c: 0.0731, batch_loss_s: 0.0930, time:4.9313, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:32 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2890/3125], step: 27890, 8.187 samples/sec, batch_loss: 0.3429, batch_loss_c: 0.3444, batch_loss_s: 0.3395, time:4.8856, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:36 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2900/3125], step: 27900, 8.443 samples/sec, batch_loss: 0.1741, batch_loss_c: 0.1900, batch_loss_s: 0.1371, time:4.7376, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:41 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2910/3125], step: 27910, 7.703 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3172, batch_loss_s: 0.3278, time:5.1927, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:46 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2920/3125], step: 27920, 8.765 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3662, batch_loss_s: 0.3067, time:4.5636, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:50 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2930/3125], step: 27930, 8.980 samples/sec, batch_loss: 0.2969, batch_loss_c: 0.2964, batch_loss_s: 0.2983, time:4.4542, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:54:55 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2940/3125], step: 27940, 8.261 samples/sec, batch_loss: 0.0973, batch_loss_c: 0.0916, batch_loss_s: 0.1106, time:4.8422, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:01 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2950/3125], step: 27950, 7.574 samples/sec, batch_loss: 0.2908, batch_loss_c: 0.2878, batch_loss_s: 0.2978, time:5.2811, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:05 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2960/3125], step: 27960, 8.772 samples/sec, batch_loss: 0.1212, batch_loss_c: 0.1273, batch_loss_s: 0.1071, time:4.5600, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:10 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2970/3125], step: 27970, 8.019 samples/sec, batch_loss: 0.0471, batch_loss_c: 0.0461, batch_loss_s: 0.0494, time:4.9882, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:15 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2980/3125], step: 27980, 8.928 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0922, batch_loss_s: 0.0958, time:4.4802, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:19 \u001b[32mINFO     \u001b[0m train.py: [8/10], [2990/3125], step: 27990, 8.687 samples/sec, batch_loss: 0.0666, batch_loss_c: 0.0596, batch_loss_s: 0.0829, time:4.6048, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:24 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3000/3125], step: 28000, 8.202 samples/sec, batch_loss: 0.3042, batch_loss_c: 0.2930, batch_loss_s: 0.3304, time:4.8766, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:29 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3010/3125], step: 28010, 7.540 samples/sec, batch_loss: 0.3220, batch_loss_c: 0.3204, batch_loss_s: 0.3257, time:5.3052, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:34 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3020/3125], step: 28020, 8.932 samples/sec, batch_loss: 0.1013, batch_loss_c: 0.1124, batch_loss_s: 0.0752, time:4.4782, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:39 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3030/3125], step: 28030, 8.414 samples/sec, batch_loss: 0.0876, batch_loss_c: 0.0808, batch_loss_s: 0.1034, time:4.7540, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:43 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3040/3125], step: 28040, 8.381 samples/sec, batch_loss: 0.1752, batch_loss_c: 0.1917, batch_loss_s: 0.1369, time:4.7727, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:48 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3050/3125], step: 28050, 8.519 samples/sec, batch_loss: 0.3584, batch_loss_c: 0.3756, batch_loss_s: 0.3182, time:4.6955, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:53 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3060/3125], step: 28060, 8.993 samples/sec, batch_loss: 0.3341, batch_loss_c: 0.3442, batch_loss_s: 0.3104, time:4.4477, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:55:57 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3070/3125], step: 28070, 8.952 samples/sec, batch_loss: 0.0714, batch_loss_c: 0.0684, batch_loss_s: 0.0783, time:4.4682, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:02 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3080/3125], step: 28080, 7.990 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0757, batch_loss_s: 0.1001, time:5.0062, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:07 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3090/3125], step: 28090, 7.589 samples/sec, batch_loss: 0.2646, batch_loss_c: 0.2479, batch_loss_s: 0.3037, time:5.2708, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:13 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3100/3125], step: 28100, 7.705 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1063, batch_loss_s: 0.1178, time:5.1911, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:16 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3110/3125], step: 28110, 10.415 samples/sec, batch_loss: 0.3882, batch_loss_c: 0.3890, batch_loss_s: 0.3865, time:3.8406, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:20 \u001b[32mINFO     \u001b[0m train.py: [8/10], [3120/3125], step: 28120, 10.389 samples/sec, batch_loss: 0.0750, batch_loss_c: 0.0692, batch_loss_s: 0.0886, time:3.8503, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:22 \u001b[32mINFO     \u001b[0m train.py: [8/10], train_loss: 0.1676, time: 1513.2592, lr: 0.0001\u001b[0m\n",
            "2019-11-24 12:56:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [0/3125], step: 28125, 8.011 samples/sec, batch_loss: 0.0754, batch_loss_c: 0.0714, batch_loss_s: 0.0846, time:4.9929, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [10/3125], step: 28135, 6.426 samples/sec, batch_loss: 0.0655, batch_loss_c: 0.0582, batch_loss_s: 0.0828, time:6.2250, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [20/3125], step: 28145, 7.687 samples/sec, batch_loss: 0.2799, batch_loss_c: 0.2712, batch_loss_s: 0.3003, time:5.2037, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [30/3125], step: 28155, 8.998 samples/sec, batch_loss: 0.2954, batch_loss_c: 0.2915, batch_loss_s: 0.3046, time:4.4454, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [40/3125], step: 28165, 9.045 samples/sec, batch_loss: 0.1139, batch_loss_c: 0.1125, batch_loss_s: 0.1172, time:4.4223, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [50/3125], step: 28175, 8.373 samples/sec, batch_loss: 0.0625, batch_loss_c: 0.0601, batch_loss_s: 0.0682, time:4.7770, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:56:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [60/3125], step: 28185, 8.212 samples/sec, batch_loss: 0.0704, batch_loss_c: 0.0662, batch_loss_s: 0.0801, time:4.8707, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [70/3125], step: 28195, 8.657 samples/sec, batch_loss: 0.0871, batch_loss_c: 0.0791, batch_loss_s: 0.1058, time:4.6205, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [80/3125], step: 28205, 8.686 samples/sec, batch_loss: 0.0526, batch_loss_c: 0.0494, batch_loss_s: 0.0600, time:4.6052, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [90/3125], step: 28215, 7.330 samples/sec, batch_loss: 0.0707, batch_loss_c: 0.0690, batch_loss_s: 0.0748, time:5.4573, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [100/3125], step: 28225, 7.326 samples/sec, batch_loss: 0.1477, batch_loss_c: 0.1638, batch_loss_s: 0.1102, time:5.4600, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [110/3125], step: 28235, 8.521 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0838, batch_loss_s: 0.0910, time:4.6944, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [120/3125], step: 28245, 8.276 samples/sec, batch_loss: 0.0698, batch_loss_c: 0.0616, batch_loss_s: 0.0889, time:4.8330, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [130/3125], step: 28255, 8.168 samples/sec, batch_loss: 0.0789, batch_loss_c: 0.0723, batch_loss_s: 0.0944, time:4.8973, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [140/3125], step: 28265, 8.767 samples/sec, batch_loss: 0.0694, batch_loss_c: 0.0672, batch_loss_s: 0.0746, time:4.5627, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [150/3125], step: 28275, 7.592 samples/sec, batch_loss: 0.0983, batch_loss_c: 0.1019, batch_loss_s: 0.0900, time:5.2687, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [160/3125], step: 28285, 7.951 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.1010, batch_loss_s: 0.0878, time:5.0306, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [170/3125], step: 28295, 7.931 samples/sec, batch_loss: 0.0866, batch_loss_c: 0.0804, batch_loss_s: 0.1012, time:5.0435, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:57:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [180/3125], step: 28305, 7.129 samples/sec, batch_loss: 0.0682, batch_loss_c: 0.0662, batch_loss_s: 0.0727, time:5.6106, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [190/3125], step: 28315, 8.066 samples/sec, batch_loss: 0.4817, batch_loss_c: 0.4523, batch_loss_s: 0.5502, time:4.9593, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [200/3125], step: 28325, 8.172 samples/sec, batch_loss: 0.2737, batch_loss_c: 0.2656, batch_loss_s: 0.2928, time:4.8950, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [210/3125], step: 28335, 6.884 samples/sec, batch_loss: 0.3289, batch_loss_c: 0.3396, batch_loss_s: 0.3039, time:5.8109, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [220/3125], step: 28345, 8.146 samples/sec, batch_loss: 0.2716, batch_loss_c: 0.2614, batch_loss_s: 0.2952, time:4.9101, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [230/3125], step: 28355, 8.236 samples/sec, batch_loss: 0.1144, batch_loss_c: 0.1167, batch_loss_s: 0.1091, time:4.8565, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [240/3125], step: 28365, 7.656 samples/sec, batch_loss: 0.1257, batch_loss_c: 0.1342, batch_loss_s: 0.1058, time:5.2246, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [250/3125], step: 28375, 7.717 samples/sec, batch_loss: 0.1370, batch_loss_c: 0.1373, batch_loss_s: 0.1365, time:5.1832, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [260/3125], step: 28385, 8.222 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3484, batch_loss_s: 0.3371, time:4.8652, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [270/3125], step: 28395, 7.596 samples/sec, batch_loss: 0.1211, batch_loss_c: 0.1394, batch_loss_s: 0.0784, time:5.2660, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [280/3125], step: 28405, 6.887 samples/sec, batch_loss: 0.2349, batch_loss_c: 0.2207, batch_loss_s: 0.2682, time:5.8084, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:58:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [290/3125], step: 28415, 7.382 samples/sec, batch_loss: 0.0587, batch_loss_c: 0.0543, batch_loss_s: 0.0691, time:5.4186, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [300/3125], step: 28425, 7.210 samples/sec, batch_loss: 0.0850, batch_loss_c: 0.0836, batch_loss_s: 0.0883, time:5.5481, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [310/3125], step: 28435, 7.663 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3208, batch_loss_s: 0.3244, time:5.2200, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [320/3125], step: 28445, 7.965 samples/sec, batch_loss: 0.1806, batch_loss_c: 0.2191, batch_loss_s: 0.0907, time:5.0221, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [330/3125], step: 28455, 8.384 samples/sec, batch_loss: 0.3381, batch_loss_c: 0.3260, batch_loss_s: 0.3662, time:4.7711, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [340/3125], step: 28465, 7.649 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0692, batch_loss_s: 0.0881, time:5.2292, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [350/3125], step: 28475, 7.737 samples/sec, batch_loss: 0.0596, batch_loss_c: 0.0551, batch_loss_s: 0.0703, time:5.1697, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [360/3125], step: 28485, 7.344 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3158, batch_loss_s: 0.3063, time:5.4470, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [370/3125], step: 28495, 7.764 samples/sec, batch_loss: 0.3266, batch_loss_c: 0.3358, batch_loss_s: 0.3049, time:5.1521, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [380/3125], step: 28505, 7.825 samples/sec, batch_loss: 0.0879, batch_loss_c: 0.0955, batch_loss_s: 0.0703, time:5.1119, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [390/3125], step: 28515, 7.267 samples/sec, batch_loss: 0.3279, batch_loss_c: 0.3270, batch_loss_s: 0.3299, time:5.5042, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [400/3125], step: 28525, 8.006 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1236, batch_loss_s: 0.1248, time:4.9965, lr:0.0001\u001b[0m\n",
            "2019-11-24 12:59:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [410/3125], step: 28535, 8.460 samples/sec, batch_loss: 0.0664, batch_loss_c: 0.0668, batch_loss_s: 0.0656, time:4.7282, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [420/3125], step: 28545, 8.347 samples/sec, batch_loss: 0.1418, batch_loss_c: 0.1659, batch_loss_s: 0.0857, time:4.7921, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [430/3125], step: 28555, 7.603 samples/sec, batch_loss: 0.3559, batch_loss_c: 0.3548, batch_loss_s: 0.3586, time:5.2610, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [440/3125], step: 28565, 8.031 samples/sec, batch_loss: 0.2091, batch_loss_c: 0.2069, batch_loss_s: 0.2141, time:4.9810, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [450/3125], step: 28575, 7.945 samples/sec, batch_loss: 0.0898, batch_loss_c: 0.0990, batch_loss_s: 0.0685, time:5.0349, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [460/3125], step: 28585, 8.543 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0716, batch_loss_s: 0.0757, time:4.6819, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [470/3125], step: 28595, 8.085 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0751, batch_loss_s: 0.0859, time:4.9477, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [480/3125], step: 28605, 8.998 samples/sec, batch_loss: 0.3077, batch_loss_c: 0.2893, batch_loss_s: 0.3507, time:4.4454, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [490/3125], step: 28615, 8.880 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0800, batch_loss_s: 0.0785, time:4.5046, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [500/3125], step: 28625, 8.115 samples/sec, batch_loss: 0.0715, batch_loss_c: 0.0688, batch_loss_s: 0.0776, time:4.9294, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [510/3125], step: 28635, 8.509 samples/sec, batch_loss: 0.0994, batch_loss_c: 0.0959, batch_loss_s: 0.1076, time:4.7007, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [520/3125], step: 28645, 8.211 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1203, batch_loss_s: 0.0971, time:4.8718, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [530/3125], step: 28655, 8.624 samples/sec, batch_loss: 0.1106, batch_loss_c: 0.1231, batch_loss_s: 0.0814, time:4.6380, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:00:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [540/3125], step: 28665, 9.043 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1086, batch_loss_s: 0.0926, time:4.4232, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [550/3125], step: 28675, 8.426 samples/sec, batch_loss: 0.0604, batch_loss_c: 0.0560, batch_loss_s: 0.0706, time:4.7475, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [560/3125], step: 28685, 8.092 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0837, batch_loss_s: 0.0728, time:4.9434, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [570/3125], step: 28695, 9.379 samples/sec, batch_loss: 0.1152, batch_loss_c: 0.1171, batch_loss_s: 0.1107, time:4.2650, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [580/3125], step: 28705, 8.754 samples/sec, batch_loss: 0.1025, batch_loss_c: 0.0965, batch_loss_s: 0.1164, time:4.5695, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [590/3125], step: 28715, 8.506 samples/sec, batch_loss: 0.1258, batch_loss_c: 0.1509, batch_loss_s: 0.0674, time:4.7026, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [600/3125], step: 28725, 8.455 samples/sec, batch_loss: 0.0891, batch_loss_c: 0.0937, batch_loss_s: 0.0784, time:4.7309, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [610/3125], step: 28735, 7.991 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1953, batch_loss_s: 0.0748, time:5.0055, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [620/3125], step: 28745, 7.777 samples/sec, batch_loss: 0.3271, batch_loss_c: 0.3365, batch_loss_s: 0.3052, time:5.1435, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [630/3125], step: 28755, 8.776 samples/sec, batch_loss: 0.1115, batch_loss_c: 0.1160, batch_loss_s: 0.1009, time:4.5578, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [640/3125], step: 28765, 8.458 samples/sec, batch_loss: 0.0862, batch_loss_c: 0.0841, batch_loss_s: 0.0911, time:4.7292, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [650/3125], step: 28775, 8.000 samples/sec, batch_loss: 0.3016, batch_loss_c: 0.2959, batch_loss_s: 0.3149, time:5.0002, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:01:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [660/3125], step: 28785, 8.115 samples/sec, batch_loss: 0.4080, batch_loss_c: 0.4182, batch_loss_s: 0.3841, time:4.9292, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [670/3125], step: 28795, 8.311 samples/sec, batch_loss: 0.3069, batch_loss_c: 0.3039, batch_loss_s: 0.3141, time:4.8130, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [680/3125], step: 28805, 8.243 samples/sec, batch_loss: 0.0916, batch_loss_c: 0.0954, batch_loss_s: 0.0826, time:4.8523, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [690/3125], step: 28815, 8.132 samples/sec, batch_loss: 0.4206, batch_loss_c: 0.4527, batch_loss_s: 0.3457, time:4.9187, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [700/3125], step: 28825, 8.726 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1323, batch_loss_s: 0.1045, time:4.5838, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [710/3125], step: 28835, 7.633 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0751, batch_loss_s: 0.0855, time:5.2404, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [720/3125], step: 28845, 8.453 samples/sec, batch_loss: 0.3127, batch_loss_c: 0.3045, batch_loss_s: 0.3318, time:4.7319, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [730/3125], step: 28855, 8.190 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1286, batch_loss_s: 0.0776, time:4.8842, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [740/3125], step: 28865, 8.082 samples/sec, batch_loss: 0.1666, batch_loss_c: 0.1938, batch_loss_s: 0.1030, time:4.9492, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [750/3125], step: 28875, 7.217 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0847, batch_loss_s: 0.1084, time:5.5428, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [760/3125], step: 28885, 7.585 samples/sec, batch_loss: 0.3105, batch_loss_c: 0.2972, batch_loss_s: 0.3415, time:5.2737, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [770/3125], step: 28895, 7.963 samples/sec, batch_loss: 0.4085, batch_loss_c: 0.4172, batch_loss_s: 0.3880, time:5.0235, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:02:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [780/3125], step: 28905, 8.620 samples/sec, batch_loss: 0.0589, batch_loss_c: 0.0555, batch_loss_s: 0.0668, time:4.6404, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [790/3125], step: 28915, 8.583 samples/sec, batch_loss: 0.0491, batch_loss_c: 0.0437, batch_loss_s: 0.0615, time:4.6603, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [800/3125], step: 28925, 8.657 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1097, batch_loss_s: 0.1377, time:4.6203, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [810/3125], step: 28935, 7.760 samples/sec, batch_loss: 0.1118, batch_loss_c: 0.1219, batch_loss_s: 0.0883, time:5.1548, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [820/3125], step: 28945, 8.237 samples/sec, batch_loss: 0.0824, batch_loss_c: 0.0805, batch_loss_s: 0.0868, time:4.8561, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [830/3125], step: 28955, 7.951 samples/sec, batch_loss: 0.0941, batch_loss_c: 0.0994, batch_loss_s: 0.0820, time:5.0309, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [840/3125], step: 28965, 8.237 samples/sec, batch_loss: 0.0590, batch_loss_c: 0.0567, batch_loss_s: 0.0643, time:4.8559, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [850/3125], step: 28975, 8.004 samples/sec, batch_loss: 0.1288, batch_loss_c: 0.1346, batch_loss_s: 0.1151, time:4.9974, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:34 \u001b[32mINFO     \u001b[0m train.py: [9/10], [860/3125], step: 28985, 8.808 samples/sec, batch_loss: 0.0716, batch_loss_c: 0.0700, batch_loss_s: 0.0753, time:4.5415, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [870/3125], step: 28995, 7.821 samples/sec, batch_loss: 0.0498, batch_loss_c: 0.0457, batch_loss_s: 0.0594, time:5.1148, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [880/3125], step: 29005, 7.910 samples/sec, batch_loss: 0.3351, batch_loss_c: 0.3408, batch_loss_s: 0.3217, time:5.0571, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [890/3125], step: 29015, 7.795 samples/sec, batch_loss: 0.3173, batch_loss_c: 0.3272, batch_loss_s: 0.2943, time:5.1318, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [900/3125], step: 29025, 8.021 samples/sec, batch_loss: 0.3113, batch_loss_c: 0.3085, batch_loss_s: 0.3180, time:4.9871, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:03:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [910/3125], step: 29035, 8.400 samples/sec, batch_loss: 0.3332, batch_loss_c: 0.3405, batch_loss_s: 0.3163, time:4.7621, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [920/3125], step: 29045, 8.932 samples/sec, batch_loss: 0.0926, batch_loss_c: 0.0983, batch_loss_s: 0.0792, time:4.4785, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [930/3125], step: 29055, 8.160 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0879, batch_loss_s: 0.0897, time:4.9018, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [940/3125], step: 29065, 8.738 samples/sec, batch_loss: 0.0697, batch_loss_c: 0.0689, batch_loss_s: 0.0715, time:4.5779, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [950/3125], step: 29075, 8.902 samples/sec, batch_loss: 0.0697, batch_loss_c: 0.0637, batch_loss_s: 0.0838, time:4.4936, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [960/3125], step: 29085, 7.857 samples/sec, batch_loss: 0.2641, batch_loss_c: 0.2607, batch_loss_s: 0.2721, time:5.0910, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [970/3125], step: 29095, 8.748 samples/sec, batch_loss: 0.0951, batch_loss_c: 0.0913, batch_loss_s: 0.1041, time:4.5724, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [980/3125], step: 29105, 8.100 samples/sec, batch_loss: 0.0773, batch_loss_c: 0.0807, batch_loss_s: 0.0695, time:4.9383, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [990/3125], step: 29115, 8.069 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0795, batch_loss_s: 0.0987, time:4.9575, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1000/3125], step: 29125, 8.178 samples/sec, batch_loss: 0.1292, batch_loss_c: 0.1312, batch_loss_s: 0.1244, time:4.8912, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1010/3125], step: 29135, 8.234 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0604, batch_loss_s: 0.0696, time:4.8578, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1020/3125], step: 29145, 8.390 samples/sec, batch_loss: 0.3114, batch_loss_c: 0.3057, batch_loss_s: 0.3249, time:4.7677, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:04:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1030/3125], step: 29155, 8.192 samples/sec, batch_loss: 0.1150, batch_loss_c: 0.1205, batch_loss_s: 0.1020, time:4.8827, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1040/3125], step: 29165, 8.594 samples/sec, batch_loss: 0.1201, batch_loss_c: 0.1358, batch_loss_s: 0.0837, time:4.6543, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1050/3125], step: 29175, 8.505 samples/sec, batch_loss: 0.1234, batch_loss_c: 0.1305, batch_loss_s: 0.1066, time:4.7031, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1060/3125], step: 29185, 7.929 samples/sec, batch_loss: 0.0626, batch_loss_c: 0.0577, batch_loss_s: 0.0741, time:5.0445, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1070/3125], step: 29195, 8.194 samples/sec, batch_loss: 0.1262, batch_loss_c: 0.1234, batch_loss_s: 0.1329, time:4.8817, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1080/3125], step: 29205, 8.468 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1160, batch_loss_s: 0.1258, time:4.7237, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1090/3125], step: 29215, 7.495 samples/sec, batch_loss: 0.3102, batch_loss_c: 0.3120, batch_loss_s: 0.3058, time:5.3366, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1100/3125], step: 29225, 8.205 samples/sec, batch_loss: 0.3524, batch_loss_c: 0.3480, batch_loss_s: 0.3628, time:4.8749, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1110/3125], step: 29235, 7.979 samples/sec, batch_loss: 0.1414, batch_loss_c: 0.1388, batch_loss_s: 0.1476, time:5.0130, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1120/3125], step: 29245, 7.986 samples/sec, batch_loss: 0.3162, batch_loss_c: 0.3137, batch_loss_s: 0.3219, time:5.0089, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1130/3125], step: 29255, 8.783 samples/sec, batch_loss: 0.2090, batch_loss_c: 0.2374, batch_loss_s: 0.1426, time:4.5542, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1140/3125], step: 29265, 7.275 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1573, batch_loss_s: 0.1257, time:5.4983, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:05:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1150/3125], step: 29275, 7.623 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.0950, batch_loss_s: 0.1918, time:5.2475, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1160/3125], step: 29285, 7.327 samples/sec, batch_loss: 0.1801, batch_loss_c: 0.1841, batch_loss_s: 0.1706, time:5.4593, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1170/3125], step: 29295, 7.865 samples/sec, batch_loss: 0.3399, batch_loss_c: 0.3417, batch_loss_s: 0.3359, time:5.0856, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1180/3125], step: 29305, 7.876 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0769, batch_loss_s: 0.0755, time:5.0790, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1190/3125], step: 29315, 8.612 samples/sec, batch_loss: 0.0950, batch_loss_c: 0.0993, batch_loss_s: 0.0849, time:4.6449, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1200/3125], step: 29325, 7.695 samples/sec, batch_loss: 0.0695, batch_loss_c: 0.0685, batch_loss_s: 0.0718, time:5.1980, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1210/3125], step: 29335, 7.470 samples/sec, batch_loss: 0.0878, batch_loss_c: 0.0868, batch_loss_s: 0.0901, time:5.3549, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1220/3125], step: 29345, 8.119 samples/sec, batch_loss: 0.0568, batch_loss_c: 0.0519, batch_loss_s: 0.0682, time:4.9266, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1230/3125], step: 29355, 9.020 samples/sec, batch_loss: 0.0848, batch_loss_c: 0.0866, batch_loss_s: 0.0805, time:4.4346, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1240/3125], step: 29365, 8.541 samples/sec, batch_loss: 0.2999, batch_loss_c: 0.2959, batch_loss_s: 0.3094, time:4.6832, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1250/3125], step: 29375, 8.553 samples/sec, batch_loss: 0.1516, batch_loss_c: 0.1571, batch_loss_s: 0.1389, time:4.6766, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1260/3125], step: 29385, 8.984 samples/sec, batch_loss: 0.2809, batch_loss_c: 0.2753, batch_loss_s: 0.2939, time:4.4522, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1270/3125], step: 29395, 8.928 samples/sec, batch_loss: 0.1039, batch_loss_c: 0.0944, batch_loss_s: 0.1259, time:4.4804, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:06:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1280/3125], step: 29405, 8.985 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1244, batch_loss_s: 0.0715, time:4.4517, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1290/3125], step: 29415, 9.213 samples/sec, batch_loss: 0.2372, batch_loss_c: 0.2600, batch_loss_s: 0.1841, time:4.3415, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1300/3125], step: 29425, 8.734 samples/sec, batch_loss: 0.0513, batch_loss_c: 0.0504, batch_loss_s: 0.0533, time:4.5800, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1310/3125], step: 29435, 8.088 samples/sec, batch_loss: 0.1248, batch_loss_c: 0.1415, batch_loss_s: 0.0859, time:4.9456, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1320/3125], step: 29445, 8.695 samples/sec, batch_loss: 0.0632, batch_loss_c: 0.0637, batch_loss_s: 0.0620, time:4.6006, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1330/3125], step: 29455, 8.398 samples/sec, batch_loss: 0.0762, batch_loss_c: 0.0748, batch_loss_s: 0.0795, time:4.7633, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1340/3125], step: 29465, 8.221 samples/sec, batch_loss: 0.0618, batch_loss_c: 0.0590, batch_loss_s: 0.0684, time:4.8658, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1350/3125], step: 29475, 8.718 samples/sec, batch_loss: 0.0783, batch_loss_c: 0.0736, batch_loss_s: 0.0892, time:4.5880, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1360/3125], step: 29485, 8.404 samples/sec, batch_loss: 0.1314, batch_loss_c: 0.1351, batch_loss_s: 0.1226, time:4.7596, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1370/3125], step: 29495, 8.753 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.2946, batch_loss_s: 0.2994, time:4.5699, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1380/3125], step: 29505, 8.893 samples/sec, batch_loss: 0.1004, batch_loss_c: 0.1058, batch_loss_s: 0.0878, time:4.4977, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1390/3125], step: 29515, 8.212 samples/sec, batch_loss: 0.1372, batch_loss_c: 0.1371, batch_loss_s: 0.1376, time:4.8710, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:07:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1400/3125], step: 29525, 7.144 samples/sec, batch_loss: 0.0624, batch_loss_c: 0.0620, batch_loss_s: 0.0633, time:5.5990, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1410/3125], step: 29535, 8.314 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.1057, batch_loss_s: 0.0844, time:4.8109, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1420/3125], step: 29545, 7.666 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0826, batch_loss_s: 0.0971, time:5.2181, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1430/3125], step: 29555, 8.372 samples/sec, batch_loss: 0.0478, batch_loss_c: 0.0450, batch_loss_s: 0.0545, time:4.7777, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1440/3125], step: 29565, 7.765 samples/sec, batch_loss: 0.0633, batch_loss_c: 0.0663, batch_loss_s: 0.0562, time:5.1511, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1450/3125], step: 29575, 8.774 samples/sec, batch_loss: 0.3561, batch_loss_c: 0.3584, batch_loss_s: 0.3506, time:4.5592, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1460/3125], step: 29585, 7.920 samples/sec, batch_loss: 0.0972, batch_loss_c: 0.0976, batch_loss_s: 0.0964, time:5.0505, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1470/3125], step: 29595, 8.693 samples/sec, batch_loss: 0.0557, batch_loss_c: 0.0518, batch_loss_s: 0.0648, time:4.6013, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1480/3125], step: 29605, 9.103 samples/sec, batch_loss: 0.1000, batch_loss_c: 0.1093, batch_loss_s: 0.0783, time:4.3942, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1490/3125], step: 29615, 8.197 samples/sec, batch_loss: 0.3109, batch_loss_c: 0.3055, batch_loss_s: 0.3234, time:4.8797, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1500/3125], step: 29625, 8.100 samples/sec, batch_loss: 0.0779, batch_loss_c: 0.0723, batch_loss_s: 0.0909, time:4.9384, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1510/3125], step: 29635, 8.253 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1502, batch_loss_s: 0.1286, time:4.8470, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1520/3125], step: 29645, 7.831 samples/sec, batch_loss: 0.1490, batch_loss_c: 0.1514, batch_loss_s: 0.1435, time:5.1076, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:08:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1530/3125], step: 29655, 8.458 samples/sec, batch_loss: 0.3137, batch_loss_c: 0.2921, batch_loss_s: 0.3640, time:4.7295, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1540/3125], step: 29665, 8.439 samples/sec, batch_loss: 0.2766, batch_loss_c: 0.2690, batch_loss_s: 0.2943, time:4.7397, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1550/3125], step: 29675, 8.393 samples/sec, batch_loss: 0.0566, batch_loss_c: 0.0523, batch_loss_s: 0.0667, time:4.7660, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1560/3125], step: 29685, 9.346 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0719, batch_loss_s: 0.0941, time:4.2799, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1570/3125], step: 29695, 7.513 samples/sec, batch_loss: 0.0571, batch_loss_c: 0.0545, batch_loss_s: 0.0632, time:5.3242, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1580/3125], step: 29705, 8.475 samples/sec, batch_loss: 0.0938, batch_loss_c: 0.1033, batch_loss_s: 0.0714, time:4.7199, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1590/3125], step: 29715, 8.121 samples/sec, batch_loss: 0.0511, batch_loss_c: 0.0467, batch_loss_s: 0.0613, time:4.9255, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1600/3125], step: 29725, 9.130 samples/sec, batch_loss: 0.0855, batch_loss_c: 0.0825, batch_loss_s: 0.0926, time:4.3812, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1610/3125], step: 29735, 8.388 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0777, batch_loss_s: 0.0837, time:4.7688, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1620/3125], step: 29745, 8.418 samples/sec, batch_loss: 0.0708, batch_loss_c: 0.0679, batch_loss_s: 0.0777, time:4.7520, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1630/3125], step: 29755, 7.979 samples/sec, batch_loss: 0.3281, batch_loss_c: 0.3220, batch_loss_s: 0.3424, time:5.0134, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1640/3125], step: 29765, 7.665 samples/sec, batch_loss: 0.3283, batch_loss_c: 0.3235, batch_loss_s: 0.3396, time:5.2184, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:09:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1650/3125], step: 29775, 8.631 samples/sec, batch_loss: 0.2017, batch_loss_c: 0.2177, batch_loss_s: 0.1645, time:4.6343, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1660/3125], step: 29785, 8.938 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1192, batch_loss_s: 0.0801, time:4.4751, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1670/3125], step: 29795, 8.153 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1046, batch_loss_s: 0.0963, time:4.9060, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1680/3125], step: 29805, 7.716 samples/sec, batch_loss: 0.4831, batch_loss_c: 0.4591, batch_loss_s: 0.5390, time:5.1840, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1690/3125], step: 29815, 9.040 samples/sec, batch_loss: 0.2605, batch_loss_c: 0.2450, batch_loss_s: 0.2968, time:4.4247, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1700/3125], step: 29825, 8.444 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1063, batch_loss_s: 0.1182, time:4.7372, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1710/3125], step: 29835, 8.497 samples/sec, batch_loss: 0.0746, batch_loss_c: 0.0705, batch_loss_s: 0.0840, time:4.7077, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1720/3125], step: 29845, 8.498 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.0960, batch_loss_s: 0.1025, time:4.7072, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1730/3125], step: 29855, 7.903 samples/sec, batch_loss: 0.3377, batch_loss_c: 0.3395, batch_loss_s: 0.3337, time:5.0614, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1740/3125], step: 29865, 8.127 samples/sec, batch_loss: 0.1696, batch_loss_c: 0.1826, batch_loss_s: 0.1392, time:4.9222, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1750/3125], step: 29875, 8.155 samples/sec, batch_loss: 0.0503, batch_loss_c: 0.0459, batch_loss_s: 0.0606, time:4.9049, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1760/3125], step: 29885, 8.266 samples/sec, batch_loss: 0.3249, batch_loss_c: 0.3244, batch_loss_s: 0.3261, time:4.8389, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1770/3125], step: 29895, 8.634 samples/sec, batch_loss: 0.1475, batch_loss_c: 0.1464, batch_loss_s: 0.1502, time:4.6331, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:10:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1780/3125], step: 29905, 8.296 samples/sec, batch_loss: 0.0732, batch_loss_c: 0.0789, batch_loss_s: 0.0599, time:4.8217, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:04 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1790/3125], step: 29915, 8.042 samples/sec, batch_loss: 0.0635, batch_loss_c: 0.0669, batch_loss_s: 0.0557, time:4.9737, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:09 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1800/3125], step: 29925, 8.578 samples/sec, batch_loss: 0.0562, batch_loss_c: 0.0549, batch_loss_s: 0.0592, time:4.6632, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:14 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1810/3125], step: 29935, 8.392 samples/sec, batch_loss: 0.2831, batch_loss_c: 0.2810, batch_loss_s: 0.2880, time:4.7667, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1820/3125], step: 29945, 8.207 samples/sec, batch_loss: 0.3584, batch_loss_c: 0.3857, batch_loss_s: 0.2947, time:4.8737, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1830/3125], step: 29955, 8.670 samples/sec, batch_loss: 0.1592, batch_loss_c: 0.1622, batch_loss_s: 0.1521, time:4.6138, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1840/3125], step: 29965, 7.976 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0900, batch_loss_s: 0.0967, time:5.0150, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1850/3125], step: 29975, 8.478 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0620, batch_loss_s: 0.0794, time:4.7181, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1860/3125], step: 29985, 9.081 samples/sec, batch_loss: 0.5983, batch_loss_c: 0.6021, batch_loss_s: 0.5894, time:4.4047, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1870/3125], step: 29995, 8.476 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0920, batch_loss_s: 0.1074, time:4.7190, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1880/3125], step: 30005, 8.731 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.1024, batch_loss_s: 0.0992, time:4.5816, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:51 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1890/3125], step: 30015, 8.160 samples/sec, batch_loss: 0.0877, batch_loss_c: 0.0875, batch_loss_s: 0.0881, time:4.9017, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:11:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1900/3125], step: 30025, 7.545 samples/sec, batch_loss: 0.1734, batch_loss_c: 0.1729, batch_loss_s: 0.1743, time:5.3016, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1910/3125], step: 30035, 8.278 samples/sec, batch_loss: 0.1242, batch_loss_c: 0.1280, batch_loss_s: 0.1155, time:4.8322, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1920/3125], step: 30045, 8.420 samples/sec, batch_loss: 0.1459, batch_loss_c: 0.1678, batch_loss_s: 0.0948, time:4.7504, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1930/3125], step: 30055, 7.685 samples/sec, batch_loss: 0.0639, batch_loss_c: 0.0617, batch_loss_s: 0.0692, time:5.2047, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1940/3125], step: 30065, 8.788 samples/sec, batch_loss: 0.3810, batch_loss_c: 0.3978, batch_loss_s: 0.3418, time:4.5519, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1950/3125], step: 30075, 8.418 samples/sec, batch_loss: 0.3046, batch_loss_c: 0.3021, batch_loss_s: 0.3104, time:4.7518, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1960/3125], step: 30085, 9.031 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1429, batch_loss_s: 0.0952, time:4.4293, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1970/3125], step: 30095, 7.690 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0863, batch_loss_s: 0.0657, time:5.2015, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1980/3125], step: 30105, 8.508 samples/sec, batch_loss: 0.0728, batch_loss_c: 0.0759, batch_loss_s: 0.0657, time:4.7016, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [1990/3125], step: 30115, 8.933 samples/sec, batch_loss: 0.2943, batch_loss_c: 0.2928, batch_loss_s: 0.2979, time:4.4775, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2000/3125], step: 30125, 7.405 samples/sec, batch_loss: 0.0667, batch_loss_c: 0.0571, batch_loss_s: 0.0892, time:5.4015, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2010/3125], step: 30135, 8.154 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.0929, batch_loss_s: 0.1218, time:4.9054, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:12:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2020/3125], step: 30145, 7.933 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1030, batch_loss_s: 0.1125, time:5.0422, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2030/3125], step: 30155, 8.629 samples/sec, batch_loss: 0.3124, batch_loss_c: 0.3124, batch_loss_s: 0.3124, time:4.6353, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2040/3125], step: 30165, 7.879 samples/sec, batch_loss: 0.3141, batch_loss_c: 0.3135, batch_loss_s: 0.3155, time:5.0769, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2050/3125], step: 30175, 8.011 samples/sec, batch_loss: 0.3373, batch_loss_c: 0.3481, batch_loss_s: 0.3120, time:4.9932, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2060/3125], step: 30185, 8.160 samples/sec, batch_loss: 0.1239, batch_loss_c: 0.1198, batch_loss_s: 0.1335, time:4.9021, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:19 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2070/3125], step: 30195, 8.174 samples/sec, batch_loss: 0.0740, batch_loss_c: 0.0776, batch_loss_s: 0.0655, time:4.8935, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2080/3125], step: 30205, 8.004 samples/sec, batch_loss: 0.0577, batch_loss_c: 0.0550, batch_loss_s: 0.0641, time:4.9973, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2090/3125], step: 30215, 8.286 samples/sec, batch_loss: 0.2479, batch_loss_c: 0.2278, batch_loss_s: 0.2947, time:4.8272, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:34 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2100/3125], step: 30225, 8.294 samples/sec, batch_loss: 0.0804, batch_loss_c: 0.0794, batch_loss_s: 0.0830, time:4.8227, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2110/3125], step: 30235, 8.836 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1192, batch_loss_s: 0.0950, time:4.5271, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2120/3125], step: 30245, 7.098 samples/sec, batch_loss: 0.3780, batch_loss_c: 0.3819, batch_loss_s: 0.3689, time:5.6353, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2130/3125], step: 30255, 7.906 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0966, batch_loss_s: 0.0824, time:5.0596, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2140/3125], step: 30265, 8.614 samples/sec, batch_loss: 0.0843, batch_loss_c: 0.0789, batch_loss_s: 0.0969, time:4.6439, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:13:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2150/3125], step: 30275, 9.482 samples/sec, batch_loss: 0.2417, batch_loss_c: 0.2769, batch_loss_s: 0.1597, time:4.2186, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2160/3125], step: 30285, 8.522 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0883, batch_loss_s: 0.1037, time:4.6937, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2170/3125], step: 30295, 8.534 samples/sec, batch_loss: 0.0758, batch_loss_c: 0.0769, batch_loss_s: 0.0732, time:4.6871, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2180/3125], step: 30305, 8.458 samples/sec, batch_loss: 0.4184, batch_loss_c: 0.4492, batch_loss_s: 0.3465, time:4.7295, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2190/3125], step: 30315, 8.479 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1124, batch_loss_s: 0.0835, time:4.7175, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2200/3125], step: 30325, 8.642 samples/sec, batch_loss: 0.0743, batch_loss_c: 0.0678, batch_loss_s: 0.0893, time:4.6288, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2210/3125], step: 30335, 8.522 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0762, batch_loss_s: 0.0872, time:4.6940, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2220/3125], step: 30345, 8.854 samples/sec, batch_loss: 0.0673, batch_loss_c: 0.0707, batch_loss_s: 0.0594, time:4.5175, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2230/3125], step: 30355, 8.271 samples/sec, batch_loss: 0.2721, batch_loss_c: 0.2524, batch_loss_s: 0.3180, time:4.8361, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2240/3125], step: 30365, 8.340 samples/sec, batch_loss: 0.0685, batch_loss_c: 0.0664, batch_loss_s: 0.0736, time:4.7960, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2250/3125], step: 30375, 7.968 samples/sec, batch_loss: 0.2920, batch_loss_c: 0.2921, batch_loss_s: 0.2918, time:5.0199, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2260/3125], step: 30385, 8.669 samples/sec, batch_loss: 0.0814, batch_loss_c: 0.0795, batch_loss_s: 0.0857, time:4.6142, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:14:55 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2270/3125], step: 30395, 8.417 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.1948, batch_loss_s: 0.1937, time:4.7522, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:00 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2280/3125], step: 30405, 7.683 samples/sec, batch_loss: 0.3455, batch_loss_c: 0.3495, batch_loss_s: 0.3364, time:5.2060, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:05 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2290/3125], step: 30415, 8.090 samples/sec, batch_loss: 0.0556, batch_loss_c: 0.0530, batch_loss_s: 0.0617, time:4.9443, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2300/3125], step: 30425, 8.478 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.3080, batch_loss_s: 0.3087, time:4.7180, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2310/3125], step: 30435, 7.810 samples/sec, batch_loss: 0.1243, batch_loss_c: 0.1164, batch_loss_s: 0.1425, time:5.1214, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2320/3125], step: 30445, 7.920 samples/sec, batch_loss: 0.0616, batch_loss_c: 0.0618, batch_loss_s: 0.0612, time:5.0503, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:24 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2330/3125], step: 30455, 8.739 samples/sec, batch_loss: 0.2826, batch_loss_c: 0.2766, batch_loss_s: 0.2967, time:4.5770, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:29 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2340/3125], step: 30465, 8.313 samples/sec, batch_loss: 0.5507, batch_loss_c: 0.5570, batch_loss_s: 0.5360, time:4.8117, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:34 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2350/3125], step: 30475, 7.933 samples/sec, batch_loss: 0.0476, batch_loss_c: 0.0436, batch_loss_s: 0.0569, time:5.0423, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2360/3125], step: 30485, 8.913 samples/sec, batch_loss: 0.0651, batch_loss_c: 0.0641, batch_loss_s: 0.0675, time:4.4880, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:44 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2370/3125], step: 30495, 8.588 samples/sec, batch_loss: 0.1408, batch_loss_c: 0.1303, batch_loss_s: 0.1654, time:4.6577, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:48 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2380/3125], step: 30505, 9.144 samples/sec, batch_loss: 0.3221, batch_loss_c: 0.3197, batch_loss_s: 0.3277, time:4.3746, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:53 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2390/3125], step: 30515, 8.357 samples/sec, batch_loss: 0.0934, batch_loss_c: 0.0866, batch_loss_s: 0.1094, time:4.7861, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:15:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2400/3125], step: 30525, 9.129 samples/sec, batch_loss: 0.0713, batch_loss_c: 0.0684, batch_loss_s: 0.0780, time:4.3817, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2410/3125], step: 30535, 8.117 samples/sec, batch_loss: 0.0667, batch_loss_c: 0.0636, batch_loss_s: 0.0741, time:4.9281, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2420/3125], step: 30545, 8.473 samples/sec, batch_loss: 0.0830, batch_loss_c: 0.0834, batch_loss_s: 0.0822, time:4.7208, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2430/3125], step: 30555, 8.387 samples/sec, batch_loss: 0.1337, batch_loss_c: 0.1568, batch_loss_s: 0.0796, time:4.7690, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2440/3125], step: 30565, 8.553 samples/sec, batch_loss: 0.2986, batch_loss_c: 0.2858, batch_loss_s: 0.3284, time:4.6768, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:21 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2450/3125], step: 30575, 8.586 samples/sec, batch_loss: 0.0807, batch_loss_c: 0.0868, batch_loss_s: 0.0666, time:4.6586, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2460/3125], step: 30585, 7.707 samples/sec, batch_loss: 0.0458, batch_loss_c: 0.0433, batch_loss_s: 0.0516, time:5.1904, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:31 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2470/3125], step: 30595, 8.106 samples/sec, batch_loss: 0.0953, batch_loss_c: 0.0921, batch_loss_s: 0.1029, time:4.9345, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:35 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2480/3125], step: 30605, 8.861 samples/sec, batch_loss: 0.3158, batch_loss_c: 0.3104, batch_loss_s: 0.3284, time:4.5143, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:40 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2490/3125], step: 30615, 8.568 samples/sec, batch_loss: 0.0650, batch_loss_c: 0.0616, batch_loss_s: 0.0730, time:4.6685, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2500/3125], step: 30625, 8.704 samples/sec, batch_loss: 0.0801, batch_loss_c: 0.0847, batch_loss_s: 0.0693, time:4.5956, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2510/3125], step: 30635, 8.125 samples/sec, batch_loss: 0.0796, batch_loss_c: 0.0756, batch_loss_s: 0.0888, time:4.9231, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2520/3125], step: 30645, 8.661 samples/sec, batch_loss: 0.1692, batch_loss_c: 0.1658, batch_loss_s: 0.1771, time:4.6183, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:16:59 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2530/3125], step: 30655, 8.432 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1350, batch_loss_s: 0.1332, time:4.7437, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2540/3125], step: 30665, 9.229 samples/sec, batch_loss: 0.0845, batch_loss_c: 0.0790, batch_loss_s: 0.0974, time:4.3343, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2550/3125], step: 30675, 8.235 samples/sec, batch_loss: 0.3711, batch_loss_c: 0.3752, batch_loss_s: 0.3617, time:4.8574, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:13 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2560/3125], step: 30685, 8.483 samples/sec, batch_loss: 0.0603, batch_loss_c: 0.0604, batch_loss_s: 0.0601, time:4.7153, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:18 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2570/3125], step: 30695, 7.175 samples/sec, batch_loss: 0.0912, batch_loss_c: 0.0838, batch_loss_s: 0.1083, time:5.5750, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:23 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2580/3125], step: 30705, 8.358 samples/sec, batch_loss: 0.0747, batch_loss_c: 0.0729, batch_loss_s: 0.0790, time:4.7861, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:28 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2590/3125], step: 30715, 8.633 samples/sec, batch_loss: 0.1582, batch_loss_c: 0.1776, batch_loss_s: 0.1128, time:4.6332, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:33 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2600/3125], step: 30725, 8.301 samples/sec, batch_loss: 0.2972, batch_loss_c: 0.2959, batch_loss_s: 0.3002, time:4.8184, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:38 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2610/3125], step: 30735, 8.176 samples/sec, batch_loss: 0.0659, batch_loss_c: 0.0607, batch_loss_s: 0.0781, time:4.8924, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:42 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2620/3125], step: 30745, 8.541 samples/sec, batch_loss: 0.1229, batch_loss_c: 0.1248, batch_loss_s: 0.1183, time:4.6834, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2630/3125], step: 30755, 8.192 samples/sec, batch_loss: 0.3040, batch_loss_c: 0.3006, batch_loss_s: 0.3120, time:4.8826, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2640/3125], step: 30765, 7.884 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0861, batch_loss_s: 0.0616, time:5.0733, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:17:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2650/3125], step: 30775, 7.850 samples/sec, batch_loss: 0.2698, batch_loss_c: 0.2547, batch_loss_s: 0.3052, time:5.0957, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2660/3125], step: 30785, 8.514 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1589, batch_loss_s: 0.1072, time:4.6981, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:07 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2670/3125], step: 30795, 8.003 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1290, batch_loss_s: 0.1310, time:4.9982, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2680/3125], step: 30805, 8.022 samples/sec, batch_loss: 0.2956, batch_loss_c: 0.2925, batch_loss_s: 0.3030, time:4.9864, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2690/3125], step: 30815, 7.966 samples/sec, batch_loss: 0.1661, batch_loss_c: 0.1922, batch_loss_s: 0.1054, time:5.0215, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2700/3125], step: 30825, 8.080 samples/sec, batch_loss: 0.3721, batch_loss_c: 0.3822, batch_loss_s: 0.3483, time:4.9502, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:26 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2710/3125], step: 30835, 9.266 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0833, batch_loss_s: 0.0937, time:4.3169, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2720/3125], step: 30845, 7.391 samples/sec, batch_loss: 0.0646, batch_loss_c: 0.0611, batch_loss_s: 0.0726, time:5.4120, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2730/3125], step: 30855, 8.698 samples/sec, batch_loss: 0.1192, batch_loss_c: 0.1298, batch_loss_s: 0.0943, time:4.5987, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2740/3125], step: 30865, 8.266 samples/sec, batch_loss: 0.3385, batch_loss_c: 0.3374, batch_loss_s: 0.3410, time:4.8392, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2750/3125], step: 30875, 7.540 samples/sec, batch_loss: 0.3005, batch_loss_c: 0.2964, batch_loss_s: 0.3101, time:5.3051, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:52 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2760/3125], step: 30885, 7.589 samples/sec, batch_loss: 0.3556, batch_loss_c: 0.3699, batch_loss_s: 0.3221, time:5.2707, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:18:57 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2770/3125], step: 30895, 7.584 samples/sec, batch_loss: 0.1405, batch_loss_c: 0.1423, batch_loss_s: 0.1365, time:5.2740, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:02 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2780/3125], step: 30905, 8.296 samples/sec, batch_loss: 0.0672, batch_loss_c: 0.0615, batch_loss_s: 0.0804, time:4.8218, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2790/3125], step: 30915, 9.106 samples/sec, batch_loss: 0.0795, batch_loss_c: 0.0653, batch_loss_s: 0.1125, time:4.3929, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:11 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2800/3125], step: 30925, 8.763 samples/sec, batch_loss: 0.0710, batch_loss_c: 0.0712, batch_loss_s: 0.0703, time:4.5645, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:16 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2810/3125], step: 30935, 8.270 samples/sec, batch_loss: 0.0818, batch_loss_c: 0.0887, batch_loss_s: 0.0657, time:4.8366, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2820/3125], step: 30945, 8.892 samples/sec, batch_loss: 0.1049, batch_loss_c: 0.1090, batch_loss_s: 0.0955, time:4.4986, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2830/3125], step: 30955, 8.224 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1082, batch_loss_s: 0.1024, time:4.8636, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2840/3125], step: 30965, 7.613 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1169, batch_loss_s: 0.0791, time:5.2540, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:36 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2850/3125], step: 30975, 7.068 samples/sec, batch_loss: 0.3343, batch_loss_c: 0.3387, batch_loss_s: 0.3242, time:5.6591, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2860/3125], step: 30985, 8.335 samples/sec, batch_loss: 0.4768, batch_loss_c: 0.4466, batch_loss_s: 0.5473, time:4.7993, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:46 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2870/3125], step: 30995, 8.078 samples/sec, batch_loss: 0.0559, batch_loss_c: 0.0533, batch_loss_s: 0.0620, time:4.9517, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:50 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2880/3125], step: 31005, 8.389 samples/sec, batch_loss: 0.0529, batch_loss_c: 0.0455, batch_loss_s: 0.0703, time:4.7683, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:19:56 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2890/3125], step: 31015, 7.092 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0856, batch_loss_s: 0.0761, time:5.6403, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:01 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2900/3125], step: 31025, 8.760 samples/sec, batch_loss: 0.3258, batch_loss_c: 0.3286, batch_loss_s: 0.3194, time:4.5664, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:06 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2910/3125], step: 31035, 7.790 samples/sec, batch_loss: 0.0442, batch_loss_c: 0.0403, batch_loss_s: 0.0532, time:5.1347, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:10 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2920/3125], step: 31045, 8.824 samples/sec, batch_loss: 0.0920, batch_loss_c: 0.0989, batch_loss_s: 0.0759, time:4.5329, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:15 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2930/3125], step: 31055, 8.530 samples/sec, batch_loss: 0.2773, batch_loss_c: 0.2694, batch_loss_s: 0.2956, time:4.6893, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:20 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2940/3125], step: 31065, 8.023 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0658, batch_loss_s: 0.0809, time:4.9855, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:25 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2950/3125], step: 31075, 7.989 samples/sec, batch_loss: 0.1173, batch_loss_c: 0.1293, batch_loss_s: 0.0893, time:5.0068, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:30 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2960/3125], step: 31085, 8.465 samples/sec, batch_loss: 0.1179, batch_loss_c: 0.1318, batch_loss_s: 0.0854, time:4.7253, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:34 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2970/3125], step: 31095, 8.789 samples/sec, batch_loss: 0.3147, batch_loss_c: 0.3098, batch_loss_s: 0.3262, time:4.5512, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:39 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2980/3125], step: 31105, 9.047 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.1048, batch_loss_s: 0.0788, time:4.4212, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:43 \u001b[32mINFO     \u001b[0m train.py: [9/10], [2990/3125], step: 31115, 8.458 samples/sec, batch_loss: 0.1139, batch_loss_c: 0.1120, batch_loss_s: 0.1183, time:4.7295, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:49 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3000/3125], step: 31125, 7.949 samples/sec, batch_loss: 0.0715, batch_loss_c: 0.0737, batch_loss_s: 0.0663, time:5.0324, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:54 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3010/3125], step: 31135, 7.982 samples/sec, batch_loss: 0.3270, batch_loss_c: 0.3237, batch_loss_s: 0.3349, time:5.0114, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:20:58 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3020/3125], step: 31145, 8.518 samples/sec, batch_loss: 0.3652, batch_loss_c: 0.3815, batch_loss_s: 0.3272, time:4.6961, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:03 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3030/3125], step: 31155, 8.678 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1031, batch_loss_s: 0.1082, time:4.6092, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:08 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3040/3125], step: 31165, 8.422 samples/sec, batch_loss: 0.0874, batch_loss_c: 0.0876, batch_loss_s: 0.0869, time:4.7492, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:12 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3050/3125], step: 31175, 8.702 samples/sec, batch_loss: 0.3192, batch_loss_c: 0.3170, batch_loss_s: 0.3245, time:4.5968, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:17 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3060/3125], step: 31185, 8.586 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.1019, batch_loss_s: 0.0931, time:4.6589, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:22 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3070/3125], step: 31195, 7.804 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.0980, batch_loss_s: 0.1165, time:5.1256, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:27 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3080/3125], step: 31205, 7.953 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1181, batch_loss_s: 0.1170, time:5.0295, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:32 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3090/3125], step: 31215, 8.193 samples/sec, batch_loss: 0.2961, batch_loss_c: 0.2880, batch_loss_s: 0.3150, time:4.8820, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:37 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3100/3125], step: 31225, 8.134 samples/sec, batch_loss: 0.3566, batch_loss_c: 0.3531, batch_loss_s: 0.3648, time:4.9178, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:41 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3110/3125], step: 31235, 9.740 samples/sec, batch_loss: 0.3130, batch_loss_c: 0.3124, batch_loss_s: 0.3145, time:4.1066, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:45 \u001b[32mINFO     \u001b[0m train.py: [9/10], [3120/3125], step: 31245, 10.362 samples/sec, batch_loss: 0.0965, batch_loss_c: 0.0978, batch_loss_s: 0.0936, time:3.8604, lr:0.0001\u001b[0m\n",
            "2019-11-24 13:21:47 \u001b[32mINFO     \u001b[0m train.py: [9/10], train_loss: 0.1667, time: 1524.3044, lr: 0.0001\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}