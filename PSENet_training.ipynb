{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSENet_trial_run.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/PSENet.pytorch/blob/master/PSENet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UByxwp0F3QUp",
        "colab_type": "text"
      },
      "source": [
        "## Installing softwares and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSEHnmCxK_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99kqKlHoYkz",
        "colab_type": "code",
        "outputId": "fb6277ac-b6a6-4422-d788-24d8433864a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "!pip install pyclipper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyclipper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/67/2691f7cbb28fb9dbf423f2302fe489f9cee34d9a50a743c95032a24ac597/pyclipper-1.1.0.post1-cp36-cp36m-manylinux1_x86_64.whl (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyclipper\n",
            "Successfully installed pyclipper-1.1.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoynOlfnIW1",
        "colab_type": "code",
        "outputId": "3ae4265e-27da-4e0b-ea99-45891c3a44e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhJ-6yyXcnRx",
        "colab_type": "code",
        "outputId": "7f3fb23a-212e-4253-e8ed-6906f000d997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import shutil, os\n",
        "os.chdir('/content')\n",
        "directory = '/content/cloned-repo'\n",
        "if os.path.exists(directory):\n",
        "  shutil.rmtree(directory)\n",
        "\n",
        "!git clone https://github.com/kavyajeetbora/PSENet.pytorch.git /content/cloned-repo\n",
        "print(\"Cloned the repository\")\n",
        "os.chdir('/content/cloned-repo')\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/cloned-repo'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/69)\u001b[K\rremote: Counting objects:   2% (2/69)\u001b[K\rremote: Counting objects:   4% (3/69)\u001b[K\rremote: Counting objects:   5% (4/69)\u001b[K\rremote: Counting objects:   7% (5/69)\u001b[K\rremote: Counting objects:   8% (6/69)\u001b[K\rremote: Counting objects:  10% (7/69)\u001b[K\rremote: Counting objects:  11% (8/69)\u001b[K\rremote: Counting objects:  13% (9/69)\u001b[K\rremote: Counting objects:  14% (10/69)\u001b[K\rremote: Counting objects:  15% (11/69)\u001b[K\rremote: Counting objects:  17% (12/69)\u001b[K\rremote: Counting objects:  18% (13/69)\u001b[K\rremote: Counting objects:  20% (14/69)\u001b[K\rremote: Counting objects:  21% (15/69)\u001b[K\rremote: Counting objects:  23% (16/69)\u001b[K\rremote: Counting objects:  24% (17/69)\u001b[K\rremote: Counting objects:  26% (18/69)\u001b[K\rremote: Counting objects:  27% (19/69)\u001b[K\rremote: Counting objects:  28% (20/69)\u001b[K\rremote: Counting objects:  30% (21/69)\u001b[K\rremote: Counting objects:  31% (22/69)\u001b[K\rremote: Counting objects:  33% (23/69)\u001b[K\rremote: Counting objects:  34% (24/69)\u001b[K\rremote: Counting objects:  36% (25/69)\u001b[K\rremote: Counting objects:  37% (26/69)\u001b[K\rremote: Counting objects:  39% (27/69)\u001b[K\rremote: Counting objects:  40% (28/69)\u001b[K\rremote: Counting objects:  42% (29/69)\u001b[K\rremote: Counting objects:  43% (30/69)\u001b[K\rremote: Counting objects:  44% (31/69)\u001b[K\rremote: Counting objects:  46% (32/69)\u001b[K\rremote: Counting objects:  47% (33/69)\u001b[K\rremote: Counting objects:  49% (34/69)\u001b[K\rremote: Counting objects:  50% (35/69)\u001b[K\rremote: Counting objects:  52% (36/69)\u001b[K\rremote: Counting objects:  53% (37/69)\u001b[K\rremote: Counting objects:  55% (38/69)\u001b[K\rremote: Counting objects:  56% (39/69)\u001b[K\rremote: Counting objects:  57% (40/69)\u001b[K\rremote: Counting objects:  59% (41/69)\u001b[K\rremote: Counting objects:  60% (42/69)\u001b[K\rremote: Counting objects:  62% (43/69)\u001b[K\rremote: Counting objects:  63% (44/69)\u001b[K\rremote: Counting objects:  65% (45/69)\u001b[K\rremote: Counting objects:  66% (46/69)\u001b[K\rremote: Counting objects:  68% (47/69)\u001b[K\rremote: Counting objects:  69% (48/69)\u001b[K\rremote: Counting objects:  71% (49/69)\u001b[K\rremote: Counting objects:  72% (50/69)\u001b[K\rremote: Counting objects:  73% (51/69)\u001b[K\rremote: Counting objects:  75% (52/69)\u001b[K\rremote: Counting objects:  76% (53/69)\u001b[K\rremote: Counting objects:  78% (54/69)\u001b[K\rremote: Counting objects:  79% (55/69)\u001b[K\rremote: Counting objects:  81% (56/69)\u001b[K\rremote: Counting objects:  82% (57/69)\u001b[K\rremote: Counting objects:  84% (58/69)\u001b[K\rremote: Counting objects:  85% (59/69)\u001b[K\rremote: Counting objects:  86% (60/69)\u001b[K\rremote: Counting objects:  88% (61/69)\u001b[K\rremote: Counting objects:  89% (62/69)\u001b[K\rremote: Counting objects:  91% (63/69)\u001b[K\rremote: Counting objects:  92% (64/69)\u001b[K\rremote: Counting objects:  94% (65/69)\u001b[K\rremote: Counting objects:  95% (66/69)\u001b[K\rremote: Counting objects:  97% (67/69)\u001b[K\rremote: Counting objects:  98% (68/69)\u001b[K\rremote: Counting objects: 100% (69/69)\u001b[K\rremote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 469 (delta 39), reused 0 (delta 0), pack-reused 400\u001b[K\n",
            "Receiving objects: 100% (469/469), 8.64 MiB | 5.45 MiB/s, done.\n",
            "Resolving deltas: 100% (233/233), done.\n",
            "Cloned the repository\n",
            "cal_recall  install_dependencies.sh  PSENet.ipynb\t     train.py\n",
            "config.py   LICENSE\t\t     PSENet_predict.ipynb    utils\n",
            "dataset     models\t\t     PSENet_training.ipynb\n",
            "eval.py     predict.py\t\t     PSENet_trial_run.ipynb\n",
            "imgs\t    pse\t\t\t     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrOmfo6_3X2I",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the data and setting up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLMxTujlm0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## unzipping the files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def unzip_files(file,output_dir):\n",
        "  with ZipFile(file, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall(output_dir)\n",
        "  print('Extracted to',output_dir)\n",
        "\n",
        "def make_directory(directory):\n",
        "  if os.path.isdir(directory):\n",
        "    shutil.rmtree(directory)\n",
        "  \n",
        "  os.mkdir(directory)\n",
        "  print('Created a new directory')\n",
        "\n",
        "training_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Training Set/Random 5000.zip'\n",
        "test_data_zip = '/content/drive/My Drive/Colab Notebooks/padh.ai.notebooks/15. Object Detection/AI4Bharat Dataset/Test Set/real_Image_dataset_Detection.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJ6xb5u2dgg",
        "colab_type": "code",
        "outputId": "469deef7-807a-4a44-fbd8-d1359915cfac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# make directories\n",
        "make_directory('Training Set')\n",
        "make_directory('Test Set')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created a new directory\n",
            "Created a new directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSaSXr-m-K4",
        "colab_type": "code",
        "outputId": "50687637-bff4-484d-e69d-d1987548b74c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "%%time\n",
        "unzip_files(training_data_zip,'Training Set')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted to Training Set\n",
            "CPU times: user 4.77 s, sys: 1.98 s, total: 6.75 s\n",
            "Wall time: 10.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRSeyluknVH4",
        "colab_type": "code",
        "outputId": "17360c51-e346-4ce1-9d75-ecc7ee21cea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Images')))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOp4JsZ6nXvn",
        "colab_type": "code",
        "outputId": "999b016f-6186-47cd-85a5-c4a781264ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(os.listdir('Training Set/Annotations')))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhvg89mXn8zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataset.data_utils import *\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JeHTz3G6Lyj",
        "colab_type": "code",
        "outputId": "9ca94ba2-a38a-4837-88cd-dd4b8bbca9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_data = MyDataset('Training Set',transform=transforms.ToTensor())\n",
        "len(train_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLKMn-5SBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9a9PsyF3dqo",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9x221Ya0RBGO",
        "outputId": "fa9ba55a-3460-47d8-da87-492fa622cb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "!chmod +x install_dependencies.sh # make shell script executable\n",
        "!./install_dependencies.sh # run the shell script"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.6/dist-packages (1.1.0.post1)\n",
            "Collecting Polygon3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/a0/d07a4f3e80ed7020a33f3111db217f54ac44a485ff45da3c21ce49f65041/Polygon3-3.0.8.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Polygon3\n",
            "  Building wheel for Polygon3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Polygon3: filename=Polygon3-3.0.8-cp36-cp36m-linux_x86_64.whl size=101483 sha256=13165451eba44368d10c6a6a5f8849da08cae8ec64cd0d698db89c093bf4d247\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/32/f1/5525b233996d9d99cbce2f0a8da60d137ddddc555d3e8b0e2a\n",
            "Successfully built Polygon3\n",
            "Installing collected packages: Polygon3\n",
            "Successfully installed Polygon3-3.0.8\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/68/4d/892728b0c14547224f0ac40884e722a3d00cb54e7a146aea0b3186806c9e/colorlog-4.0.2-py2.py3-none-any.whl\n",
            "Installing collected packages: colorlog\n",
            "Successfully installed colorlog-4.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD4GuTKC3wXY",
        "colab_type": "code",
        "outputId": "4ae94673-7814-46c1-a981-0cd4533b279f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "make: Entering directory '/content/cloned-repo/pse'\n",
            "make: 'pse.so' is up to date.\n",
            "make: Leaving directory '/content/cloned-repo/pse'\n",
            "2019-11-25 06:22:33 \u001b[32mINFO     \u001b[0m utils.py: logger init finished\u001b[0m\n",
            "2019-11-25 06:22:33 \u001b[32mINFO     \u001b[0m train.py: {'Lambda': 0.7,\n",
            " 'OHEM_ratio': 3,\n",
            " 'backbone': 'resnet18',\n",
            " 'checkpoint': '',\n",
            " 'data_shape': 640,\n",
            " 'display_input_images': False,\n",
            " 'display_interval': 10,\n",
            " 'display_output_images': False,\n",
            " 'end_lr': 1e-07,\n",
            " 'epochs': 10,\n",
            " 'gpu_id': '0',\n",
            " 'lr': 0.001,\n",
            " 'lr_decay_step': [200, 400],\n",
            " 'lr_gamma': 0.1,\n",
            " 'm': 0.5,\n",
            " 'n': 6,\n",
            " 'output_dir': '/content/drive/My Drive/PSENet',\n",
            " 'pretrained': False,\n",
            " 'pretrained_path': '/content/drive/My Drive/PSENet/PSENet_resnet18.pth',\n",
            " 'restart_training': False,\n",
            " 'scale': 1,\n",
            " 'seed': 2,\n",
            " 'show_images_interval': 50,\n",
            " 'start_epoch': 0,\n",
            " 'testroot': 'Test Set',\n",
            " 'train_batch_size': 4,\n",
            " 'trainroot': 'Training Set',\n",
            " 'warm_up_epoch': 6,\n",
            " 'warm_up_lr': 0.0001,\n",
            " 'weight_decay': 0.0005,\n",
            " 'workers': 12}\u001b[0m\n",
            "2019-11-25 06:22:33 \u001b[32mINFO     \u001b[0m train.py: train with gpu 0 and pytorch 1.3.1\u001b[0m\n",
            "2019-11-25 06:22:44 \u001b[32mINFO     \u001b[0m train.py: train dataset has 12500 samples,3125 in dataloader\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "2019-11-25 06:23:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [0/3125], step: 0, 1.602 samples/sec, batch_loss: 0.3198, batch_loss_c: 0.3230, batch_loss_s: 0.3123, time:24.9627, lr:0.001\u001b[0m\n",
            "2019-11-25 06:23:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [10/3125], step: 10, 2.895 samples/sec, batch_loss: 0.3567, batch_loss_c: 0.3621, batch_loss_s: 0.3441, time:13.8173, lr:0.001\u001b[0m\n",
            "2019-11-25 06:23:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [20/3125], step: 20, 2.973 samples/sec, batch_loss: 0.2245, batch_loss_c: 0.2687, batch_loss_s: 0.1214, time:13.4541, lr:0.001\u001b[0m\n",
            "2019-11-25 06:23:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [30/3125], step: 30, 2.934 samples/sec, batch_loss: 0.2462, batch_loss_c: 0.2592, batch_loss_s: 0.2157, time:13.6339, lr:0.001\u001b[0m\n",
            "2019-11-25 06:24:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [40/3125], step: 40, 2.928 samples/sec, batch_loss: 0.1931, batch_loss_c: 0.2268, batch_loss_s: 0.1143, time:13.6628, lr:0.001\u001b[0m\n",
            "2019-11-25 06:24:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [50/3125], step: 50, 2.992 samples/sec, batch_loss: 0.1480, batch_loss_c: 0.1591, batch_loss_s: 0.1219, time:13.3683, lr:0.001\u001b[0m\n",
            "2019-11-25 06:24:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [60/3125], step: 60, 2.959 samples/sec, batch_loss: 0.4557, batch_loss_c: 0.4554, batch_loss_s: 0.4563, time:13.5199, lr:0.001\u001b[0m\n",
            "2019-11-25 06:24:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [70/3125], step: 70, 2.937 samples/sec, batch_loss: 0.1366, batch_loss_c: 0.1425, batch_loss_s: 0.1229, time:13.6212, lr:0.001\u001b[0m\n",
            "2019-11-25 06:24:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [80/3125], step: 80, 2.978 samples/sec, batch_loss: 0.4071, batch_loss_c: 0.4262, batch_loss_s: 0.3625, time:13.4302, lr:0.001\u001b[0m\n",
            "2019-11-25 06:25:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [90/3125], step: 90, 2.979 samples/sec, batch_loss: 0.3218, batch_loss_c: 0.3158, batch_loss_s: 0.3358, time:13.4255, lr:0.001\u001b[0m\n",
            "2019-11-25 06:25:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [100/3125], step: 100, 2.997 samples/sec, batch_loss: 0.3337, batch_loss_c: 0.3409, batch_loss_s: 0.3169, time:13.3487, lr:0.001\u001b[0m\n",
            "2019-11-25 06:25:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [110/3125], step: 110, 2.980 samples/sec, batch_loss: 0.2012, batch_loss_c: 0.2123, batch_loss_s: 0.1754, time:13.4222, lr:0.001\u001b[0m\n",
            "2019-11-25 06:25:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [120/3125], step: 120, 3.032 samples/sec, batch_loss: 0.1319, batch_loss_c: 0.1412, batch_loss_s: 0.1103, time:13.1909, lr:0.001\u001b[0m\n",
            "2019-11-25 06:26:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [130/3125], step: 130, 3.044 samples/sec, batch_loss: 0.2161, batch_loss_c: 0.2367, batch_loss_s: 0.1680, time:13.1426, lr:0.001\u001b[0m\n",
            "2019-11-25 06:26:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [140/3125], step: 140, 3.023 samples/sec, batch_loss: 0.1775, batch_loss_c: 0.1995, batch_loss_s: 0.1264, time:13.2321, lr:0.001\u001b[0m\n",
            "2019-11-25 06:26:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], [150/3125], step: 150, 3.072 samples/sec, batch_loss: 0.2481, batch_loss_c: 0.2733, batch_loss_s: 0.1895, time:13.0210, lr:0.001\u001b[0m\n",
            "2019-11-25 06:26:43 \u001b[32mINFO     \u001b[0m train.py: [0/10], [160/3125], step: 160, 3.074 samples/sec, batch_loss: 0.1321, batch_loss_c: 0.1408, batch_loss_s: 0.1119, time:13.0142, lr:0.001\u001b[0m\n",
            "2019-11-25 06:26:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [170/3125], step: 170, 2.989 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1340, batch_loss_s: 0.1457, time:13.3841, lr:0.001\u001b[0m\n",
            "2019-11-25 06:27:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [180/3125], step: 180, 3.021 samples/sec, batch_loss: 0.1705, batch_loss_c: 0.1939, batch_loss_s: 0.1158, time:13.2410, lr:0.001\u001b[0m\n",
            "2019-11-25 06:27:23 \u001b[32mINFO     \u001b[0m train.py: [0/10], [190/3125], step: 190, 2.998 samples/sec, batch_loss: 0.1282, batch_loss_c: 0.1364, batch_loss_s: 0.1090, time:13.3424, lr:0.001\u001b[0m\n",
            "2019-11-25 06:27:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [200/3125], step: 200, 3.026 samples/sec, batch_loss: 0.3253, batch_loss_c: 0.3210, batch_loss_s: 0.3351, time:13.2182, lr:0.001\u001b[0m\n",
            "2019-11-25 06:27:50 \u001b[32mINFO     \u001b[0m train.py: [0/10], [210/3125], step: 210, 3.002 samples/sec, batch_loss: 0.1478, batch_loss_c: 0.1717, batch_loss_s: 0.0919, time:13.3249, lr:0.001\u001b[0m\n",
            "2019-11-25 06:28:03 \u001b[32mINFO     \u001b[0m train.py: [0/10], [220/3125], step: 220, 3.051 samples/sec, batch_loss: 0.3168, batch_loss_c: 0.3096, batch_loss_s: 0.3336, time:13.1093, lr:0.001\u001b[0m\n",
            "2019-11-25 06:28:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [230/3125], step: 230, 2.982 samples/sec, batch_loss: 0.1386, batch_loss_c: 0.1580, batch_loss_s: 0.0933, time:13.4155, lr:0.001\u001b[0m\n",
            "2019-11-25 06:28:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [240/3125], step: 240, 3.038 samples/sec, batch_loss: 0.1222, batch_loss_c: 0.1262, batch_loss_s: 0.1128, time:13.1666, lr:0.001\u001b[0m\n",
            "2019-11-25 06:28:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [250/3125], step: 250, 3.047 samples/sec, batch_loss: 0.1462, batch_loss_c: 0.1549, batch_loss_s: 0.1258, time:13.1273, lr:0.001\u001b[0m\n",
            "2019-11-25 06:28:56 \u001b[32mINFO     \u001b[0m train.py: [0/10], [260/3125], step: 260, 3.029 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1404, batch_loss_s: 0.1186, time:13.2063, lr:0.001\u001b[0m\n",
            "2019-11-25 06:29:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [270/3125], step: 270, 3.014 samples/sec, batch_loss: 0.2810, batch_loss_c: 0.3169, batch_loss_s: 0.1974, time:13.2706, lr:0.001\u001b[0m\n",
            "2019-11-25 06:29:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [280/3125], step: 280, 3.052 samples/sec, batch_loss: 0.3072, batch_loss_c: 0.2963, batch_loss_s: 0.3326, time:13.1052, lr:0.001\u001b[0m\n",
            "2019-11-25 06:29:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [290/3125], step: 290, 3.027 samples/sec, batch_loss: 0.3034, batch_loss_c: 0.2905, batch_loss_s: 0.3336, time:13.2152, lr:0.001\u001b[0m\n",
            "2019-11-25 06:29:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [300/3125], step: 300, 3.004 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1361, batch_loss_s: 0.1286, time:13.3176, lr:0.001\u001b[0m\n",
            "2019-11-25 06:30:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [310/3125], step: 310, 2.994 samples/sec, batch_loss: 0.2384, batch_loss_c: 0.2367, batch_loss_s: 0.2425, time:13.3600, lr:0.001\u001b[0m\n",
            "2019-11-25 06:30:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [320/3125], step: 320, 3.047 samples/sec, batch_loss: 0.3024, batch_loss_c: 0.2917, batch_loss_s: 0.3274, time:13.1272, lr:0.001\u001b[0m\n",
            "2019-11-25 06:30:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [330/3125], step: 330, 2.977 samples/sec, batch_loss: 0.2346, batch_loss_c: 0.2318, batch_loss_s: 0.2413, time:13.4370, lr:0.001\u001b[0m\n",
            "2019-11-25 06:30:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [340/3125], step: 340, 2.954 samples/sec, batch_loss: 0.3352, batch_loss_c: 0.3250, batch_loss_s: 0.3591, time:13.5421, lr:0.001\u001b[0m\n",
            "2019-11-25 06:30:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [350/3125], step: 350, 3.018 samples/sec, batch_loss: 0.6981, batch_loss_c: 0.7337, batch_loss_s: 0.6150, time:13.2525, lr:0.001\u001b[0m\n",
            "2019-11-25 06:31:09 \u001b[32mINFO     \u001b[0m train.py: [0/10], [360/3125], step: 360, 3.016 samples/sec, batch_loss: 0.4532, batch_loss_c: 0.4280, batch_loss_s: 0.5121, time:13.2626, lr:0.001\u001b[0m\n",
            "2019-11-25 06:31:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [370/3125], step: 370, 2.965 samples/sec, batch_loss: 0.3797, batch_loss_c: 0.3840, batch_loss_s: 0.3696, time:13.4922, lr:0.001\u001b[0m\n",
            "2019-11-25 06:31:36 \u001b[32mINFO     \u001b[0m train.py: [0/10], [380/3125], step: 380, 2.942 samples/sec, batch_loss: 0.3988, batch_loss_c: 0.4182, batch_loss_s: 0.3535, time:13.5973, lr:0.001\u001b[0m\n",
            "2019-11-25 06:31:49 \u001b[32mINFO     \u001b[0m train.py: [0/10], [390/3125], step: 390, 2.993 samples/sec, batch_loss: 0.2539, batch_loss_c: 0.3026, batch_loss_s: 0.1403, time:13.3639, lr:0.001\u001b[0m\n",
            "2019-11-25 06:32:02 \u001b[32mINFO     \u001b[0m train.py: [0/10], [400/3125], step: 400, 2.980 samples/sec, batch_loss: 0.3201, batch_loss_c: 0.3117, batch_loss_s: 0.3396, time:13.4246, lr:0.001\u001b[0m\n",
            "2019-11-25 06:32:16 \u001b[32mINFO     \u001b[0m train.py: [0/10], [410/3125], step: 410, 2.997 samples/sec, batch_loss: 0.2256, batch_loss_c: 0.2307, batch_loss_s: 0.2139, time:13.3454, lr:0.001\u001b[0m\n",
            "2019-11-25 06:32:29 \u001b[32mINFO     \u001b[0m train.py: [0/10], [420/3125], step: 420, 3.024 samples/sec, batch_loss: 0.1491, batch_loss_c: 0.1509, batch_loss_s: 0.1448, time:13.2258, lr:0.001\u001b[0m\n",
            "2019-11-25 06:32:42 \u001b[32mINFO     \u001b[0m train.py: [0/10], [430/3125], step: 430, 3.049 samples/sec, batch_loss: 0.3996, batch_loss_c: 0.4275, batch_loss_s: 0.3345, time:13.1175, lr:0.001\u001b[0m\n",
            "2019-11-25 06:32:55 \u001b[32mINFO     \u001b[0m train.py: [0/10], [440/3125], step: 440, 3.022 samples/sec, batch_loss: 0.3066, batch_loss_c: 0.2865, batch_loss_s: 0.3536, time:13.2344, lr:0.001\u001b[0m\n",
            "2019-11-25 06:33:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [450/3125], step: 450, 3.038 samples/sec, batch_loss: 0.1946, batch_loss_c: 0.2184, batch_loss_s: 0.1391, time:13.1668, lr:0.001\u001b[0m\n",
            "2019-11-25 06:33:22 \u001b[32mINFO     \u001b[0m train.py: [0/10], [460/3125], step: 460, 2.992 samples/sec, batch_loss: 0.2321, batch_loss_c: 0.2567, batch_loss_s: 0.1747, time:13.3698, lr:0.001\u001b[0m\n",
            "2019-11-25 06:33:35 \u001b[32mINFO     \u001b[0m train.py: [0/10], [470/3125], step: 470, 3.042 samples/sec, batch_loss: 0.1293, batch_loss_c: 0.1297, batch_loss_s: 0.1283, time:13.1487, lr:0.001\u001b[0m\n",
            "2019-11-25 06:33:48 \u001b[32mINFO     \u001b[0m train.py: [0/10], [480/3125], step: 480, 3.039 samples/sec, batch_loss: 0.3404, batch_loss_c: 0.3471, batch_loss_s: 0.3249, time:13.1629, lr:0.001\u001b[0m\n",
            "2019-11-25 06:34:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [490/3125], step: 490, 3.030 samples/sec, batch_loss: 0.4251, batch_loss_c: 0.4417, batch_loss_s: 0.3864, time:13.2009, lr:0.001\u001b[0m\n",
            "2019-11-25 06:34:15 \u001b[32mINFO     \u001b[0m train.py: [0/10], [500/3125], step: 500, 3.030 samples/sec, batch_loss: 0.2705, batch_loss_c: 0.3448, batch_loss_s: 0.0969, time:13.2033, lr:0.001\u001b[0m\n",
            "2019-11-25 06:34:28 \u001b[32mINFO     \u001b[0m train.py: [0/10], [510/3125], step: 510, 2.996 samples/sec, batch_loss: 0.3870, batch_loss_c: 0.3950, batch_loss_s: 0.3685, time:13.3521, lr:0.001\u001b[0m\n",
            "2019-11-25 06:34:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [520/3125], step: 520, 3.033 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1267, batch_loss_s: 0.1411, time:13.1877, lr:0.001\u001b[0m\n",
            "2019-11-25 06:34:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [530/3125], step: 530, 3.011 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1699, batch_loss_s: 0.1339, time:13.2854, lr:0.001\u001b[0m\n",
            "2019-11-25 06:35:08 \u001b[32mINFO     \u001b[0m train.py: [0/10], [540/3125], step: 540, 2.995 samples/sec, batch_loss: 0.1973, batch_loss_c: 0.2245, batch_loss_s: 0.1338, time:13.3561, lr:0.001\u001b[0m\n",
            "2019-11-25 06:35:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [550/3125], step: 550, 3.029 samples/sec, batch_loss: 0.2284, batch_loss_c: 0.2529, batch_loss_s: 0.1712, time:13.2035, lr:0.001\u001b[0m\n",
            "2019-11-25 06:35:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [560/3125], step: 560, 3.034 samples/sec, batch_loss: 0.1590, batch_loss_c: 0.1744, batch_loss_s: 0.1232, time:13.1830, lr:0.001\u001b[0m\n",
            "2019-11-25 06:35:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [570/3125], step: 570, 3.004 samples/sec, batch_loss: 0.4224, batch_loss_c: 0.4469, batch_loss_s: 0.3651, time:13.3157, lr:0.001\u001b[0m\n",
            "2019-11-25 06:36:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [580/3125], step: 580, 3.018 samples/sec, batch_loss: 0.2005, batch_loss_c: 0.2220, batch_loss_s: 0.1506, time:13.2533, lr:0.001\u001b[0m\n",
            "2019-11-25 06:36:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [590/3125], step: 590, 3.057 samples/sec, batch_loss: 0.1618, batch_loss_c: 0.1609, batch_loss_s: 0.1639, time:13.0854, lr:0.001\u001b[0m\n",
            "2019-11-25 06:36:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [600/3125], step: 600, 3.002 samples/sec, batch_loss: 0.1589, batch_loss_c: 0.1806, batch_loss_s: 0.1081, time:13.3231, lr:0.001\u001b[0m\n",
            "2019-11-25 06:36:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [610/3125], step: 610, 3.008 samples/sec, batch_loss: 0.1074, batch_loss_c: 0.1028, batch_loss_s: 0.1182, time:13.2989, lr:0.001\u001b[0m\n",
            "2019-11-25 06:36:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [620/3125], step: 620, 3.000 samples/sec, batch_loss: 0.3690, batch_loss_c: 0.3655, batch_loss_s: 0.3769, time:13.3314, lr:0.001\u001b[0m\n",
            "2019-11-25 06:37:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [630/3125], step: 630, 2.992 samples/sec, batch_loss: 0.2201, batch_loss_c: 0.2531, batch_loss_s: 0.1430, time:13.3686, lr:0.001\u001b[0m\n",
            "2019-11-25 06:37:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [640/3125], step: 640, 3.020 samples/sec, batch_loss: 0.4141, batch_loss_c: 0.4255, batch_loss_s: 0.3876, time:13.2465, lr:0.001\u001b[0m\n",
            "2019-11-25 06:37:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [650/3125], step: 650, 3.058 samples/sec, batch_loss: 0.5337, batch_loss_c: 0.5236, batch_loss_s: 0.5571, time:13.0812, lr:0.001\u001b[0m\n",
            "2019-11-25 06:37:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [660/3125], step: 660, 3.020 samples/sec, batch_loss: 0.1589, batch_loss_c: 0.1752, batch_loss_s: 0.1208, time:13.2463, lr:0.001\u001b[0m\n",
            "2019-11-25 06:38:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [670/3125], step: 670, 3.028 samples/sec, batch_loss: 0.3958, batch_loss_c: 0.4015, batch_loss_s: 0.3824, time:13.2112, lr:0.001\u001b[0m\n",
            "2019-11-25 06:38:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [680/3125], step: 680, 3.060 samples/sec, batch_loss: 0.2524, batch_loss_c: 0.2672, batch_loss_s: 0.2177, time:13.0723, lr:0.001\u001b[0m\n",
            "2019-11-25 06:38:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [690/3125], step: 690, 2.973 samples/sec, batch_loss: 0.3427, batch_loss_c: 0.4329, batch_loss_s: 0.1323, time:13.4547, lr:0.001\u001b[0m\n",
            "2019-11-25 06:38:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [700/3125], step: 700, 3.059 samples/sec, batch_loss: 0.1782, batch_loss_c: 0.1842, batch_loss_s: 0.1642, time:13.0762, lr:0.001\u001b[0m\n",
            "2019-11-25 06:38:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [710/3125], step: 710, 3.014 samples/sec, batch_loss: 0.1545, batch_loss_c: 0.1543, batch_loss_s: 0.1549, time:13.2722, lr:0.001\u001b[0m\n",
            "2019-11-25 06:39:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [720/3125], step: 720, 2.935 samples/sec, batch_loss: 0.3353, batch_loss_c: 0.3330, batch_loss_s: 0.3409, time:13.6308, lr:0.001\u001b[0m\n",
            "2019-11-25 06:39:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [730/3125], step: 730, 3.006 samples/sec, batch_loss: 0.4304, batch_loss_c: 0.4489, batch_loss_s: 0.3875, time:13.3084, lr:0.001\u001b[0m\n",
            "2019-11-25 06:39:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [740/3125], step: 740, 3.023 samples/sec, batch_loss: 0.2930, batch_loss_c: 0.2790, batch_loss_s: 0.3255, time:13.2341, lr:0.001\u001b[0m\n",
            "2019-11-25 06:39:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [750/3125], step: 750, 3.053 samples/sec, batch_loss: 0.1901, batch_loss_c: 0.1980, batch_loss_s: 0.1716, time:13.1016, lr:0.001\u001b[0m\n",
            "2019-11-25 06:39:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [760/3125], step: 760, 3.026 samples/sec, batch_loss: 0.3444, batch_loss_c: 0.3388, batch_loss_s: 0.3572, time:13.2202, lr:0.001\u001b[0m\n",
            "2019-11-25 06:40:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [770/3125], step: 770, 2.972 samples/sec, batch_loss: 0.2760, batch_loss_c: 0.3255, batch_loss_s: 0.1604, time:13.4609, lr:0.001\u001b[0m\n",
            "2019-11-25 06:40:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [780/3125], step: 780, 3.016 samples/sec, batch_loss: 0.3022, batch_loss_c: 0.2847, batch_loss_s: 0.3430, time:13.2643, lr:0.001\u001b[0m\n",
            "2019-11-25 06:40:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [790/3125], step: 790, 2.973 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1388, batch_loss_s: 0.1015, time:13.4529, lr:0.001\u001b[0m\n",
            "2019-11-25 06:40:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [800/3125], step: 800, 3.007 samples/sec, batch_loss: 0.2018, batch_loss_c: 0.2506, batch_loss_s: 0.0878, time:13.3028, lr:0.001\u001b[0m\n",
            "2019-11-25 06:41:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [810/3125], step: 810, 2.895 samples/sec, batch_loss: 0.1923, batch_loss_c: 0.1975, batch_loss_s: 0.1801, time:13.8185, lr:0.001\u001b[0m\n",
            "2019-11-25 06:41:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [820/3125], step: 820, 2.965 samples/sec, batch_loss: 0.4230, batch_loss_c: 0.4298, batch_loss_s: 0.4071, time:13.4893, lr:0.001\u001b[0m\n",
            "2019-11-25 06:41:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [830/3125], step: 830, 3.003 samples/sec, batch_loss: 0.1736, batch_loss_c: 0.1904, batch_loss_s: 0.1343, time:13.3205, lr:0.001\u001b[0m\n",
            "2019-11-25 06:41:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [840/3125], step: 840, 2.968 samples/sec, batch_loss: 0.3869, batch_loss_c: 0.4038, batch_loss_s: 0.3475, time:13.4768, lr:0.001\u001b[0m\n",
            "2019-11-25 06:42:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [850/3125], step: 850, 3.001 samples/sec, batch_loss: 0.2652, batch_loss_c: 0.2769, batch_loss_s: 0.2380, time:13.3279, lr:0.001\u001b[0m\n",
            "2019-11-25 06:42:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [860/3125], step: 860, 2.988 samples/sec, batch_loss: 0.6012, batch_loss_c: 0.6031, batch_loss_s: 0.5969, time:13.3858, lr:0.001\u001b[0m\n",
            "2019-11-25 06:42:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [870/3125], step: 870, 2.976 samples/sec, batch_loss: 0.2537, batch_loss_c: 0.2754, batch_loss_s: 0.2032, time:13.4402, lr:0.001\u001b[0m\n",
            "2019-11-25 06:42:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [880/3125], step: 880, 3.057 samples/sec, batch_loss: 0.3715, batch_loss_c: 0.3873, batch_loss_s: 0.3346, time:13.0837, lr:0.001\u001b[0m\n",
            "2019-11-25 06:42:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [890/3125], step: 890, 3.023 samples/sec, batch_loss: 0.5173, batch_loss_c: 0.4994, batch_loss_s: 0.5593, time:13.2310, lr:0.001\u001b[0m\n",
            "2019-11-25 06:43:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [900/3125], step: 900, 3.022 samples/sec, batch_loss: 0.6912, batch_loss_c: 0.6581, batch_loss_s: 0.7684, time:13.2377, lr:0.001\u001b[0m\n",
            "2019-11-25 06:43:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [910/3125], step: 910, 3.012 samples/sec, batch_loss: 0.1707, batch_loss_c: 0.1867, batch_loss_s: 0.1335, time:13.2799, lr:0.001\u001b[0m\n",
            "2019-11-25 06:43:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [920/3125], step: 920, 2.976 samples/sec, batch_loss: 0.2716, batch_loss_c: 0.2515, batch_loss_s: 0.3188, time:13.4392, lr:0.001\u001b[0m\n",
            "2019-11-25 06:43:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [930/3125], step: 930, 3.013 samples/sec, batch_loss: 0.4510, batch_loss_c: 0.4286, batch_loss_s: 0.5033, time:13.2760, lr:0.001\u001b[0m\n",
            "2019-11-25 06:44:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [940/3125], step: 940, 3.014 samples/sec, batch_loss: 0.2395, batch_loss_c: 0.2524, batch_loss_s: 0.2093, time:13.2726, lr:0.001\u001b[0m\n",
            "2019-11-25 06:44:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [950/3125], step: 950, 2.931 samples/sec, batch_loss: 0.1461, batch_loss_c: 0.1516, batch_loss_s: 0.1334, time:13.6459, lr:0.001\u001b[0m\n",
            "2019-11-25 06:44:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [960/3125], step: 960, 3.021 samples/sec, batch_loss: 0.1328, batch_loss_c: 0.1408, batch_loss_s: 0.1141, time:13.2426, lr:0.001\u001b[0m\n",
            "2019-11-25 06:44:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [970/3125], step: 970, 2.971 samples/sec, batch_loss: 0.3364, batch_loss_c: 0.3397, batch_loss_s: 0.3288, time:13.4643, lr:0.001\u001b[0m\n",
            "2019-11-25 06:44:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [980/3125], step: 980, 2.959 samples/sec, batch_loss: 0.2541, batch_loss_c: 0.3000, batch_loss_s: 0.1473, time:13.5187, lr:0.001\u001b[0m\n",
            "2019-11-25 06:45:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [990/3125], step: 990, 2.981 samples/sec, batch_loss: 0.3731, batch_loss_c: 0.3800, batch_loss_s: 0.3572, time:13.4165, lr:0.001\u001b[0m\n",
            "2019-11-25 06:45:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1000/3125], step: 1000, 3.070 samples/sec, batch_loss: 0.5180, batch_loss_c: 0.5064, batch_loss_s: 0.5450, time:13.0313, lr:0.001\u001b[0m\n",
            "2019-11-25 06:45:33 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1010/3125], step: 1010, 3.021 samples/sec, batch_loss: 0.6164, batch_loss_c: 0.6101, batch_loss_s: 0.6311, time:13.2392, lr:0.001\u001b[0m\n",
            "2019-11-25 06:45:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1020/3125], step: 1020, 3.009 samples/sec, batch_loss: 0.1479, batch_loss_c: 0.1615, batch_loss_s: 0.1160, time:13.2927, lr:0.001\u001b[0m\n",
            "2019-11-25 06:46:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1030/3125], step: 1030, 3.013 samples/sec, batch_loss: 0.4016, batch_loss_c: 0.4282, batch_loss_s: 0.3393, time:13.2777, lr:0.001\u001b[0m\n",
            "2019-11-25 06:46:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1040/3125], step: 1040, 2.976 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1175, batch_loss_s: 0.1043, time:13.4424, lr:0.001\u001b[0m\n",
            "2019-11-25 06:46:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1050/3125], step: 1050, 2.966 samples/sec, batch_loss: 0.2728, batch_loss_c: 0.3403, batch_loss_s: 0.1152, time:13.4843, lr:0.001\u001b[0m\n",
            "2019-11-25 06:46:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1060/3125], step: 1060, 3.030 samples/sec, batch_loss: 0.4298, batch_loss_c: 0.3918, batch_loss_s: 0.5185, time:13.2023, lr:0.001\u001b[0m\n",
            "2019-11-25 06:46:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1070/3125], step: 1070, 3.000 samples/sec, batch_loss: 0.1542, batch_loss_c: 0.1691, batch_loss_s: 0.1194, time:13.3324, lr:0.001\u001b[0m\n",
            "2019-11-25 06:47:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1080/3125], step: 1080, 3.007 samples/sec, batch_loss: 0.1064, batch_loss_c: 0.1096, batch_loss_s: 0.0989, time:13.3016, lr:0.001\u001b[0m\n",
            "2019-11-25 06:47:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1090/3125], step: 1090, 2.994 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1613, batch_loss_s: 0.1015, time:13.3600, lr:0.001\u001b[0m\n",
            "2019-11-25 06:47:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1100/3125], step: 1100, 2.987 samples/sec, batch_loss: 0.2726, batch_loss_c: 0.2753, batch_loss_s: 0.2663, time:13.3893, lr:0.001\u001b[0m\n",
            "2019-11-25 06:47:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1110/3125], step: 1110, 3.015 samples/sec, batch_loss: 0.5012, batch_loss_c: 0.5135, batch_loss_s: 0.4727, time:13.2684, lr:0.001\u001b[0m\n",
            "2019-11-25 06:48:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1120/3125], step: 1120, 2.954 samples/sec, batch_loss: 0.2594, batch_loss_c: 0.2737, batch_loss_s: 0.2259, time:13.5431, lr:0.001\u001b[0m\n",
            "2019-11-25 06:48:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1130/3125], step: 1130, 2.967 samples/sec, batch_loss: 0.1219, batch_loss_c: 0.1311, batch_loss_s: 0.1005, time:13.4813, lr:0.001\u001b[0m\n",
            "2019-11-25 06:48:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1140/3125], step: 1140, 2.997 samples/sec, batch_loss: 0.3226, batch_loss_c: 0.3259, batch_loss_s: 0.3151, time:13.3488, lr:0.001\u001b[0m\n",
            "2019-11-25 06:48:40 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1150/3125], step: 1150, 3.029 samples/sec, batch_loss: 0.1419, batch_loss_c: 0.1544, batch_loss_s: 0.1126, time:13.2055, lr:0.001\u001b[0m\n",
            "2019-11-25 06:48:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1160/3125], step: 1160, 2.978 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3567, batch_loss_s: 0.3316, time:13.4302, lr:0.001\u001b[0m\n",
            "2019-11-25 06:49:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1170/3125], step: 1170, 2.963 samples/sec, batch_loss: 0.1386, batch_loss_c: 0.1493, batch_loss_s: 0.1136, time:13.5010, lr:0.001\u001b[0m\n",
            "2019-11-25 06:49:21 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1180/3125], step: 1180, 2.976 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1557, batch_loss_s: 0.1065, time:13.4408, lr:0.001\u001b[0m\n",
            "2019-11-25 06:49:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1190/3125], step: 1190, 2.971 samples/sec, batch_loss: 0.1823, batch_loss_c: 0.1933, batch_loss_s: 0.1565, time:13.4635, lr:0.001\u001b[0m\n",
            "2019-11-25 06:49:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1200/3125], step: 1200, 3.012 samples/sec, batch_loss: 0.1966, batch_loss_c: 0.2167, batch_loss_s: 0.1497, time:13.2787, lr:0.001\u001b[0m\n",
            "2019-11-25 06:50:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1210/3125], step: 1210, 3.045 samples/sec, batch_loss: 0.2613, batch_loss_c: 0.2750, batch_loss_s: 0.2294, time:13.1354, lr:0.001\u001b[0m\n",
            "2019-11-25 06:50:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1220/3125], step: 1220, 3.040 samples/sec, batch_loss: 0.1945, batch_loss_c: 0.2180, batch_loss_s: 0.1395, time:13.1593, lr:0.001\u001b[0m\n",
            "2019-11-25 06:50:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1230/3125], step: 1230, 2.962 samples/sec, batch_loss: 0.4576, batch_loss_c: 0.4785, batch_loss_s: 0.4087, time:13.5024, lr:0.001\u001b[0m\n",
            "2019-11-25 06:50:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1240/3125], step: 1240, 3.004 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1249, batch_loss_s: 0.1077, time:13.3152, lr:0.001\u001b[0m\n",
            "2019-11-25 06:50:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1250/3125], step: 1250, 2.986 samples/sec, batch_loss: 0.1562, batch_loss_c: 0.1603, batch_loss_s: 0.1467, time:13.3946, lr:0.001\u001b[0m\n",
            "2019-11-25 06:51:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1260/3125], step: 1260, 3.012 samples/sec, batch_loss: 0.1322, batch_loss_c: 0.1430, batch_loss_s: 0.1070, time:13.2822, lr:0.001\u001b[0m\n",
            "2019-11-25 06:51:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1270/3125], step: 1270, 3.033 samples/sec, batch_loss: 0.3064, batch_loss_c: 0.3609, batch_loss_s: 0.1795, time:13.1894, lr:0.001\u001b[0m\n",
            "2019-11-25 06:51:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1280/3125], step: 1280, 2.948 samples/sec, batch_loss: 0.2262, batch_loss_c: 0.2693, batch_loss_s: 0.1259, time:13.5665, lr:0.001\u001b[0m\n",
            "2019-11-25 06:51:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1290/3125], step: 1290, 2.989 samples/sec, batch_loss: 0.5055, batch_loss_c: 0.5480, batch_loss_s: 0.4062, time:13.3829, lr:0.001\u001b[0m\n",
            "2019-11-25 06:52:01 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1300/3125], step: 1300, 3.038 samples/sec, batch_loss: 0.3282, batch_loss_c: 0.3154, batch_loss_s: 0.3579, time:13.1656, lr:0.001\u001b[0m\n",
            "2019-11-25 06:52:14 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1310/3125], step: 1310, 3.004 samples/sec, batch_loss: 0.5519, batch_loss_c: 0.5384, batch_loss_s: 0.5833, time:13.3172, lr:0.001\u001b[0m\n",
            "2019-11-25 06:52:27 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1320/3125], step: 1320, 2.989 samples/sec, batch_loss: 0.1750, batch_loss_c: 0.1948, batch_loss_s: 0.1288, time:13.3807, lr:0.001\u001b[0m\n",
            "2019-11-25 06:52:41 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1330/3125], step: 1330, 3.002 samples/sec, batch_loss: 0.1996, batch_loss_c: 0.2389, batch_loss_s: 0.1078, time:13.3228, lr:0.001\u001b[0m\n",
            "2019-11-25 06:52:54 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1340/3125], step: 1340, 3.021 samples/sec, batch_loss: 0.1421, batch_loss_c: 0.1512, batch_loss_s: 0.1208, time:13.2414, lr:0.001\u001b[0m\n",
            "2019-11-25 06:53:07 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1350/3125], step: 1350, 3.029 samples/sec, batch_loss: 0.3692, batch_loss_c: 0.3782, batch_loss_s: 0.3483, time:13.2046, lr:0.001\u001b[0m\n",
            "2019-11-25 06:53:20 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1360/3125], step: 1360, 3.026 samples/sec, batch_loss: 0.1527, batch_loss_c: 0.1574, batch_loss_s: 0.1416, time:13.2192, lr:0.001\u001b[0m\n",
            "2019-11-25 06:53:34 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1370/3125], step: 1370, 3.001 samples/sec, batch_loss: 0.2313, batch_loss_c: 0.2448, batch_loss_s: 0.1998, time:13.3293, lr:0.001\u001b[0m\n",
            "2019-11-25 06:53:47 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1380/3125], step: 1380, 3.045 samples/sec, batch_loss: 0.1568, batch_loss_c: 0.1590, batch_loss_s: 0.1515, time:13.1370, lr:0.001\u001b[0m\n",
            "2019-11-25 06:54:00 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1390/3125], step: 1390, 3.050 samples/sec, batch_loss: 0.1474, batch_loss_c: 0.1603, batch_loss_s: 0.1173, time:13.1133, lr:0.001\u001b[0m\n",
            "2019-11-25 06:54:13 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1400/3125], step: 1400, 3.046 samples/sec, batch_loss: 0.5748, batch_loss_c: 0.5715, batch_loss_s: 0.5828, time:13.1311, lr:0.001\u001b[0m\n",
            "2019-11-25 06:54:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1410/3125], step: 1410, 3.032 samples/sec, batch_loss: 0.1603, batch_loss_c: 0.1882, batch_loss_s: 0.0954, time:13.1925, lr:0.001\u001b[0m\n",
            "2019-11-25 06:54:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1420/3125], step: 1420, 3.059 samples/sec, batch_loss: 0.1805, batch_loss_c: 0.2071, batch_loss_s: 0.1184, time:13.0783, lr:0.001\u001b[0m\n",
            "2019-11-25 06:54:53 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1430/3125], step: 1430, 2.998 samples/sec, batch_loss: 0.3363, batch_loss_c: 0.3337, batch_loss_s: 0.3423, time:13.3410, lr:0.001\u001b[0m\n",
            "2019-11-25 06:55:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1440/3125], step: 1440, 2.993 samples/sec, batch_loss: 0.2018, batch_loss_c: 0.2177, batch_loss_s: 0.1646, time:13.3627, lr:0.001\u001b[0m\n",
            "2019-11-25 06:55:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1450/3125], step: 1450, 3.048 samples/sec, batch_loss: 0.3513, batch_loss_c: 0.3393, batch_loss_s: 0.3793, time:13.1218, lr:0.001\u001b[0m\n",
            "2019-11-25 06:55:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1460/3125], step: 1460, 3.001 samples/sec, batch_loss: 0.1630, batch_loss_c: 0.1772, batch_loss_s: 0.1296, time:13.3290, lr:0.001\u001b[0m\n",
            "2019-11-25 06:55:46 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1470/3125], step: 1470, 3.043 samples/sec, batch_loss: 0.2422, batch_loss_c: 0.2309, batch_loss_s: 0.2684, time:13.1448, lr:0.001\u001b[0m\n",
            "2019-11-25 06:55:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1480/3125], step: 1480, 3.047 samples/sec, batch_loss: 0.1597, batch_loss_c: 0.1670, batch_loss_s: 0.1427, time:13.1295, lr:0.001\u001b[0m\n",
            "2019-11-25 06:56:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1490/3125], step: 1490, 2.928 samples/sec, batch_loss: 0.2387, batch_loss_c: 0.2541, batch_loss_s: 0.2028, time:13.6601, lr:0.001\u001b[0m\n",
            "2019-11-25 06:56:26 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1500/3125], step: 1500, 2.990 samples/sec, batch_loss: 0.3659, batch_loss_c: 0.3625, batch_loss_s: 0.3736, time:13.3772, lr:0.001\u001b[0m\n",
            "2019-11-25 06:56:39 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1510/3125], step: 1510, 3.014 samples/sec, batch_loss: 0.1467, batch_loss_c: 0.1555, batch_loss_s: 0.1261, time:13.2693, lr:0.001\u001b[0m\n",
            "2019-11-25 06:56:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1520/3125], step: 1520, 2.995 samples/sec, batch_loss: 0.1616, batch_loss_c: 0.1704, batch_loss_s: 0.1411, time:13.3541, lr:0.001\u001b[0m\n",
            "2019-11-25 06:57:06 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1530/3125], step: 1530, 3.005 samples/sec, batch_loss: 0.4065, batch_loss_c: 0.4429, batch_loss_s: 0.3217, time:13.3131, lr:0.001\u001b[0m\n",
            "2019-11-25 06:57:19 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1540/3125], step: 1540, 3.006 samples/sec, batch_loss: 0.0956, batch_loss_c: 0.0895, batch_loss_s: 0.1098, time:13.3064, lr:0.001\u001b[0m\n",
            "2019-11-25 06:57:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1550/3125], step: 1550, 3.025 samples/sec, batch_loss: 0.2769, batch_loss_c: 0.2540, batch_loss_s: 0.3303, time:13.2223, lr:0.001\u001b[0m\n",
            "2019-11-25 06:57:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1560/3125], step: 1560, 3.011 samples/sec, batch_loss: 0.2442, batch_loss_c: 0.2777, batch_loss_s: 0.1660, time:13.2836, lr:0.001\u001b[0m\n",
            "2019-11-25 06:57:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1570/3125], step: 1570, 3.018 samples/sec, batch_loss: 0.4028, batch_loss_c: 0.4138, batch_loss_s: 0.3773, time:13.2530, lr:0.001\u001b[0m\n",
            "2019-11-25 06:58:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1580/3125], step: 1580, 3.041 samples/sec, batch_loss: 0.2913, batch_loss_c: 0.2798, batch_loss_s: 0.3182, time:13.1545, lr:0.001\u001b[0m\n",
            "2019-11-25 06:58:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1590/3125], step: 1590, 3.017 samples/sec, batch_loss: 0.4692, batch_loss_c: 0.4792, batch_loss_s: 0.4458, time:13.2572, lr:0.001\u001b[0m\n",
            "2019-11-25 06:58:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1600/3125], step: 1600, 3.008 samples/sec, batch_loss: 0.2897, batch_loss_c: 0.2724, batch_loss_s: 0.3300, time:13.2977, lr:0.001\u001b[0m\n",
            "2019-11-25 06:58:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1610/3125], step: 1610, 3.030 samples/sec, batch_loss: 0.4176, batch_loss_c: 0.4416, batch_loss_s: 0.3618, time:13.2019, lr:0.001\u001b[0m\n",
            "2019-11-25 06:59:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1620/3125], step: 1620, 2.973 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1660, batch_loss_s: 0.1152, time:13.4537, lr:0.001\u001b[0m\n",
            "2019-11-25 06:59:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1630/3125], step: 1630, 3.030 samples/sec, batch_loss: 0.5565, batch_loss_c: 0.5538, batch_loss_s: 0.5629, time:13.2008, lr:0.001\u001b[0m\n",
            "2019-11-25 06:59:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1640/3125], step: 1640, 3.048 samples/sec, batch_loss: 0.1729, batch_loss_c: 0.1993, batch_loss_s: 0.1113, time:13.1216, lr:0.001\u001b[0m\n",
            "2019-11-25 06:59:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1650/3125], step: 1650, 3.003 samples/sec, batch_loss: 0.3834, batch_loss_c: 0.4041, batch_loss_s: 0.3352, time:13.3189, lr:0.001\u001b[0m\n",
            "2019-11-25 06:59:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1660/3125], step: 1660, 2.994 samples/sec, batch_loss: 0.4373, batch_loss_c: 0.4231, batch_loss_s: 0.4703, time:13.3588, lr:0.001\u001b[0m\n",
            "2019-11-25 07:00:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1670/3125], step: 1670, 2.993 samples/sec, batch_loss: 0.2961, batch_loss_c: 0.2755, batch_loss_s: 0.3441, time:13.3642, lr:0.001\u001b[0m\n",
            "2019-11-25 07:00:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1680/3125], step: 1680, 2.996 samples/sec, batch_loss: 0.1519, batch_loss_c: 0.1626, batch_loss_s: 0.1271, time:13.3507, lr:0.001\u001b[0m\n",
            "2019-11-25 07:00:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1690/3125], step: 1690, 2.963 samples/sec, batch_loss: 0.1640, batch_loss_c: 0.1729, batch_loss_s: 0.1433, time:13.4980, lr:0.001\u001b[0m\n",
            "2019-11-25 07:00:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1700/3125], step: 1700, 2.974 samples/sec, batch_loss: 0.1492, batch_loss_c: 0.1647, batch_loss_s: 0.1129, time:13.4521, lr:0.001\u001b[0m\n",
            "2019-11-25 07:01:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1710/3125], step: 1710, 3.067 samples/sec, batch_loss: 0.3769, batch_loss_c: 0.3927, batch_loss_s: 0.3398, time:13.0420, lr:0.001\u001b[0m\n",
            "2019-11-25 07:01:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1720/3125], step: 1720, 2.967 samples/sec, batch_loss: 0.2812, batch_loss_c: 0.3311, batch_loss_s: 0.1648, time:13.4828, lr:0.001\u001b[0m\n",
            "2019-11-25 07:01:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1730/3125], step: 1730, 3.027 samples/sec, batch_loss: 0.1200, batch_loss_c: 0.1287, batch_loss_s: 0.0999, time:13.2136, lr:0.001\u001b[0m\n",
            "2019-11-25 07:01:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1740/3125], step: 1740, 2.961 samples/sec, batch_loss: 0.0911, batch_loss_c: 0.0916, batch_loss_s: 0.0899, time:13.5082, lr:0.001\u001b[0m\n",
            "2019-11-25 07:01:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1750/3125], step: 1750, 2.974 samples/sec, batch_loss: 0.1872, batch_loss_c: 0.2126, batch_loss_s: 0.1278, time:13.4514, lr:0.001\u001b[0m\n",
            "2019-11-25 07:02:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1760/3125], step: 1760, 3.018 samples/sec, batch_loss: 0.1492, batch_loss_c: 0.1602, batch_loss_s: 0.1236, time:13.2557, lr:0.001\u001b[0m\n",
            "2019-11-25 07:02:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1770/3125], step: 1770, 3.042 samples/sec, batch_loss: 0.1325, batch_loss_c: 0.1381, batch_loss_s: 0.1195, time:13.1500, lr:0.001\u001b[0m\n",
            "2019-11-25 07:02:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1780/3125], step: 1780, 2.979 samples/sec, batch_loss: 0.2332, batch_loss_c: 0.2566, batch_loss_s: 0.1784, time:13.4270, lr:0.001\u001b[0m\n",
            "2019-11-25 07:02:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1790/3125], step: 1790, 3.007 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1439, batch_loss_s: 0.0894, time:13.3024, lr:0.001\u001b[0m\n",
            "2019-11-25 07:03:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1800/3125], step: 1800, 3.068 samples/sec, batch_loss: 0.3650, batch_loss_c: 0.3780, batch_loss_s: 0.3348, time:13.0394, lr:0.001\u001b[0m\n",
            "2019-11-25 07:03:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1810/3125], step: 1810, 2.962 samples/sec, batch_loss: 0.1293, batch_loss_c: 0.1375, batch_loss_s: 0.1101, time:13.5060, lr:0.001\u001b[0m\n",
            "2019-11-25 07:03:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1820/3125], step: 1820, 3.013 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1276, batch_loss_s: 0.0883, time:13.2750, lr:0.001\u001b[0m\n",
            "2019-11-25 07:03:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1830/3125], step: 1830, 2.987 samples/sec, batch_loss: 0.3752, batch_loss_c: 0.3744, batch_loss_s: 0.3770, time:13.3912, lr:0.001\u001b[0m\n",
            "2019-11-25 07:03:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1840/3125], step: 1840, 3.013 samples/sec, batch_loss: 0.1343, batch_loss_c: 0.1378, batch_loss_s: 0.1261, time:13.2738, lr:0.001\u001b[0m\n",
            "2019-11-25 07:04:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1850/3125], step: 1850, 2.995 samples/sec, batch_loss: 0.2486, batch_loss_c: 0.2849, batch_loss_s: 0.1639, time:13.3559, lr:0.001\u001b[0m\n",
            "2019-11-25 07:04:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1860/3125], step: 1860, 3.020 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1789, batch_loss_s: 0.1074, time:13.2462, lr:0.001\u001b[0m\n",
            "2019-11-25 07:04:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1870/3125], step: 1870, 2.968 samples/sec, batch_loss: 0.1434, batch_loss_c: 0.1550, batch_loss_s: 0.1164, time:13.4784, lr:0.001\u001b[0m\n",
            "2019-11-25 07:04:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1880/3125], step: 1880, 3.008 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1256, batch_loss_s: 0.0932, time:13.2998, lr:0.001\u001b[0m\n",
            "2019-11-25 07:05:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1890/3125], step: 1890, 3.025 samples/sec, batch_loss: 0.2887, batch_loss_c: 0.2772, batch_loss_s: 0.3157, time:13.2248, lr:0.001\u001b[0m\n",
            "2019-11-25 07:05:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1900/3125], step: 1900, 2.998 samples/sec, batch_loss: 0.3565, batch_loss_c: 0.3574, batch_loss_s: 0.3543, time:13.3439, lr:0.001\u001b[0m\n",
            "2019-11-25 07:05:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1910/3125], step: 1910, 3.037 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0772, batch_loss_s: 0.0695, time:13.1691, lr:0.001\u001b[0m\n",
            "2019-11-25 07:05:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1920/3125], step: 1920, 2.973 samples/sec, batch_loss: 0.2177, batch_loss_c: 0.2568, batch_loss_s: 0.1267, time:13.4541, lr:0.001\u001b[0m\n",
            "2019-11-25 07:05:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1930/3125], step: 1930, 3.020 samples/sec, batch_loss: 0.4299, batch_loss_c: 0.4435, batch_loss_s: 0.3979, time:13.2451, lr:0.001\u001b[0m\n",
            "2019-11-25 07:06:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1940/3125], step: 1940, 3.013 samples/sec, batch_loss: 0.1959, batch_loss_c: 0.2104, batch_loss_s: 0.1620, time:13.2740, lr:0.001\u001b[0m\n",
            "2019-11-25 07:06:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1950/3125], step: 1950, 3.044 samples/sec, batch_loss: 0.5024, batch_loss_c: 0.4781, batch_loss_s: 0.5591, time:13.1416, lr:0.001\u001b[0m\n",
            "2019-11-25 07:06:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1960/3125], step: 1960, 3.014 samples/sec, batch_loss: 0.1021, batch_loss_c: 0.1011, batch_loss_s: 0.1044, time:13.2710, lr:0.001\u001b[0m\n",
            "2019-11-25 07:06:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1970/3125], step: 1970, 2.953 samples/sec, batch_loss: 0.1124, batch_loss_c: 0.1204, batch_loss_s: 0.0938, time:13.5434, lr:0.001\u001b[0m\n",
            "2019-11-25 07:07:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1980/3125], step: 1980, 3.040 samples/sec, batch_loss: 0.3212, batch_loss_c: 0.3099, batch_loss_s: 0.3475, time:13.1598, lr:0.001\u001b[0m\n",
            "2019-11-25 07:07:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [1990/3125], step: 1990, 2.994 samples/sec, batch_loss: 0.3116, batch_loss_c: 0.2966, batch_loss_s: 0.3467, time:13.3594, lr:0.001\u001b[0m\n",
            "2019-11-25 07:07:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2000/3125], step: 2000, 3.040 samples/sec, batch_loss: 0.2161, batch_loss_c: 0.2456, batch_loss_s: 0.1471, time:13.1578, lr:0.001\u001b[0m\n",
            "2019-11-25 07:07:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2010/3125], step: 2010, 3.041 samples/sec, batch_loss: 0.2230, batch_loss_c: 0.2274, batch_loss_s: 0.2127, time:13.1536, lr:0.001\u001b[0m\n",
            "2019-11-25 07:07:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2020/3125], step: 2020, 3.020 samples/sec, batch_loss: 0.1779, batch_loss_c: 0.1946, batch_loss_s: 0.1390, time:13.2455, lr:0.001\u001b[0m\n",
            "2019-11-25 07:08:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2030/3125], step: 2030, 2.955 samples/sec, batch_loss: 0.1402, batch_loss_c: 0.1589, batch_loss_s: 0.0966, time:13.5373, lr:0.001\u001b[0m\n",
            "2019-11-25 07:08:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2040/3125], step: 2040, 2.942 samples/sec, batch_loss: 0.1682, batch_loss_c: 0.1781, batch_loss_s: 0.1452, time:13.5939, lr:0.001\u001b[0m\n",
            "2019-11-25 07:08:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2050/3125], step: 2050, 3.046 samples/sec, batch_loss: 0.1214, batch_loss_c: 0.1230, batch_loss_s: 0.1175, time:13.1330, lr:0.001\u001b[0m\n",
            "2019-11-25 07:08:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2060/3125], step: 2060, 3.033 samples/sec, batch_loss: 0.1055, batch_loss_c: 0.1126, batch_loss_s: 0.0891, time:13.1886, lr:0.001\u001b[0m\n",
            "2019-11-25 07:09:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2070/3125], step: 2070, 2.912 samples/sec, batch_loss: 0.1509, batch_loss_c: 0.1570, batch_loss_s: 0.1367, time:13.7382, lr:0.001\u001b[0m\n",
            "2019-11-25 07:09:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2080/3125], step: 2080, 3.013 samples/sec, batch_loss: 0.2337, batch_loss_c: 0.2719, batch_loss_s: 0.1446, time:13.2743, lr:0.001\u001b[0m\n",
            "2019-11-25 07:09:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2090/3125], step: 2090, 3.046 samples/sec, batch_loss: 0.1313, batch_loss_c: 0.1489, batch_loss_s: 0.0901, time:13.1330, lr:0.001\u001b[0m\n",
            "2019-11-25 07:09:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2100/3125], step: 2100, 3.015 samples/sec, batch_loss: 0.2841, batch_loss_c: 0.2848, batch_loss_s: 0.2826, time:13.2654, lr:0.001\u001b[0m\n",
            "2019-11-25 07:09:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2110/3125], step: 2110, 2.999 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1089, batch_loss_s: 0.0995, time:13.3397, lr:0.001\u001b[0m\n",
            "2019-11-25 07:10:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2120/3125], step: 2120, 3.030 samples/sec, batch_loss: 0.3783, batch_loss_c: 0.3753, batch_loss_s: 0.3852, time:13.2012, lr:0.001\u001b[0m\n",
            "2019-11-25 07:10:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2130/3125], step: 2130, 2.999 samples/sec, batch_loss: 0.3185, batch_loss_c: 0.3181, batch_loss_s: 0.3194, time:13.3362, lr:0.001\u001b[0m\n",
            "2019-11-25 07:10:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2140/3125], step: 2140, 2.981 samples/sec, batch_loss: 0.2689, batch_loss_c: 0.3320, batch_loss_s: 0.1218, time:13.4186, lr:0.001\u001b[0m\n",
            "2019-11-25 07:10:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2150/3125], step: 2150, 2.951 samples/sec, batch_loss: 0.4122, batch_loss_c: 0.4275, batch_loss_s: 0.3767, time:13.5551, lr:0.001\u001b[0m\n",
            "2019-11-25 07:11:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2160/3125], step: 2160, 2.995 samples/sec, batch_loss: 0.5550, batch_loss_c: 0.5562, batch_loss_s: 0.5521, time:13.3568, lr:0.001\u001b[0m\n",
            "2019-11-25 07:11:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2170/3125], step: 2170, 2.993 samples/sec, batch_loss: 0.2075, batch_loss_c: 0.2151, batch_loss_s: 0.1898, time:13.3635, lr:0.001\u001b[0m\n",
            "2019-11-25 07:11:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2180/3125], step: 2180, 2.966 samples/sec, batch_loss: 0.2788, batch_loss_c: 0.2549, batch_loss_s: 0.3346, time:13.4854, lr:0.001\u001b[0m\n",
            "2019-11-25 07:11:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2190/3125], step: 2190, 3.061 samples/sec, batch_loss: 0.2450, batch_loss_c: 0.2673, batch_loss_s: 0.1931, time:13.0678, lr:0.001\u001b[0m\n",
            "2019-11-25 07:11:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2200/3125], step: 2200, 2.998 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3223, batch_loss_s: 0.3227, time:13.3421, lr:0.001\u001b[0m\n",
            "2019-11-25 07:12:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2210/3125], step: 2210, 3.000 samples/sec, batch_loss: 0.3562, batch_loss_c: 0.3566, batch_loss_s: 0.3553, time:13.3337, lr:0.001\u001b[0m\n",
            "2019-11-25 07:12:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2220/3125], step: 2220, 3.030 samples/sec, batch_loss: 0.1067, batch_loss_c: 0.1111, batch_loss_s: 0.0963, time:13.2006, lr:0.001\u001b[0m\n",
            "2019-11-25 07:12:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2230/3125], step: 2230, 3.015 samples/sec, batch_loss: 0.4324, batch_loss_c: 0.4527, batch_loss_s: 0.3852, time:13.2661, lr:0.001\u001b[0m\n",
            "2019-11-25 07:12:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2240/3125], step: 2240, 3.026 samples/sec, batch_loss: 0.7338, batch_loss_c: 0.7163, batch_loss_s: 0.7747, time:13.2166, lr:0.001\u001b[0m\n",
            "2019-11-25 07:13:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2250/3125], step: 2250, 2.961 samples/sec, batch_loss: 0.4087, batch_loss_c: 0.4059, batch_loss_s: 0.4152, time:13.5093, lr:0.001\u001b[0m\n",
            "2019-11-25 07:13:17 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2260/3125], step: 2260, 3.019 samples/sec, batch_loss: 0.1824, batch_loss_c: 0.1987, batch_loss_s: 0.1445, time:13.2501, lr:0.001\u001b[0m\n",
            "2019-11-25 07:13:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2270/3125], step: 2270, 3.022 samples/sec, batch_loss: 0.3315, batch_loss_c: 0.3301, batch_loss_s: 0.3345, time:13.2376, lr:0.001\u001b[0m\n",
            "2019-11-25 07:13:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2280/3125], step: 2280, 3.019 samples/sec, batch_loss: 0.1414, batch_loss_c: 0.1573, batch_loss_s: 0.1042, time:13.2507, lr:0.001\u001b[0m\n",
            "2019-11-25 07:13:57 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2290/3125], step: 2290, 3.052 samples/sec, batch_loss: 0.4704, batch_loss_c: 0.4819, batch_loss_s: 0.4436, time:13.1076, lr:0.001\u001b[0m\n",
            "2019-11-25 07:14:10 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2300/3125], step: 2300, 3.004 samples/sec, batch_loss: 0.2330, batch_loss_c: 0.2591, batch_loss_s: 0.1720, time:13.3164, lr:0.001\u001b[0m\n",
            "2019-11-25 07:14:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2310/3125], step: 2310, 2.909 samples/sec, batch_loss: 0.2616, batch_loss_c: 0.2761, batch_loss_s: 0.2276, time:13.7491, lr:0.001\u001b[0m\n",
            "2019-11-25 07:14:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2320/3125], step: 2320, 2.931 samples/sec, batch_loss: 0.2684, batch_loss_c: 0.2946, batch_loss_s: 0.2071, time:13.6484, lr:0.001\u001b[0m\n",
            "2019-11-25 07:14:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2330/3125], step: 2330, 3.010 samples/sec, batch_loss: 0.1888, batch_loss_c: 0.2097, batch_loss_s: 0.1399, time:13.2885, lr:0.001\u001b[0m\n",
            "2019-11-25 07:15:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2340/3125], step: 2340, 3.042 samples/sec, batch_loss: 0.3035, batch_loss_c: 0.3722, batch_loss_s: 0.1433, time:13.1490, lr:0.001\u001b[0m\n",
            "2019-11-25 07:15:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2350/3125], step: 2350, 2.991 samples/sec, batch_loss: 0.1780, batch_loss_c: 0.1951, batch_loss_s: 0.1383, time:13.3733, lr:0.001\u001b[0m\n",
            "2019-11-25 07:15:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2360/3125], step: 2360, 2.950 samples/sec, batch_loss: 0.3668, batch_loss_c: 0.3808, batch_loss_s: 0.3340, time:13.5594, lr:0.001\u001b[0m\n",
            "2019-11-25 07:15:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2370/3125], step: 2370, 3.048 samples/sec, batch_loss: 0.4638, batch_loss_c: 0.4764, batch_loss_s: 0.4344, time:13.1233, lr:0.001\u001b[0m\n",
            "2019-11-25 07:15:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2380/3125], step: 2380, 2.956 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2371, batch_loss_s: 0.1242, time:13.5336, lr:0.001\u001b[0m\n",
            "2019-11-25 07:16:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2390/3125], step: 2390, 2.988 samples/sec, batch_loss: 0.3325, batch_loss_c: 0.3322, batch_loss_s: 0.3331, time:13.3848, lr:0.001\u001b[0m\n",
            "2019-11-25 07:16:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2400/3125], step: 2400, 3.069 samples/sec, batch_loss: 0.6834, batch_loss_c: 0.6437, batch_loss_s: 0.7760, time:13.0340, lr:0.001\u001b[0m\n",
            "2019-11-25 07:16:37 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2410/3125], step: 2410, 3.011 samples/sec, batch_loss: 0.1337, batch_loss_c: 0.1440, batch_loss_s: 0.1094, time:13.2858, lr:0.001\u001b[0m\n",
            "2019-11-25 07:16:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2420/3125], step: 2420, 3.033 samples/sec, batch_loss: 0.3398, batch_loss_c: 0.3516, batch_loss_s: 0.3121, time:13.1875, lr:0.001\u001b[0m\n",
            "2019-11-25 07:17:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2430/3125], step: 2430, 2.936 samples/sec, batch_loss: 0.3066, batch_loss_c: 0.2981, batch_loss_s: 0.3263, time:13.6229, lr:0.001\u001b[0m\n",
            "2019-11-25 07:17:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2440/3125], step: 2440, 3.013 samples/sec, batch_loss: 0.3675, batch_loss_c: 0.3765, batch_loss_s: 0.3464, time:13.2749, lr:0.001\u001b[0m\n",
            "2019-11-25 07:17:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2450/3125], step: 2450, 2.916 samples/sec, batch_loss: 0.1327, batch_loss_c: 0.1486, batch_loss_s: 0.0957, time:13.7170, lr:0.001\u001b[0m\n",
            "2019-11-25 07:17:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2460/3125], step: 2460, 2.998 samples/sec, batch_loss: 0.2878, batch_loss_c: 0.2718, batch_loss_s: 0.3252, time:13.3442, lr:0.001\u001b[0m\n",
            "2019-11-25 07:17:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2470/3125], step: 2470, 3.006 samples/sec, batch_loss: 0.2225, batch_loss_c: 0.2277, batch_loss_s: 0.2103, time:13.3049, lr:0.001\u001b[0m\n",
            "2019-11-25 07:18:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2480/3125], step: 2480, 2.992 samples/sec, batch_loss: 0.2826, batch_loss_c: 0.3294, batch_loss_s: 0.1734, time:13.3668, lr:0.001\u001b[0m\n",
            "2019-11-25 07:18:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2490/3125], step: 2490, 3.027 samples/sec, batch_loss: 0.3745, batch_loss_c: 0.3863, batch_loss_s: 0.3470, time:13.2145, lr:0.001\u001b[0m\n",
            "2019-11-25 07:18:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2500/3125], step: 2500, 3.010 samples/sec, batch_loss: 0.2533, batch_loss_c: 0.3044, batch_loss_s: 0.1338, time:13.2876, lr:0.001\u001b[0m\n",
            "2019-11-25 07:18:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2510/3125], step: 2510, 3.034 samples/sec, batch_loss: 0.2446, batch_loss_c: 0.2528, batch_loss_s: 0.2257, time:13.1825, lr:0.001\u001b[0m\n",
            "2019-11-25 07:19:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2520/3125], step: 2520, 2.982 samples/sec, batch_loss: 0.4434, batch_loss_c: 0.4434, batch_loss_s: 0.4435, time:13.4146, lr:0.001\u001b[0m\n",
            "2019-11-25 07:19:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2530/3125], step: 2530, 3.035 samples/sec, batch_loss: 0.2753, batch_loss_c: 0.2800, batch_loss_s: 0.2642, time:13.1793, lr:0.001\u001b[0m\n",
            "2019-11-25 07:19:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2540/3125], step: 2540, 2.977 samples/sec, batch_loss: 0.2722, batch_loss_c: 0.2746, batch_loss_s: 0.2665, time:13.4355, lr:0.001\u001b[0m\n",
            "2019-11-25 07:19:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2550/3125], step: 2550, 3.033 samples/sec, batch_loss: 0.2583, batch_loss_c: 0.2515, batch_loss_s: 0.2741, time:13.1865, lr:0.001\u001b[0m\n",
            "2019-11-25 07:19:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2560/3125], step: 2560, 2.984 samples/sec, batch_loss: 0.3683, batch_loss_c: 0.3862, batch_loss_s: 0.3265, time:13.4060, lr:0.001\u001b[0m\n",
            "2019-11-25 07:20:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2570/3125], step: 2570, 3.041 samples/sec, batch_loss: 0.3138, batch_loss_c: 0.3116, batch_loss_s: 0.3189, time:13.1522, lr:0.001\u001b[0m\n",
            "2019-11-25 07:20:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2580/3125], step: 2580, 3.009 samples/sec, batch_loss: 0.1886, batch_loss_c: 0.2123, batch_loss_s: 0.1334, time:13.2940, lr:0.001\u001b[0m\n",
            "2019-11-25 07:20:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2590/3125], step: 2590, 2.958 samples/sec, batch_loss: 0.1391, batch_loss_c: 0.1531, batch_loss_s: 0.1065, time:13.5225, lr:0.001\u001b[0m\n",
            "2019-11-25 07:20:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2600/3125], step: 2600, 3.008 samples/sec, batch_loss: 0.2194, batch_loss_c: 0.2412, batch_loss_s: 0.1687, time:13.2982, lr:0.001\u001b[0m\n",
            "2019-11-25 07:21:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2610/3125], step: 2610, 2.996 samples/sec, batch_loss: 0.3275, batch_loss_c: 0.3250, batch_loss_s: 0.3332, time:13.3511, lr:0.001\u001b[0m\n",
            "2019-11-25 07:21:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2620/3125], step: 2620, 2.979 samples/sec, batch_loss: 0.3461, batch_loss_c: 0.3633, batch_loss_s: 0.3059, time:13.4263, lr:0.001\u001b[0m\n",
            "2019-11-25 07:21:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2630/3125], step: 2630, 3.017 samples/sec, batch_loss: 0.1863, batch_loss_c: 0.2281, batch_loss_s: 0.0889, time:13.2596, lr:0.001\u001b[0m\n",
            "2019-11-25 07:21:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2640/3125], step: 2640, 3.015 samples/sec, batch_loss: 0.3809, batch_loss_c: 0.3993, batch_loss_s: 0.3378, time:13.2661, lr:0.001\u001b[0m\n",
            "2019-11-25 07:21:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2650/3125], step: 2650, 2.941 samples/sec, batch_loss: 0.1833, batch_loss_c: 0.2178, batch_loss_s: 0.1027, time:13.6017, lr:0.001\u001b[0m\n",
            "2019-11-25 07:22:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2660/3125], step: 2660, 2.980 samples/sec, batch_loss: 0.1531, batch_loss_c: 0.1659, batch_loss_s: 0.1232, time:13.4224, lr:0.001\u001b[0m\n",
            "2019-11-25 07:22:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2670/3125], step: 2670, 2.985 samples/sec, batch_loss: 0.1915, batch_loss_c: 0.2065, batch_loss_s: 0.1564, time:13.3982, lr:0.001\u001b[0m\n",
            "2019-11-25 07:22:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2680/3125], step: 2680, 2.976 samples/sec, batch_loss: 0.3435, batch_loss_c: 0.3472, batch_loss_s: 0.3347, time:13.4397, lr:0.001\u001b[0m\n",
            "2019-11-25 07:22:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2690/3125], step: 2690, 2.988 samples/sec, batch_loss: 0.5428, batch_loss_c: 0.5418, batch_loss_s: 0.5451, time:13.3885, lr:0.001\u001b[0m\n",
            "2019-11-25 07:23:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2700/3125], step: 2700, 3.010 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1057, batch_loss_s: 0.1123, time:13.2883, lr:0.001\u001b[0m\n",
            "2019-11-25 07:23:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2710/3125], step: 2710, 3.009 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1212, batch_loss_s: 0.1041, time:13.2929, lr:0.001\u001b[0m\n",
            "2019-11-25 07:23:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2720/3125], step: 2720, 2.972 samples/sec, batch_loss: 0.1838, batch_loss_c: 0.2144, batch_loss_s: 0.1122, time:13.4568, lr:0.001\u001b[0m\n",
            "2019-11-25 07:23:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2730/3125], step: 2730, 2.931 samples/sec, batch_loss: 0.4044, batch_loss_c: 0.4220, batch_loss_s: 0.3632, time:13.6476, lr:0.001\u001b[0m\n",
            "2019-11-25 07:23:59 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2740/3125], step: 2740, 2.969 samples/sec, batch_loss: 0.1158, batch_loss_c: 0.1092, batch_loss_s: 0.1311, time:13.4726, lr:0.001\u001b[0m\n",
            "2019-11-25 07:24:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2750/3125], step: 2750, 3.068 samples/sec, batch_loss: 0.5794, batch_loss_c: 0.5775, batch_loss_s: 0.5839, time:13.0380, lr:0.001\u001b[0m\n",
            "2019-11-25 07:24:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2760/3125], step: 2760, 3.022 samples/sec, batch_loss: 0.3144, batch_loss_c: 0.3392, batch_loss_s: 0.2565, time:13.2352, lr:0.001\u001b[0m\n",
            "2019-11-25 07:24:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2770/3125], step: 2770, 2.983 samples/sec, batch_loss: 0.1639, batch_loss_c: 0.1857, batch_loss_s: 0.1132, time:13.4076, lr:0.001\u001b[0m\n",
            "2019-11-25 07:24:52 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2780/3125], step: 2780, 3.014 samples/sec, batch_loss: 0.3241, batch_loss_c: 0.3042, batch_loss_s: 0.3708, time:13.2726, lr:0.001\u001b[0m\n",
            "2019-11-25 07:25:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2790/3125], step: 2790, 3.017 samples/sec, batch_loss: 0.4144, batch_loss_c: 0.4123, batch_loss_s: 0.4192, time:13.2602, lr:0.001\u001b[0m\n",
            "2019-11-25 07:25:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2800/3125], step: 2800, 2.988 samples/sec, batch_loss: 0.4651, batch_loss_c: 0.4358, batch_loss_s: 0.5336, time:13.3865, lr:0.001\u001b[0m\n",
            "2019-11-25 07:25:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2810/3125], step: 2810, 3.011 samples/sec, batch_loss: 0.1604, batch_loss_c: 0.1639, batch_loss_s: 0.1522, time:13.2851, lr:0.001\u001b[0m\n",
            "2019-11-25 07:25:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2820/3125], step: 2820, 3.028 samples/sec, batch_loss: 0.3186, batch_loss_c: 0.3113, batch_loss_s: 0.3355, time:13.2100, lr:0.001\u001b[0m\n",
            "2019-11-25 07:25:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2830/3125], step: 2830, 3.020 samples/sec, batch_loss: 0.3727, batch_loss_c: 0.3903, batch_loss_s: 0.3318, time:13.2471, lr:0.001\u001b[0m\n",
            "2019-11-25 07:26:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2840/3125], step: 2840, 2.997 samples/sec, batch_loss: 0.1541, batch_loss_c: 0.1627, batch_loss_s: 0.1340, time:13.3455, lr:0.001\u001b[0m\n",
            "2019-11-25 07:26:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2850/3125], step: 2850, 3.011 samples/sec, batch_loss: 0.4649, batch_loss_c: 0.4846, batch_loss_s: 0.4189, time:13.2832, lr:0.001\u001b[0m\n",
            "2019-11-25 07:26:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2860/3125], step: 2860, 3.002 samples/sec, batch_loss: 0.1842, batch_loss_c: 0.2057, batch_loss_s: 0.1339, time:13.3252, lr:0.001\u001b[0m\n",
            "2019-11-25 07:26:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2870/3125], step: 2870, 3.024 samples/sec, batch_loss: 0.1756, batch_loss_c: 0.1939, batch_loss_s: 0.1330, time:13.2287, lr:0.001\u001b[0m\n",
            "2019-11-25 07:27:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2880/3125], step: 2880, 3.053 samples/sec, batch_loss: 0.2963, batch_loss_c: 0.2792, batch_loss_s: 0.3362, time:13.1033, lr:0.001\u001b[0m\n",
            "2019-11-25 07:27:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2890/3125], step: 2890, 2.978 samples/sec, batch_loss: 0.3910, batch_loss_c: 0.4104, batch_loss_s: 0.3455, time:13.4327, lr:0.001\u001b[0m\n",
            "2019-11-25 07:27:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2900/3125], step: 2900, 3.006 samples/sec, batch_loss: 0.1348, batch_loss_c: 0.1230, batch_loss_s: 0.1624, time:13.3066, lr:0.001\u001b[0m\n",
            "2019-11-25 07:27:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2910/3125], step: 2910, 2.939 samples/sec, batch_loss: 0.3222, batch_loss_c: 0.3238, batch_loss_s: 0.3187, time:13.6107, lr:0.001\u001b[0m\n",
            "2019-11-25 07:27:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2920/3125], step: 2920, 2.949 samples/sec, batch_loss: 0.3149, batch_loss_c: 0.3123, batch_loss_s: 0.3209, time:13.5641, lr:0.001\u001b[0m\n",
            "2019-11-25 07:28:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2930/3125], step: 2930, 3.008 samples/sec, batch_loss: 0.2982, batch_loss_c: 0.3403, batch_loss_s: 0.1999, time:13.2962, lr:0.001\u001b[0m\n",
            "2019-11-25 07:28:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2940/3125], step: 2940, 3.014 samples/sec, batch_loss: 0.1788, batch_loss_c: 0.1919, batch_loss_s: 0.1483, time:13.2694, lr:0.001\u001b[0m\n",
            "2019-11-25 07:28:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2950/3125], step: 2950, 3.051 samples/sec, batch_loss: 0.3252, batch_loss_c: 0.3135, batch_loss_s: 0.3526, time:13.1115, lr:0.001\u001b[0m\n",
            "2019-11-25 07:28:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2960/3125], step: 2960, 3.014 samples/sec, batch_loss: 0.1605, batch_loss_c: 0.1707, batch_loss_s: 0.1367, time:13.2734, lr:0.001\u001b[0m\n",
            "2019-11-25 07:29:04 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2970/3125], step: 2970, 2.983 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1390, batch_loss_s: 0.1013, time:13.4103, lr:0.001\u001b[0m\n",
            "2019-11-25 07:29:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2980/3125], step: 2980, 2.988 samples/sec, batch_loss: 0.3898, batch_loss_c: 0.4045, batch_loss_s: 0.3555, time:13.3848, lr:0.001\u001b[0m\n",
            "2019-11-25 07:29:31 \u001b[32mINFO     \u001b[0m train.py: [0/10], [2990/3125], step: 2990, 3.012 samples/sec, batch_loss: 0.1218, batch_loss_c: 0.1215, batch_loss_s: 0.1223, time:13.2807, lr:0.001\u001b[0m\n",
            "2019-11-25 07:29:44 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3000/3125], step: 3000, 2.998 samples/sec, batch_loss: 0.2478, batch_loss_c: 0.2647, batch_loss_s: 0.2084, time:13.3426, lr:0.001\u001b[0m\n",
            "2019-11-25 07:29:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3010/3125], step: 3010, 2.933 samples/sec, batch_loss: 0.4859, batch_loss_c: 0.4830, batch_loss_s: 0.4928, time:13.6373, lr:0.001\u001b[0m\n",
            "2019-11-25 07:30:12 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3020/3125], step: 3020, 2.960 samples/sec, batch_loss: 0.1652, batch_loss_c: 0.1850, batch_loss_s: 0.1190, time:13.5147, lr:0.001\u001b[0m\n",
            "2019-11-25 07:30:25 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3030/3125], step: 3030, 3.023 samples/sec, batch_loss: 0.3701, batch_loss_c: 0.3771, batch_loss_s: 0.3537, time:13.2313, lr:0.001\u001b[0m\n",
            "2019-11-25 07:30:38 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3040/3125], step: 3040, 2.971 samples/sec, batch_loss: 0.2082, batch_loss_c: 0.2457, batch_loss_s: 0.1206, time:13.4633, lr:0.001\u001b[0m\n",
            "2019-11-25 07:30:51 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3050/3125], step: 3050, 3.044 samples/sec, batch_loss: 0.4143, batch_loss_c: 0.4329, batch_loss_s: 0.3708, time:13.1386, lr:0.001\u001b[0m\n",
            "2019-11-25 07:31:05 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3060/3125], step: 3060, 2.997 samples/sec, batch_loss: 0.1718, batch_loss_c: 0.1996, batch_loss_s: 0.1070, time:13.3446, lr:0.001\u001b[0m\n",
            "2019-11-25 07:31:18 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3070/3125], step: 3070, 3.011 samples/sec, batch_loss: 0.2864, batch_loss_c: 0.2729, batch_loss_s: 0.3181, time:13.2858, lr:0.001\u001b[0m\n",
            "2019-11-25 07:31:32 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3080/3125], step: 3080, 2.983 samples/sec, batch_loss: 0.3545, batch_loss_c: 0.3464, batch_loss_s: 0.3732, time:13.4097, lr:0.001\u001b[0m\n",
            "2019-11-25 07:31:45 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3090/3125], step: 3090, 3.014 samples/sec, batch_loss: 0.2063, batch_loss_c: 0.2290, batch_loss_s: 0.1533, time:13.2724, lr:0.001\u001b[0m\n",
            "2019-11-25 07:31:58 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3100/3125], step: 3100, 2.994 samples/sec, batch_loss: 0.1469, batch_loss_c: 0.1491, batch_loss_s: 0.1417, time:13.3599, lr:0.001\u001b[0m\n",
            "2019-11-25 07:32:11 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3110/3125], step: 3110, 3.081 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1130, batch_loss_s: 0.1143, time:12.9843, lr:0.001\u001b[0m\n",
            "2019-11-25 07:32:24 \u001b[32mINFO     \u001b[0m train.py: [0/10], [3120/3125], step: 3120, 3.065 samples/sec, batch_loss: 0.3205, batch_loss_c: 0.3322, batch_loss_s: 0.2932, time:13.0500, lr:0.001\u001b[0m\n",
            "2019-11-25 07:32:30 \u001b[32mINFO     \u001b[0m train.py: [0/10], train_loss: 0.2739, time: 4185.8798, lr: 0.001\u001b[0m\n",
            "2019-11-25 07:32:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [0/3125], step: 3125, 5.490 samples/sec, batch_loss: 0.3345, batch_loss_c: 0.3298, batch_loss_s: 0.3452, time:7.2854, lr:0.001\u001b[0m\n",
            "2019-11-25 07:32:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [10/3125], step: 3135, 2.610 samples/sec, batch_loss: 0.2765, batch_loss_c: 0.2850, batch_loss_s: 0.2567, time:15.3248, lr:0.001\u001b[0m\n",
            "2019-11-25 07:33:06 \u001b[32mINFO     \u001b[0m train.py: [1/10], [20/3125], step: 3145, 3.011 samples/sec, batch_loss: 0.1724, batch_loss_c: 0.2012, batch_loss_s: 0.1052, time:13.2830, lr:0.001\u001b[0m\n",
            "2019-11-25 07:33:19 \u001b[32mINFO     \u001b[0m train.py: [1/10], [30/3125], step: 3155, 2.994 samples/sec, batch_loss: 0.3336, batch_loss_c: 0.3300, batch_loss_s: 0.3421, time:13.3622, lr:0.001\u001b[0m\n",
            "2019-11-25 07:33:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [40/3125], step: 3165, 2.953 samples/sec, batch_loss: 0.4319, batch_loss_c: 0.4132, batch_loss_s: 0.4753, time:13.5457, lr:0.001\u001b[0m\n",
            "2019-11-25 07:33:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [50/3125], step: 3175, 2.998 samples/sec, batch_loss: 0.1622, batch_loss_c: 0.1842, batch_loss_s: 0.1109, time:13.3432, lr:0.001\u001b[0m\n",
            "2019-11-25 07:34:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [60/3125], step: 3185, 2.968 samples/sec, batch_loss: 0.4432, batch_loss_c: 0.4660, batch_loss_s: 0.3898, time:13.4758, lr:0.001\u001b[0m\n",
            "2019-11-25 07:34:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [70/3125], step: 3195, 3.017 samples/sec, batch_loss: 0.3546, batch_loss_c: 0.4086, batch_loss_s: 0.2288, time:13.2591, lr:0.001\u001b[0m\n",
            "2019-11-25 07:34:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [80/3125], step: 3205, 2.949 samples/sec, batch_loss: 0.3574, batch_loss_c: 0.3971, batch_loss_s: 0.2649, time:13.5648, lr:0.001\u001b[0m\n",
            "2019-11-25 07:34:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [90/3125], step: 3215, 2.979 samples/sec, batch_loss: 0.1548, batch_loss_c: 0.1685, batch_loss_s: 0.1229, time:13.4275, lr:0.001\u001b[0m\n",
            "2019-11-25 07:34:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [100/3125], step: 3225, 2.976 samples/sec, batch_loss: 0.2631, batch_loss_c: 0.3007, batch_loss_s: 0.1753, time:13.4405, lr:0.001\u001b[0m\n",
            "2019-11-25 07:35:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [110/3125], step: 3235, 2.936 samples/sec, batch_loss: 0.2706, batch_loss_c: 0.2672, batch_loss_s: 0.2785, time:13.6262, lr:0.001\u001b[0m\n",
            "2019-11-25 07:35:20 \u001b[32mINFO     \u001b[0m train.py: [1/10], [120/3125], step: 3245, 3.046 samples/sec, batch_loss: 0.3970, batch_loss_c: 0.3993, batch_loss_s: 0.3915, time:13.1323, lr:0.001\u001b[0m\n",
            "2019-11-25 07:35:33 \u001b[32mINFO     \u001b[0m train.py: [1/10], [130/3125], step: 3255, 3.062 samples/sec, batch_loss: 0.1809, batch_loss_c: 0.2087, batch_loss_s: 0.1159, time:13.0649, lr:0.001\u001b[0m\n",
            "2019-11-25 07:35:46 \u001b[32mINFO     \u001b[0m train.py: [1/10], [140/3125], step: 3265, 3.013 samples/sec, batch_loss: 0.3261, batch_loss_c: 0.3186, batch_loss_s: 0.3436, time:13.2747, lr:0.001\u001b[0m\n",
            "2019-11-25 07:35:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], [150/3125], step: 3275, 3.047 samples/sec, batch_loss: 0.1562, batch_loss_c: 0.1833, batch_loss_s: 0.0929, time:13.1283, lr:0.001\u001b[0m\n",
            "2019-11-25 07:36:13 \u001b[32mINFO     \u001b[0m train.py: [1/10], [160/3125], step: 3285, 2.992 samples/sec, batch_loss: 0.3781, batch_loss_c: 0.3692, batch_loss_s: 0.3987, time:13.3676, lr:0.001\u001b[0m\n",
            "2019-11-25 07:36:26 \u001b[32mINFO     \u001b[0m train.py: [1/10], [170/3125], step: 3295, 3.020 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1094, batch_loss_s: 0.1224, time:13.2453, lr:0.001\u001b[0m\n",
            "2019-11-25 07:36:39 \u001b[32mINFO     \u001b[0m train.py: [1/10], [180/3125], step: 3305, 3.060 samples/sec, batch_loss: 0.1520, batch_loss_c: 0.1755, batch_loss_s: 0.0973, time:13.0714, lr:0.001\u001b[0m\n",
            "2019-11-25 07:36:52 \u001b[32mINFO     \u001b[0m train.py: [1/10], [190/3125], step: 3315, 3.067 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1457, batch_loss_s: 0.1009, time:13.0404, lr:0.001\u001b[0m\n",
            "2019-11-25 07:37:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [200/3125], step: 3325, 3.043 samples/sec, batch_loss: 0.2297, batch_loss_c: 0.2683, batch_loss_s: 0.1397, time:13.1435, lr:0.001\u001b[0m\n",
            "2019-11-25 07:37:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [210/3125], step: 3335, 3.054 samples/sec, batch_loss: 0.0905, batch_loss_c: 0.0943, batch_loss_s: 0.0815, time:13.0965, lr:0.001\u001b[0m\n",
            "2019-11-25 07:37:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [220/3125], step: 3345, 3.066 samples/sec, batch_loss: 0.2918, batch_loss_c: 0.2793, batch_loss_s: 0.3209, time:13.0473, lr:0.001\u001b[0m\n",
            "2019-11-25 07:37:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [230/3125], step: 3355, 3.029 samples/sec, batch_loss: 0.1878, batch_loss_c: 0.2332, batch_loss_s: 0.0818, time:13.2073, lr:0.001\u001b[0m\n",
            "2019-11-25 07:37:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [240/3125], step: 3365, 2.990 samples/sec, batch_loss: 0.0930, batch_loss_c: 0.0964, batch_loss_s: 0.0852, time:13.3786, lr:0.001\u001b[0m\n",
            "2019-11-25 07:38:12 \u001b[32mINFO     \u001b[0m train.py: [1/10], [250/3125], step: 3375, 2.957 samples/sec, batch_loss: 0.1433, batch_loss_c: 0.1504, batch_loss_s: 0.1268, time:13.5264, lr:0.001\u001b[0m\n",
            "2019-11-25 07:38:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [260/3125], step: 3385, 3.029 samples/sec, batch_loss: 0.1437, batch_loss_c: 0.1599, batch_loss_s: 0.1059, time:13.2067, lr:0.001\u001b[0m\n",
            "2019-11-25 07:38:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [270/3125], step: 3395, 2.976 samples/sec, batch_loss: 0.2425, batch_loss_c: 0.2527, batch_loss_s: 0.2187, time:13.4426, lr:0.001\u001b[0m\n",
            "2019-11-25 07:38:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [280/3125], step: 3405, 3.060 samples/sec, batch_loss: 0.2481, batch_loss_c: 0.2763, batch_loss_s: 0.1824, time:13.0725, lr:0.001\u001b[0m\n",
            "2019-11-25 07:39:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [290/3125], step: 3415, 2.983 samples/sec, batch_loss: 0.1340, batch_loss_c: 0.1416, batch_loss_s: 0.1165, time:13.4085, lr:0.001\u001b[0m\n",
            "2019-11-25 07:39:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [300/3125], step: 3425, 2.997 samples/sec, batch_loss: 0.1009, batch_loss_c: 0.1071, batch_loss_s: 0.0866, time:13.3470, lr:0.001\u001b[0m\n",
            "2019-11-25 07:39:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [310/3125], step: 3435, 3.006 samples/sec, batch_loss: 0.1898, batch_loss_c: 0.2045, batch_loss_s: 0.1556, time:13.3085, lr:0.001\u001b[0m\n",
            "2019-11-25 07:39:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [320/3125], step: 3445, 3.005 samples/sec, batch_loss: 0.1277, batch_loss_c: 0.1380, batch_loss_s: 0.1036, time:13.3121, lr:0.001\u001b[0m\n",
            "2019-11-25 07:39:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [330/3125], step: 3455, 3.003 samples/sec, batch_loss: 0.1345, batch_loss_c: 0.1483, batch_loss_s: 0.1025, time:13.3206, lr:0.001\u001b[0m\n",
            "2019-11-25 07:40:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [340/3125], step: 3465, 2.976 samples/sec, batch_loss: 0.2768, batch_loss_c: 0.2692, batch_loss_s: 0.2945, time:13.4424, lr:0.001\u001b[0m\n",
            "2019-11-25 07:40:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [350/3125], step: 3475, 3.011 samples/sec, batch_loss: 0.3671, batch_loss_c: 0.3604, batch_loss_s: 0.3826, time:13.2838, lr:0.001\u001b[0m\n",
            "2019-11-25 07:40:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [360/3125], step: 3485, 3.046 samples/sec, batch_loss: 0.2499, batch_loss_c: 0.2693, batch_loss_s: 0.2045, time:13.1330, lr:0.001\u001b[0m\n",
            "2019-11-25 07:40:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [370/3125], step: 3495, 3.054 samples/sec, batch_loss: 0.6833, batch_loss_c: 0.6503, batch_loss_s: 0.7604, time:13.0980, lr:0.001\u001b[0m\n",
            "2019-11-25 07:41:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [380/3125], step: 3505, 3.028 samples/sec, batch_loss: 0.4538, batch_loss_c: 0.4948, batch_loss_s: 0.3579, time:13.2081, lr:0.001\u001b[0m\n",
            "2019-11-25 07:41:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [390/3125], step: 3515, 3.033 samples/sec, batch_loss: 0.3468, batch_loss_c: 0.3341, batch_loss_s: 0.3764, time:13.1880, lr:0.001\u001b[0m\n",
            "2019-11-25 07:41:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [400/3125], step: 3525, 2.975 samples/sec, batch_loss: 0.3126, batch_loss_c: 0.3084, batch_loss_s: 0.3225, time:13.4467, lr:0.001\u001b[0m\n",
            "2019-11-25 07:41:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [410/3125], step: 3535, 2.998 samples/sec, batch_loss: 0.2323, batch_loss_c: 0.2845, batch_loss_s: 0.1105, time:13.3419, lr:0.001\u001b[0m\n",
            "2019-11-25 07:41:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [420/3125], step: 3545, 3.038 samples/sec, batch_loss: 0.2303, batch_loss_c: 0.2492, batch_loss_s: 0.1862, time:13.1652, lr:0.001\u001b[0m\n",
            "2019-11-25 07:42:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [430/3125], step: 3555, 3.043 samples/sec, batch_loss: 0.4613, batch_loss_c: 0.4598, batch_loss_s: 0.4650, time:13.1449, lr:0.001\u001b[0m\n",
            "2019-11-25 07:42:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [440/3125], step: 3565, 2.979 samples/sec, batch_loss: 0.2081, batch_loss_c: 0.2338, batch_loss_s: 0.1482, time:13.4280, lr:0.001\u001b[0m\n",
            "2019-11-25 07:42:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [450/3125], step: 3575, 3.042 samples/sec, batch_loss: 0.3250, batch_loss_c: 0.3502, batch_loss_s: 0.2662, time:13.1471, lr:0.001\u001b[0m\n",
            "2019-11-25 07:42:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [460/3125], step: 3585, 2.950 samples/sec, batch_loss: 0.1379, batch_loss_c: 0.1484, batch_loss_s: 0.1134, time:13.5583, lr:0.001\u001b[0m\n",
            "2019-11-25 07:43:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [470/3125], step: 3595, 3.007 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3323, batch_loss_s: 0.3525, time:13.3021, lr:0.001\u001b[0m\n",
            "2019-11-25 07:43:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [480/3125], step: 3605, 2.966 samples/sec, batch_loss: 0.1983, batch_loss_c: 0.2279, batch_loss_s: 0.1291, time:13.4868, lr:0.001\u001b[0m\n",
            "2019-11-25 07:43:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [490/3125], step: 3615, 2.999 samples/sec, batch_loss: 0.3518, batch_loss_c: 0.3581, batch_loss_s: 0.3372, time:13.3368, lr:0.001\u001b[0m\n",
            "2019-11-25 07:43:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [500/3125], step: 3625, 2.961 samples/sec, batch_loss: 0.3081, batch_loss_c: 0.3012, batch_loss_s: 0.3241, time:13.5108, lr:0.001\u001b[0m\n",
            "2019-11-25 07:43:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [510/3125], step: 3635, 2.967 samples/sec, batch_loss: 0.3249, batch_loss_c: 0.3276, batch_loss_s: 0.3187, time:13.4813, lr:0.001\u001b[0m\n",
            "2019-11-25 07:44:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [520/3125], step: 3645, 2.969 samples/sec, batch_loss: 0.3747, batch_loss_c: 0.3568, batch_loss_s: 0.4166, time:13.4728, lr:0.001\u001b[0m\n",
            "2019-11-25 07:44:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [530/3125], step: 3655, 3.036 samples/sec, batch_loss: 0.1851, batch_loss_c: 0.1949, batch_loss_s: 0.1622, time:13.1734, lr:0.001\u001b[0m\n",
            "2019-11-25 07:44:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [540/3125], step: 3665, 2.979 samples/sec, batch_loss: 0.2453, batch_loss_c: 0.2173, batch_loss_s: 0.3108, time:13.4269, lr:0.001\u001b[0m\n",
            "2019-11-25 07:44:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [550/3125], step: 3675, 3.007 samples/sec, batch_loss: 0.1554, batch_loss_c: 0.1689, batch_loss_s: 0.1240, time:13.3026, lr:0.001\u001b[0m\n",
            "2019-11-25 07:45:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [560/3125], step: 3685, 3.022 samples/sec, batch_loss: 0.1850, batch_loss_c: 0.2075, batch_loss_s: 0.1323, time:13.2344, lr:0.001\u001b[0m\n",
            "2019-11-25 07:45:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [570/3125], step: 3695, 3.051 samples/sec, batch_loss: 0.1611, batch_loss_c: 0.1819, batch_loss_s: 0.1125, time:13.1087, lr:0.001\u001b[0m\n",
            "2019-11-25 07:45:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [580/3125], step: 3705, 3.017 samples/sec, batch_loss: 0.1914, batch_loss_c: 0.2150, batch_loss_s: 0.1363, time:13.2569, lr:0.001\u001b[0m\n",
            "2019-11-25 07:45:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [590/3125], step: 3715, 2.949 samples/sec, batch_loss: 0.1886, batch_loss_c: 0.1768, batch_loss_s: 0.2163, time:13.5624, lr:0.001\u001b[0m\n",
            "2019-11-25 07:45:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [600/3125], step: 3725, 3.045 samples/sec, batch_loss: 0.3193, batch_loss_c: 0.3039, batch_loss_s: 0.3551, time:13.1342, lr:0.001\u001b[0m\n",
            "2019-11-25 07:46:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [610/3125], step: 3735, 3.024 samples/sec, batch_loss: 0.4773, batch_loss_c: 0.4953, batch_loss_s: 0.4352, time:13.2291, lr:0.001\u001b[0m\n",
            "2019-11-25 07:46:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [620/3125], step: 3745, 3.013 samples/sec, batch_loss: 0.1892, batch_loss_c: 0.1942, batch_loss_s: 0.1773, time:13.2738, lr:0.001\u001b[0m\n",
            "2019-11-25 07:46:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [630/3125], step: 3755, 3.026 samples/sec, batch_loss: 0.6348, batch_loss_c: 0.6143, batch_loss_s: 0.6826, time:13.2208, lr:0.001\u001b[0m\n",
            "2019-11-25 07:46:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [640/3125], step: 3765, 3.013 samples/sec, batch_loss: 0.1780, batch_loss_c: 0.1950, batch_loss_s: 0.1381, time:13.2740, lr:0.001\u001b[0m\n",
            "2019-11-25 07:47:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [650/3125], step: 3775, 2.987 samples/sec, batch_loss: 0.1162, batch_loss_c: 0.1215, batch_loss_s: 0.1040, time:13.3936, lr:0.001\u001b[0m\n",
            "2019-11-25 07:47:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [660/3125], step: 3785, 2.984 samples/sec, batch_loss: 0.1177, batch_loss_c: 0.1328, batch_loss_s: 0.0825, time:13.4065, lr:0.001\u001b[0m\n",
            "2019-11-25 07:47:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [670/3125], step: 3795, 3.049 samples/sec, batch_loss: 0.3140, batch_loss_c: 0.2958, batch_loss_s: 0.3566, time:13.1208, lr:0.001\u001b[0m\n",
            "2019-11-25 07:47:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [680/3125], step: 3805, 3.020 samples/sec, batch_loss: 0.3943, batch_loss_c: 0.3986, batch_loss_s: 0.3844, time:13.2455, lr:0.001\u001b[0m\n",
            "2019-11-25 07:47:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [690/3125], step: 3815, 3.010 samples/sec, batch_loss: 0.1398, batch_loss_c: 0.1424, batch_loss_s: 0.1339, time:13.2874, lr:0.001\u001b[0m\n",
            "2019-11-25 07:48:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [700/3125], step: 3825, 3.003 samples/sec, batch_loss: 0.3197, batch_loss_c: 0.3392, batch_loss_s: 0.2740, time:13.3180, lr:0.001\u001b[0m\n",
            "2019-11-25 07:48:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [710/3125], step: 3835, 3.044 samples/sec, batch_loss: 0.1628, batch_loss_c: 0.1926, batch_loss_s: 0.0935, time:13.1411, lr:0.001\u001b[0m\n",
            "2019-11-25 07:48:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [720/3125], step: 3845, 3.024 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1517, batch_loss_s: 0.1156, time:13.2259, lr:0.001\u001b[0m\n",
            "2019-11-25 07:48:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [730/3125], step: 3855, 3.064 samples/sec, batch_loss: 0.3766, batch_loss_c: 0.4088, batch_loss_s: 0.3015, time:13.0532, lr:0.001\u001b[0m\n",
            "2019-11-25 07:49:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [740/3125], step: 3865, 3.038 samples/sec, batch_loss: 0.3266, batch_loss_c: 0.3941, batch_loss_s: 0.1692, time:13.1664, lr:0.001\u001b[0m\n",
            "2019-11-25 07:49:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [750/3125], step: 3875, 2.968 samples/sec, batch_loss: 0.1360, batch_loss_c: 0.1378, batch_loss_s: 0.1318, time:13.4748, lr:0.001\u001b[0m\n",
            "2019-11-25 07:49:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [760/3125], step: 3885, 2.971 samples/sec, batch_loss: 0.2410, batch_loss_c: 0.2129, batch_loss_s: 0.3067, time:13.4652, lr:0.001\u001b[0m\n",
            "2019-11-25 07:49:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [770/3125], step: 3895, 2.916 samples/sec, batch_loss: 0.3558, batch_loss_c: 0.3725, batch_loss_s: 0.3168, time:13.7162, lr:0.001\u001b[0m\n",
            "2019-11-25 07:49:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [780/3125], step: 3905, 3.031 samples/sec, batch_loss: 0.3645, batch_loss_c: 0.3709, batch_loss_s: 0.3496, time:13.1958, lr:0.001\u001b[0m\n",
            "2019-11-25 07:50:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [790/3125], step: 3915, 2.992 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1043, batch_loss_s: 0.1154, time:13.3702, lr:0.001\u001b[0m\n",
            "2019-11-25 07:50:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [800/3125], step: 3925, 2.995 samples/sec, batch_loss: 0.1593, batch_loss_c: 0.1589, batch_loss_s: 0.1601, time:13.3570, lr:0.001\u001b[0m\n",
            "2019-11-25 07:50:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [810/3125], step: 3935, 2.949 samples/sec, batch_loss: 0.1477, batch_loss_c: 0.1638, batch_loss_s: 0.1100, time:13.5657, lr:0.001\u001b[0m\n",
            "2019-11-25 07:50:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [820/3125], step: 3945, 3.003 samples/sec, batch_loss: 0.3721, batch_loss_c: 0.3877, batch_loss_s: 0.3357, time:13.3179, lr:0.001\u001b[0m\n",
            "2019-11-25 07:51:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [830/3125], step: 3955, 2.989 samples/sec, batch_loss: 0.5227, batch_loss_c: 0.5099, batch_loss_s: 0.5527, time:13.3823, lr:0.001\u001b[0m\n",
            "2019-11-25 07:51:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [840/3125], step: 3965, 2.970 samples/sec, batch_loss: 0.3614, batch_loss_c: 0.3511, batch_loss_s: 0.3853, time:13.4664, lr:0.001\u001b[0m\n",
            "2019-11-25 07:51:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [850/3125], step: 3975, 3.035 samples/sec, batch_loss: 0.3831, batch_loss_c: 0.3555, batch_loss_s: 0.4475, time:13.1776, lr:0.001\u001b[0m\n",
            "2019-11-25 07:51:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [860/3125], step: 3985, 2.979 samples/sec, batch_loss: 0.4600, batch_loss_c: 0.4983, batch_loss_s: 0.3706, time:13.4281, lr:0.001\u001b[0m\n",
            "2019-11-25 07:51:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [870/3125], step: 3995, 2.964 samples/sec, batch_loss: 0.1774, batch_loss_c: 0.1994, batch_loss_s: 0.1260, time:13.4961, lr:0.001\u001b[0m\n",
            "2019-11-25 07:52:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [880/3125], step: 4005, 3.015 samples/sec, batch_loss: 0.2189, batch_loss_c: 0.2683, batch_loss_s: 0.1036, time:13.2661, lr:0.001\u001b[0m\n",
            "2019-11-25 07:52:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [890/3125], step: 4015, 2.984 samples/sec, batch_loss: 0.1947, batch_loss_c: 0.2213, batch_loss_s: 0.1326, time:13.4032, lr:0.001\u001b[0m\n",
            "2019-11-25 07:52:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [900/3125], step: 4025, 2.977 samples/sec, batch_loss: 0.1081, batch_loss_c: 0.1069, batch_loss_s: 0.1109, time:13.4381, lr:0.001\u001b[0m\n",
            "2019-11-25 07:52:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [910/3125], step: 4035, 3.030 samples/sec, batch_loss: 0.3967, batch_loss_c: 0.4048, batch_loss_s: 0.3778, time:13.2029, lr:0.001\u001b[0m\n",
            "2019-11-25 07:53:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [920/3125], step: 4045, 2.992 samples/sec, batch_loss: 0.1727, batch_loss_c: 0.1940, batch_loss_s: 0.1230, time:13.3681, lr:0.001\u001b[0m\n",
            "2019-11-25 07:53:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [930/3125], step: 4055, 3.022 samples/sec, batch_loss: 0.2841, batch_loss_c: 0.2637, batch_loss_s: 0.3316, time:13.2381, lr:0.001\u001b[0m\n",
            "2019-11-25 07:53:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [940/3125], step: 4065, 2.959 samples/sec, batch_loss: 0.3253, batch_loss_c: 0.3253, batch_loss_s: 0.3253, time:13.5198, lr:0.001\u001b[0m\n",
            "2019-11-25 07:53:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [950/3125], step: 4075, 2.965 samples/sec, batch_loss: 0.2079, batch_loss_c: 0.2584, batch_loss_s: 0.0900, time:13.4902, lr:0.001\u001b[0m\n",
            "2019-11-25 07:53:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [960/3125], step: 4085, 3.000 samples/sec, batch_loss: 0.2912, batch_loss_c: 0.2831, batch_loss_s: 0.3100, time:13.3329, lr:0.001\u001b[0m\n",
            "2019-11-25 07:54:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [970/3125], step: 4095, 2.974 samples/sec, batch_loss: 0.2318, batch_loss_c: 0.2742, batch_loss_s: 0.1331, time:13.4479, lr:0.001\u001b[0m\n",
            "2019-11-25 07:54:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [980/3125], step: 4105, 3.033 samples/sec, batch_loss: 0.3939, batch_loss_c: 0.4030, batch_loss_s: 0.3727, time:13.1883, lr:0.001\u001b[0m\n",
            "2019-11-25 07:54:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [990/3125], step: 4115, 3.021 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1226, batch_loss_s: 0.0908, time:13.2413, lr:0.001\u001b[0m\n",
            "2019-11-25 07:54:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1000/3125], step: 4125, 3.032 samples/sec, batch_loss: 0.2808, batch_loss_c: 0.2678, batch_loss_s: 0.3110, time:13.1907, lr:0.001\u001b[0m\n",
            "2019-11-25 07:55:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1010/3125], step: 4135, 3.021 samples/sec, batch_loss: 0.3089, batch_loss_c: 0.2924, batch_loss_s: 0.3474, time:13.2419, lr:0.001\u001b[0m\n",
            "2019-11-25 07:55:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1020/3125], step: 4145, 3.032 samples/sec, batch_loss: 0.3743, batch_loss_c: 0.3860, batch_loss_s: 0.3471, time:13.1913, lr:0.001\u001b[0m\n",
            "2019-11-25 07:55:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1030/3125], step: 4155, 2.994 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.3118, batch_loss_s: 0.3311, time:13.3600, lr:0.001\u001b[0m\n",
            "2019-11-25 07:55:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1040/3125], step: 4165, 2.957 samples/sec, batch_loss: 0.3715, batch_loss_c: 0.4001, batch_loss_s: 0.3049, time:13.5252, lr:0.001\u001b[0m\n",
            "2019-11-25 07:55:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1050/3125], step: 4175, 2.975 samples/sec, batch_loss: 0.3224, batch_loss_c: 0.3008, batch_loss_s: 0.3728, time:13.4469, lr:0.001\u001b[0m\n",
            "2019-11-25 07:56:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1060/3125], step: 4185, 3.035 samples/sec, batch_loss: 0.4384, batch_loss_c: 0.4690, batch_loss_s: 0.3670, time:13.1789, lr:0.001\u001b[0m\n",
            "2019-11-25 07:56:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1070/3125], step: 4195, 2.977 samples/sec, batch_loss: 0.1187, batch_loss_c: 0.1291, batch_loss_s: 0.0943, time:13.4381, lr:0.001\u001b[0m\n",
            "2019-11-25 07:56:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1080/3125], step: 4205, 2.972 samples/sec, batch_loss: 0.1065, batch_loss_c: 0.1181, batch_loss_s: 0.0796, time:13.4586, lr:0.001\u001b[0m\n",
            "2019-11-25 07:56:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1090/3125], step: 4215, 2.930 samples/sec, batch_loss: 0.1300, batch_loss_c: 0.1412, batch_loss_s: 0.1038, time:13.6499, lr:0.001\u001b[0m\n",
            "2019-11-25 07:57:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1100/3125], step: 4225, 2.993 samples/sec, batch_loss: 0.2084, batch_loss_c: 0.2281, batch_loss_s: 0.1626, time:13.3657, lr:0.001\u001b[0m\n",
            "2019-11-25 07:57:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1110/3125], step: 4235, 2.973 samples/sec, batch_loss: 0.1421, batch_loss_c: 0.1582, batch_loss_s: 0.1047, time:13.4538, lr:0.001\u001b[0m\n",
            "2019-11-25 07:57:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1120/3125], step: 4245, 2.996 samples/sec, batch_loss: 0.2818, batch_loss_c: 0.2669, batch_loss_s: 0.3167, time:13.3514, lr:0.001\u001b[0m\n",
            "2019-11-25 07:57:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1130/3125], step: 4255, 3.038 samples/sec, batch_loss: 0.2687, batch_loss_c: 0.2421, batch_loss_s: 0.3309, time:13.1658, lr:0.001\u001b[0m\n",
            "2019-11-25 07:57:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1140/3125], step: 4265, 3.002 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1376, batch_loss_s: 0.1144, time:13.3258, lr:0.001\u001b[0m\n",
            "2019-11-25 07:58:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1150/3125], step: 4275, 2.936 samples/sec, batch_loss: 0.3854, batch_loss_c: 0.4037, batch_loss_s: 0.3426, time:13.6221, lr:0.001\u001b[0m\n",
            "2019-11-25 07:58:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1160/3125], step: 4285, 2.996 samples/sec, batch_loss: 0.1445, batch_loss_c: 0.1562, batch_loss_s: 0.1173, time:13.3492, lr:0.001\u001b[0m\n",
            "2019-11-25 07:58:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1170/3125], step: 4295, 2.992 samples/sec, batch_loss: 0.1266, batch_loss_c: 0.1478, batch_loss_s: 0.0771, time:13.3690, lr:0.001\u001b[0m\n",
            "2019-11-25 07:58:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1180/3125], step: 4305, 2.977 samples/sec, batch_loss: 0.4119, batch_loss_c: 0.4316, batch_loss_s: 0.3660, time:13.4361, lr:0.001\u001b[0m\n",
            "2019-11-25 07:59:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1190/3125], step: 4315, 3.000 samples/sec, batch_loss: 0.3772, batch_loss_c: 0.3882, batch_loss_s: 0.3516, time:13.3336, lr:0.001\u001b[0m\n",
            "2019-11-25 07:59:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1200/3125], step: 4325, 3.010 samples/sec, batch_loss: 0.1260, batch_loss_c: 0.1308, batch_loss_s: 0.1146, time:13.2911, lr:0.001\u001b[0m\n",
            "2019-11-25 07:59:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1210/3125], step: 4335, 2.998 samples/sec, batch_loss: 0.3399, batch_loss_c: 0.4090, batch_loss_s: 0.1785, time:13.3416, lr:0.001\u001b[0m\n",
            "2019-11-25 07:59:45 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1220/3125], step: 4345, 2.993 samples/sec, batch_loss: 0.3512, batch_loss_c: 0.3573, batch_loss_s: 0.3370, time:13.3634, lr:0.001\u001b[0m\n",
            "2019-11-25 07:59:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1230/3125], step: 4355, 3.037 samples/sec, batch_loss: 0.5345, batch_loss_c: 0.5144, batch_loss_s: 0.5813, time:13.1699, lr:0.001\u001b[0m\n",
            "2019-11-25 08:00:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1240/3125], step: 4365, 3.026 samples/sec, batch_loss: 0.1610, batch_loss_c: 0.1611, batch_loss_s: 0.1609, time:13.2170, lr:0.001\u001b[0m\n",
            "2019-11-25 08:00:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1250/3125], step: 4375, 3.031 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3062, batch_loss_s: 0.3291, time:13.1965, lr:0.001\u001b[0m\n",
            "2019-11-25 08:00:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1260/3125], step: 4385, 2.994 samples/sec, batch_loss: 0.1462, batch_loss_c: 0.1691, batch_loss_s: 0.0927, time:13.3586, lr:0.001\u001b[0m\n",
            "2019-11-25 08:00:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1270/3125], step: 4395, 2.979 samples/sec, batch_loss: 0.2632, batch_loss_c: 0.2590, batch_loss_s: 0.2730, time:13.4286, lr:0.001\u001b[0m\n",
            "2019-11-25 08:01:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1280/3125], step: 4405, 3.032 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1279, batch_loss_s: 0.1338, time:13.1934, lr:0.001\u001b[0m\n",
            "2019-11-25 08:01:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1290/3125], step: 4415, 2.998 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.0930, batch_loss_s: 0.1038, time:13.3418, lr:0.001\u001b[0m\n",
            "2019-11-25 08:01:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1300/3125], step: 4425, 2.999 samples/sec, batch_loss: 0.1034, batch_loss_c: 0.1031, batch_loss_s: 0.1040, time:13.3391, lr:0.001\u001b[0m\n",
            "2019-11-25 08:01:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1310/3125], step: 4435, 2.984 samples/sec, batch_loss: 0.3710, batch_loss_c: 0.3682, batch_loss_s: 0.3776, time:13.4043, lr:0.001\u001b[0m\n",
            "2019-11-25 08:01:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1320/3125], step: 4445, 3.024 samples/sec, batch_loss: 0.2254, batch_loss_c: 0.2489, batch_loss_s: 0.1704, time:13.2268, lr:0.001\u001b[0m\n",
            "2019-11-25 08:02:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1330/3125], step: 4455, 2.950 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1264, batch_loss_s: 0.1066, time:13.5592, lr:0.001\u001b[0m\n",
            "2019-11-25 08:02:25 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1340/3125], step: 4465, 2.963 samples/sec, batch_loss: 0.1959, batch_loss_c: 0.2305, batch_loss_s: 0.1150, time:13.5013, lr:0.001\u001b[0m\n",
            "2019-11-25 08:02:38 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1350/3125], step: 4475, 3.049 samples/sec, batch_loss: 0.4258, batch_loss_c: 0.3975, batch_loss_s: 0.4918, time:13.1209, lr:0.001\u001b[0m\n",
            "2019-11-25 08:02:51 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1360/3125], step: 4485, 2.961 samples/sec, batch_loss: 0.3778, batch_loss_c: 0.3907, batch_loss_s: 0.3479, time:13.5091, lr:0.001\u001b[0m\n",
            "2019-11-25 08:03:05 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1370/3125], step: 4495, 2.992 samples/sec, batch_loss: 0.1246, batch_loss_c: 0.1361, batch_loss_s: 0.0978, time:13.3689, lr:0.001\u001b[0m\n",
            "2019-11-25 08:03:18 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1380/3125], step: 4505, 3.008 samples/sec, batch_loss: 0.1681, batch_loss_c: 0.1881, batch_loss_s: 0.1213, time:13.2995, lr:0.001\u001b[0m\n",
            "2019-11-25 08:03:31 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1390/3125], step: 4515, 3.044 samples/sec, batch_loss: 0.5647, batch_loss_c: 0.5632, batch_loss_s: 0.5682, time:13.1386, lr:0.001\u001b[0m\n",
            "2019-11-25 08:03:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1400/3125], step: 4525, 3.045 samples/sec, batch_loss: 0.3976, batch_loss_c: 0.4165, batch_loss_s: 0.3535, time:13.1344, lr:0.001\u001b[0m\n",
            "2019-11-25 08:03:58 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1410/3125], step: 4535, 3.026 samples/sec, batch_loss: 0.1452, batch_loss_c: 0.1742, batch_loss_s: 0.0774, time:13.2169, lr:0.001\u001b[0m\n",
            "2019-11-25 08:04:11 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1420/3125], step: 4545, 3.047 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1099, batch_loss_s: 0.1287, time:13.1297, lr:0.001\u001b[0m\n",
            "2019-11-25 08:04:24 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1430/3125], step: 4555, 3.012 samples/sec, batch_loss: 0.0895, batch_loss_c: 0.0875, batch_loss_s: 0.0941, time:13.2823, lr:0.001\u001b[0m\n",
            "2019-11-25 08:04:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1440/3125], step: 4565, 3.018 samples/sec, batch_loss: 0.1664, batch_loss_c: 0.1911, batch_loss_s: 0.1087, time:13.2542, lr:0.001\u001b[0m\n",
            "2019-11-25 08:04:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1450/3125], step: 4575, 3.067 samples/sec, batch_loss: 0.1665, batch_loss_c: 0.1830, batch_loss_s: 0.1280, time:13.0411, lr:0.001\u001b[0m\n",
            "2019-11-25 08:05:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1460/3125], step: 4585, 3.029 samples/sec, batch_loss: 0.1645, batch_loss_c: 0.1905, batch_loss_s: 0.1038, time:13.2076, lr:0.001\u001b[0m\n",
            "2019-11-25 08:05:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1470/3125], step: 4595, 2.943 samples/sec, batch_loss: 0.2668, batch_loss_c: 0.3054, batch_loss_s: 0.1768, time:13.5929, lr:0.001\u001b[0m\n",
            "2019-11-25 08:05:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1480/3125], step: 4605, 3.034 samples/sec, batch_loss: 0.3679, batch_loss_c: 0.3837, batch_loss_s: 0.3312, time:13.1857, lr:0.001\u001b[0m\n",
            "2019-11-25 08:05:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1490/3125], step: 4615, 3.025 samples/sec, batch_loss: 0.3014, batch_loss_c: 0.2840, batch_loss_s: 0.3421, time:13.2211, lr:0.001\u001b[0m\n",
            "2019-11-25 08:05:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1500/3125], step: 4625, 3.026 samples/sec, batch_loss: 0.3746, batch_loss_c: 0.3884, batch_loss_s: 0.3424, time:13.2193, lr:0.001\u001b[0m\n",
            "2019-11-25 08:06:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1510/3125], step: 4635, 2.961 samples/sec, batch_loss: 0.2368, batch_loss_c: 0.2051, batch_loss_s: 0.3108, time:13.5094, lr:0.001\u001b[0m\n",
            "2019-11-25 08:06:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1520/3125], step: 4645, 3.019 samples/sec, batch_loss: 0.1208, batch_loss_c: 0.1175, batch_loss_s: 0.1286, time:13.2473, lr:0.001\u001b[0m\n",
            "2019-11-25 08:06:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1530/3125], step: 4655, 2.996 samples/sec, batch_loss: 0.1220, batch_loss_c: 0.1347, batch_loss_s: 0.0924, time:13.3532, lr:0.001\u001b[0m\n",
            "2019-11-25 08:06:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1540/3125], step: 4665, 3.060 samples/sec, batch_loss: 0.3135, batch_loss_c: 0.3132, batch_loss_s: 0.3141, time:13.0705, lr:0.001\u001b[0m\n",
            "2019-11-25 08:07:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1550/3125], step: 4675, 2.997 samples/sec, batch_loss: 0.1827, batch_loss_c: 0.2001, batch_loss_s: 0.1421, time:13.3471, lr:0.001\u001b[0m\n",
            "2019-11-25 08:07:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1560/3125], step: 4685, 3.016 samples/sec, batch_loss: 0.2857, batch_loss_c: 0.2713, batch_loss_s: 0.3193, time:13.2633, lr:0.001\u001b[0m\n",
            "2019-11-25 08:07:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1570/3125], step: 4695, 3.015 samples/sec, batch_loss: 0.3919, batch_loss_c: 0.3914, batch_loss_s: 0.3931, time:13.2681, lr:0.001\u001b[0m\n",
            "2019-11-25 08:07:43 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1580/3125], step: 4705, 3.020 samples/sec, batch_loss: 0.3600, batch_loss_c: 0.3645, batch_loss_s: 0.3494, time:13.2446, lr:0.001\u001b[0m\n",
            "2019-11-25 08:07:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1590/3125], step: 4715, 3.050 samples/sec, batch_loss: 0.2825, batch_loss_c: 0.2644, batch_loss_s: 0.3248, time:13.1135, lr:0.001\u001b[0m\n",
            "2019-11-25 08:08:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1600/3125], step: 4725, 2.937 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1656, batch_loss_s: 0.1138, time:13.6191, lr:0.001\u001b[0m\n",
            "2019-11-25 08:08:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1610/3125], step: 4735, 2.910 samples/sec, batch_loss: 0.3578, batch_loss_c: 0.3613, batch_loss_s: 0.3495, time:13.7456, lr:0.001\u001b[0m\n",
            "2019-11-25 08:08:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1620/3125], step: 4745, 2.969 samples/sec, batch_loss: 0.4691, batch_loss_c: 0.4704, batch_loss_s: 0.4659, time:13.4745, lr:0.001\u001b[0m\n",
            "2019-11-25 08:08:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1630/3125], step: 4755, 3.005 samples/sec, batch_loss: 0.1264, batch_loss_c: 0.1312, batch_loss_s: 0.1153, time:13.3108, lr:0.001\u001b[0m\n",
            "2019-11-25 08:09:04 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1640/3125], step: 4765, 3.018 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1697, batch_loss_s: 0.0898, time:13.2528, lr:0.001\u001b[0m\n",
            "2019-11-25 08:09:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1650/3125], step: 4775, 2.998 samples/sec, batch_loss: 0.3312, batch_loss_c: 0.3432, batch_loss_s: 0.3032, time:13.3437, lr:0.001\u001b[0m\n",
            "2019-11-25 08:09:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1660/3125], step: 4785, 2.969 samples/sec, batch_loss: 0.0912, batch_loss_c: 0.0909, batch_loss_s: 0.0918, time:13.4720, lr:0.001\u001b[0m\n",
            "2019-11-25 08:09:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1670/3125], step: 4795, 3.034 samples/sec, batch_loss: 0.3030, batch_loss_c: 0.2863, batch_loss_s: 0.3422, time:13.1859, lr:0.001\u001b[0m\n",
            "2019-11-25 08:09:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1680/3125], step: 4805, 3.037 samples/sec, batch_loss: 0.1560, batch_loss_c: 0.1634, batch_loss_s: 0.1385, time:13.1690, lr:0.001\u001b[0m\n",
            "2019-11-25 08:10:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1690/3125], step: 4815, 3.013 samples/sec, batch_loss: 0.2182, batch_loss_c: 0.2377, batch_loss_s: 0.1726, time:13.2752, lr:0.001\u001b[0m\n",
            "2019-11-25 08:10:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1700/3125], step: 4825, 2.985 samples/sec, batch_loss: 0.1145, batch_loss_c: 0.1091, batch_loss_s: 0.1270, time:13.4000, lr:0.001\u001b[0m\n",
            "2019-11-25 08:10:37 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1710/3125], step: 4835, 3.025 samples/sec, batch_loss: 0.3458, batch_loss_c: 0.3542, batch_loss_s: 0.3263, time:13.2218, lr:0.001\u001b[0m\n",
            "2019-11-25 08:10:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1720/3125], step: 4845, 3.023 samples/sec, batch_loss: 0.2611, batch_loss_c: 0.2583, batch_loss_s: 0.2677, time:13.2313, lr:0.001\u001b[0m\n",
            "2019-11-25 08:11:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1730/3125], step: 4855, 2.980 samples/sec, batch_loss: 0.4532, batch_loss_c: 0.4509, batch_loss_s: 0.4584, time:13.4223, lr:0.001\u001b[0m\n",
            "2019-11-25 08:11:17 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1740/3125], step: 4865, 2.995 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1342, batch_loss_s: 0.1129, time:13.3560, lr:0.001\u001b[0m\n",
            "2019-11-25 08:11:30 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1750/3125], step: 4875, 3.015 samples/sec, batch_loss: 0.1259, batch_loss_c: 0.1368, batch_loss_s: 0.1003, time:13.2677, lr:0.001\u001b[0m\n",
            "2019-11-25 08:11:44 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1760/3125], step: 4885, 2.929 samples/sec, batch_loss: 0.3486, batch_loss_c: 0.3467, batch_loss_s: 0.3530, time:13.6547, lr:0.001\u001b[0m\n",
            "2019-11-25 08:11:57 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1770/3125], step: 4895, 3.032 samples/sec, batch_loss: 0.1975, batch_loss_c: 0.2234, batch_loss_s: 0.1370, time:13.1946, lr:0.001\u001b[0m\n",
            "2019-11-25 08:12:10 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1780/3125], step: 4905, 3.039 samples/sec, batch_loss: 0.2203, batch_loss_c: 0.2554, batch_loss_s: 0.1383, time:13.1601, lr:0.001\u001b[0m\n",
            "2019-11-25 08:12:23 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1790/3125], step: 4915, 3.029 samples/sec, batch_loss: 0.1569, batch_loss_c: 0.1643, batch_loss_s: 0.1396, time:13.2064, lr:0.001\u001b[0m\n",
            "2019-11-25 08:12:36 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1800/3125], step: 4925, 3.029 samples/sec, batch_loss: 0.1773, batch_loss_c: 0.2022, batch_loss_s: 0.1193, time:13.2051, lr:0.001\u001b[0m\n",
            "2019-11-25 08:12:50 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1810/3125], step: 4935, 3.018 samples/sec, batch_loss: 0.5548, batch_loss_c: 0.5516, batch_loss_s: 0.5623, time:13.2534, lr:0.001\u001b[0m\n",
            "2019-11-25 08:13:03 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1820/3125], step: 4945, 3.014 samples/sec, batch_loss: 0.1871, batch_loss_c: 0.2143, batch_loss_s: 0.1235, time:13.2714, lr:0.001\u001b[0m\n",
            "2019-11-25 08:13:16 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1830/3125], step: 4955, 3.002 samples/sec, batch_loss: 0.1526, batch_loss_c: 0.1630, batch_loss_s: 0.1286, time:13.3251, lr:0.001\u001b[0m\n",
            "2019-11-25 08:13:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1840/3125], step: 4965, 3.022 samples/sec, batch_loss: 0.4071, batch_loss_c: 0.4244, batch_loss_s: 0.3667, time:13.2377, lr:0.001\u001b[0m\n",
            "2019-11-25 08:13:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1850/3125], step: 4975, 3.055 samples/sec, batch_loss: 0.2753, batch_loss_c: 0.2537, batch_loss_s: 0.3256, time:13.0943, lr:0.001\u001b[0m\n",
            "2019-11-25 08:13:56 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1860/3125], step: 4985, 3.036 samples/sec, batch_loss: 0.1407, batch_loss_c: 0.1576, batch_loss_s: 0.1012, time:13.1757, lr:0.001\u001b[0m\n",
            "2019-11-25 08:14:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1870/3125], step: 4995, 3.028 samples/sec, batch_loss: 0.4702, batch_loss_c: 0.5244, batch_loss_s: 0.3439, time:13.2111, lr:0.001\u001b[0m\n",
            "2019-11-25 08:14:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1880/3125], step: 5005, 3.058 samples/sec, batch_loss: 0.1818, batch_loss_c: 0.1939, batch_loss_s: 0.1537, time:13.0798, lr:0.001\u001b[0m\n",
            "2019-11-25 08:14:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1890/3125], step: 5015, 3.037 samples/sec, batch_loss: 0.1538, batch_loss_c: 0.1585, batch_loss_s: 0.1426, time:13.1703, lr:0.001\u001b[0m\n",
            "2019-11-25 08:14:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1900/3125], step: 5025, 2.998 samples/sec, batch_loss: 0.1316, batch_loss_c: 0.1250, batch_loss_s: 0.1469, time:13.3412, lr:0.001\u001b[0m\n",
            "2019-11-25 08:15:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1910/3125], step: 5035, 3.021 samples/sec, batch_loss: 0.1075, batch_loss_c: 0.1045, batch_loss_s: 0.1146, time:13.2402, lr:0.001\u001b[0m\n",
            "2019-11-25 08:15:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1920/3125], step: 5045, 3.011 samples/sec, batch_loss: 0.0839, batch_loss_c: 0.0830, batch_loss_s: 0.0861, time:13.2850, lr:0.001\u001b[0m\n",
            "2019-11-25 08:15:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1930/3125], step: 5055, 2.981 samples/sec, batch_loss: 0.2811, batch_loss_c: 0.3175, batch_loss_s: 0.1963, time:13.4185, lr:0.001\u001b[0m\n",
            "2019-11-25 08:15:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1940/3125], step: 5065, 3.032 samples/sec, batch_loss: 0.2777, batch_loss_c: 0.3052, batch_loss_s: 0.2138, time:13.1938, lr:0.001\u001b[0m\n",
            "2019-11-25 08:15:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1950/3125], step: 5075, 3.001 samples/sec, batch_loss: 0.2555, batch_loss_c: 0.2480, batch_loss_s: 0.2728, time:13.3299, lr:0.001\u001b[0m\n",
            "2019-11-25 08:16:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1960/3125], step: 5085, 3.005 samples/sec, batch_loss: 0.5153, batch_loss_c: 0.4934, batch_loss_s: 0.5665, time:13.3090, lr:0.001\u001b[0m\n",
            "2019-11-25 08:16:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1970/3125], step: 5095, 2.980 samples/sec, batch_loss: 0.3389, batch_loss_c: 0.4088, batch_loss_s: 0.1759, time:13.4206, lr:0.001\u001b[0m\n",
            "2019-11-25 08:16:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1980/3125], step: 5105, 3.002 samples/sec, batch_loss: 0.1182, batch_loss_c: 0.1214, batch_loss_s: 0.1106, time:13.3243, lr:0.001\u001b[0m\n",
            "2019-11-25 08:16:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [1990/3125], step: 5115, 3.007 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1563, batch_loss_s: 0.1162, time:13.3008, lr:0.001\u001b[0m\n",
            "2019-11-25 08:17:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2000/3125], step: 5125, 2.973 samples/sec, batch_loss: 0.1120, batch_loss_c: 0.1142, batch_loss_s: 0.1069, time:13.4547, lr:0.001\u001b[0m\n",
            "2019-11-25 08:17:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2010/3125], step: 5135, 2.988 samples/sec, batch_loss: 0.3176, batch_loss_c: 0.3131, batch_loss_s: 0.3282, time:13.3876, lr:0.001\u001b[0m\n",
            "2019-11-25 08:17:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2020/3125], step: 5145, 2.997 samples/sec, batch_loss: 0.3039, batch_loss_c: 0.2899, batch_loss_s: 0.3367, time:13.3477, lr:0.001\u001b[0m\n",
            "2019-11-25 08:17:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2030/3125], step: 5155, 2.974 samples/sec, batch_loss: 0.2472, batch_loss_c: 0.2443, batch_loss_s: 0.2542, time:13.4497, lr:0.001\u001b[0m\n",
            "2019-11-25 08:17:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2040/3125], step: 5165, 2.997 samples/sec, batch_loss: 0.3495, batch_loss_c: 0.3511, batch_loss_s: 0.3458, time:13.3445, lr:0.001\u001b[0m\n",
            "2019-11-25 08:18:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2050/3125], step: 5175, 3.013 samples/sec, batch_loss: 0.0952, batch_loss_c: 0.0947, batch_loss_s: 0.0964, time:13.2766, lr:0.001\u001b[0m\n",
            "2019-11-25 08:18:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2060/3125], step: 5185, 3.039 samples/sec, batch_loss: 0.1259, batch_loss_c: 0.1365, batch_loss_s: 0.1014, time:13.1620, lr:0.001\u001b[0m\n",
            "2019-11-25 08:18:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2070/3125], step: 5195, 3.015 samples/sec, batch_loss: 0.3274, batch_loss_c: 0.3314, batch_loss_s: 0.3182, time:13.2677, lr:0.001\u001b[0m\n",
            "2019-11-25 08:18:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2080/3125], step: 5205, 3.017 samples/sec, batch_loss: 0.0751, batch_loss_c: 0.0720, batch_loss_s: 0.0825, time:13.2587, lr:0.001\u001b[0m\n",
            "2019-11-25 08:19:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2090/3125], step: 5215, 3.018 samples/sec, batch_loss: 0.3841, batch_loss_c: 0.4000, batch_loss_s: 0.3470, time:13.2542, lr:0.001\u001b[0m\n",
            "2019-11-25 08:19:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2100/3125], step: 5225, 2.992 samples/sec, batch_loss: 0.2976, batch_loss_c: 0.2824, batch_loss_s: 0.3330, time:13.3706, lr:0.001\u001b[0m\n",
            "2019-11-25 08:19:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2110/3125], step: 5235, 2.999 samples/sec, batch_loss: 0.3049, batch_loss_c: 0.2938, batch_loss_s: 0.3309, time:13.3399, lr:0.001\u001b[0m\n",
            "2019-11-25 08:19:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2120/3125], step: 5245, 2.936 samples/sec, batch_loss: 0.1343, batch_loss_c: 0.1430, batch_loss_s: 0.1139, time:13.6252, lr:0.001\u001b[0m\n",
            "2019-11-25 08:19:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2130/3125], step: 5255, 3.022 samples/sec, batch_loss: 0.2525, batch_loss_c: 0.2330, batch_loss_s: 0.2981, time:13.2345, lr:0.001\u001b[0m\n",
            "2019-11-25 08:20:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2140/3125], step: 5265, 3.026 samples/sec, batch_loss: 0.4837, batch_loss_c: 0.5134, batch_loss_s: 0.4145, time:13.2179, lr:0.001\u001b[0m\n",
            "2019-11-25 08:20:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2150/3125], step: 5275, 3.039 samples/sec, batch_loss: 0.1538, batch_loss_c: 0.1788, batch_loss_s: 0.0952, time:13.1607, lr:0.001\u001b[0m\n",
            "2019-11-25 08:20:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2160/3125], step: 5285, 2.979 samples/sec, batch_loss: 0.3425, batch_loss_c: 0.3525, batch_loss_s: 0.3192, time:13.4271, lr:0.001\u001b[0m\n",
            "2019-11-25 08:20:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2170/3125], step: 5295, 2.946 samples/sec, batch_loss: 0.2063, batch_loss_c: 0.2184, batch_loss_s: 0.1779, time:13.5789, lr:0.001\u001b[0m\n",
            "2019-11-25 08:21:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2180/3125], step: 5305, 2.953 samples/sec, batch_loss: 0.1549, batch_loss_c: 0.1749, batch_loss_s: 0.1081, time:13.5433, lr:0.001\u001b[0m\n",
            "2019-11-25 08:21:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2190/3125], step: 5315, 2.997 samples/sec, batch_loss: 0.6365, batch_loss_c: 0.6630, batch_loss_s: 0.5748, time:13.3454, lr:0.001\u001b[0m\n",
            "2019-11-25 08:21:29 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2200/3125], step: 5325, 3.023 samples/sec, batch_loss: 0.1725, batch_loss_c: 0.1874, batch_loss_s: 0.1379, time:13.2323, lr:0.001\u001b[0m\n",
            "2019-11-25 08:21:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2210/3125], step: 5335, 3.038 samples/sec, batch_loss: 0.1640, batch_loss_c: 0.1777, batch_loss_s: 0.1321, time:13.1686, lr:0.001\u001b[0m\n",
            "2019-11-25 08:21:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2220/3125], step: 5345, 3.012 samples/sec, batch_loss: 0.1618, batch_loss_c: 0.1830, batch_loss_s: 0.1125, time:13.2804, lr:0.001\u001b[0m\n",
            "2019-11-25 08:22:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2230/3125], step: 5355, 3.010 samples/sec, batch_loss: 0.2792, batch_loss_c: 0.2574, batch_loss_s: 0.3302, time:13.2903, lr:0.001\u001b[0m\n",
            "2019-11-25 08:22:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2240/3125], step: 5365, 3.045 samples/sec, batch_loss: 0.4049, batch_loss_c: 0.4448, batch_loss_s: 0.3118, time:13.1346, lr:0.001\u001b[0m\n",
            "2019-11-25 08:22:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2250/3125], step: 5375, 3.038 samples/sec, batch_loss: 0.6549, batch_loss_c: 0.6738, batch_loss_s: 0.6109, time:13.1660, lr:0.001\u001b[0m\n",
            "2019-11-25 08:22:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2260/3125], step: 5385, 2.991 samples/sec, batch_loss: 0.1058, batch_loss_c: 0.1062, batch_loss_s: 0.1049, time:13.3735, lr:0.001\u001b[0m\n",
            "2019-11-25 08:23:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2270/3125], step: 5395, 3.048 samples/sec, batch_loss: 0.1512, batch_loss_c: 0.1515, batch_loss_s: 0.1506, time:13.1235, lr:0.001\u001b[0m\n",
            "2019-11-25 08:23:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2280/3125], step: 5405, 2.993 samples/sec, batch_loss: 0.0978, batch_loss_c: 0.1006, batch_loss_s: 0.0915, time:13.3660, lr:0.001\u001b[0m\n",
            "2019-11-25 08:23:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2290/3125], step: 5415, 3.017 samples/sec, batch_loss: 0.3238, batch_loss_c: 0.3226, batch_loss_s: 0.3266, time:13.2600, lr:0.001\u001b[0m\n",
            "2019-11-25 08:23:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2300/3125], step: 5425, 2.963 samples/sec, batch_loss: 0.1398, batch_loss_c: 0.1548, batch_loss_s: 0.1048, time:13.5009, lr:0.001\u001b[0m\n",
            "2019-11-25 08:23:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2310/3125], step: 5435, 2.982 samples/sec, batch_loss: 0.1399, batch_loss_c: 0.1616, batch_loss_s: 0.0892, time:13.4125, lr:0.001\u001b[0m\n",
            "2019-11-25 08:24:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2320/3125], step: 5445, 2.965 samples/sec, batch_loss: 0.3790, batch_loss_c: 0.3920, batch_loss_s: 0.3487, time:13.4921, lr:0.001\u001b[0m\n",
            "2019-11-25 08:24:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2330/3125], step: 5455, 2.991 samples/sec, batch_loss: 0.2150, batch_loss_c: 0.2117, batch_loss_s: 0.2226, time:13.3748, lr:0.001\u001b[0m\n",
            "2019-11-25 08:24:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2340/3125], step: 5465, 3.034 samples/sec, batch_loss: 0.2053, batch_loss_c: 0.2369, batch_loss_s: 0.1316, time:13.1836, lr:0.001\u001b[0m\n",
            "2019-11-25 08:24:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2350/3125], step: 5475, 2.972 samples/sec, batch_loss: 0.4190, batch_loss_c: 0.4336, batch_loss_s: 0.3847, time:13.4597, lr:0.001\u001b[0m\n",
            "2019-11-25 08:25:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2360/3125], step: 5485, 3.042 samples/sec, batch_loss: 0.3716, batch_loss_c: 0.3927, batch_loss_s: 0.3222, time:13.1508, lr:0.001\u001b[0m\n",
            "2019-11-25 08:25:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2370/3125], step: 5495, 3.009 samples/sec, batch_loss: 0.3306, batch_loss_c: 0.3305, batch_loss_s: 0.3307, time:13.2921, lr:0.001\u001b[0m\n",
            "2019-11-25 08:25:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2380/3125], step: 5505, 2.935 samples/sec, batch_loss: 0.1920, batch_loss_c: 0.1986, batch_loss_s: 0.1766, time:13.6268, lr:0.001\u001b[0m\n",
            "2019-11-25 08:25:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2390/3125], step: 5515, 2.968 samples/sec, batch_loss: 0.4501, batch_loss_c: 0.4502, batch_loss_s: 0.4499, time:13.4787, lr:0.001\u001b[0m\n",
            "2019-11-25 08:25:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2400/3125], step: 5525, 2.992 samples/sec, batch_loss: 0.3956, batch_loss_c: 0.4120, batch_loss_s: 0.3574, time:13.3669, lr:0.001\u001b[0m\n",
            "2019-11-25 08:26:09 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2410/3125], step: 5535, 2.982 samples/sec, batch_loss: 0.5372, batch_loss_c: 0.5272, batch_loss_s: 0.5605, time:13.4136, lr:0.001\u001b[0m\n",
            "2019-11-25 08:26:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2420/3125], step: 5545, 3.003 samples/sec, batch_loss: 0.4087, batch_loss_c: 0.4076, batch_loss_s: 0.4112, time:13.3212, lr:0.001\u001b[0m\n",
            "2019-11-25 08:26:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2430/3125], step: 5555, 3.011 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.1081, batch_loss_s: 0.0747, time:13.2864, lr:0.001\u001b[0m\n",
            "2019-11-25 08:26:49 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2440/3125], step: 5565, 2.967 samples/sec, batch_loss: 0.5708, batch_loss_c: 0.5752, batch_loss_s: 0.5605, time:13.4811, lr:0.001\u001b[0m\n",
            "2019-11-25 08:27:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2450/3125], step: 5575, 3.012 samples/sec, batch_loss: 0.1281, batch_loss_c: 0.1334, batch_loss_s: 0.1157, time:13.2818, lr:0.001\u001b[0m\n",
            "2019-11-25 08:27:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2460/3125], step: 5585, 2.991 samples/sec, batch_loss: 0.1811, batch_loss_c: 0.2005, batch_loss_s: 0.1357, time:13.3718, lr:0.001\u001b[0m\n",
            "2019-11-25 08:27:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2470/3125], step: 5595, 3.031 samples/sec, batch_loss: 0.1516, batch_loss_c: 0.1396, batch_loss_s: 0.1796, time:13.1978, lr:0.001\u001b[0m\n",
            "2019-11-25 08:27:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2480/3125], step: 5605, 2.989 samples/sec, batch_loss: 0.2874, batch_loss_c: 0.2740, batch_loss_s: 0.3187, time:13.3830, lr:0.001\u001b[0m\n",
            "2019-11-25 08:27:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2490/3125], step: 5615, 3.016 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3600, batch_loss_s: 0.3240, time:13.2633, lr:0.001\u001b[0m\n",
            "2019-11-25 08:28:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2500/3125], step: 5625, 3.011 samples/sec, batch_loss: 0.1880, batch_loss_c: 0.2005, batch_loss_s: 0.1590, time:13.2829, lr:0.001\u001b[0m\n",
            "2019-11-25 08:28:22 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2510/3125], step: 5635, 3.019 samples/sec, batch_loss: 0.1043, batch_loss_c: 0.1138, batch_loss_s: 0.0823, time:13.2506, lr:0.001\u001b[0m\n",
            "2019-11-25 08:28:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2520/3125], step: 5645, 2.982 samples/sec, batch_loss: 0.1882, batch_loss_c: 0.2226, batch_loss_s: 0.1078, time:13.4154, lr:0.001\u001b[0m\n",
            "2019-11-25 08:28:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2530/3125], step: 5655, 3.001 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1098, batch_loss_s: 0.1087, time:13.3296, lr:0.001\u001b[0m\n",
            "2019-11-25 08:29:02 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2540/3125], step: 5665, 3.003 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1072, batch_loss_s: 0.1147, time:13.3216, lr:0.001\u001b[0m\n",
            "2019-11-25 08:29:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2550/3125], step: 5675, 3.010 samples/sec, batch_loss: 0.1041, batch_loss_c: 0.1018, batch_loss_s: 0.1093, time:13.2877, lr:0.001\u001b[0m\n",
            "2019-11-25 08:29:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2560/3125], step: 5685, 2.983 samples/sec, batch_loss: 0.3638, batch_loss_c: 0.3717, batch_loss_s: 0.3453, time:13.4091, lr:0.001\u001b[0m\n",
            "2019-11-25 08:29:42 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2570/3125], step: 5695, 3.035 samples/sec, batch_loss: 0.4122, batch_loss_c: 0.4475, batch_loss_s: 0.3298, time:13.1790, lr:0.001\u001b[0m\n",
            "2019-11-25 08:29:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2580/3125], step: 5705, 2.988 samples/sec, batch_loss: 0.2226, batch_loss_c: 0.1860, batch_loss_s: 0.3081, time:13.3848, lr:0.001\u001b[0m\n",
            "2019-11-25 08:30:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2590/3125], step: 5715, 3.067 samples/sec, batch_loss: 0.2149, batch_loss_c: 0.2552, batch_loss_s: 0.1208, time:13.0418, lr:0.001\u001b[0m\n",
            "2019-11-25 08:30:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2600/3125], step: 5725, 3.022 samples/sec, batch_loss: 0.3510, batch_loss_c: 0.3584, batch_loss_s: 0.3337, time:13.2384, lr:0.001\u001b[0m\n",
            "2019-11-25 08:30:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2610/3125], step: 5735, 2.961 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1187, batch_loss_s: 0.1053, time:13.5089, lr:0.001\u001b[0m\n",
            "2019-11-25 08:30:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2620/3125], step: 5745, 3.056 samples/sec, batch_loss: 0.3206, batch_loss_c: 0.3147, batch_loss_s: 0.3344, time:13.0894, lr:0.001\u001b[0m\n",
            "2019-11-25 08:31:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2630/3125], step: 5755, 2.965 samples/sec, batch_loss: 0.4146, batch_loss_c: 0.4382, batch_loss_s: 0.3596, time:13.4902, lr:0.001\u001b[0m\n",
            "2019-11-25 08:31:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2640/3125], step: 5765, 3.053 samples/sec, batch_loss: 0.3450, batch_loss_c: 0.3414, batch_loss_s: 0.3533, time:13.1002, lr:0.001\u001b[0m\n",
            "2019-11-25 08:31:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2650/3125], step: 5775, 3.020 samples/sec, batch_loss: 0.1855, batch_loss_c: 0.2102, batch_loss_s: 0.1277, time:13.2432, lr:0.001\u001b[0m\n",
            "2019-11-25 08:31:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2660/3125], step: 5785, 3.013 samples/sec, batch_loss: 0.1648, batch_loss_c: 0.1864, batch_loss_s: 0.1144, time:13.2738, lr:0.001\u001b[0m\n",
            "2019-11-25 08:31:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2670/3125], step: 5795, 2.963 samples/sec, batch_loss: 0.1451, batch_loss_c: 0.1577, batch_loss_s: 0.1157, time:13.5002, lr:0.001\u001b[0m\n",
            "2019-11-25 08:32:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2680/3125], step: 5805, 2.966 samples/sec, batch_loss: 0.1220, batch_loss_c: 0.1320, batch_loss_s: 0.0985, time:13.4874, lr:0.001\u001b[0m\n",
            "2019-11-25 08:32:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2690/3125], step: 5815, 3.051 samples/sec, batch_loss: 0.4469, batch_loss_c: 0.4644, batch_loss_s: 0.4062, time:13.1105, lr:0.001\u001b[0m\n",
            "2019-11-25 08:32:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2700/3125], step: 5825, 2.948 samples/sec, batch_loss: 0.5528, batch_loss_c: 0.5485, batch_loss_s: 0.5630, time:13.5704, lr:0.001\u001b[0m\n",
            "2019-11-25 08:32:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2710/3125], step: 5835, 3.039 samples/sec, batch_loss: 0.3285, batch_loss_c: 0.3161, batch_loss_s: 0.3574, time:13.1634, lr:0.001\u001b[0m\n",
            "2019-11-25 08:33:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2720/3125], step: 5845, 3.062 samples/sec, batch_loss: 0.2856, batch_loss_c: 0.2743, batch_loss_s: 0.3118, time:13.0626, lr:0.001\u001b[0m\n",
            "2019-11-25 08:33:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2730/3125], step: 5855, 3.003 samples/sec, batch_loss: 0.1679, batch_loss_c: 0.1895, batch_loss_s: 0.1177, time:13.3199, lr:0.001\u001b[0m\n",
            "2019-11-25 08:33:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2740/3125], step: 5865, 2.989 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1410, batch_loss_s: 0.1260, time:13.3841, lr:0.001\u001b[0m\n",
            "2019-11-25 08:33:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2750/3125], step: 5875, 3.027 samples/sec, batch_loss: 0.0900, batch_loss_c: 0.0943, batch_loss_s: 0.0798, time:13.2165, lr:0.001\u001b[0m\n",
            "2019-11-25 08:33:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2760/3125], step: 5885, 2.998 samples/sec, batch_loss: 0.2327, batch_loss_c: 0.2604, batch_loss_s: 0.1681, time:13.3443, lr:0.001\u001b[0m\n",
            "2019-11-25 08:34:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2770/3125], step: 5895, 3.002 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0832, batch_loss_s: 0.0901, time:13.3241, lr:0.001\u001b[0m\n",
            "2019-11-25 08:34:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2780/3125], step: 5905, 2.978 samples/sec, batch_loss: 0.1253, batch_loss_c: 0.1291, batch_loss_s: 0.1166, time:13.4319, lr:0.001\u001b[0m\n",
            "2019-11-25 08:34:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2790/3125], step: 5915, 2.968 samples/sec, batch_loss: 0.1907, batch_loss_c: 0.2246, batch_loss_s: 0.1115, time:13.4754, lr:0.001\u001b[0m\n",
            "2019-11-25 08:34:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2800/3125], step: 5925, 3.046 samples/sec, batch_loss: 0.4151, batch_loss_c: 0.4156, batch_loss_s: 0.4140, time:13.1323, lr:0.001\u001b[0m\n",
            "2019-11-25 08:35:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2810/3125], step: 5935, 3.021 samples/sec, batch_loss: 0.5683, batch_loss_c: 0.5691, batch_loss_s: 0.5664, time:13.2409, lr:0.001\u001b[0m\n",
            "2019-11-25 08:35:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2820/3125], step: 5945, 3.009 samples/sec, batch_loss: 0.1554, batch_loss_c: 0.1740, batch_loss_s: 0.1121, time:13.2945, lr:0.001\u001b[0m\n",
            "2019-11-25 08:35:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2830/3125], step: 5955, 3.056 samples/sec, batch_loss: 0.5215, batch_loss_c: 0.5031, batch_loss_s: 0.5645, time:13.0903, lr:0.001\u001b[0m\n",
            "2019-11-25 08:35:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2840/3125], step: 5965, 3.013 samples/sec, batch_loss: 0.1353, batch_loss_c: 0.1436, batch_loss_s: 0.1158, time:13.2752, lr:0.001\u001b[0m\n",
            "2019-11-25 08:35:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2850/3125], step: 5975, 2.959 samples/sec, batch_loss: 0.1582, batch_loss_c: 0.1722, batch_loss_s: 0.1256, time:13.5195, lr:0.001\u001b[0m\n",
            "2019-11-25 08:36:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2860/3125], step: 5985, 2.974 samples/sec, batch_loss: 0.2444, batch_loss_c: 0.2816, batch_loss_s: 0.1577, time:13.4506, lr:0.001\u001b[0m\n",
            "2019-11-25 08:36:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2870/3125], step: 5995, 3.002 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1296, batch_loss_s: 0.0883, time:13.3235, lr:0.001\u001b[0m\n",
            "2019-11-25 08:36:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2880/3125], step: 6005, 2.999 samples/sec, batch_loss: 0.4341, batch_loss_c: 0.4088, batch_loss_s: 0.4933, time:13.3360, lr:0.001\u001b[0m\n",
            "2019-11-25 08:36:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2890/3125], step: 6015, 2.980 samples/sec, batch_loss: 0.1875, batch_loss_c: 0.2191, batch_loss_s: 0.1139, time:13.4227, lr:0.001\u001b[0m\n",
            "2019-11-25 08:37:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2900/3125], step: 6025, 2.949 samples/sec, batch_loss: 0.1803, batch_loss_c: 0.2081, batch_loss_s: 0.1155, time:13.5657, lr:0.001\u001b[0m\n",
            "2019-11-25 08:37:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2910/3125], step: 6035, 2.988 samples/sec, batch_loss: 0.2007, batch_loss_c: 0.2358, batch_loss_s: 0.1188, time:13.3878, lr:0.001\u001b[0m\n",
            "2019-11-25 08:37:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2920/3125], step: 6045, 2.986 samples/sec, batch_loss: 0.3184, batch_loss_c: 0.2962, batch_loss_s: 0.3703, time:13.3943, lr:0.001\u001b[0m\n",
            "2019-11-25 08:37:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2930/3125], step: 6055, 3.035 samples/sec, batch_loss: 0.4603, batch_loss_c: 0.4619, batch_loss_s: 0.4568, time:13.1790, lr:0.001\u001b[0m\n",
            "2019-11-25 08:37:55 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2940/3125], step: 6065, 2.953 samples/sec, batch_loss: 0.4098, batch_loss_c: 0.4054, batch_loss_s: 0.4200, time:13.5478, lr:0.001\u001b[0m\n",
            "2019-11-25 08:38:08 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2950/3125], step: 6075, 2.992 samples/sec, batch_loss: 0.2414, batch_loss_c: 0.2712, batch_loss_s: 0.1717, time:13.3678, lr:0.001\u001b[0m\n",
            "2019-11-25 08:38:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2960/3125], step: 6085, 2.993 samples/sec, batch_loss: 0.3431, batch_loss_c: 0.3409, batch_loss_s: 0.3483, time:13.3648, lr:0.001\u001b[0m\n",
            "2019-11-25 08:38:35 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2970/3125], step: 6095, 2.982 samples/sec, batch_loss: 0.1327, batch_loss_c: 0.1289, batch_loss_s: 0.1413, time:13.4158, lr:0.001\u001b[0m\n",
            "2019-11-25 08:38:48 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2980/3125], step: 6105, 3.040 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0857, batch_loss_s: 0.0730, time:13.1582, lr:0.001\u001b[0m\n",
            "2019-11-25 08:39:01 \u001b[32mINFO     \u001b[0m train.py: [1/10], [2990/3125], step: 6115, 2.968 samples/sec, batch_loss: 0.1450, batch_loss_c: 0.1622, batch_loss_s: 0.1048, time:13.4753, lr:0.001\u001b[0m\n",
            "2019-11-25 08:39:15 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3000/3125], step: 6125, 3.005 samples/sec, batch_loss: 0.3224, batch_loss_c: 0.3021, batch_loss_s: 0.3699, time:13.3114, lr:0.001\u001b[0m\n",
            "2019-11-25 08:39:28 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3010/3125], step: 6135, 3.057 samples/sec, batch_loss: 0.1392, batch_loss_c: 0.1545, batch_loss_s: 0.1037, time:13.0863, lr:0.001\u001b[0m\n",
            "2019-11-25 08:39:41 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3020/3125], step: 6145, 3.036 samples/sec, batch_loss: 0.2042, batch_loss_c: 0.2257, batch_loss_s: 0.1541, time:13.1754, lr:0.001\u001b[0m\n",
            "2019-11-25 08:39:54 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3030/3125], step: 6155, 3.039 samples/sec, batch_loss: 0.1314, batch_loss_c: 0.1408, batch_loss_s: 0.1095, time:13.1632, lr:0.001\u001b[0m\n",
            "2019-11-25 08:40:07 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3040/3125], step: 6165, 3.015 samples/sec, batch_loss: 0.0677, batch_loss_c: 0.0638, batch_loss_s: 0.0767, time:13.2678, lr:0.001\u001b[0m\n",
            "2019-11-25 08:40:21 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3050/3125], step: 6175, 3.028 samples/sec, batch_loss: 0.2136, batch_loss_c: 0.2153, batch_loss_s: 0.2095, time:13.2097, lr:0.001\u001b[0m\n",
            "2019-11-25 08:40:34 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3060/3125], step: 6185, 3.042 samples/sec, batch_loss: 0.0923, batch_loss_c: 0.0782, batch_loss_s: 0.1251, time:13.1486, lr:0.001\u001b[0m\n",
            "2019-11-25 08:40:47 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3070/3125], step: 6195, 2.958 samples/sec, batch_loss: 0.1783, batch_loss_c: 0.2047, batch_loss_s: 0.1168, time:13.5214, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:00 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3080/3125], step: 6205, 3.009 samples/sec, batch_loss: 0.2463, batch_loss_c: 0.2809, batch_loss_s: 0.1656, time:13.2925, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:14 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3090/3125], step: 6215, 2.980 samples/sec, batch_loss: 0.1766, batch_loss_c: 0.1969, batch_loss_s: 0.1293, time:13.4246, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:27 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3100/3125], step: 6225, 3.035 samples/sec, batch_loss: 0.2831, batch_loss_c: 0.2923, batch_loss_s: 0.2618, time:13.1778, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:40 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3110/3125], step: 6235, 3.077 samples/sec, batch_loss: 0.2499, batch_loss_c: 0.3153, batch_loss_s: 0.0973, time:12.9998, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:53 \u001b[32mINFO     \u001b[0m train.py: [1/10], [3120/3125], step: 6245, 3.084 samples/sec, batch_loss: 0.3950, batch_loss_c: 0.4284, batch_loss_s: 0.3171, time:12.9717, lr:0.001\u001b[0m\n",
            "2019-11-25 08:41:59 \u001b[32mINFO     \u001b[0m train.py: [1/10], train_loss: 0.2586, time: 4168.6732, lr: 0.001\u001b[0m\n",
            "2019-11-25 08:42:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [0/3125], step: 6250, 5.992 samples/sec, batch_loss: 0.5233, batch_loss_c: 0.5076, batch_loss_s: 0.5599, time:6.6761, lr:0.001\u001b[0m\n",
            "2019-11-25 08:42:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [10/3125], step: 6260, 2.609 samples/sec, batch_loss: 0.4067, batch_loss_c: 0.3670, batch_loss_s: 0.4993, time:15.3316, lr:0.001\u001b[0m\n",
            "2019-11-25 08:42:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [20/3125], step: 6270, 3.053 samples/sec, batch_loss: 0.3940, batch_loss_c: 0.4048, batch_loss_s: 0.3689, time:13.1013, lr:0.001\u001b[0m\n",
            "2019-11-25 08:42:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [30/3125], step: 6280, 3.020 samples/sec, batch_loss: 0.3044, batch_loss_c: 0.2970, batch_loss_s: 0.3217, time:13.2453, lr:0.001\u001b[0m\n",
            "2019-11-25 08:43:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [40/3125], step: 6290, 2.987 samples/sec, batch_loss: 0.1804, batch_loss_c: 0.1839, batch_loss_s: 0.1724, time:13.3916, lr:0.001\u001b[0m\n",
            "2019-11-25 08:43:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [50/3125], step: 6300, 3.003 samples/sec, batch_loss: 0.4751, batch_loss_c: 0.4866, batch_loss_s: 0.4481, time:13.3199, lr:0.001\u001b[0m\n",
            "2019-11-25 08:43:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [60/3125], step: 6310, 3.018 samples/sec, batch_loss: 0.1281, batch_loss_c: 0.1326, batch_loss_s: 0.1177, time:13.2518, lr:0.001\u001b[0m\n",
            "2019-11-25 08:43:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [70/3125], step: 6320, 2.964 samples/sec, batch_loss: 0.1707, batch_loss_c: 0.1762, batch_loss_s: 0.1578, time:13.4958, lr:0.001\u001b[0m\n",
            "2019-11-25 08:43:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [80/3125], step: 6330, 2.998 samples/sec, batch_loss: 0.3484, batch_loss_c: 0.3344, batch_loss_s: 0.3811, time:13.3428, lr:0.001\u001b[0m\n",
            "2019-11-25 08:44:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [90/3125], step: 6340, 2.981 samples/sec, batch_loss: 0.3461, batch_loss_c: 0.3543, batch_loss_s: 0.3270, time:13.4170, lr:0.001\u001b[0m\n",
            "2019-11-25 08:44:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [100/3125], step: 6350, 2.989 samples/sec, batch_loss: 0.6070, batch_loss_c: 0.5853, batch_loss_s: 0.6577, time:13.3840, lr:0.001\u001b[0m\n",
            "2019-11-25 08:44:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [110/3125], step: 6360, 2.977 samples/sec, batch_loss: 0.5507, batch_loss_c: 0.5517, batch_loss_s: 0.5483, time:13.4386, lr:0.001\u001b[0m\n",
            "2019-11-25 08:44:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [120/3125], step: 6370, 2.976 samples/sec, batch_loss: 0.1257, batch_loss_c: 0.1293, batch_loss_s: 0.1173, time:13.4427, lr:0.001\u001b[0m\n",
            "2019-11-25 08:45:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [130/3125], step: 6380, 3.029 samples/sec, batch_loss: 0.1751, batch_loss_c: 0.1793, batch_loss_s: 0.1654, time:13.2036, lr:0.001\u001b[0m\n",
            "2019-11-25 08:45:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [140/3125], step: 6390, 3.066 samples/sec, batch_loss: 0.1232, batch_loss_c: 0.1274, batch_loss_s: 0.1136, time:13.0484, lr:0.001\u001b[0m\n",
            "2019-11-25 08:45:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [150/3125], step: 6400, 3.015 samples/sec, batch_loss: 0.4997, batch_loss_c: 0.4809, batch_loss_s: 0.5437, time:13.2655, lr:0.001\u001b[0m\n",
            "2019-11-25 08:45:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [160/3125], step: 6410, 2.996 samples/sec, batch_loss: 0.1059, batch_loss_c: 0.1107, batch_loss_s: 0.0948, time:13.3493, lr:0.001\u001b[0m\n",
            "2019-11-25 08:45:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [170/3125], step: 6420, 3.034 samples/sec, batch_loss: 0.3939, batch_loss_c: 0.4115, batch_loss_s: 0.3527, time:13.1843, lr:0.001\u001b[0m\n",
            "2019-11-25 08:46:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [180/3125], step: 6430, 3.019 samples/sec, batch_loss: 0.8490, batch_loss_c: 0.8490, batch_loss_s: 0.8490, time:13.2504, lr:0.001\u001b[0m\n",
            "2019-11-25 08:46:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [190/3125], step: 6440, 3.016 samples/sec, batch_loss: 0.3567, batch_loss_c: 0.3591, batch_loss_s: 0.3512, time:13.2607, lr:0.001\u001b[0m\n",
            "2019-11-25 08:46:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [200/3125], step: 6450, 3.026 samples/sec, batch_loss: 0.2061, batch_loss_c: 0.2443, batch_loss_s: 0.1171, time:13.2188, lr:0.001\u001b[0m\n",
            "2019-11-25 08:46:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [210/3125], step: 6460, 3.035 samples/sec, batch_loss: 0.2579, batch_loss_c: 0.2976, batch_loss_s: 0.1653, time:13.1793, lr:0.001\u001b[0m\n",
            "2019-11-25 08:47:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [220/3125], step: 6470, 3.063 samples/sec, batch_loss: 0.3392, batch_loss_c: 0.3391, batch_loss_s: 0.3396, time:13.0592, lr:0.001\u001b[0m\n",
            "2019-11-25 08:47:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [230/3125], step: 6480, 3.038 samples/sec, batch_loss: 0.4865, batch_loss_c: 0.4659, batch_loss_s: 0.5344, time:13.1673, lr:0.001\u001b[0m\n",
            "2019-11-25 08:47:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [240/3125], step: 6490, 3.007 samples/sec, batch_loss: 0.1617, batch_loss_c: 0.1876, batch_loss_s: 0.1014, time:13.3020, lr:0.001\u001b[0m\n",
            "2019-11-25 08:47:40 \u001b[32mINFO     \u001b[0m train.py: [2/10], [250/3125], step: 6500, 2.977 samples/sec, batch_loss: 0.1847, batch_loss_c: 0.1930, batch_loss_s: 0.1656, time:13.4358, lr:0.001\u001b[0m\n",
            "2019-11-25 08:47:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [260/3125], step: 6510, 3.049 samples/sec, batch_loss: 0.1380, batch_loss_c: 0.1463, batch_loss_s: 0.1186, time:13.1175, lr:0.001\u001b[0m\n",
            "2019-11-25 08:48:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [270/3125], step: 6520, 3.022 samples/sec, batch_loss: 0.4037, batch_loss_c: 0.3687, batch_loss_s: 0.4856, time:13.2341, lr:0.001\u001b[0m\n",
            "2019-11-25 08:48:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [280/3125], step: 6530, 3.034 samples/sec, batch_loss: 0.3131, batch_loss_c: 0.3032, batch_loss_s: 0.3361, time:13.1821, lr:0.001\u001b[0m\n",
            "2019-11-25 08:48:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [290/3125], step: 6540, 3.037 samples/sec, batch_loss: 0.1212, batch_loss_c: 0.1220, batch_loss_s: 0.1194, time:13.1723, lr:0.001\u001b[0m\n",
            "2019-11-25 08:48:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [300/3125], step: 6550, 3.010 samples/sec, batch_loss: 0.2016, batch_loss_c: 0.2373, batch_loss_s: 0.1181, time:13.2891, lr:0.001\u001b[0m\n",
            "2019-11-25 08:48:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [310/3125], step: 6560, 3.025 samples/sec, batch_loss: 0.1061, batch_loss_c: 0.1103, batch_loss_s: 0.0961, time:13.2232, lr:0.001\u001b[0m\n",
            "2019-11-25 08:49:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [320/3125], step: 6570, 2.973 samples/sec, batch_loss: 0.3117, batch_loss_c: 0.3088, batch_loss_s: 0.3183, time:13.4526, lr:0.001\u001b[0m\n",
            "2019-11-25 08:49:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [330/3125], step: 6580, 2.974 samples/sec, batch_loss: 0.1038, batch_loss_c: 0.1122, batch_loss_s: 0.0844, time:13.4491, lr:0.001\u001b[0m\n",
            "2019-11-25 08:49:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [340/3125], step: 6590, 2.975 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0885, batch_loss_s: 0.1076, time:13.4468, lr:0.001\u001b[0m\n",
            "2019-11-25 08:49:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [350/3125], step: 6600, 3.010 samples/sec, batch_loss: 0.3420, batch_loss_c: 0.3409, batch_loss_s: 0.3446, time:13.2877, lr:0.001\u001b[0m\n",
            "2019-11-25 08:50:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [360/3125], step: 6610, 2.998 samples/sec, batch_loss: 0.3205, batch_loss_c: 0.3190, batch_loss_s: 0.3240, time:13.3442, lr:0.001\u001b[0m\n",
            "2019-11-25 08:50:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [370/3125], step: 6620, 3.018 samples/sec, batch_loss: 0.1024, batch_loss_c: 0.0981, batch_loss_s: 0.1123, time:13.2526, lr:0.001\u001b[0m\n",
            "2019-11-25 08:50:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [380/3125], step: 6630, 2.965 samples/sec, batch_loss: 0.1625, batch_loss_c: 0.1939, batch_loss_s: 0.0893, time:13.4891, lr:0.001\u001b[0m\n",
            "2019-11-25 08:50:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [390/3125], step: 6640, 3.016 samples/sec, batch_loss: 0.3447, batch_loss_c: 0.3470, batch_loss_s: 0.3394, time:13.2608, lr:0.001\u001b[0m\n",
            "2019-11-25 08:50:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [400/3125], step: 6650, 2.998 samples/sec, batch_loss: 0.3067, batch_loss_c: 0.2781, batch_loss_s: 0.3732, time:13.3421, lr:0.001\u001b[0m\n",
            "2019-11-25 08:51:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [410/3125], step: 6660, 3.041 samples/sec, batch_loss: 0.3294, batch_loss_c: 0.3255, batch_loss_s: 0.3384, time:13.1525, lr:0.001\u001b[0m\n",
            "2019-11-25 08:51:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [420/3125], step: 6670, 2.993 samples/sec, batch_loss: 0.3111, batch_loss_c: 0.2991, batch_loss_s: 0.3391, time:13.3625, lr:0.001\u001b[0m\n",
            "2019-11-25 08:51:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [430/3125], step: 6680, 3.005 samples/sec, batch_loss: 0.1319, batch_loss_c: 0.1321, batch_loss_s: 0.1314, time:13.3115, lr:0.001\u001b[0m\n",
            "2019-11-25 08:51:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [440/3125], step: 6690, 3.075 samples/sec, batch_loss: 0.1230, batch_loss_c: 0.1275, batch_loss_s: 0.1124, time:13.0099, lr:0.001\u001b[0m\n",
            "2019-11-25 08:52:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [450/3125], step: 6700, 3.039 samples/sec, batch_loss: 0.3596, batch_loss_c: 0.3580, batch_loss_s: 0.3633, time:13.1618, lr:0.001\u001b[0m\n",
            "2019-11-25 08:52:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [460/3125], step: 6710, 2.994 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0671, batch_loss_s: 0.0682, time:13.3582, lr:0.001\u001b[0m\n",
            "2019-11-25 08:52:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [470/3125], step: 6720, 2.965 samples/sec, batch_loss: 0.1733, batch_loss_c: 0.1817, batch_loss_s: 0.1536, time:13.4902, lr:0.001\u001b[0m\n",
            "2019-11-25 08:52:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [480/3125], step: 6730, 2.988 samples/sec, batch_loss: 0.1463, batch_loss_c: 0.1673, batch_loss_s: 0.0971, time:13.3854, lr:0.001\u001b[0m\n",
            "2019-11-25 08:52:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [490/3125], step: 6740, 2.990 samples/sec, batch_loss: 0.3189, batch_loss_c: 0.3215, batch_loss_s: 0.3129, time:13.3791, lr:0.001\u001b[0m\n",
            "2019-11-25 08:53:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [500/3125], step: 6750, 3.033 samples/sec, batch_loss: 0.5593, batch_loss_c: 0.5649, batch_loss_s: 0.5462, time:13.1892, lr:0.001\u001b[0m\n",
            "2019-11-25 08:53:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [510/3125], step: 6760, 3.049 samples/sec, batch_loss: 0.2066, batch_loss_c: 0.2177, batch_loss_s: 0.1809, time:13.1205, lr:0.001\u001b[0m\n",
            "2019-11-25 08:53:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [520/3125], step: 6770, 2.961 samples/sec, batch_loss: 0.1832, batch_loss_c: 0.2029, batch_loss_s: 0.1371, time:13.5077, lr:0.001\u001b[0m\n",
            "2019-11-25 08:53:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [530/3125], step: 6780, 2.978 samples/sec, batch_loss: 0.2477, batch_loss_c: 0.2699, batch_loss_s: 0.1961, time:13.4328, lr:0.001\u001b[0m\n",
            "2019-11-25 08:54:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [540/3125], step: 6790, 3.003 samples/sec, batch_loss: 0.2222, batch_loss_c: 0.2415, batch_loss_s: 0.1772, time:13.3209, lr:0.001\u001b[0m\n",
            "2019-11-25 08:54:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [550/3125], step: 6800, 3.000 samples/sec, batch_loss: 0.2741, batch_loss_c: 0.2989, batch_loss_s: 0.2163, time:13.3316, lr:0.001\u001b[0m\n",
            "2019-11-25 08:54:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [560/3125], step: 6810, 3.030 samples/sec, batch_loss: 0.3193, batch_loss_c: 0.3201, batch_loss_s: 0.3175, time:13.2016, lr:0.001\u001b[0m\n",
            "2019-11-25 08:54:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [570/3125], step: 6820, 3.040 samples/sec, batch_loss: 0.2886, batch_loss_c: 0.2787, batch_loss_s: 0.3116, time:13.1580, lr:0.001\u001b[0m\n",
            "2019-11-25 08:54:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [580/3125], step: 6830, 2.951 samples/sec, batch_loss: 0.1993, batch_loss_c: 0.2254, batch_loss_s: 0.1384, time:13.5536, lr:0.001\u001b[0m\n",
            "2019-11-25 08:55:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [590/3125], step: 6840, 2.996 samples/sec, batch_loss: 0.1686, batch_loss_c: 0.1908, batch_loss_s: 0.1168, time:13.3520, lr:0.001\u001b[0m\n",
            "2019-11-25 08:55:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [600/3125], step: 6850, 3.037 samples/sec, batch_loss: 0.2542, batch_loss_c: 0.2657, batch_loss_s: 0.2272, time:13.1703, lr:0.001\u001b[0m\n",
            "2019-11-25 08:55:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [610/3125], step: 6860, 2.988 samples/sec, batch_loss: 0.3268, batch_loss_c: 0.3312, batch_loss_s: 0.3167, time:13.3849, lr:0.001\u001b[0m\n",
            "2019-11-25 08:55:52 \u001b[32mINFO     \u001b[0m train.py: [2/10], [620/3125], step: 6870, 3.004 samples/sec, batch_loss: 0.2856, batch_loss_c: 0.3279, batch_loss_s: 0.1870, time:13.3170, lr:0.001\u001b[0m\n",
            "2019-11-25 08:56:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [630/3125], step: 6880, 3.061 samples/sec, batch_loss: 0.1326, batch_loss_c: 0.1533, batch_loss_s: 0.0841, time:13.0696, lr:0.001\u001b[0m\n",
            "2019-11-25 08:56:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [640/3125], step: 6890, 3.018 samples/sec, batch_loss: 0.2277, batch_loss_c: 0.2765, batch_loss_s: 0.1136, time:13.2528, lr:0.001\u001b[0m\n",
            "2019-11-25 08:56:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [650/3125], step: 6900, 2.988 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.3127, batch_loss_s: 0.2571, time:13.3846, lr:0.001\u001b[0m\n",
            "2019-11-25 08:56:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [660/3125], step: 6910, 3.026 samples/sec, batch_loss: 0.1272, batch_loss_c: 0.1448, batch_loss_s: 0.0863, time:13.2204, lr:0.001\u001b[0m\n",
            "2019-11-25 08:56:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [670/3125], step: 6920, 2.970 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1602, batch_loss_s: 0.1071, time:13.4682, lr:0.001\u001b[0m\n",
            "2019-11-25 08:57:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [680/3125], step: 6930, 2.983 samples/sec, batch_loss: 0.3579, batch_loss_c: 0.3552, batch_loss_s: 0.3643, time:13.4107, lr:0.001\u001b[0m\n",
            "2019-11-25 08:57:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [690/3125], step: 6940, 3.011 samples/sec, batch_loss: 0.3364, batch_loss_c: 0.3126, batch_loss_s: 0.3920, time:13.2846, lr:0.001\u001b[0m\n",
            "2019-11-25 08:57:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [700/3125], step: 6950, 3.036 samples/sec, batch_loss: 0.2873, batch_loss_c: 0.2607, batch_loss_s: 0.3495, time:13.1755, lr:0.001\u001b[0m\n",
            "2019-11-25 08:57:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [710/3125], step: 6960, 3.045 samples/sec, batch_loss: 0.3231, batch_loss_c: 0.3315, batch_loss_s: 0.3036, time:13.1369, lr:0.001\u001b[0m\n",
            "2019-11-25 08:58:05 \u001b[32mINFO     \u001b[0m train.py: [2/10], [720/3125], step: 6970, 2.974 samples/sec, batch_loss: 0.1398, batch_loss_c: 0.1686, batch_loss_s: 0.0725, time:13.4496, lr:0.001\u001b[0m\n",
            "2019-11-25 08:58:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [730/3125], step: 6980, 3.014 samples/sec, batch_loss: 0.3561, batch_loss_c: 0.3751, batch_loss_s: 0.3118, time:13.2718, lr:0.001\u001b[0m\n",
            "2019-11-25 08:58:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [740/3125], step: 6990, 3.025 samples/sec, batch_loss: 0.2875, batch_loss_c: 0.2733, batch_loss_s: 0.3206, time:13.2228, lr:0.001\u001b[0m\n",
            "2019-11-25 08:58:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [750/3125], step: 7000, 3.006 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.0989, batch_loss_s: 0.1082, time:13.3085, lr:0.001\u001b[0m\n",
            "2019-11-25 08:58:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [760/3125], step: 7010, 3.081 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0883, batch_loss_s: 0.0881, time:12.9823, lr:0.001\u001b[0m\n",
            "2019-11-25 08:59:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [770/3125], step: 7020, 3.008 samples/sec, batch_loss: 0.3591, batch_loss_c: 0.3468, batch_loss_s: 0.3877, time:13.3000, lr:0.001\u001b[0m\n",
            "2019-11-25 08:59:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [780/3125], step: 7030, 3.007 samples/sec, batch_loss: 0.2655, batch_loss_c: 0.2495, batch_loss_s: 0.3029, time:13.3010, lr:0.001\u001b[0m\n",
            "2019-11-25 08:59:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [790/3125], step: 7040, 3.070 samples/sec, batch_loss: 0.1289, batch_loss_c: 0.1344, batch_loss_s: 0.1160, time:13.0296, lr:0.001\u001b[0m\n",
            "2019-11-25 08:59:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [800/3125], step: 7050, 3.025 samples/sec, batch_loss: 0.1454, batch_loss_c: 0.1507, batch_loss_s: 0.1332, time:13.2234, lr:0.001\u001b[0m\n",
            "2019-11-25 09:00:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [810/3125], step: 7060, 2.988 samples/sec, batch_loss: 0.3161, batch_loss_c: 0.3135, batch_loss_s: 0.3221, time:13.3863, lr:0.001\u001b[0m\n",
            "2019-11-25 09:00:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [820/3125], step: 7070, 2.996 samples/sec, batch_loss: 0.1796, batch_loss_c: 0.2108, batch_loss_s: 0.1068, time:13.3529, lr:0.001\u001b[0m\n",
            "2019-11-25 09:00:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [830/3125], step: 7080, 3.016 samples/sec, batch_loss: 0.4014, batch_loss_c: 0.4286, batch_loss_s: 0.3378, time:13.2618, lr:0.001\u001b[0m\n",
            "2019-11-25 09:00:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [840/3125], step: 7090, 3.006 samples/sec, batch_loss: 0.2329, batch_loss_c: 0.2822, batch_loss_s: 0.1178, time:13.3074, lr:0.001\u001b[0m\n",
            "2019-11-25 09:00:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [850/3125], step: 7100, 3.047 samples/sec, batch_loss: 0.1869, batch_loss_c: 0.2128, batch_loss_s: 0.1265, time:13.1279, lr:0.001\u001b[0m\n",
            "2019-11-25 09:01:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [860/3125], step: 7110, 2.963 samples/sec, batch_loss: 0.1931, batch_loss_c: 0.2102, batch_loss_s: 0.1531, time:13.4998, lr:0.001\u001b[0m\n",
            "2019-11-25 09:01:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [870/3125], step: 7120, 3.016 samples/sec, batch_loss: 0.3025, batch_loss_c: 0.2910, batch_loss_s: 0.3293, time:13.2635, lr:0.001\u001b[0m\n",
            "2019-11-25 09:01:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [880/3125], step: 7130, 3.001 samples/sec, batch_loss: 0.0882, batch_loss_c: 0.0905, batch_loss_s: 0.0830, time:13.3284, lr:0.001\u001b[0m\n",
            "2019-11-25 09:01:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [890/3125], step: 7140, 2.998 samples/sec, batch_loss: 0.4602, batch_loss_c: 0.4839, batch_loss_s: 0.4049, time:13.3435, lr:0.001\u001b[0m\n",
            "2019-11-25 09:02:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [900/3125], step: 7150, 2.986 samples/sec, batch_loss: 0.1627, batch_loss_c: 0.1868, batch_loss_s: 0.1063, time:13.3945, lr:0.001\u001b[0m\n",
            "2019-11-25 09:02:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [910/3125], step: 7160, 2.991 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.1052, batch_loss_s: 0.0852, time:13.3740, lr:0.001\u001b[0m\n",
            "2019-11-25 09:02:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [920/3125], step: 7170, 3.009 samples/sec, batch_loss: 0.3653, batch_loss_c: 0.3674, batch_loss_s: 0.3603, time:13.2938, lr:0.001\u001b[0m\n",
            "2019-11-25 09:02:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [930/3125], step: 7180, 2.997 samples/sec, batch_loss: 0.2265, batch_loss_c: 0.2584, batch_loss_s: 0.1520, time:13.3482, lr:0.001\u001b[0m\n",
            "2019-11-25 09:02:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [940/3125], step: 7190, 2.985 samples/sec, batch_loss: 0.1511, batch_loss_c: 0.1722, batch_loss_s: 0.1021, time:13.3993, lr:0.001\u001b[0m\n",
            "2019-11-25 09:03:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [950/3125], step: 7200, 2.995 samples/sec, batch_loss: 0.2702, batch_loss_c: 0.2730, batch_loss_s: 0.2636, time:13.3545, lr:0.001\u001b[0m\n",
            "2019-11-25 09:03:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [960/3125], step: 7210, 3.020 samples/sec, batch_loss: 0.1777, batch_loss_c: 0.2064, batch_loss_s: 0.1109, time:13.2447, lr:0.001\u001b[0m\n",
            "2019-11-25 09:03:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [970/3125], step: 7220, 3.006 samples/sec, batch_loss: 0.3289, batch_loss_c: 0.3312, batch_loss_s: 0.3235, time:13.3057, lr:0.001\u001b[0m\n",
            "2019-11-25 09:03:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [980/3125], step: 7230, 3.029 samples/sec, batch_loss: 0.1810, batch_loss_c: 0.1894, batch_loss_s: 0.1614, time:13.2039, lr:0.001\u001b[0m\n",
            "2019-11-25 09:04:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [990/3125], step: 7240, 2.973 samples/sec, batch_loss: 0.3085, batch_loss_c: 0.2975, batch_loss_s: 0.3343, time:13.4553, lr:0.001\u001b[0m\n",
            "2019-11-25 09:04:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1000/3125], step: 7250, 2.951 samples/sec, batch_loss: 0.1929, batch_loss_c: 0.2329, batch_loss_s: 0.0995, time:13.5544, lr:0.001\u001b[0m\n",
            "2019-11-25 09:04:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1010/3125], step: 7260, 2.963 samples/sec, batch_loss: 0.3167, batch_loss_c: 0.3069, batch_loss_s: 0.3395, time:13.5014, lr:0.001\u001b[0m\n",
            "2019-11-25 09:04:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1020/3125], step: 7270, 2.983 samples/sec, batch_loss: 0.1103, batch_loss_c: 0.1189, batch_loss_s: 0.0904, time:13.4106, lr:0.001\u001b[0m\n",
            "2019-11-25 09:04:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1030/3125], step: 7280, 3.025 samples/sec, batch_loss: 0.3759, batch_loss_c: 0.3844, batch_loss_s: 0.3562, time:13.2211, lr:0.001\u001b[0m\n",
            "2019-11-25 09:05:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1040/3125], step: 7290, 3.037 samples/sec, batch_loss: 0.2854, batch_loss_c: 0.2721, batch_loss_s: 0.3165, time:13.1712, lr:0.001\u001b[0m\n",
            "2019-11-25 09:05:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1050/3125], step: 7300, 2.966 samples/sec, batch_loss: 0.2179, batch_loss_c: 0.2437, batch_loss_s: 0.1578, time:13.4869, lr:0.001\u001b[0m\n",
            "2019-11-25 09:05:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1060/3125], step: 7310, 2.973 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1415, batch_loss_s: 0.1020, time:13.4526, lr:0.001\u001b[0m\n",
            "2019-11-25 09:05:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1070/3125], step: 7320, 2.995 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1205, batch_loss_s: 0.0815, time:13.3547, lr:0.001\u001b[0m\n",
            "2019-11-25 09:06:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1080/3125], step: 7330, 2.967 samples/sec, batch_loss: 0.3286, batch_loss_c: 0.3178, batch_loss_s: 0.3537, time:13.4826, lr:0.001\u001b[0m\n",
            "2019-11-25 09:06:18 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1090/3125], step: 7340, 2.987 samples/sec, batch_loss: 0.2960, batch_loss_c: 0.2850, batch_loss_s: 0.3217, time:13.3892, lr:0.001\u001b[0m\n",
            "2019-11-25 09:06:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1100/3125], step: 7350, 2.994 samples/sec, batch_loss: 0.1171, batch_loss_c: 0.1198, batch_loss_s: 0.1108, time:13.3622, lr:0.001\u001b[0m\n",
            "2019-11-25 09:06:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1110/3125], step: 7360, 2.982 samples/sec, batch_loss: 0.3161, batch_loss_c: 0.3074, batch_loss_s: 0.3364, time:13.4129, lr:0.001\u001b[0m\n",
            "2019-11-25 09:06:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1120/3125], step: 7370, 3.005 samples/sec, batch_loss: 0.1622, batch_loss_c: 0.1538, batch_loss_s: 0.1817, time:13.3119, lr:0.001\u001b[0m\n",
            "2019-11-25 09:07:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1130/3125], step: 7380, 3.066 samples/sec, batch_loss: 0.2261, batch_loss_c: 0.2632, batch_loss_s: 0.1395, time:13.0464, lr:0.001\u001b[0m\n",
            "2019-11-25 09:07:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1140/3125], step: 7390, 3.022 samples/sec, batch_loss: 0.1598, batch_loss_c: 0.1730, batch_loss_s: 0.1292, time:13.2380, lr:0.001\u001b[0m\n",
            "2019-11-25 09:07:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1150/3125], step: 7400, 3.005 samples/sec, batch_loss: 0.3449, batch_loss_c: 0.3564, batch_loss_s: 0.3181, time:13.3102, lr:0.001\u001b[0m\n",
            "2019-11-25 09:07:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1160/3125], step: 7410, 3.038 samples/sec, batch_loss: 0.1643, batch_loss_c: 0.1871, batch_loss_s: 0.1110, time:13.1659, lr:0.001\u001b[0m\n",
            "2019-11-25 09:08:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1170/3125], step: 7420, 3.037 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1585, batch_loss_s: 0.0789, time:13.1706, lr:0.001\u001b[0m\n",
            "2019-11-25 09:08:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1180/3125], step: 7430, 2.988 samples/sec, batch_loss: 0.1014, batch_loss_c: 0.0994, batch_loss_s: 0.1062, time:13.3852, lr:0.001\u001b[0m\n",
            "2019-11-25 09:08:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1190/3125], step: 7440, 3.027 samples/sec, batch_loss: 0.1553, batch_loss_c: 0.1586, batch_loss_s: 0.1477, time:13.2142, lr:0.001\u001b[0m\n",
            "2019-11-25 09:08:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1200/3125], step: 7450, 2.937 samples/sec, batch_loss: 0.1196, batch_loss_c: 0.1157, batch_loss_s: 0.1286, time:13.6190, lr:0.001\u001b[0m\n",
            "2019-11-25 09:08:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1210/3125], step: 7460, 2.943 samples/sec, batch_loss: 0.1448, batch_loss_c: 0.1508, batch_loss_s: 0.1307, time:13.5912, lr:0.001\u001b[0m\n",
            "2019-11-25 09:09:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1220/3125], step: 7470, 3.022 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.1000, batch_loss_s: 0.1025, time:13.2363, lr:0.001\u001b[0m\n",
            "2019-11-25 09:09:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1230/3125], step: 7480, 3.034 samples/sec, batch_loss: 0.4528, batch_loss_c: 0.4647, batch_loss_s: 0.4251, time:13.1846, lr:0.001\u001b[0m\n",
            "2019-11-25 09:09:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1240/3125], step: 7490, 2.992 samples/sec, batch_loss: 0.3398, batch_loss_c: 0.3499, batch_loss_s: 0.3163, time:13.3706, lr:0.001\u001b[0m\n",
            "2019-11-25 09:09:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1250/3125], step: 7500, 2.983 samples/sec, batch_loss: 0.3424, batch_loss_c: 0.3319, batch_loss_s: 0.3669, time:13.4103, lr:0.001\u001b[0m\n",
            "2019-11-25 09:10:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1260/3125], step: 7510, 3.060 samples/sec, batch_loss: 0.6547, batch_loss_c: 0.6918, batch_loss_s: 0.5684, time:13.0705, lr:0.001\u001b[0m\n",
            "2019-11-25 09:10:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1270/3125], step: 7520, 3.034 samples/sec, batch_loss: 0.3015, batch_loss_c: 0.2759, batch_loss_s: 0.3613, time:13.1856, lr:0.001\u001b[0m\n",
            "2019-11-25 09:10:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1280/3125], step: 7530, 3.027 samples/sec, batch_loss: 0.3022, batch_loss_c: 0.2837, batch_loss_s: 0.3455, time:13.2141, lr:0.001\u001b[0m\n",
            "2019-11-25 09:10:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1290/3125], step: 7540, 3.075 samples/sec, batch_loss: 0.3734, batch_loss_c: 0.3739, batch_loss_s: 0.3722, time:13.0082, lr:0.001\u001b[0m\n",
            "2019-11-25 09:10:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1300/3125], step: 7550, 2.953 samples/sec, batch_loss: 0.3803, batch_loss_c: 0.3907, batch_loss_s: 0.3561, time:13.5451, lr:0.001\u001b[0m\n",
            "2019-11-25 09:11:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1310/3125], step: 7560, 3.053 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1380, batch_loss_s: 0.1103, time:13.1031, lr:0.001\u001b[0m\n",
            "2019-11-25 09:11:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1320/3125], step: 7570, 2.989 samples/sec, batch_loss: 0.1018, batch_loss_c: 0.1113, batch_loss_s: 0.0796, time:13.3820, lr:0.001\u001b[0m\n",
            "2019-11-25 09:11:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1330/3125], step: 7580, 2.965 samples/sec, batch_loss: 0.1369, batch_loss_c: 0.1467, batch_loss_s: 0.1141, time:13.4888, lr:0.001\u001b[0m\n",
            "2019-11-25 09:11:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1340/3125], step: 7590, 2.999 samples/sec, batch_loss: 0.3441, batch_loss_c: 0.3467, batch_loss_s: 0.3378, time:13.3388, lr:0.001\u001b[0m\n",
            "2019-11-25 09:12:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1350/3125], step: 7600, 2.989 samples/sec, batch_loss: 0.4338, batch_loss_c: 0.4281, batch_loss_s: 0.4471, time:13.3829, lr:0.001\u001b[0m\n",
            "2019-11-25 09:12:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1360/3125], step: 7610, 2.998 samples/sec, batch_loss: 0.1736, batch_loss_c: 0.2052, batch_loss_s: 0.0998, time:13.3409, lr:0.001\u001b[0m\n",
            "2019-11-25 09:12:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1370/3125], step: 7620, 3.034 samples/sec, batch_loss: 0.4416, batch_loss_c: 0.4735, batch_loss_s: 0.3670, time:13.1846, lr:0.001\u001b[0m\n",
            "2019-11-25 09:12:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1380/3125], step: 7630, 2.978 samples/sec, batch_loss: 0.1286, batch_loss_c: 0.1481, batch_loss_s: 0.0830, time:13.4306, lr:0.001\u001b[0m\n",
            "2019-11-25 09:12:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1390/3125], step: 7640, 2.952 samples/sec, batch_loss: 0.1588, batch_loss_c: 0.1852, batch_loss_s: 0.0970, time:13.5493, lr:0.001\u001b[0m\n",
            "2019-11-25 09:13:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1400/3125], step: 7650, 3.005 samples/sec, batch_loss: 0.5716, batch_loss_c: 0.5766, batch_loss_s: 0.5599, time:13.3126, lr:0.001\u001b[0m\n",
            "2019-11-25 09:13:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1410/3125], step: 7660, 3.024 samples/sec, batch_loss: 0.2822, batch_loss_c: 0.2829, batch_loss_s: 0.2804, time:13.2256, lr:0.001\u001b[0m\n",
            "2019-11-25 09:13:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1420/3125], step: 7670, 3.051 samples/sec, batch_loss: 0.1422, batch_loss_c: 0.1611, batch_loss_s: 0.0982, time:13.1114, lr:0.001\u001b[0m\n",
            "2019-11-25 09:13:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1430/3125], step: 7680, 3.008 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1329, batch_loss_s: 0.1078, time:13.2997, lr:0.001\u001b[0m\n",
            "2019-11-25 09:14:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1440/3125], step: 7690, 3.041 samples/sec, batch_loss: 0.2479, batch_loss_c: 0.2477, batch_loss_s: 0.2484, time:13.1548, lr:0.001\u001b[0m\n",
            "2019-11-25 09:14:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1450/3125], step: 7700, 3.033 samples/sec, batch_loss: 0.1375, batch_loss_c: 0.1433, batch_loss_s: 0.1240, time:13.1876, lr:0.001\u001b[0m\n",
            "2019-11-25 09:14:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1460/3125], step: 7710, 3.000 samples/sec, batch_loss: 0.1900, batch_loss_c: 0.1896, batch_loss_s: 0.1909, time:13.3333, lr:0.001\u001b[0m\n",
            "2019-11-25 09:14:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1470/3125], step: 7720, 3.042 samples/sec, batch_loss: 0.1156, batch_loss_c: 0.1252, batch_loss_s: 0.0932, time:13.1512, lr:0.001\u001b[0m\n",
            "2019-11-25 09:14:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1480/3125], step: 7730, 3.011 samples/sec, batch_loss: 0.1029, batch_loss_c: 0.1066, batch_loss_s: 0.0941, time:13.2849, lr:0.001\u001b[0m\n",
            "2019-11-25 09:15:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1490/3125], step: 7740, 3.019 samples/sec, batch_loss: 0.1488, batch_loss_c: 0.1715, batch_loss_s: 0.0957, time:13.2507, lr:0.001\u001b[0m\n",
            "2019-11-25 09:15:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1500/3125], step: 7750, 3.015 samples/sec, batch_loss: 0.2883, batch_loss_c: 0.2817, batch_loss_s: 0.3036, time:13.2678, lr:0.001\u001b[0m\n",
            "2019-11-25 09:15:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1510/3125], step: 7760, 3.013 samples/sec, batch_loss: 0.2332, batch_loss_c: 0.2274, batch_loss_s: 0.2468, time:13.2771, lr:0.001\u001b[0m\n",
            "2019-11-25 09:15:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1520/3125], step: 7770, 3.028 samples/sec, batch_loss: 0.0849, batch_loss_c: 0.0841, batch_loss_s: 0.0866, time:13.2100, lr:0.001\u001b[0m\n",
            "2019-11-25 09:16:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1530/3125], step: 7780, 3.065 samples/sec, batch_loss: 0.3429, batch_loss_c: 0.3265, batch_loss_s: 0.3812, time:13.0509, lr:0.001\u001b[0m\n",
            "2019-11-25 09:16:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1540/3125], step: 7790, 3.052 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1397, batch_loss_s: 0.0923, time:13.1068, lr:0.001\u001b[0m\n",
            "2019-11-25 09:16:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1550/3125], step: 7800, 3.032 samples/sec, batch_loss: 0.1600, batch_loss_c: 0.1788, batch_loss_s: 0.1163, time:13.1935, lr:0.001\u001b[0m\n",
            "2019-11-25 09:16:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1560/3125], step: 7810, 3.019 samples/sec, batch_loss: 0.3056, batch_loss_c: 0.3011, batch_loss_s: 0.3160, time:13.2476, lr:0.001\u001b[0m\n",
            "2019-11-25 09:16:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1570/3125], step: 7820, 2.976 samples/sec, batch_loss: 0.2439, batch_loss_c: 0.3020, batch_loss_s: 0.1081, time:13.4417, lr:0.001\u001b[0m\n",
            "2019-11-25 09:17:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1580/3125], step: 7830, 2.935 samples/sec, batch_loss: 0.1394, batch_loss_c: 0.1312, batch_loss_s: 0.1584, time:13.6274, lr:0.001\u001b[0m\n",
            "2019-11-25 09:17:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1590/3125], step: 7840, 3.021 samples/sec, batch_loss: 0.1432, batch_loss_c: 0.1647, batch_loss_s: 0.0929, time:13.2414, lr:0.001\u001b[0m\n",
            "2019-11-25 09:17:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1600/3125], step: 7850, 2.949 samples/sec, batch_loss: 0.2303, batch_loss_c: 0.2686, batch_loss_s: 0.1408, time:13.5639, lr:0.001\u001b[0m\n",
            "2019-11-25 09:17:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1610/3125], step: 7860, 3.040 samples/sec, batch_loss: 0.1921, batch_loss_c: 0.2147, batch_loss_s: 0.1392, time:13.1577, lr:0.001\u001b[0m\n",
            "2019-11-25 09:18:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1620/3125], step: 7870, 3.004 samples/sec, batch_loss: 0.3868, batch_loss_c: 0.3990, batch_loss_s: 0.3582, time:13.3169, lr:0.001\u001b[0m\n",
            "2019-11-25 09:18:15 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1630/3125], step: 7880, 3.017 samples/sec, batch_loss: 0.0799, batch_loss_c: 0.0764, batch_loss_s: 0.0883, time:13.2591, lr:0.001\u001b[0m\n",
            "2019-11-25 09:18:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1640/3125], step: 7890, 2.985 samples/sec, batch_loss: 0.4289, batch_loss_c: 0.4620, batch_loss_s: 0.3515, time:13.3991, lr:0.001\u001b[0m\n",
            "2019-11-25 09:18:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1650/3125], step: 7900, 3.071 samples/sec, batch_loss: 0.5871, batch_loss_c: 0.6040, batch_loss_s: 0.5476, time:13.0249, lr:0.001\u001b[0m\n",
            "2019-11-25 09:18:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1660/3125], step: 7910, 3.056 samples/sec, batch_loss: 0.1699, batch_loss_c: 0.1910, batch_loss_s: 0.1207, time:13.0880, lr:0.001\u001b[0m\n",
            "2019-11-25 09:19:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1670/3125], step: 7920, 3.041 samples/sec, batch_loss: 0.5026, batch_loss_c: 0.4773, batch_loss_s: 0.5615, time:13.1549, lr:0.001\u001b[0m\n",
            "2019-11-25 09:19:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1680/3125], step: 7930, 3.033 samples/sec, batch_loss: 0.1952, batch_loss_c: 0.2096, batch_loss_s: 0.1615, time:13.1875, lr:0.001\u001b[0m\n",
            "2019-11-25 09:19:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1690/3125], step: 7940, 3.024 samples/sec, batch_loss: 0.3637, batch_loss_c: 0.3647, batch_loss_s: 0.3614, time:13.2283, lr:0.001\u001b[0m\n",
            "2019-11-25 09:19:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1700/3125], step: 7950, 3.017 samples/sec, batch_loss: 0.2724, batch_loss_c: 0.3321, batch_loss_s: 0.1332, time:13.2591, lr:0.001\u001b[0m\n",
            "2019-11-25 09:20:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1710/3125], step: 7960, 3.004 samples/sec, batch_loss: 0.3082, batch_loss_c: 0.2952, batch_loss_s: 0.3384, time:13.3147, lr:0.001\u001b[0m\n",
            "2019-11-25 09:20:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1720/3125], step: 7970, 3.027 samples/sec, batch_loss: 0.0896, batch_loss_c: 0.0836, batch_loss_s: 0.1034, time:13.2143, lr:0.001\u001b[0m\n",
            "2019-11-25 09:20:27 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1730/3125], step: 7980, 2.994 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1305, batch_loss_s: 0.0986, time:13.3605, lr:0.001\u001b[0m\n",
            "2019-11-25 09:20:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1740/3125], step: 7990, 3.024 samples/sec, batch_loss: 0.3229, batch_loss_c: 0.3222, batch_loss_s: 0.3244, time:13.2289, lr:0.001\u001b[0m\n",
            "2019-11-25 09:20:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1750/3125], step: 8000, 3.032 samples/sec, batch_loss: 0.3879, batch_loss_c: 0.3789, batch_loss_s: 0.4090, time:13.1921, lr:0.001\u001b[0m\n",
            "2019-11-25 09:21:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1760/3125], step: 8010, 3.057 samples/sec, batch_loss: 0.1508, batch_loss_c: 0.1698, batch_loss_s: 0.1064, time:13.0855, lr:0.001\u001b[0m\n",
            "2019-11-25 09:21:20 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1770/3125], step: 8020, 3.031 samples/sec, batch_loss: 0.3548, batch_loss_c: 0.3630, batch_loss_s: 0.3358, time:13.1967, lr:0.001\u001b[0m\n",
            "2019-11-25 09:21:33 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1780/3125], step: 8030, 3.048 samples/sec, batch_loss: 0.1612, batch_loss_c: 0.1648, batch_loss_s: 0.1526, time:13.1216, lr:0.001\u001b[0m\n",
            "2019-11-25 09:21:46 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1790/3125], step: 8040, 3.032 samples/sec, batch_loss: 0.3433, batch_loss_c: 0.3429, batch_loss_s: 0.3441, time:13.1910, lr:0.001\u001b[0m\n",
            "2019-11-25 09:22:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1800/3125], step: 8050, 3.028 samples/sec, batch_loss: 0.4081, batch_loss_c: 0.4025, batch_loss_s: 0.4213, time:13.2083, lr:0.001\u001b[0m\n",
            "2019-11-25 09:22:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1810/3125], step: 8060, 3.026 samples/sec, batch_loss: 0.1591, batch_loss_c: 0.1578, batch_loss_s: 0.1622, time:13.2193, lr:0.001\u001b[0m\n",
            "2019-11-25 09:22:26 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1820/3125], step: 8070, 3.041 samples/sec, batch_loss: 0.3486, batch_loss_c: 0.3332, batch_loss_s: 0.3846, time:13.1545, lr:0.001\u001b[0m\n",
            "2019-11-25 09:22:39 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1830/3125], step: 8080, 3.018 samples/sec, batch_loss: 0.1798, batch_loss_c: 0.2095, batch_loss_s: 0.1105, time:13.2543, lr:0.001\u001b[0m\n",
            "2019-11-25 09:22:53 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1840/3125], step: 8090, 3.003 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3122, batch_loss_s: 0.3540, time:13.3200, lr:0.001\u001b[0m\n",
            "2019-11-25 09:23:06 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1850/3125], step: 8100, 2.988 samples/sec, batch_loss: 0.1546, batch_loss_c: 0.1616, batch_loss_s: 0.1384, time:13.3886, lr:0.001\u001b[0m\n",
            "2019-11-25 09:23:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1860/3125], step: 8110, 3.030 samples/sec, batch_loss: 0.1072, batch_loss_c: 0.1096, batch_loss_s: 0.1016, time:13.1994, lr:0.001\u001b[0m\n",
            "2019-11-25 09:23:32 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1870/3125], step: 8120, 3.035 samples/sec, batch_loss: 0.3170, batch_loss_c: 0.3079, batch_loss_s: 0.3382, time:13.1811, lr:0.001\u001b[0m\n",
            "2019-11-25 09:23:45 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1880/3125], step: 8130, 3.065 samples/sec, batch_loss: 0.2977, batch_loss_c: 0.2920, batch_loss_s: 0.3109, time:13.0492, lr:0.001\u001b[0m\n",
            "2019-11-25 09:23:59 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1890/3125], step: 8140, 3.027 samples/sec, batch_loss: 0.0776, batch_loss_c: 0.0733, batch_loss_s: 0.0876, time:13.2136, lr:0.001\u001b[0m\n",
            "2019-11-25 09:24:12 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1900/3125], step: 8150, 3.058 samples/sec, batch_loss: 0.3879, batch_loss_c: 0.4128, batch_loss_s: 0.3300, time:13.0786, lr:0.001\u001b[0m\n",
            "2019-11-25 09:24:25 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1910/3125], step: 8160, 3.046 samples/sec, batch_loss: 0.1047, batch_loss_c: 0.1027, batch_loss_s: 0.1094, time:13.1339, lr:0.001\u001b[0m\n",
            "2019-11-25 09:24:38 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1920/3125], step: 8170, 3.072 samples/sec, batch_loss: 0.3672, batch_loss_c: 0.3812, batch_loss_s: 0.3346, time:13.0192, lr:0.001\u001b[0m\n",
            "2019-11-25 09:24:51 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1930/3125], step: 8180, 3.055 samples/sec, batch_loss: 0.0915, batch_loss_c: 0.0927, batch_loss_s: 0.0889, time:13.0920, lr:0.001\u001b[0m\n",
            "2019-11-25 09:25:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1940/3125], step: 8190, 3.043 samples/sec, batch_loss: 0.1663, batch_loss_c: 0.1721, batch_loss_s: 0.1528, time:13.1471, lr:0.001\u001b[0m\n",
            "2019-11-25 09:25:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1950/3125], step: 8200, 3.017 samples/sec, batch_loss: 0.1306, batch_loss_c: 0.1289, batch_loss_s: 0.1347, time:13.2573, lr:0.001\u001b[0m\n",
            "2019-11-25 09:25:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1960/3125], step: 8210, 3.016 samples/sec, batch_loss: 0.0834, batch_loss_c: 0.0818, batch_loss_s: 0.0871, time:13.2628, lr:0.001\u001b[0m\n",
            "2019-11-25 09:25:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1970/3125], step: 8220, 3.020 samples/sec, batch_loss: 0.5442, batch_loss_c: 0.5458, batch_loss_s: 0.5404, time:13.2452, lr:0.001\u001b[0m\n",
            "2019-11-25 09:25:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1980/3125], step: 8230, 2.992 samples/sec, batch_loss: 0.3895, batch_loss_c: 0.4054, batch_loss_s: 0.3522, time:13.3686, lr:0.001\u001b[0m\n",
            "2019-11-25 09:26:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [1990/3125], step: 8240, 3.010 samples/sec, batch_loss: 0.2796, batch_loss_c: 0.3505, batch_loss_s: 0.1142, time:13.2893, lr:0.001\u001b[0m\n",
            "2019-11-25 09:26:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2000/3125], step: 8250, 3.063 samples/sec, batch_loss: 0.3649, batch_loss_c: 0.3715, batch_loss_s: 0.3494, time:13.0591, lr:0.001\u001b[0m\n",
            "2019-11-25 09:26:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2010/3125], step: 8260, 3.004 samples/sec, batch_loss: 0.1338, batch_loss_c: 0.1349, batch_loss_s: 0.1312, time:13.3156, lr:0.001\u001b[0m\n",
            "2019-11-25 09:26:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2020/3125], step: 8270, 2.995 samples/sec, batch_loss: 0.3120, batch_loss_c: 0.3771, batch_loss_s: 0.1600, time:13.3553, lr:0.001\u001b[0m\n",
            "2019-11-25 09:27:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2030/3125], step: 8280, 3.058 samples/sec, batch_loss: 0.1533, batch_loss_c: 0.1880, batch_loss_s: 0.0724, time:13.0785, lr:0.001\u001b[0m\n",
            "2019-11-25 09:27:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2040/3125], step: 8290, 2.995 samples/sec, batch_loss: 0.1813, batch_loss_c: 0.2069, batch_loss_s: 0.1216, time:13.3560, lr:0.001\u001b[0m\n",
            "2019-11-25 09:27:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2050/3125], step: 8300, 2.948 samples/sec, batch_loss: 0.1569, batch_loss_c: 0.1801, batch_loss_s: 0.1027, time:13.5703, lr:0.001\u001b[0m\n",
            "2019-11-25 09:27:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2060/3125], step: 8310, 2.949 samples/sec, batch_loss: 0.2323, batch_loss_c: 0.2541, batch_loss_s: 0.1815, time:13.5627, lr:0.001\u001b[0m\n",
            "2019-11-25 09:27:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2070/3125], step: 8320, 3.002 samples/sec, batch_loss: 0.5819, batch_loss_c: 0.5853, batch_loss_s: 0.5742, time:13.3257, lr:0.001\u001b[0m\n",
            "2019-11-25 09:28:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2080/3125], step: 8330, 2.994 samples/sec, batch_loss: 0.5425, batch_loss_c: 0.5746, batch_loss_s: 0.4676, time:13.3595, lr:0.001\u001b[0m\n",
            "2019-11-25 09:28:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2090/3125], step: 8340, 3.043 samples/sec, batch_loss: 0.3945, batch_loss_c: 0.4192, batch_loss_s: 0.3370, time:13.1468, lr:0.001\u001b[0m\n",
            "2019-11-25 09:28:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2100/3125], step: 8350, 3.033 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1172, batch_loss_s: 0.0912, time:13.1881, lr:0.001\u001b[0m\n",
            "2019-11-25 09:28:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2110/3125], step: 8360, 3.020 samples/sec, batch_loss: 0.3041, batch_loss_c: 0.3224, batch_loss_s: 0.2616, time:13.2468, lr:0.001\u001b[0m\n",
            "2019-11-25 09:29:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2120/3125], step: 8370, 2.991 samples/sec, batch_loss: 0.1088, batch_loss_c: 0.1100, batch_loss_s: 0.1061, time:13.3724, lr:0.001\u001b[0m\n",
            "2019-11-25 09:29:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2130/3125], step: 8380, 3.062 samples/sec, batch_loss: 0.3583, batch_loss_c: 0.3782, batch_loss_s: 0.3120, time:13.0635, lr:0.001\u001b[0m\n",
            "2019-11-25 09:29:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2140/3125], step: 8390, 3.000 samples/sec, batch_loss: 0.2003, batch_loss_c: 0.2366, batch_loss_s: 0.1157, time:13.3329, lr:0.001\u001b[0m\n",
            "2019-11-25 09:29:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2150/3125], step: 8400, 3.043 samples/sec, batch_loss: 0.3308, batch_loss_c: 0.3283, batch_loss_s: 0.3368, time:13.1433, lr:0.001\u001b[0m\n",
            "2019-11-25 09:29:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2160/3125], step: 8410, 3.016 samples/sec, batch_loss: 0.3024, batch_loss_c: 0.3000, batch_loss_s: 0.3080, time:13.2646, lr:0.001\u001b[0m\n",
            "2019-11-25 09:30:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2170/3125], step: 8420, 2.991 samples/sec, batch_loss: 0.1797, batch_loss_c: 0.2022, batch_loss_s: 0.1271, time:13.3723, lr:0.001\u001b[0m\n",
            "2019-11-25 09:30:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2180/3125], step: 8430, 3.022 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0965, batch_loss_s: 0.0845, time:13.2344, lr:0.001\u001b[0m\n",
            "2019-11-25 09:30:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2190/3125], step: 8440, 2.999 samples/sec, batch_loss: 0.4042, batch_loss_c: 0.4223, batch_loss_s: 0.3619, time:13.3395, lr:0.001\u001b[0m\n",
            "2019-11-25 09:30:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2200/3125], step: 8450, 2.988 samples/sec, batch_loss: 0.2948, batch_loss_c: 0.2849, batch_loss_s: 0.3179, time:13.3857, lr:0.001\u001b[0m\n",
            "2019-11-25 09:31:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2210/3125], step: 8460, 2.995 samples/sec, batch_loss: 0.3423, batch_loss_c: 0.3443, batch_loss_s: 0.3377, time:13.3534, lr:0.001\u001b[0m\n",
            "2019-11-25 09:31:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2220/3125], step: 8470, 2.995 samples/sec, batch_loss: 0.1668, batch_loss_c: 0.1692, batch_loss_s: 0.1614, time:13.3557, lr:0.001\u001b[0m\n",
            "2019-11-25 09:31:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2230/3125], step: 8480, 3.031 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3561, batch_loss_s: 0.3330, time:13.1957, lr:0.001\u001b[0m\n",
            "2019-11-25 09:31:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2240/3125], step: 8490, 2.986 samples/sec, batch_loss: 0.3896, batch_loss_c: 0.3982, batch_loss_s: 0.3698, time:13.3966, lr:0.001\u001b[0m\n",
            "2019-11-25 09:31:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2250/3125], step: 8500, 2.988 samples/sec, batch_loss: 0.1546, batch_loss_c: 0.1590, batch_loss_s: 0.1443, time:13.3866, lr:0.001\u001b[0m\n",
            "2019-11-25 09:32:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2260/3125], step: 8510, 3.005 samples/sec, batch_loss: 0.1416, batch_loss_c: 0.1656, batch_loss_s: 0.0856, time:13.3131, lr:0.001\u001b[0m\n",
            "2019-11-25 09:32:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2270/3125], step: 8520, 3.023 samples/sec, batch_loss: 0.0883, batch_loss_c: 0.0852, batch_loss_s: 0.0955, time:13.2298, lr:0.001\u001b[0m\n",
            "2019-11-25 09:32:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2280/3125], step: 8530, 2.979 samples/sec, batch_loss: 0.4703, batch_loss_c: 0.4804, batch_loss_s: 0.4467, time:13.4256, lr:0.001\u001b[0m\n",
            "2019-11-25 09:32:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2290/3125], step: 8540, 2.959 samples/sec, batch_loss: 0.4834, batch_loss_c: 0.5131, batch_loss_s: 0.4142, time:13.5203, lr:0.001\u001b[0m\n",
            "2019-11-25 09:33:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2300/3125], step: 8550, 2.989 samples/sec, batch_loss: 0.1325, batch_loss_c: 0.1498, batch_loss_s: 0.0923, time:13.3820, lr:0.001\u001b[0m\n",
            "2019-11-25 09:33:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2310/3125], step: 8560, 2.988 samples/sec, batch_loss: 0.2177, batch_loss_c: 0.2478, batch_loss_s: 0.1475, time:13.3891, lr:0.001\u001b[0m\n",
            "2019-11-25 09:33:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2320/3125], step: 8570, 3.019 samples/sec, batch_loss: 0.1025, batch_loss_c: 0.1120, batch_loss_s: 0.0804, time:13.2490, lr:0.001\u001b[0m\n",
            "2019-11-25 09:33:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2330/3125], step: 8580, 3.018 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1292, batch_loss_s: 0.0952, time:13.2519, lr:0.001\u001b[0m\n",
            "2019-11-25 09:33:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2340/3125], step: 8590, 2.977 samples/sec, batch_loss: 0.2758, batch_loss_c: 0.3281, batch_loss_s: 0.1536, time:13.4377, lr:0.001\u001b[0m\n",
            "2019-11-25 09:34:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2350/3125], step: 8600, 2.953 samples/sec, batch_loss: 0.3557, batch_loss_c: 0.3645, batch_loss_s: 0.3351, time:13.5459, lr:0.001\u001b[0m\n",
            "2019-11-25 09:34:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2360/3125], step: 8610, 3.011 samples/sec, batch_loss: 0.5686, batch_loss_c: 0.5753, batch_loss_s: 0.5529, time:13.2840, lr:0.001\u001b[0m\n",
            "2019-11-25 09:34:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2370/3125], step: 8620, 2.977 samples/sec, batch_loss: 0.1869, batch_loss_c: 0.2116, batch_loss_s: 0.1292, time:13.4373, lr:0.001\u001b[0m\n",
            "2019-11-25 09:34:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2380/3125], step: 8630, 2.948 samples/sec, batch_loss: 0.1956, batch_loss_c: 0.2051, batch_loss_s: 0.1735, time:13.5700, lr:0.001\u001b[0m\n",
            "2019-11-25 09:35:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2390/3125], step: 8640, 2.949 samples/sec, batch_loss: 0.1213, batch_loss_c: 0.1195, batch_loss_s: 0.1254, time:13.5647, lr:0.001\u001b[0m\n",
            "2019-11-25 09:35:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2400/3125], step: 8650, 2.978 samples/sec, batch_loss: 0.1700, batch_loss_c: 0.1797, batch_loss_s: 0.1474, time:13.4332, lr:0.001\u001b[0m\n",
            "2019-11-25 09:35:31 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2410/3125], step: 8660, 2.969 samples/sec, batch_loss: 0.3737, batch_loss_c: 0.3798, batch_loss_s: 0.3592, time:13.4730, lr:0.001\u001b[0m\n",
            "2019-11-25 09:35:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2420/3125], step: 8670, 2.973 samples/sec, batch_loss: 0.4098, batch_loss_c: 0.3882, batch_loss_s: 0.4602, time:13.4523, lr:0.001\u001b[0m\n",
            "2019-11-25 09:35:58 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2430/3125], step: 8680, 2.989 samples/sec, batch_loss: 0.0886, batch_loss_c: 0.0932, batch_loss_s: 0.0777, time:13.3831, lr:0.001\u001b[0m\n",
            "2019-11-25 09:36:11 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2440/3125], step: 8690, 3.004 samples/sec, batch_loss: 0.1472, batch_loss_c: 0.1526, batch_loss_s: 0.1346, time:13.3140, lr:0.001\u001b[0m\n",
            "2019-11-25 09:36:24 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2450/3125], step: 8700, 3.052 samples/sec, batch_loss: 0.1210, batch_loss_c: 0.1361, batch_loss_s: 0.0858, time:13.1043, lr:0.001\u001b[0m\n",
            "2019-11-25 09:36:37 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2460/3125], step: 8710, 3.019 samples/sec, batch_loss: 0.0869, batch_loss_c: 0.0847, batch_loss_s: 0.0921, time:13.2483, lr:0.001\u001b[0m\n",
            "2019-11-25 09:36:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2470/3125], step: 8720, 3.039 samples/sec, batch_loss: 0.4400, batch_loss_c: 0.4208, batch_loss_s: 0.4849, time:13.1624, lr:0.001\u001b[0m\n",
            "2019-11-25 09:37:04 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2480/3125], step: 8730, 2.975 samples/sec, batch_loss: 0.6597, batch_loss_c: 0.6754, batch_loss_s: 0.6231, time:13.4454, lr:0.001\u001b[0m\n",
            "2019-11-25 09:37:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2490/3125], step: 8740, 3.043 samples/sec, batch_loss: 0.4083, batch_loss_c: 0.4346, batch_loss_s: 0.3470, time:13.1429, lr:0.001\u001b[0m\n",
            "2019-11-25 09:37:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2500/3125], step: 8750, 3.038 samples/sec, batch_loss: 0.2784, batch_loss_c: 0.2656, batch_loss_s: 0.3082, time:13.1675, lr:0.001\u001b[0m\n",
            "2019-11-25 09:37:44 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2510/3125], step: 8760, 2.981 samples/sec, batch_loss: 0.1539, batch_loss_c: 0.1777, batch_loss_s: 0.0985, time:13.4204, lr:0.001\u001b[0m\n",
            "2019-11-25 09:37:57 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2520/3125], step: 8770, 3.084 samples/sec, batch_loss: 0.4106, batch_loss_c: 0.4291, batch_loss_s: 0.3677, time:12.9696, lr:0.001\u001b[0m\n",
            "2019-11-25 09:38:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2530/3125], step: 8780, 2.998 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.0998, batch_loss_s: 0.0978, time:13.3403, lr:0.001\u001b[0m\n",
            "2019-11-25 09:38:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2540/3125], step: 8790, 3.027 samples/sec, batch_loss: 0.4200, batch_loss_c: 0.4206, batch_loss_s: 0.4186, time:13.2144, lr:0.001\u001b[0m\n",
            "2019-11-25 09:38:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2550/3125], step: 8800, 3.008 samples/sec, batch_loss: 0.2030, batch_loss_c: 0.2412, batch_loss_s: 0.1138, time:13.2981, lr:0.001\u001b[0m\n",
            "2019-11-25 09:38:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2560/3125], step: 8810, 3.021 samples/sec, batch_loss: 0.4104, batch_loss_c: 0.4351, batch_loss_s: 0.3528, time:13.2397, lr:0.001\u001b[0m\n",
            "2019-11-25 09:39:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2570/3125], step: 8820, 3.050 samples/sec, batch_loss: 0.5433, batch_loss_c: 0.5326, batch_loss_s: 0.5683, time:13.1162, lr:0.001\u001b[0m\n",
            "2019-11-25 09:39:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2580/3125], step: 8830, 3.022 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1235, batch_loss_s: 0.0905, time:13.2354, lr:0.001\u001b[0m\n",
            "2019-11-25 09:39:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2590/3125], step: 8840, 3.009 samples/sec, batch_loss: 0.3235, batch_loss_c: 0.3336, batch_loss_s: 0.2999, time:13.2952, lr:0.001\u001b[0m\n",
            "2019-11-25 09:39:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2600/3125], step: 8850, 2.994 samples/sec, batch_loss: 0.3718, batch_loss_c: 0.3896, batch_loss_s: 0.3303, time:13.3605, lr:0.001\u001b[0m\n",
            "2019-11-25 09:39:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2610/3125], step: 8860, 3.031 samples/sec, batch_loss: 0.3171, batch_loss_c: 0.3198, batch_loss_s: 0.3108, time:13.1949, lr:0.001\u001b[0m\n",
            "2019-11-25 09:40:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2620/3125], step: 8870, 3.005 samples/sec, batch_loss: 0.5033, batch_loss_c: 0.4935, batch_loss_s: 0.5260, time:13.3095, lr:0.001\u001b[0m\n",
            "2019-11-25 09:40:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2630/3125], step: 8880, 2.973 samples/sec, batch_loss: 0.3388, batch_loss_c: 0.3482, batch_loss_s: 0.3169, time:13.4537, lr:0.001\u001b[0m\n",
            "2019-11-25 09:40:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2640/3125], step: 8890, 2.988 samples/sec, batch_loss: 0.2734, batch_loss_c: 0.2591, batch_loss_s: 0.3068, time:13.3857, lr:0.001\u001b[0m\n",
            "2019-11-25 09:40:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2650/3125], step: 8900, 3.000 samples/sec, batch_loss: 0.3239, batch_loss_c: 0.3192, batch_loss_s: 0.3350, time:13.3331, lr:0.001\u001b[0m\n",
            "2019-11-25 09:41:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2660/3125], step: 8910, 2.952 samples/sec, batch_loss: 0.4664, batch_loss_c: 0.4776, batch_loss_s: 0.4405, time:13.5493, lr:0.001\u001b[0m\n",
            "2019-11-25 09:41:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2670/3125], step: 8920, 2.979 samples/sec, batch_loss: 0.3469, batch_loss_c: 0.3618, batch_loss_s: 0.3121, time:13.4260, lr:0.001\u001b[0m\n",
            "2019-11-25 09:41:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2680/3125], step: 8930, 2.958 samples/sec, batch_loss: 0.1588, batch_loss_c: 0.1583, batch_loss_s: 0.1601, time:13.5242, lr:0.001\u001b[0m\n",
            "2019-11-25 09:41:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2690/3125], step: 8940, 3.044 samples/sec, batch_loss: 0.1601, batch_loss_c: 0.1903, batch_loss_s: 0.0894, time:13.1388, lr:0.001\u001b[0m\n",
            "2019-11-25 09:41:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2700/3125], step: 8950, 3.016 samples/sec, batch_loss: 0.2209, batch_loss_c: 0.2391, batch_loss_s: 0.1786, time:13.2610, lr:0.001\u001b[0m\n",
            "2019-11-25 09:42:10 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2710/3125], step: 8960, 3.009 samples/sec, batch_loss: 0.3985, batch_loss_c: 0.4024, batch_loss_s: 0.3896, time:13.2943, lr:0.001\u001b[0m\n",
            "2019-11-25 09:42:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2720/3125], step: 8970, 2.974 samples/sec, batch_loss: 0.3460, batch_loss_c: 0.3443, batch_loss_s: 0.3501, time:13.4504, lr:0.001\u001b[0m\n",
            "2019-11-25 09:42:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2730/3125], step: 8980, 2.982 samples/sec, batch_loss: 0.0827, batch_loss_c: 0.0865, batch_loss_s: 0.0740, time:13.4138, lr:0.001\u001b[0m\n",
            "2019-11-25 09:42:50 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2740/3125], step: 8990, 2.994 samples/sec, batch_loss: 0.3167, batch_loss_c: 0.3003, batch_loss_s: 0.3549, time:13.3611, lr:0.001\u001b[0m\n",
            "2019-11-25 09:43:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2750/3125], step: 9000, 2.979 samples/sec, batch_loss: 0.1926, batch_loss_c: 0.2291, batch_loss_s: 0.1072, time:13.4259, lr:0.001\u001b[0m\n",
            "2019-11-25 09:43:17 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2760/3125], step: 9010, 3.002 samples/sec, batch_loss: 0.2856, batch_loss_c: 0.2687, batch_loss_s: 0.3251, time:13.3244, lr:0.001\u001b[0m\n",
            "2019-11-25 09:43:30 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2770/3125], step: 9020, 3.046 samples/sec, batch_loss: 0.5824, batch_loss_c: 0.5953, batch_loss_s: 0.5523, time:13.1332, lr:0.001\u001b[0m\n",
            "2019-11-25 09:43:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2780/3125], step: 9030, 3.065 samples/sec, batch_loss: 0.3088, batch_loss_c: 0.3067, batch_loss_s: 0.3136, time:13.0522, lr:0.001\u001b[0m\n",
            "2019-11-25 09:43:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2790/3125], step: 9040, 2.990 samples/sec, batch_loss: 0.1927, batch_loss_c: 0.2212, batch_loss_s: 0.1262, time:13.3769, lr:0.001\u001b[0m\n",
            "2019-11-25 09:44:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2800/3125], step: 9050, 3.050 samples/sec, batch_loss: 0.2262, batch_loss_c: 0.2600, batch_loss_s: 0.1473, time:13.1132, lr:0.001\u001b[0m\n",
            "2019-11-25 09:44:23 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2810/3125], step: 9060, 3.008 samples/sec, batch_loss: 0.1147, batch_loss_c: 0.1196, batch_loss_s: 0.1033, time:13.3001, lr:0.001\u001b[0m\n",
            "2019-11-25 09:44:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2820/3125], step: 9070, 3.077 samples/sec, batch_loss: 0.2145, batch_loss_c: 0.2448, batch_loss_s: 0.1439, time:12.9993, lr:0.001\u001b[0m\n",
            "2019-11-25 09:44:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2830/3125], step: 9080, 2.983 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0884, batch_loss_s: 0.0847, time:13.4072, lr:0.001\u001b[0m\n",
            "2019-11-25 09:45:03 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2840/3125], step: 9090, 2.940 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1547, batch_loss_s: 0.1399, time:13.6051, lr:0.001\u001b[0m\n",
            "2019-11-25 09:45:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2850/3125], step: 9100, 3.003 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1179, batch_loss_s: 0.1027, time:13.3207, lr:0.001\u001b[0m\n",
            "2019-11-25 09:45:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2860/3125], step: 9110, 3.002 samples/sec, batch_loss: 0.3265, batch_loss_c: 0.3267, batch_loss_s: 0.3259, time:13.3223, lr:0.001\u001b[0m\n",
            "2019-11-25 09:45:43 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2870/3125], step: 9120, 2.990 samples/sec, batch_loss: 0.0711, batch_loss_c: 0.0673, batch_loss_s: 0.0799, time:13.3772, lr:0.001\u001b[0m\n",
            "2019-11-25 09:45:56 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2880/3125], step: 9130, 3.035 samples/sec, batch_loss: 0.2038, batch_loss_c: 0.2423, batch_loss_s: 0.1138, time:13.1813, lr:0.001\u001b[0m\n",
            "2019-11-25 09:46:09 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2890/3125], step: 9140, 3.016 samples/sec, batch_loss: 0.2068, batch_loss_c: 0.2359, batch_loss_s: 0.1390, time:13.2620, lr:0.001\u001b[0m\n",
            "2019-11-25 09:46:22 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2900/3125], step: 9150, 2.997 samples/sec, batch_loss: 0.2516, batch_loss_c: 0.2539, batch_loss_s: 0.2461, time:13.3464, lr:0.001\u001b[0m\n",
            "2019-11-25 09:46:36 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2910/3125], step: 9160, 3.019 samples/sec, batch_loss: 0.2374, batch_loss_c: 0.2844, batch_loss_s: 0.1275, time:13.2499, lr:0.001\u001b[0m\n",
            "2019-11-25 09:46:49 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2920/3125], step: 9170, 2.980 samples/sec, batch_loss: 0.4386, batch_loss_c: 0.4467, batch_loss_s: 0.4196, time:13.4216, lr:0.001\u001b[0m\n",
            "2019-11-25 09:47:02 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2930/3125], step: 9180, 3.018 samples/sec, batch_loss: 0.2521, batch_loss_c: 0.2696, batch_loss_s: 0.2111, time:13.2560, lr:0.001\u001b[0m\n",
            "2019-11-25 09:47:16 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2940/3125], step: 9190, 3.010 samples/sec, batch_loss: 0.3639, batch_loss_c: 0.3801, batch_loss_s: 0.3260, time:13.2873, lr:0.001\u001b[0m\n",
            "2019-11-25 09:47:29 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2950/3125], step: 9200, 3.054 samples/sec, batch_loss: 0.1706, batch_loss_c: 0.1985, batch_loss_s: 0.1055, time:13.0983, lr:0.001\u001b[0m\n",
            "2019-11-25 09:47:42 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2960/3125], step: 9210, 3.073 samples/sec, batch_loss: 0.1567, batch_loss_c: 0.1741, batch_loss_s: 0.1162, time:13.0169, lr:0.001\u001b[0m\n",
            "2019-11-25 09:47:55 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2970/3125], step: 9220, 3.049 samples/sec, batch_loss: 0.1857, batch_loss_c: 0.1927, batch_loss_s: 0.1694, time:13.1172, lr:0.001\u001b[0m\n",
            "2019-11-25 09:48:08 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2980/3125], step: 9230, 3.007 samples/sec, batch_loss: 0.1115, batch_loss_c: 0.1044, batch_loss_s: 0.1280, time:13.3016, lr:0.001\u001b[0m\n",
            "2019-11-25 09:48:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [2990/3125], step: 9240, 3.013 samples/sec, batch_loss: 0.3455, batch_loss_c: 0.3549, batch_loss_s: 0.3236, time:13.2747, lr:0.001\u001b[0m\n",
            "2019-11-25 09:48:35 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3000/3125], step: 9250, 3.014 samples/sec, batch_loss: 0.5106, batch_loss_c: 0.5004, batch_loss_s: 0.5342, time:13.2729, lr:0.001\u001b[0m\n",
            "2019-11-25 09:48:48 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3010/3125], step: 9260, 3.023 samples/sec, batch_loss: 0.2069, batch_loss_c: 0.2103, batch_loss_s: 0.1988, time:13.2336, lr:0.001\u001b[0m\n",
            "2019-11-25 09:49:01 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3020/3125], step: 9270, 2.984 samples/sec, batch_loss: 0.0860, batch_loss_c: 0.0862, batch_loss_s: 0.0855, time:13.4056, lr:0.001\u001b[0m\n",
            "2019-11-25 09:49:14 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3030/3125], step: 9280, 3.051 samples/sec, batch_loss: 0.1775, batch_loss_c: 0.1795, batch_loss_s: 0.1727, time:13.1107, lr:0.001\u001b[0m\n",
            "2019-11-25 09:49:28 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3040/3125], step: 9290, 2.994 samples/sec, batch_loss: 0.1133, batch_loss_c: 0.1183, batch_loss_s: 0.1015, time:13.3594, lr:0.001\u001b[0m\n",
            "2019-11-25 09:49:41 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3050/3125], step: 9300, 3.017 samples/sec, batch_loss: 0.1151, batch_loss_c: 0.1298, batch_loss_s: 0.0809, time:13.2587, lr:0.001\u001b[0m\n",
            "2019-11-25 09:49:54 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3060/3125], step: 9310, 3.076 samples/sec, batch_loss: 0.1418, batch_loss_c: 0.1555, batch_loss_s: 0.1097, time:13.0018, lr:0.001\u001b[0m\n",
            "2019-11-25 09:50:07 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3070/3125], step: 9320, 2.995 samples/sec, batch_loss: 0.1814, batch_loss_c: 0.2171, batch_loss_s: 0.0980, time:13.3559, lr:0.001\u001b[0m\n",
            "2019-11-25 09:50:21 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3080/3125], step: 9330, 3.023 samples/sec, batch_loss: 0.3335, batch_loss_c: 0.3288, batch_loss_s: 0.3446, time:13.2307, lr:0.001\u001b[0m\n",
            "2019-11-25 09:50:34 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3090/3125], step: 9340, 3.025 samples/sec, batch_loss: 0.4706, batch_loss_c: 0.4751, batch_loss_s: 0.4603, time:13.2219, lr:0.001\u001b[0m\n",
            "2019-11-25 09:50:47 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3100/3125], step: 9350, 2.992 samples/sec, batch_loss: 0.1382, batch_loss_c: 0.1590, batch_loss_s: 0.0897, time:13.3695, lr:0.001\u001b[0m\n",
            "2019-11-25 09:51:00 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3110/3125], step: 9360, 3.076 samples/sec, batch_loss: 0.3949, batch_loss_c: 0.4099, batch_loss_s: 0.3599, time:13.0053, lr:0.001\u001b[0m\n",
            "2019-11-25 09:51:13 \u001b[32mINFO     \u001b[0m train.py: [2/10], [3120/3125], step: 9370, 3.078 samples/sec, batch_loss: 0.2168, batch_loss_c: 0.2246, batch_loss_s: 0.1988, time:12.9938, lr:0.001\u001b[0m\n",
            "2019-11-25 09:51:19 \u001b[32mINFO     \u001b[0m train.py: [2/10], train_loss: 0.2450, time: 4159.9792, lr: 0.001\u001b[0m\n",
            "2019-11-25 09:51:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [0/3125], step: 9375, 4.210 samples/sec, batch_loss: 0.1326, batch_loss_c: 0.1470, batch_loss_s: 0.0988, time:9.5001, lr:0.001\u001b[0m\n",
            "2019-11-25 09:51:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [10/3125], step: 9385, 2.939 samples/sec, batch_loss: 0.4862, batch_loss_c: 0.4610, batch_loss_s: 0.5449, time:13.6094, lr:0.001\u001b[0m\n",
            "2019-11-25 09:51:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [20/3125], step: 9395, 3.024 samples/sec, batch_loss: 0.1602, batch_loss_c: 0.1864, batch_loss_s: 0.0991, time:13.2263, lr:0.001\u001b[0m\n",
            "2019-11-25 09:52:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [30/3125], step: 9405, 3.009 samples/sec, batch_loss: 0.1610, batch_loss_c: 0.1815, batch_loss_s: 0.1132, time:13.2953, lr:0.001\u001b[0m\n",
            "2019-11-25 09:52:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [40/3125], step: 9415, 3.005 samples/sec, batch_loss: 0.2217, batch_loss_c: 0.2166, batch_loss_s: 0.2334, time:13.3108, lr:0.001\u001b[0m\n",
            "2019-11-25 09:52:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [50/3125], step: 9425, 2.994 samples/sec, batch_loss: 0.2808, batch_loss_c: 0.2604, batch_loss_s: 0.3284, time:13.3616, lr:0.001\u001b[0m\n",
            "2019-11-25 09:52:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [60/3125], step: 9435, 2.974 samples/sec, batch_loss: 0.4905, batch_loss_c: 0.5065, batch_loss_s: 0.4533, time:13.4518, lr:0.001\u001b[0m\n",
            "2019-11-25 09:53:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [70/3125], step: 9445, 2.996 samples/sec, batch_loss: 0.2863, batch_loss_c: 0.2756, batch_loss_s: 0.3113, time:13.3498, lr:0.001\u001b[0m\n",
            "2019-11-25 09:53:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [80/3125], step: 9455, 3.012 samples/sec, batch_loss: 0.2786, batch_loss_c: 0.2657, batch_loss_s: 0.3085, time:13.2792, lr:0.001\u001b[0m\n",
            "2019-11-25 09:53:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [90/3125], step: 9465, 2.992 samples/sec, batch_loss: 0.1008, batch_loss_c: 0.0987, batch_loss_s: 0.1058, time:13.3669, lr:0.001\u001b[0m\n",
            "2019-11-25 09:53:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [100/3125], step: 9475, 3.018 samples/sec, batch_loss: 0.2363, batch_loss_c: 0.2234, batch_loss_s: 0.2664, time:13.2536, lr:0.001\u001b[0m\n",
            "2019-11-25 09:53:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [110/3125], step: 9485, 3.016 samples/sec, batch_loss: 0.1070, batch_loss_c: 0.1130, batch_loss_s: 0.0930, time:13.2638, lr:0.001\u001b[0m\n",
            "2019-11-25 09:54:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [120/3125], step: 9495, 3.025 samples/sec, batch_loss: 0.0873, batch_loss_c: 0.0907, batch_loss_s: 0.0792, time:13.2233, lr:0.001\u001b[0m\n",
            "2019-11-25 09:54:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [130/3125], step: 9505, 3.038 samples/sec, batch_loss: 0.3451, batch_loss_c: 0.3469, batch_loss_s: 0.3408, time:13.1664, lr:0.001\u001b[0m\n",
            "2019-11-25 09:54:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [140/3125], step: 9515, 3.016 samples/sec, batch_loss: 0.2331, batch_loss_c: 0.2600, batch_loss_s: 0.1704, time:13.2631, lr:0.001\u001b[0m\n",
            "2019-11-25 09:54:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [150/3125], step: 9525, 3.016 samples/sec, batch_loss: 0.1283, batch_loss_c: 0.1268, batch_loss_s: 0.1318, time:13.2623, lr:0.001\u001b[0m\n",
            "2019-11-25 09:55:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [160/3125], step: 9535, 2.965 samples/sec, batch_loss: 0.3478, batch_loss_c: 0.3781, batch_loss_s: 0.2769, time:13.4922, lr:0.001\u001b[0m\n",
            "2019-11-25 09:55:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [170/3125], step: 9545, 3.039 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0881, batch_loss_s: 0.0978, time:13.1611, lr:0.001\u001b[0m\n",
            "2019-11-25 09:55:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [180/3125], step: 9555, 3.001 samples/sec, batch_loss: 0.1520, batch_loss_c: 0.1613, batch_loss_s: 0.1302, time:13.3294, lr:0.001\u001b[0m\n",
            "2019-11-25 09:55:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [190/3125], step: 9565, 3.070 samples/sec, batch_loss: 0.0835, batch_loss_c: 0.0798, batch_loss_s: 0.0920, time:13.0287, lr:0.001\u001b[0m\n",
            "2019-11-25 09:55:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [200/3125], step: 9575, 3.008 samples/sec, batch_loss: 0.1016, batch_loss_c: 0.1004, batch_loss_s: 0.1044, time:13.2973, lr:0.001\u001b[0m\n",
            "2019-11-25 09:56:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [210/3125], step: 9585, 3.018 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1132, batch_loss_s: 0.1349, time:13.2547, lr:0.001\u001b[0m\n",
            "2019-11-25 09:56:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [220/3125], step: 9595, 3.009 samples/sec, batch_loss: 0.1161, batch_loss_c: 0.1169, batch_loss_s: 0.1145, time:13.2933, lr:0.001\u001b[0m\n",
            "2019-11-25 09:56:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [230/3125], step: 9605, 3.055 samples/sec, batch_loss: 0.1600, batch_loss_c: 0.1699, batch_loss_s: 0.1371, time:13.0918, lr:0.001\u001b[0m\n",
            "2019-11-25 09:56:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [240/3125], step: 9615, 3.047 samples/sec, batch_loss: 0.1035, batch_loss_c: 0.1069, batch_loss_s: 0.0955, time:13.1272, lr:0.001\u001b[0m\n",
            "2019-11-25 09:57:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [250/3125], step: 9625, 2.987 samples/sec, batch_loss: 0.1905, batch_loss_c: 0.1850, batch_loss_s: 0.2032, time:13.3898, lr:0.001\u001b[0m\n",
            "2019-11-25 09:57:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [260/3125], step: 9635, 3.016 samples/sec, batch_loss: 0.1650, batch_loss_c: 0.1666, batch_loss_s: 0.1613, time:13.2640, lr:0.001\u001b[0m\n",
            "2019-11-25 09:57:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [270/3125], step: 9645, 3.040 samples/sec, batch_loss: 0.3225, batch_loss_c: 0.3016, batch_loss_s: 0.3715, time:13.1580, lr:0.001\u001b[0m\n",
            "2019-11-25 09:57:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [280/3125], step: 9655, 3.041 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.1001, batch_loss_s: 0.0962, time:13.1552, lr:0.001\u001b[0m\n",
            "2019-11-25 09:57:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [290/3125], step: 9665, 3.018 samples/sec, batch_loss: 0.3524, batch_loss_c: 0.3556, batch_loss_s: 0.3448, time:13.2558, lr:0.001\u001b[0m\n",
            "2019-11-25 09:58:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [300/3125], step: 9675, 3.019 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1033, batch_loss_s: 0.0999, time:13.2478, lr:0.001\u001b[0m\n",
            "2019-11-25 09:58:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [310/3125], step: 9685, 2.975 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1263, batch_loss_s: 0.1217, time:13.4447, lr:0.001\u001b[0m\n",
            "2019-11-25 09:58:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [320/3125], step: 9695, 2.988 samples/sec, batch_loss: 0.1141, batch_loss_c: 0.1086, batch_loss_s: 0.1268, time:13.3880, lr:0.001\u001b[0m\n",
            "2019-11-25 09:58:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [330/3125], step: 9705, 3.017 samples/sec, batch_loss: 0.4230, batch_loss_c: 0.4159, batch_loss_s: 0.4395, time:13.2599, lr:0.001\u001b[0m\n",
            "2019-11-25 09:59:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [340/3125], step: 9715, 3.015 samples/sec, batch_loss: 0.1526, batch_loss_c: 0.1714, batch_loss_s: 0.1088, time:13.2689, lr:0.001\u001b[0m\n",
            "2019-11-25 09:59:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [350/3125], step: 9725, 3.041 samples/sec, batch_loss: 0.7416, batch_loss_c: 0.7248, batch_loss_s: 0.7808, time:13.1551, lr:0.001\u001b[0m\n",
            "2019-11-25 09:59:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [360/3125], step: 9735, 3.057 samples/sec, batch_loss: 0.3580, batch_loss_c: 0.3692, batch_loss_s: 0.3319, time:13.0858, lr:0.001\u001b[0m\n",
            "2019-11-25 09:59:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [370/3125], step: 9745, 3.024 samples/sec, batch_loss: 0.5375, batch_loss_c: 0.5412, batch_loss_s: 0.5290, time:13.2272, lr:0.001\u001b[0m\n",
            "2019-11-25 09:59:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [380/3125], step: 9755, 3.011 samples/sec, batch_loss: 0.1225, batch_loss_c: 0.1382, batch_loss_s: 0.0861, time:13.2858, lr:0.001\u001b[0m\n",
            "2019-11-25 10:00:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [390/3125], step: 9765, 3.032 samples/sec, batch_loss: 0.3398, batch_loss_c: 0.3414, batch_loss_s: 0.3360, time:13.1919, lr:0.001\u001b[0m\n",
            "2019-11-25 10:00:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [400/3125], step: 9775, 2.978 samples/sec, batch_loss: 0.1949, batch_loss_c: 0.2326, batch_loss_s: 0.1069, time:13.4298, lr:0.001\u001b[0m\n",
            "2019-11-25 10:00:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [410/3125], step: 9785, 2.984 samples/sec, batch_loss: 0.2993, batch_loss_c: 0.3486, batch_loss_s: 0.1844, time:13.4067, lr:0.001\u001b[0m\n",
            "2019-11-25 10:00:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [420/3125], step: 9795, 3.063 samples/sec, batch_loss: 0.1419, batch_loss_c: 0.1507, batch_loss_s: 0.1215, time:13.0572, lr:0.001\u001b[0m\n",
            "2019-11-25 10:00:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [430/3125], step: 9805, 3.020 samples/sec, batch_loss: 0.3821, batch_loss_c: 0.3892, batch_loss_s: 0.3655, time:13.2462, lr:0.001\u001b[0m\n",
            "2019-11-25 10:01:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [440/3125], step: 9815, 3.005 samples/sec, batch_loss: 0.1224, batch_loss_c: 0.1287, batch_loss_s: 0.1076, time:13.3113, lr:0.001\u001b[0m\n",
            "2019-11-25 10:01:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [450/3125], step: 9825, 3.037 samples/sec, batch_loss: 0.3216, batch_loss_c: 0.3176, batch_loss_s: 0.3309, time:13.1706, lr:0.001\u001b[0m\n",
            "2019-11-25 10:01:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [460/3125], step: 9835, 2.986 samples/sec, batch_loss: 0.2055, batch_loss_c: 0.2122, batch_loss_s: 0.1897, time:13.3976, lr:0.001\u001b[0m\n",
            "2019-11-25 10:01:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [470/3125], step: 9845, 2.956 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1131, batch_loss_s: 0.0947, time:13.5329, lr:0.001\u001b[0m\n",
            "2019-11-25 10:02:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [480/3125], step: 9855, 3.035 samples/sec, batch_loss: 0.1629, batch_loss_c: 0.1850, batch_loss_s: 0.1116, time:13.1815, lr:0.001\u001b[0m\n",
            "2019-11-25 10:02:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [490/3125], step: 9865, 3.026 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3133, batch_loss_s: 0.3420, time:13.2199, lr:0.001\u001b[0m\n",
            "2019-11-25 10:02:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [500/3125], step: 9875, 2.937 samples/sec, batch_loss: 0.3583, batch_loss_c: 0.3793, batch_loss_s: 0.3093, time:13.6196, lr:0.001\u001b[0m\n",
            "2019-11-25 10:02:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [510/3125], step: 9885, 3.033 samples/sec, batch_loss: 0.5928, batch_loss_c: 0.5866, batch_loss_s: 0.6074, time:13.1866, lr:0.001\u001b[0m\n",
            "2019-11-25 10:02:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [520/3125], step: 9895, 2.962 samples/sec, batch_loss: 0.3150, batch_loss_c: 0.2992, batch_loss_s: 0.3519, time:13.5049, lr:0.001\u001b[0m\n",
            "2019-11-25 10:03:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [530/3125], step: 9905, 3.039 samples/sec, batch_loss: 0.0992, batch_loss_c: 0.1009, batch_loss_s: 0.0954, time:13.1633, lr:0.001\u001b[0m\n",
            "2019-11-25 10:03:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [540/3125], step: 9915, 3.048 samples/sec, batch_loss: 0.0825, batch_loss_c: 0.0829, batch_loss_s: 0.0816, time:13.1252, lr:0.001\u001b[0m\n",
            "2019-11-25 10:03:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [550/3125], step: 9925, 3.019 samples/sec, batch_loss: 0.1769, batch_loss_c: 0.2036, batch_loss_s: 0.1145, time:13.2513, lr:0.001\u001b[0m\n",
            "2019-11-25 10:03:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [560/3125], step: 9935, 3.053 samples/sec, batch_loss: 0.1220, batch_loss_c: 0.1279, batch_loss_s: 0.1083, time:13.1026, lr:0.001\u001b[0m\n",
            "2019-11-25 10:04:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [570/3125], step: 9945, 3.052 samples/sec, batch_loss: 0.5483, batch_loss_c: 0.5457, batch_loss_s: 0.5544, time:13.1042, lr:0.001\u001b[0m\n",
            "2019-11-25 10:04:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [580/3125], step: 9955, 2.960 samples/sec, batch_loss: 0.2049, batch_loss_c: 0.2595, batch_loss_s: 0.0774, time:13.5143, lr:0.001\u001b[0m\n",
            "2019-11-25 10:04:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [590/3125], step: 9965, 3.010 samples/sec, batch_loss: 0.2680, batch_loss_c: 0.2392, batch_loss_s: 0.3350, time:13.2886, lr:0.001\u001b[0m\n",
            "2019-11-25 10:04:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [600/3125], step: 9975, 3.101 samples/sec, batch_loss: 0.1517, batch_loss_c: 0.1524, batch_loss_s: 0.1500, time:12.9002, lr:0.001\u001b[0m\n",
            "2019-11-25 10:04:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [610/3125], step: 9985, 3.039 samples/sec, batch_loss: 0.1535, batch_loss_c: 0.1588, batch_loss_s: 0.1411, time:13.1639, lr:0.001\u001b[0m\n",
            "2019-11-25 10:05:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [620/3125], step: 9995, 2.974 samples/sec, batch_loss: 0.0966, batch_loss_c: 0.0965, batch_loss_s: 0.0968, time:13.4517, lr:0.001\u001b[0m\n",
            "2019-11-25 10:05:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [630/3125], step: 10005, 3.011 samples/sec, batch_loss: 0.3186, batch_loss_c: 0.3135, batch_loss_s: 0.3304, time:13.2864, lr:0.001\u001b[0m\n",
            "2019-11-25 10:05:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [640/3125], step: 10015, 3.031 samples/sec, batch_loss: 0.3852, batch_loss_c: 0.3955, batch_loss_s: 0.3610, time:13.1977, lr:0.001\u001b[0m\n",
            "2019-11-25 10:05:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [650/3125], step: 10025, 3.011 samples/sec, batch_loss: 0.2099, batch_loss_c: 0.2533, batch_loss_s: 0.1086, time:13.2838, lr:0.001\u001b[0m\n",
            "2019-11-25 10:06:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [660/3125], step: 10035, 3.049 samples/sec, batch_loss: 0.1206, batch_loss_c: 0.1382, batch_loss_s: 0.0798, time:13.1179, lr:0.001\u001b[0m\n",
            "2019-11-25 10:06:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [670/3125], step: 10045, 3.076 samples/sec, batch_loss: 0.0931, batch_loss_c: 0.0893, batch_loss_s: 0.1020, time:13.0045, lr:0.001\u001b[0m\n",
            "2019-11-25 10:06:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [680/3125], step: 10055, 3.040 samples/sec, batch_loss: 0.1432, batch_loss_c: 0.1549, batch_loss_s: 0.1160, time:13.1568, lr:0.001\u001b[0m\n",
            "2019-11-25 10:06:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [690/3125], step: 10065, 3.014 samples/sec, batch_loss: 0.2645, batch_loss_c: 0.2530, batch_loss_s: 0.2912, time:13.2717, lr:0.001\u001b[0m\n",
            "2019-11-25 10:06:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [700/3125], step: 10075, 3.014 samples/sec, batch_loss: 0.0703, batch_loss_c: 0.0697, batch_loss_s: 0.0715, time:13.2720, lr:0.001\u001b[0m\n",
            "2019-11-25 10:07:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [710/3125], step: 10085, 3.013 samples/sec, batch_loss: 0.3698, batch_loss_c: 0.3825, batch_loss_s: 0.3401, time:13.2757, lr:0.001\u001b[0m\n",
            "2019-11-25 10:07:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [720/3125], step: 10095, 2.962 samples/sec, batch_loss: 0.1154, batch_loss_c: 0.1184, batch_loss_s: 0.1085, time:13.5055, lr:0.001\u001b[0m\n",
            "2019-11-25 10:07:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [730/3125], step: 10105, 3.032 samples/sec, batch_loss: 0.3278, batch_loss_c: 0.3313, batch_loss_s: 0.3199, time:13.1915, lr:0.001\u001b[0m\n",
            "2019-11-25 10:07:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [740/3125], step: 10115, 3.028 samples/sec, batch_loss: 0.1519, batch_loss_c: 0.1551, batch_loss_s: 0.1443, time:13.2105, lr:0.001\u001b[0m\n",
            "2019-11-25 10:08:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [750/3125], step: 10125, 3.063 samples/sec, batch_loss: 0.1497, batch_loss_c: 0.1763, batch_loss_s: 0.0878, time:13.0610, lr:0.001\u001b[0m\n",
            "2019-11-25 10:08:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [760/3125], step: 10135, 3.029 samples/sec, batch_loss: 0.1396, batch_loss_c: 0.1520, batch_loss_s: 0.1109, time:13.2064, lr:0.001\u001b[0m\n",
            "2019-11-25 10:08:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [770/3125], step: 10145, 3.026 samples/sec, batch_loss: 0.3499, batch_loss_c: 0.3656, batch_loss_s: 0.3133, time:13.2175, lr:0.001\u001b[0m\n",
            "2019-11-25 10:08:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [780/3125], step: 10155, 2.996 samples/sec, batch_loss: 0.2113, batch_loss_c: 0.2195, batch_loss_s: 0.1922, time:13.3524, lr:0.001\u001b[0m\n",
            "2019-11-25 10:08:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [790/3125], step: 10165, 2.983 samples/sec, batch_loss: 0.1181, batch_loss_c: 0.1158, batch_loss_s: 0.1236, time:13.4087, lr:0.001\u001b[0m\n",
            "2019-11-25 10:09:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [800/3125], step: 10175, 2.981 samples/sec, batch_loss: 0.2948, batch_loss_c: 0.2903, batch_loss_s: 0.3052, time:13.4195, lr:0.001\u001b[0m\n",
            "2019-11-25 10:09:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [810/3125], step: 10185, 2.948 samples/sec, batch_loss: 0.3145, batch_loss_c: 0.3438, batch_loss_s: 0.2462, time:13.5672, lr:0.001\u001b[0m\n",
            "2019-11-25 10:09:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [820/3125], step: 10195, 3.023 samples/sec, batch_loss: 0.0989, batch_loss_c: 0.1058, batch_loss_s: 0.0829, time:13.2320, lr:0.001\u001b[0m\n",
            "2019-11-25 10:09:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [830/3125], step: 10205, 3.067 samples/sec, batch_loss: 0.1310, batch_loss_c: 0.1352, batch_loss_s: 0.1211, time:13.0433, lr:0.001\u001b[0m\n",
            "2019-11-25 10:10:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [840/3125], step: 10215, 3.046 samples/sec, batch_loss: 0.5451, batch_loss_c: 0.5480, batch_loss_s: 0.5385, time:13.1313, lr:0.001\u001b[0m\n",
            "2019-11-25 10:10:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [850/3125], step: 10225, 3.046 samples/sec, batch_loss: 0.3830, batch_loss_c: 0.4013, batch_loss_s: 0.3403, time:13.1324, lr:0.001\u001b[0m\n",
            "2019-11-25 10:10:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [860/3125], step: 10235, 2.975 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.0992, batch_loss_s: 0.1092, time:13.4450, lr:0.001\u001b[0m\n",
            "2019-11-25 10:10:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [870/3125], step: 10245, 3.023 samples/sec, batch_loss: 0.5755, batch_loss_c: 0.5704, batch_loss_s: 0.5875, time:13.2336, lr:0.001\u001b[0m\n",
            "2019-11-25 10:10:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [880/3125], step: 10255, 2.947 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1697, batch_loss_s: 0.1045, time:13.5728, lr:0.001\u001b[0m\n",
            "2019-11-25 10:11:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [890/3125], step: 10265, 2.976 samples/sec, batch_loss: 0.4765, batch_loss_c: 0.4525, batch_loss_s: 0.5326, time:13.4423, lr:0.001\u001b[0m\n",
            "2019-11-25 10:11:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [900/3125], step: 10275, 3.011 samples/sec, batch_loss: 0.2439, batch_loss_c: 0.2861, batch_loss_s: 0.1456, time:13.2858, lr:0.001\u001b[0m\n",
            "2019-11-25 10:11:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [910/3125], step: 10285, 3.034 samples/sec, batch_loss: 0.1424, batch_loss_c: 0.1410, batch_loss_s: 0.1457, time:13.1855, lr:0.001\u001b[0m\n",
            "2019-11-25 10:11:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [920/3125], step: 10295, 3.028 samples/sec, batch_loss: 0.2778, batch_loss_c: 0.2682, batch_loss_s: 0.3002, time:13.2108, lr:0.001\u001b[0m\n",
            "2019-11-25 10:12:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [930/3125], step: 10305, 2.948 samples/sec, batch_loss: 0.1753, batch_loss_c: 0.2109, batch_loss_s: 0.0924, time:13.5662, lr:0.001\u001b[0m\n",
            "2019-11-25 10:12:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [940/3125], step: 10315, 2.970 samples/sec, batch_loss: 0.1919, batch_loss_c: 0.2079, batch_loss_s: 0.1545, time:13.4661, lr:0.001\u001b[0m\n",
            "2019-11-25 10:12:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [950/3125], step: 10325, 3.050 samples/sec, batch_loss: 0.2864, batch_loss_c: 0.2676, batch_loss_s: 0.3302, time:13.1133, lr:0.001\u001b[0m\n",
            "2019-11-25 10:12:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [960/3125], step: 10335, 2.958 samples/sec, batch_loss: 0.1282, batch_loss_c: 0.1476, batch_loss_s: 0.0830, time:13.5207, lr:0.001\u001b[0m\n",
            "2019-11-25 10:12:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [970/3125], step: 10345, 2.988 samples/sec, batch_loss: 0.2119, batch_loss_c: 0.2109, batch_loss_s: 0.2144, time:13.3854, lr:0.001\u001b[0m\n",
            "2019-11-25 10:13:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [980/3125], step: 10355, 3.025 samples/sec, batch_loss: 0.3533, batch_loss_c: 0.3603, batch_loss_s: 0.3369, time:13.2237, lr:0.001\u001b[0m\n",
            "2019-11-25 10:13:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [990/3125], step: 10365, 3.042 samples/sec, batch_loss: 0.0998, batch_loss_c: 0.1095, batch_loss_s: 0.0770, time:13.1488, lr:0.001\u001b[0m\n",
            "2019-11-25 10:13:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1000/3125], step: 10375, 2.997 samples/sec, batch_loss: 0.3366, batch_loss_c: 0.3296, batch_loss_s: 0.3529, time:13.3467, lr:0.001\u001b[0m\n",
            "2019-11-25 10:13:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1010/3125], step: 10385, 2.973 samples/sec, batch_loss: 0.1012, batch_loss_c: 0.1063, batch_loss_s: 0.0895, time:13.4566, lr:0.001\u001b[0m\n",
            "2019-11-25 10:14:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1020/3125], step: 10395, 2.989 samples/sec, batch_loss: 0.4161, batch_loss_c: 0.4126, batch_loss_s: 0.4244, time:13.3814, lr:0.001\u001b[0m\n",
            "2019-11-25 10:14:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1030/3125], step: 10405, 2.978 samples/sec, batch_loss: 0.0805, batch_loss_c: 0.0791, batch_loss_s: 0.0837, time:13.4338, lr:0.001\u001b[0m\n",
            "2019-11-25 10:14:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1040/3125], step: 10415, 3.039 samples/sec, batch_loss: 0.3127, batch_loss_c: 0.3166, batch_loss_s: 0.3036, time:13.1609, lr:0.001\u001b[0m\n",
            "2019-11-25 10:14:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1050/3125], step: 10425, 2.979 samples/sec, batch_loss: 0.2546, batch_loss_c: 0.2833, batch_loss_s: 0.1876, time:13.4292, lr:0.001\u001b[0m\n",
            "2019-11-25 10:14:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1060/3125], step: 10435, 2.919 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1244, batch_loss_s: 0.1151, time:13.7053, lr:0.001\u001b[0m\n",
            "2019-11-25 10:15:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1070/3125], step: 10445, 3.009 samples/sec, batch_loss: 0.1794, batch_loss_c: 0.1918, batch_loss_s: 0.1506, time:13.2947, lr:0.001\u001b[0m\n",
            "2019-11-25 10:15:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1080/3125], step: 10455, 2.972 samples/sec, batch_loss: 0.4042, batch_loss_c: 0.4281, batch_loss_s: 0.3486, time:13.4595, lr:0.001\u001b[0m\n",
            "2019-11-25 10:15:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1090/3125], step: 10465, 2.987 samples/sec, batch_loss: 0.1881, batch_loss_c: 0.2050, batch_loss_s: 0.1485, time:13.3933, lr:0.001\u001b[0m\n",
            "2019-11-25 10:15:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1100/3125], step: 10475, 2.990 samples/sec, batch_loss: 0.2204, batch_loss_c: 0.2205, batch_loss_s: 0.2202, time:13.3759, lr:0.001\u001b[0m\n",
            "2019-11-25 10:16:04 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1110/3125], step: 10485, 2.938 samples/sec, batch_loss: 0.0870, batch_loss_c: 0.0896, batch_loss_s: 0.0809, time:13.6127, lr:0.001\u001b[0m\n",
            "2019-11-25 10:16:17 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1120/3125], step: 10495, 3.040 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2663, batch_loss_s: 0.3535, time:13.1592, lr:0.001\u001b[0m\n",
            "2019-11-25 10:16:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1130/3125], step: 10505, 3.030 samples/sec, batch_loss: 0.3514, batch_loss_c: 0.3494, batch_loss_s: 0.3561, time:13.2022, lr:0.001\u001b[0m\n",
            "2019-11-25 10:16:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1140/3125], step: 10515, 2.962 samples/sec, batch_loss: 0.2528, batch_loss_c: 0.2787, batch_loss_s: 0.1925, time:13.5053, lr:0.001\u001b[0m\n",
            "2019-11-25 10:16:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1150/3125], step: 10525, 3.009 samples/sec, batch_loss: 0.1259, batch_loss_c: 0.1241, batch_loss_s: 0.1299, time:13.2923, lr:0.001\u001b[0m\n",
            "2019-11-25 10:17:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1160/3125], step: 10535, 3.014 samples/sec, batch_loss: 0.1499, batch_loss_c: 0.1575, batch_loss_s: 0.1323, time:13.2718, lr:0.001\u001b[0m\n",
            "2019-11-25 10:17:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1170/3125], step: 10545, 2.993 samples/sec, batch_loss: 0.1835, batch_loss_c: 0.2194, batch_loss_s: 0.0998, time:13.3625, lr:0.001\u001b[0m\n",
            "2019-11-25 10:17:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1180/3125], step: 10555, 3.064 samples/sec, batch_loss: 0.1131, batch_loss_c: 0.1194, batch_loss_s: 0.0984, time:13.0542, lr:0.001\u001b[0m\n",
            "2019-11-25 10:17:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1190/3125], step: 10565, 3.001 samples/sec, batch_loss: 0.3359, batch_loss_c: 0.3437, batch_loss_s: 0.3175, time:13.3311, lr:0.001\u001b[0m\n",
            "2019-11-25 10:18:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1200/3125], step: 10575, 2.996 samples/sec, batch_loss: 0.2276, batch_loss_c: 0.2526, batch_loss_s: 0.1694, time:13.3504, lr:0.001\u001b[0m\n",
            "2019-11-25 10:18:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1210/3125], step: 10585, 3.045 samples/sec, batch_loss: 0.2041, batch_loss_c: 0.2441, batch_loss_s: 0.1109, time:13.1374, lr:0.001\u001b[0m\n",
            "2019-11-25 10:18:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1220/3125], step: 10595, 3.024 samples/sec, batch_loss: 0.1139, batch_loss_c: 0.1131, batch_loss_s: 0.1156, time:13.2261, lr:0.001\u001b[0m\n",
            "2019-11-25 10:18:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1230/3125], step: 10605, 3.020 samples/sec, batch_loss: 0.4271, batch_loss_c: 0.4526, batch_loss_s: 0.3675, time:13.2431, lr:0.001\u001b[0m\n",
            "2019-11-25 10:18:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1240/3125], step: 10615, 3.035 samples/sec, batch_loss: 0.0867, batch_loss_c: 0.0824, batch_loss_s: 0.0968, time:13.1800, lr:0.001\u001b[0m\n",
            "2019-11-25 10:19:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1250/3125], step: 10625, 3.007 samples/sec, batch_loss: 0.1806, batch_loss_c: 0.2151, batch_loss_s: 0.0999, time:13.3013, lr:0.001\u001b[0m\n",
            "2019-11-25 10:19:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1260/3125], step: 10635, 3.012 samples/sec, batch_loss: 0.0868, batch_loss_c: 0.0787, batch_loss_s: 0.1057, time:13.2805, lr:0.001\u001b[0m\n",
            "2019-11-25 10:19:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1270/3125], step: 10645, 2.970 samples/sec, batch_loss: 0.0918, batch_loss_c: 0.0945, batch_loss_s: 0.0857, time:13.4682, lr:0.001\u001b[0m\n",
            "2019-11-25 10:19:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1280/3125], step: 10655, 3.022 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1066, batch_loss_s: 0.1250, time:13.2356, lr:0.001\u001b[0m\n",
            "2019-11-25 10:20:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1290/3125], step: 10665, 3.015 samples/sec, batch_loss: 0.1026, batch_loss_c: 0.1012, batch_loss_s: 0.1058, time:13.2664, lr:0.001\u001b[0m\n",
            "2019-11-25 10:20:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1300/3125], step: 10675, 2.968 samples/sec, batch_loss: 0.2682, batch_loss_c: 0.2742, batch_loss_s: 0.2543, time:13.4760, lr:0.001\u001b[0m\n",
            "2019-11-25 10:20:30 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1310/3125], step: 10685, 2.974 samples/sec, batch_loss: 0.1470, batch_loss_c: 0.1574, batch_loss_s: 0.1230, time:13.4513, lr:0.001\u001b[0m\n",
            "2019-11-25 10:20:43 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1320/3125], step: 10695, 2.966 samples/sec, batch_loss: 0.3841, batch_loss_c: 0.3973, batch_loss_s: 0.3532, time:13.4849, lr:0.001\u001b[0m\n",
            "2019-11-25 10:20:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1330/3125], step: 10705, 3.021 samples/sec, batch_loss: 0.2967, batch_loss_c: 0.2844, batch_loss_s: 0.3254, time:13.2404, lr:0.001\u001b[0m\n",
            "2019-11-25 10:21:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1340/3125], step: 10715, 3.011 samples/sec, batch_loss: 0.1998, batch_loss_c: 0.2284, batch_loss_s: 0.1330, time:13.2831, lr:0.001\u001b[0m\n",
            "2019-11-25 10:21:23 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1350/3125], step: 10725, 3.013 samples/sec, batch_loss: 0.3389, batch_loss_c: 0.4033, batch_loss_s: 0.1887, time:13.2758, lr:0.001\u001b[0m\n",
            "2019-11-25 10:21:36 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1360/3125], step: 10735, 2.999 samples/sec, batch_loss: 0.2858, batch_loss_c: 0.2752, batch_loss_s: 0.3104, time:13.3371, lr:0.001\u001b[0m\n",
            "2019-11-25 10:21:49 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1370/3125], step: 10745, 3.018 samples/sec, batch_loss: 0.3581, batch_loss_c: 0.3760, batch_loss_s: 0.3161, time:13.2529, lr:0.001\u001b[0m\n",
            "2019-11-25 10:22:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1380/3125], step: 10755, 3.068 samples/sec, batch_loss: 0.4362, batch_loss_c: 0.4785, batch_loss_s: 0.3376, time:13.0390, lr:0.001\u001b[0m\n",
            "2019-11-25 10:22:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1390/3125], step: 10765, 2.977 samples/sec, batch_loss: 0.0885, batch_loss_c: 0.0959, batch_loss_s: 0.0712, time:13.4365, lr:0.001\u001b[0m\n",
            "2019-11-25 10:22:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1400/3125], step: 10775, 3.050 samples/sec, batch_loss: 0.3297, batch_loss_c: 0.3340, batch_loss_s: 0.3198, time:13.1152, lr:0.001\u001b[0m\n",
            "2019-11-25 10:22:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1410/3125], step: 10785, 3.076 samples/sec, batch_loss: 0.2034, batch_loss_c: 0.2389, batch_loss_s: 0.1205, time:13.0052, lr:0.001\u001b[0m\n",
            "2019-11-25 10:22:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1420/3125], step: 10795, 3.045 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0843, batch_loss_s: 0.0818, time:13.1349, lr:0.001\u001b[0m\n",
            "2019-11-25 10:23:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1430/3125], step: 10805, 2.994 samples/sec, batch_loss: 0.1343, batch_loss_c: 0.1392, batch_loss_s: 0.1228, time:13.3578, lr:0.001\u001b[0m\n",
            "2019-11-25 10:23:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1440/3125], step: 10815, 3.026 samples/sec, batch_loss: 0.1207, batch_loss_c: 0.1150, batch_loss_s: 0.1341, time:13.2205, lr:0.001\u001b[0m\n",
            "2019-11-25 10:23:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1450/3125], step: 10825, 3.006 samples/sec, batch_loss: 0.3339, batch_loss_c: 0.3326, batch_loss_s: 0.3368, time:13.3068, lr:0.001\u001b[0m\n",
            "2019-11-25 10:23:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1460/3125], step: 10835, 3.025 samples/sec, batch_loss: 0.2471, batch_loss_c: 0.2884, batch_loss_s: 0.1505, time:13.2210, lr:0.001\u001b[0m\n",
            "2019-11-25 10:24:02 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1470/3125], step: 10845, 2.969 samples/sec, batch_loss: 0.1605, batch_loss_c: 0.1734, batch_loss_s: 0.1305, time:13.4722, lr:0.001\u001b[0m\n",
            "2019-11-25 10:24:15 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1480/3125], step: 10855, 3.056 samples/sec, batch_loss: 0.0788, batch_loss_c: 0.0786, batch_loss_s: 0.0792, time:13.0871, lr:0.001\u001b[0m\n",
            "2019-11-25 10:24:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1490/3125], step: 10865, 2.987 samples/sec, batch_loss: 0.3219, batch_loss_c: 0.3108, batch_loss_s: 0.3478, time:13.3893, lr:0.001\u001b[0m\n",
            "2019-11-25 10:24:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1500/3125], step: 10875, 2.996 samples/sec, batch_loss: 0.5302, batch_loss_c: 0.5287, batch_loss_s: 0.5339, time:13.3531, lr:0.001\u001b[0m\n",
            "2019-11-25 10:24:55 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1510/3125], step: 10885, 3.042 samples/sec, batch_loss: 0.1278, batch_loss_c: 0.1324, batch_loss_s: 0.1170, time:13.1478, lr:0.001\u001b[0m\n",
            "2019-11-25 10:25:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1520/3125], step: 10895, 2.975 samples/sec, batch_loss: 0.3793, batch_loss_c: 0.3821, batch_loss_s: 0.3727, time:13.4462, lr:0.001\u001b[0m\n",
            "2019-11-25 10:25:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1530/3125], step: 10905, 3.030 samples/sec, batch_loss: 0.1802, batch_loss_c: 0.1532, batch_loss_s: 0.2429, time:13.2023, lr:0.001\u001b[0m\n",
            "2019-11-25 10:25:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1540/3125], step: 10915, 3.072 samples/sec, batch_loss: 0.3591, batch_loss_c: 0.3659, batch_loss_s: 0.3432, time:13.0209, lr:0.001\u001b[0m\n",
            "2019-11-25 10:25:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1550/3125], step: 10925, 3.020 samples/sec, batch_loss: 0.5138, batch_loss_c: 0.4485, batch_loss_s: 0.6660, time:13.2443, lr:0.001\u001b[0m\n",
            "2019-11-25 10:26:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1560/3125], step: 10935, 2.951 samples/sec, batch_loss: 0.2963, batch_loss_c: 0.3655, batch_loss_s: 0.1349, time:13.5561, lr:0.001\u001b[0m\n",
            "2019-11-25 10:26:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1570/3125], step: 10945, 3.027 samples/sec, batch_loss: 0.1441, batch_loss_c: 0.1496, batch_loss_s: 0.1312, time:13.2129, lr:0.001\u001b[0m\n",
            "2019-11-25 10:26:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1580/3125], step: 10955, 3.039 samples/sec, batch_loss: 0.3839, batch_loss_c: 0.4124, batch_loss_s: 0.3172, time:13.1607, lr:0.001\u001b[0m\n",
            "2019-11-25 10:26:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1590/3125], step: 10965, 2.983 samples/sec, batch_loss: 0.1891, batch_loss_c: 0.2247, batch_loss_s: 0.1060, time:13.4080, lr:0.001\u001b[0m\n",
            "2019-11-25 10:26:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1600/3125], step: 10975, 2.995 samples/sec, batch_loss: 0.1858, batch_loss_c: 0.2013, batch_loss_s: 0.1495, time:13.3573, lr:0.001\u001b[0m\n",
            "2019-11-25 10:27:08 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1610/3125], step: 10985, 2.981 samples/sec, batch_loss: 0.5650, batch_loss_c: 0.5658, batch_loss_s: 0.5632, time:13.4202, lr:0.001\u001b[0m\n",
            "2019-11-25 10:27:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1620/3125], step: 10995, 3.009 samples/sec, batch_loss: 0.3238, batch_loss_c: 0.3138, batch_loss_s: 0.3473, time:13.2949, lr:0.001\u001b[0m\n",
            "2019-11-25 10:27:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1630/3125], step: 11005, 2.957 samples/sec, batch_loss: 0.1431, batch_loss_c: 0.1385, batch_loss_s: 0.1538, time:13.5288, lr:0.001\u001b[0m\n",
            "2019-11-25 10:27:48 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1640/3125], step: 11015, 3.054 samples/sec, batch_loss: 0.2220, batch_loss_c: 0.2392, batch_loss_s: 0.1818, time:13.0982, lr:0.001\u001b[0m\n",
            "2019-11-25 10:28:01 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1650/3125], step: 11025, 3.021 samples/sec, batch_loss: 0.5244, batch_loss_c: 0.5200, batch_loss_s: 0.5347, time:13.2386, lr:0.001\u001b[0m\n",
            "2019-11-25 10:28:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1660/3125], step: 11035, 2.977 samples/sec, batch_loss: 0.3045, batch_loss_c: 0.3041, batch_loss_s: 0.3054, time:13.4359, lr:0.001\u001b[0m\n",
            "2019-11-25 10:28:28 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1670/3125], step: 11045, 3.023 samples/sec, batch_loss: 0.1738, batch_loss_c: 0.1995, batch_loss_s: 0.1139, time:13.2302, lr:0.001\u001b[0m\n",
            "2019-11-25 10:28:41 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1680/3125], step: 11055, 3.040 samples/sec, batch_loss: 0.3173, batch_loss_c: 0.4038, batch_loss_s: 0.1155, time:13.1569, lr:0.001\u001b[0m\n",
            "2019-11-25 10:28:54 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1690/3125], step: 11065, 3.000 samples/sec, batch_loss: 0.2924, batch_loss_c: 0.2808, batch_loss_s: 0.3195, time:13.3315, lr:0.001\u001b[0m\n",
            "2019-11-25 10:29:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1700/3125], step: 11075, 3.027 samples/sec, batch_loss: 0.2794, batch_loss_c: 0.2635, batch_loss_s: 0.3167, time:13.2152, lr:0.001\u001b[0m\n",
            "2019-11-25 10:29:21 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1710/3125], step: 11085, 3.016 samples/sec, batch_loss: 0.1805, batch_loss_c: 0.2162, batch_loss_s: 0.0971, time:13.2638, lr:0.001\u001b[0m\n",
            "2019-11-25 10:29:34 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1720/3125], step: 11095, 3.010 samples/sec, batch_loss: 0.3621, batch_loss_c: 0.3717, batch_loss_s: 0.3398, time:13.2892, lr:0.001\u001b[0m\n",
            "2019-11-25 10:29:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1730/3125], step: 11105, 2.979 samples/sec, batch_loss: 0.1228, batch_loss_c: 0.1254, batch_loss_s: 0.1168, time:13.4275, lr:0.001\u001b[0m\n",
            "2019-11-25 10:30:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1740/3125], step: 11115, 3.069 samples/sec, batch_loss: 0.2100, batch_loss_c: 0.2138, batch_loss_s: 0.2012, time:13.0328, lr:0.001\u001b[0m\n",
            "2019-11-25 10:30:14 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1750/3125], step: 11125, 3.019 samples/sec, batch_loss: 0.3365, batch_loss_c: 0.3459, batch_loss_s: 0.3146, time:13.2497, lr:0.001\u001b[0m\n",
            "2019-11-25 10:30:27 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1760/3125], step: 11135, 3.007 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1819, batch_loss_s: 0.1010, time:13.3014, lr:0.001\u001b[0m\n",
            "2019-11-25 10:30:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1770/3125], step: 11145, 3.040 samples/sec, batch_loss: 0.0933, batch_loss_c: 0.0944, batch_loss_s: 0.0908, time:13.1563, lr:0.001\u001b[0m\n",
            "2019-11-25 10:30:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1780/3125], step: 11155, 2.982 samples/sec, batch_loss: 0.3300, batch_loss_c: 0.3308, batch_loss_s: 0.3282, time:13.4155, lr:0.001\u001b[0m\n",
            "2019-11-25 10:31:07 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1790/3125], step: 11165, 2.996 samples/sec, batch_loss: 0.3142, batch_loss_c: 0.3025, batch_loss_s: 0.3413, time:13.3523, lr:0.001\u001b[0m\n",
            "2019-11-25 10:31:20 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1800/3125], step: 11175, 3.003 samples/sec, batch_loss: 0.1753, batch_loss_c: 0.1884, batch_loss_s: 0.1449, time:13.3180, lr:0.001\u001b[0m\n",
            "2019-11-25 10:31:33 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1810/3125], step: 11185, 3.045 samples/sec, batch_loss: 0.1475, batch_loss_c: 0.1751, batch_loss_s: 0.0833, time:13.1380, lr:0.001\u001b[0m\n",
            "2019-11-25 10:31:47 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1820/3125], step: 11195, 3.020 samples/sec, batch_loss: 0.1474, batch_loss_c: 0.1630, batch_loss_s: 0.1109, time:13.2428, lr:0.001\u001b[0m\n",
            "2019-11-25 10:32:00 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1830/3125], step: 11205, 2.992 samples/sec, batch_loss: 0.1953, batch_loss_c: 0.2259, batch_loss_s: 0.1240, time:13.3691, lr:0.001\u001b[0m\n",
            "2019-11-25 10:32:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1840/3125], step: 11215, 3.023 samples/sec, batch_loss: 0.2104, batch_loss_c: 0.2491, batch_loss_s: 0.1199, time:13.2323, lr:0.001\u001b[0m\n",
            "2019-11-25 10:32:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1850/3125], step: 11225, 2.988 samples/sec, batch_loss: 0.3006, batch_loss_c: 0.2838, batch_loss_s: 0.3398, time:13.3866, lr:0.001\u001b[0m\n",
            "2019-11-25 10:32:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1860/3125], step: 11235, 2.999 samples/sec, batch_loss: 0.3561, batch_loss_c: 0.3689, batch_loss_s: 0.3260, time:13.3392, lr:0.001\u001b[0m\n",
            "2019-11-25 10:32:53 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1870/3125], step: 11245, 3.043 samples/sec, batch_loss: 0.3239, batch_loss_c: 0.3248, batch_loss_s: 0.3220, time:13.1451, lr:0.001\u001b[0m\n",
            "2019-11-25 10:33:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1880/3125], step: 11255, 3.029 samples/sec, batch_loss: 0.0928, batch_loss_c: 0.0936, batch_loss_s: 0.0907, time:13.2068, lr:0.001\u001b[0m\n",
            "2019-11-25 10:33:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1890/3125], step: 11265, 3.022 samples/sec, batch_loss: 0.1052, batch_loss_c: 0.1125, batch_loss_s: 0.0882, time:13.2380, lr:0.001\u001b[0m\n",
            "2019-11-25 10:33:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1900/3125], step: 11275, 3.060 samples/sec, batch_loss: 0.1114, batch_loss_c: 0.1162, batch_loss_s: 0.1003, time:13.0714, lr:0.001\u001b[0m\n",
            "2019-11-25 10:33:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1910/3125], step: 11285, 3.010 samples/sec, batch_loss: 0.5799, batch_loss_c: 0.5684, batch_loss_s: 0.6068, time:13.2906, lr:0.001\u001b[0m\n",
            "2019-11-25 10:33:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1920/3125], step: 11295, 3.023 samples/sec, batch_loss: 0.1253, batch_loss_c: 0.1467, batch_loss_s: 0.0753, time:13.2298, lr:0.001\u001b[0m\n",
            "2019-11-25 10:34:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1930/3125], step: 11305, 3.001 samples/sec, batch_loss: 0.2032, batch_loss_c: 0.2211, batch_loss_s: 0.1615, time:13.3286, lr:0.001\u001b[0m\n",
            "2019-11-25 10:34:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1940/3125], step: 11315, 3.014 samples/sec, batch_loss: 0.4368, batch_loss_c: 0.4501, batch_loss_s: 0.4056, time:13.2736, lr:0.001\u001b[0m\n",
            "2019-11-25 10:34:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1950/3125], step: 11325, 3.016 samples/sec, batch_loss: 0.1609, batch_loss_c: 0.1876, batch_loss_s: 0.0987, time:13.2641, lr:0.001\u001b[0m\n",
            "2019-11-25 10:34:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1960/3125], step: 11335, 3.016 samples/sec, batch_loss: 0.3016, batch_loss_c: 0.2855, batch_loss_s: 0.3391, time:13.2607, lr:0.001\u001b[0m\n",
            "2019-11-25 10:35:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1970/3125], step: 11345, 2.997 samples/sec, batch_loss: 0.4047, batch_loss_c: 0.4134, batch_loss_s: 0.3843, time:13.3483, lr:0.001\u001b[0m\n",
            "2019-11-25 10:35:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1980/3125], step: 11355, 2.994 samples/sec, batch_loss: 0.3746, batch_loss_c: 0.3881, batch_loss_s: 0.3430, time:13.3606, lr:0.001\u001b[0m\n",
            "2019-11-25 10:35:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [1990/3125], step: 11365, 3.027 samples/sec, batch_loss: 0.3437, batch_loss_c: 0.3567, batch_loss_s: 0.3135, time:13.2138, lr:0.001\u001b[0m\n",
            "2019-11-25 10:35:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2000/3125], step: 11375, 2.985 samples/sec, batch_loss: 0.1265, batch_loss_c: 0.1480, batch_loss_s: 0.0763, time:13.3990, lr:0.001\u001b[0m\n",
            "2019-11-25 10:35:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2010/3125], step: 11385, 2.973 samples/sec, batch_loss: 0.1010, batch_loss_c: 0.1018, batch_loss_s: 0.0990, time:13.4538, lr:0.001\u001b[0m\n",
            "2019-11-25 10:36:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2020/3125], step: 11395, 2.988 samples/sec, batch_loss: 0.0811, batch_loss_c: 0.0771, batch_loss_s: 0.0906, time:13.3889, lr:0.001\u001b[0m\n",
            "2019-11-25 10:36:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2030/3125], step: 11405, 3.024 samples/sec, batch_loss: 0.3289, batch_loss_c: 0.3203, batch_loss_s: 0.3491, time:13.2293, lr:0.001\u001b[0m\n",
            "2019-11-25 10:36:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2040/3125], step: 11415, 2.977 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1030, batch_loss_s: 0.0988, time:13.4344, lr:0.001\u001b[0m\n",
            "2019-11-25 10:36:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2050/3125], step: 11425, 3.013 samples/sec, batch_loss: 0.3365, batch_loss_c: 0.3368, batch_loss_s: 0.3358, time:13.2738, lr:0.001\u001b[0m\n",
            "2019-11-25 10:37:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2060/3125], step: 11435, 3.041 samples/sec, batch_loss: 0.1515, batch_loss_c: 0.1725, batch_loss_s: 0.1025, time:13.1529, lr:0.001\u001b[0m\n",
            "2019-11-25 10:37:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2070/3125], step: 11445, 3.012 samples/sec, batch_loss: 0.3550, batch_loss_c: 0.3604, batch_loss_s: 0.3423, time:13.2800, lr:0.001\u001b[0m\n",
            "2019-11-25 10:37:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2080/3125], step: 11455, 2.971 samples/sec, batch_loss: 0.1255, batch_loss_c: 0.1268, batch_loss_s: 0.1227, time:13.4616, lr:0.001\u001b[0m\n",
            "2019-11-25 10:37:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2090/3125], step: 11465, 3.039 samples/sec, batch_loss: 0.1112, batch_loss_c: 0.1117, batch_loss_s: 0.1100, time:13.1624, lr:0.001\u001b[0m\n",
            "2019-11-25 10:37:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2100/3125], step: 11475, 2.953 samples/sec, batch_loss: 0.3102, batch_loss_c: 0.3056, batch_loss_s: 0.3207, time:13.5450, lr:0.001\u001b[0m\n",
            "2019-11-25 10:38:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2110/3125], step: 11485, 3.019 samples/sec, batch_loss: 0.8024, batch_loss_c: 0.8190, batch_loss_s: 0.7636, time:13.2504, lr:0.001\u001b[0m\n",
            "2019-11-25 10:38:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2120/3125], step: 11495, 3.038 samples/sec, batch_loss: 0.3009, batch_loss_c: 0.3018, batch_loss_s: 0.2989, time:13.1644, lr:0.001\u001b[0m\n",
            "2019-11-25 10:38:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2130/3125], step: 11505, 3.003 samples/sec, batch_loss: 0.2346, batch_loss_c: 0.2509, batch_loss_s: 0.1965, time:13.3203, lr:0.001\u001b[0m\n",
            "2019-11-25 10:38:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2140/3125], step: 11515, 3.022 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1822, batch_loss_s: 0.1006, time:13.2381, lr:0.001\u001b[0m\n",
            "2019-11-25 10:39:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2150/3125], step: 11525, 3.004 samples/sec, batch_loss: 0.1523, batch_loss_c: 0.1682, batch_loss_s: 0.1150, time:13.3147, lr:0.001\u001b[0m\n",
            "2019-11-25 10:39:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2160/3125], step: 11535, 3.015 samples/sec, batch_loss: 0.4042, batch_loss_c: 0.4448, batch_loss_s: 0.3095, time:13.2679, lr:0.001\u001b[0m\n",
            "2019-11-25 10:39:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2170/3125], step: 11545, 2.992 samples/sec, batch_loss: 0.3722, batch_loss_c: 0.3789, batch_loss_s: 0.3564, time:13.3682, lr:0.001\u001b[0m\n",
            "2019-11-25 10:39:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2180/3125], step: 11555, 3.041 samples/sec, batch_loss: 0.3862, batch_loss_c: 0.4240, batch_loss_s: 0.2981, time:13.1527, lr:0.001\u001b[0m\n",
            "2019-11-25 10:39:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2190/3125], step: 11565, 2.952 samples/sec, batch_loss: 0.2761, batch_loss_c: 0.2580, batch_loss_s: 0.3184, time:13.5507, lr:0.001\u001b[0m\n",
            "2019-11-25 10:40:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2200/3125], step: 11575, 2.970 samples/sec, batch_loss: 0.1494, batch_loss_c: 0.1658, batch_loss_s: 0.1110, time:13.4660, lr:0.001\u001b[0m\n",
            "2019-11-25 10:40:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2210/3125], step: 11585, 2.973 samples/sec, batch_loss: 0.2616, batch_loss_c: 0.2824, batch_loss_s: 0.2132, time:13.4526, lr:0.001\u001b[0m\n",
            "2019-11-25 10:40:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2220/3125], step: 11595, 2.970 samples/sec, batch_loss: 0.0962, batch_loss_c: 0.1025, batch_loss_s: 0.0815, time:13.4662, lr:0.001\u001b[0m\n",
            "2019-11-25 10:40:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2230/3125], step: 11605, 2.982 samples/sec, batch_loss: 0.2696, batch_loss_c: 0.2880, batch_loss_s: 0.2269, time:13.4130, lr:0.001\u001b[0m\n",
            "2019-11-25 10:41:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2240/3125], step: 11615, 3.019 samples/sec, batch_loss: 0.1898, batch_loss_c: 0.2099, batch_loss_s: 0.1429, time:13.2475, lr:0.001\u001b[0m\n",
            "2019-11-25 10:41:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2250/3125], step: 11625, 3.029 samples/sec, batch_loss: 0.2691, batch_loss_c: 0.2658, batch_loss_s: 0.2770, time:13.2068, lr:0.001\u001b[0m\n",
            "2019-11-25 10:41:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2260/3125], step: 11635, 3.013 samples/sec, batch_loss: 0.3199, batch_loss_c: 0.3134, batch_loss_s: 0.3352, time:13.2749, lr:0.001\u001b[0m\n",
            "2019-11-25 10:41:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2270/3125], step: 11645, 2.968 samples/sec, batch_loss: 0.3203, batch_loss_c: 0.3201, batch_loss_s: 0.3208, time:13.4781, lr:0.001\u001b[0m\n",
            "2019-11-25 10:41:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2280/3125], step: 11655, 3.028 samples/sec, batch_loss: 0.1501, batch_loss_c: 0.1733, batch_loss_s: 0.0960, time:13.2084, lr:0.001\u001b[0m\n",
            "2019-11-25 10:42:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2290/3125], step: 11665, 2.993 samples/sec, batch_loss: 0.1215, batch_loss_c: 0.1335, batch_loss_s: 0.0935, time:13.3662, lr:0.001\u001b[0m\n",
            "2019-11-25 10:42:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2300/3125], step: 11675, 2.986 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1494, batch_loss_s: 0.1065, time:13.3972, lr:0.001\u001b[0m\n",
            "2019-11-25 10:42:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2310/3125], step: 11685, 2.962 samples/sec, batch_loss: 0.5299, batch_loss_c: 0.5300, batch_loss_s: 0.5296, time:13.5034, lr:0.001\u001b[0m\n",
            "2019-11-25 10:42:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2320/3125], step: 11695, 3.082 samples/sec, batch_loss: 0.3819, batch_loss_c: 0.3788, batch_loss_s: 0.3892, time:12.9806, lr:0.001\u001b[0m\n",
            "2019-11-25 10:43:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2330/3125], step: 11705, 2.997 samples/sec, batch_loss: 0.1291, batch_loss_c: 0.1228, batch_loss_s: 0.1437, time:13.3469, lr:0.001\u001b[0m\n",
            "2019-11-25 10:43:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2340/3125], step: 11715, 2.951 samples/sec, batch_loss: 0.3554, batch_loss_c: 0.3610, batch_loss_s: 0.3424, time:13.5563, lr:0.001\u001b[0m\n",
            "2019-11-25 10:43:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2350/3125], step: 11725, 2.970 samples/sec, batch_loss: 0.1134, batch_loss_c: 0.1164, batch_loss_s: 0.1064, time:13.4696, lr:0.001\u001b[0m\n",
            "2019-11-25 10:43:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2360/3125], step: 11735, 3.021 samples/sec, batch_loss: 0.5401, batch_loss_c: 0.5175, batch_loss_s: 0.5928, time:13.2396, lr:0.001\u001b[0m\n",
            "2019-11-25 10:43:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2370/3125], step: 11745, 2.930 samples/sec, batch_loss: 0.2392, batch_loss_c: 0.2725, batch_loss_s: 0.1614, time:13.6529, lr:0.001\u001b[0m\n",
            "2019-11-25 10:44:13 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2380/3125], step: 11755, 2.950 samples/sec, batch_loss: 0.1346, batch_loss_c: 0.1584, batch_loss_s: 0.0791, time:13.5589, lr:0.001\u001b[0m\n",
            "2019-11-25 10:44:26 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2390/3125], step: 11765, 3.066 samples/sec, batch_loss: 0.0909, batch_loss_c: 0.0893, batch_loss_s: 0.0944, time:13.0477, lr:0.001\u001b[0m\n",
            "2019-11-25 10:44:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2400/3125], step: 11775, 3.045 samples/sec, batch_loss: 0.3811, batch_loss_c: 0.3950, batch_loss_s: 0.3486, time:13.1353, lr:0.001\u001b[0m\n",
            "2019-11-25 10:44:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2410/3125], step: 11785, 3.011 samples/sec, batch_loss: 0.1267, batch_loss_c: 0.1372, batch_loss_s: 0.1021, time:13.2826, lr:0.001\u001b[0m\n",
            "2019-11-25 10:45:06 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2420/3125], step: 11795, 3.013 samples/sec, batch_loss: 0.1150, batch_loss_c: 0.1201, batch_loss_s: 0.1030, time:13.2771, lr:0.001\u001b[0m\n",
            "2019-11-25 10:45:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2430/3125], step: 11805, 3.030 samples/sec, batch_loss: 0.3759, batch_loss_c: 0.3827, batch_loss_s: 0.3598, time:13.2013, lr:0.001\u001b[0m\n",
            "2019-11-25 10:45:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2440/3125], step: 11815, 2.978 samples/sec, batch_loss: 0.3735, batch_loss_c: 0.3414, batch_loss_s: 0.4485, time:13.4313, lr:0.001\u001b[0m\n",
            "2019-11-25 10:45:46 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2450/3125], step: 11825, 2.980 samples/sec, batch_loss: 0.1269, batch_loss_c: 0.1278, batch_loss_s: 0.1249, time:13.4214, lr:0.001\u001b[0m\n",
            "2019-11-25 10:45:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2460/3125], step: 11835, 3.031 samples/sec, batch_loss: 0.3334, batch_loss_c: 0.3589, batch_loss_s: 0.2738, time:13.1982, lr:0.001\u001b[0m\n",
            "2019-11-25 10:46:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2470/3125], step: 11845, 3.012 samples/sec, batch_loss: 0.1094, batch_loss_c: 0.1140, batch_loss_s: 0.0986, time:13.2820, lr:0.001\u001b[0m\n",
            "2019-11-25 10:46:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2480/3125], step: 11855, 2.986 samples/sec, batch_loss: 0.1641, batch_loss_c: 0.1763, batch_loss_s: 0.1356, time:13.3979, lr:0.001\u001b[0m\n",
            "2019-11-25 10:46:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2490/3125], step: 11865, 3.002 samples/sec, batch_loss: 0.1573, batch_loss_c: 0.1665, batch_loss_s: 0.1359, time:13.3223, lr:0.001\u001b[0m\n",
            "2019-11-25 10:46:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2500/3125], step: 11875, 3.007 samples/sec, batch_loss: 0.1886, batch_loss_c: 0.2076, batch_loss_s: 0.1441, time:13.3040, lr:0.001\u001b[0m\n",
            "2019-11-25 10:47:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2510/3125], step: 11885, 3.040 samples/sec, batch_loss: 0.0765, batch_loss_c: 0.0773, batch_loss_s: 0.0746, time:13.1567, lr:0.001\u001b[0m\n",
            "2019-11-25 10:47:19 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2520/3125], step: 11895, 3.015 samples/sec, batch_loss: 0.3861, batch_loss_c: 0.3963, batch_loss_s: 0.3624, time:13.2662, lr:0.001\u001b[0m\n",
            "2019-11-25 10:47:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2530/3125], step: 11905, 2.982 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1174, batch_loss_s: 0.0996, time:13.4152, lr:0.001\u001b[0m\n",
            "2019-11-25 10:47:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2540/3125], step: 11915, 2.985 samples/sec, batch_loss: 0.1681, batch_loss_c: 0.1885, batch_loss_s: 0.1206, time:13.3998, lr:0.001\u001b[0m\n",
            "2019-11-25 10:47:59 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2550/3125], step: 11925, 2.999 samples/sec, batch_loss: 0.1042, batch_loss_c: 0.1172, batch_loss_s: 0.0739, time:13.3390, lr:0.001\u001b[0m\n",
            "2019-11-25 10:48:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2560/3125], step: 11935, 3.025 samples/sec, batch_loss: 0.0803, batch_loss_c: 0.0770, batch_loss_s: 0.0881, time:13.2246, lr:0.001\u001b[0m\n",
            "2019-11-25 10:48:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2570/3125], step: 11945, 2.994 samples/sec, batch_loss: 0.1438, batch_loss_c: 0.1746, batch_loss_s: 0.0720, time:13.3618, lr:0.001\u001b[0m\n",
            "2019-11-25 10:48:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2580/3125], step: 11955, 2.958 samples/sec, batch_loss: 0.1493, batch_loss_c: 0.1566, batch_loss_s: 0.1323, time:13.5218, lr:0.001\u001b[0m\n",
            "2019-11-25 10:48:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2590/3125], step: 11965, 3.042 samples/sec, batch_loss: 0.1561, batch_loss_c: 0.1682, batch_loss_s: 0.1278, time:13.1501, lr:0.001\u001b[0m\n",
            "2019-11-25 10:49:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2600/3125], step: 11975, 3.001 samples/sec, batch_loss: 0.1136, batch_loss_c: 0.1188, batch_loss_s: 0.1016, time:13.3309, lr:0.001\u001b[0m\n",
            "2019-11-25 10:49:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2610/3125], step: 11985, 3.056 samples/sec, batch_loss: 0.1694, batch_loss_c: 0.2004, batch_loss_s: 0.0970, time:13.0879, lr:0.001\u001b[0m\n",
            "2019-11-25 10:49:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2620/3125], step: 11995, 2.995 samples/sec, batch_loss: 0.5236, batch_loss_c: 0.5130, batch_loss_s: 0.5482, time:13.3572, lr:0.001\u001b[0m\n",
            "2019-11-25 10:49:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2630/3125], step: 12005, 3.037 samples/sec, batch_loss: 0.2023, batch_loss_c: 0.2319, batch_loss_s: 0.1333, time:13.1690, lr:0.001\u001b[0m\n",
            "2019-11-25 10:49:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2640/3125], step: 12015, 2.956 samples/sec, batch_loss: 0.4209, batch_loss_c: 0.4096, batch_loss_s: 0.4472, time:13.5303, lr:0.001\u001b[0m\n",
            "2019-11-25 10:50:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2650/3125], step: 12025, 2.997 samples/sec, batch_loss: 0.3092, batch_loss_c: 0.3066, batch_loss_s: 0.3152, time:13.3480, lr:0.001\u001b[0m\n",
            "2019-11-25 10:50:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2660/3125], step: 12035, 3.003 samples/sec, batch_loss: 0.1365, batch_loss_c: 0.1393, batch_loss_s: 0.1301, time:13.3202, lr:0.001\u001b[0m\n",
            "2019-11-25 10:50:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2670/3125], step: 12045, 2.994 samples/sec, batch_loss: 0.1866, batch_loss_c: 0.2140, batch_loss_s: 0.1226, time:13.3608, lr:0.001\u001b[0m\n",
            "2019-11-25 10:50:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2680/3125], step: 12055, 3.053 samples/sec, batch_loss: 0.3371, batch_loss_c: 0.3438, batch_loss_s: 0.3216, time:13.1033, lr:0.001\u001b[0m\n",
            "2019-11-25 10:51:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2690/3125], step: 12065, 3.024 samples/sec, batch_loss: 0.1311, batch_loss_c: 0.1350, batch_loss_s: 0.1220, time:13.2259, lr:0.001\u001b[0m\n",
            "2019-11-25 10:51:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2700/3125], step: 12075, 2.978 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1299, batch_loss_s: 0.1262, time:13.4327, lr:0.001\u001b[0m\n",
            "2019-11-25 10:51:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2710/3125], step: 12085, 2.977 samples/sec, batch_loss: 0.1955, batch_loss_c: 0.2212, batch_loss_s: 0.1355, time:13.4369, lr:0.001\u001b[0m\n",
            "2019-11-25 10:51:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2720/3125], step: 12095, 2.977 samples/sec, batch_loss: 0.1516, batch_loss_c: 0.1778, batch_loss_s: 0.0905, time:13.4372, lr:0.001\u001b[0m\n",
            "2019-11-25 10:51:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2730/3125], step: 12105, 3.022 samples/sec, batch_loss: 0.2092, batch_loss_c: 0.2435, batch_loss_s: 0.1292, time:13.2373, lr:0.001\u001b[0m\n",
            "2019-11-25 10:52:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2740/3125], step: 12115, 2.958 samples/sec, batch_loss: 0.1224, batch_loss_c: 0.1313, batch_loss_s: 0.1018, time:13.5210, lr:0.001\u001b[0m\n",
            "2019-11-25 10:52:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2750/3125], step: 12125, 3.012 samples/sec, batch_loss: 0.0935, batch_loss_c: 0.0939, batch_loss_s: 0.0925, time:13.2781, lr:0.001\u001b[0m\n",
            "2019-11-25 10:52:39 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2760/3125], step: 12135, 2.982 samples/sec, batch_loss: 0.1628, batch_loss_c: 0.1832, batch_loss_s: 0.1151, time:13.4148, lr:0.001\u001b[0m\n",
            "2019-11-25 10:52:52 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2770/3125], step: 12145, 3.003 samples/sec, batch_loss: 0.0712, batch_loss_c: 0.0702, batch_loss_s: 0.0736, time:13.3197, lr:0.001\u001b[0m\n",
            "2019-11-25 10:53:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2780/3125], step: 12155, 3.036 samples/sec, batch_loss: 0.2604, batch_loss_c: 0.2413, batch_loss_s: 0.3049, time:13.1750, lr:0.001\u001b[0m\n",
            "2019-11-25 10:53:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2790/3125], step: 12165, 3.023 samples/sec, batch_loss: 0.3026, batch_loss_c: 0.2852, batch_loss_s: 0.3433, time:13.2333, lr:0.001\u001b[0m\n",
            "2019-11-25 10:53:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2800/3125], step: 12175, 3.049 samples/sec, batch_loss: 0.1944, batch_loss_c: 0.2150, batch_loss_s: 0.1464, time:13.1189, lr:0.001\u001b[0m\n",
            "2019-11-25 10:53:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2810/3125], step: 12185, 2.985 samples/sec, batch_loss: 0.3368, batch_loss_c: 0.3503, batch_loss_s: 0.3054, time:13.4005, lr:0.001\u001b[0m\n",
            "2019-11-25 10:53:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2820/3125], step: 12195, 3.014 samples/sec, batch_loss: 0.1046, batch_loss_c: 0.1076, batch_loss_s: 0.0976, time:13.2734, lr:0.001\u001b[0m\n",
            "2019-11-25 10:54:12 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2830/3125], step: 12205, 2.945 samples/sec, batch_loss: 0.1199, batch_loss_c: 0.1292, batch_loss_s: 0.0983, time:13.5839, lr:0.001\u001b[0m\n",
            "2019-11-25 10:54:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2840/3125], step: 12215, 3.034 samples/sec, batch_loss: 0.2240, batch_loss_c: 0.2417, batch_loss_s: 0.1828, time:13.1843, lr:0.001\u001b[0m\n",
            "2019-11-25 10:54:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2850/3125], step: 12225, 2.982 samples/sec, batch_loss: 0.3635, batch_loss_c: 0.3705, batch_loss_s: 0.3470, time:13.4148, lr:0.001\u001b[0m\n",
            "2019-11-25 10:54:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2860/3125], step: 12235, 3.065 samples/sec, batch_loss: 0.0748, batch_loss_c: 0.0741, batch_loss_s: 0.0764, time:13.0498, lr:0.001\u001b[0m\n",
            "2019-11-25 10:55:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2870/3125], step: 12245, 3.007 samples/sec, batch_loss: 0.3284, batch_loss_c: 0.3319, batch_loss_s: 0.3201, time:13.3045, lr:0.001\u001b[0m\n",
            "2019-11-25 10:55:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2880/3125], step: 12255, 2.938 samples/sec, batch_loss: 0.0851, batch_loss_c: 0.0916, batch_loss_s: 0.0699, time:13.6136, lr:0.001\u001b[0m\n",
            "2019-11-25 10:55:32 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2890/3125], step: 12265, 2.993 samples/sec, batch_loss: 0.3689, batch_loss_c: 0.3851, batch_loss_s: 0.3313, time:13.3656, lr:0.001\u001b[0m\n",
            "2019-11-25 10:55:45 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2900/3125], step: 12275, 3.014 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1783, batch_loss_s: 0.1086, time:13.2699, lr:0.001\u001b[0m\n",
            "2019-11-25 10:55:58 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2910/3125], step: 12285, 3.038 samples/sec, batch_loss: 0.0790, batch_loss_c: 0.0710, batch_loss_s: 0.0978, time:13.1680, lr:0.001\u001b[0m\n",
            "2019-11-25 10:56:11 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2920/3125], step: 12295, 3.007 samples/sec, batch_loss: 0.3636, batch_loss_c: 0.3661, batch_loss_s: 0.3575, time:13.3035, lr:0.001\u001b[0m\n",
            "2019-11-25 10:56:25 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2930/3125], step: 12305, 2.989 samples/sec, batch_loss: 0.1043, batch_loss_c: 0.1088, batch_loss_s: 0.0939, time:13.3832, lr:0.001\u001b[0m\n",
            "2019-11-25 10:56:38 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2940/3125], step: 12315, 3.041 samples/sec, batch_loss: 0.1628, batch_loss_c: 0.1697, batch_loss_s: 0.1470, time:13.1536, lr:0.001\u001b[0m\n",
            "2019-11-25 10:56:51 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2950/3125], step: 12325, 2.987 samples/sec, batch_loss: 0.1676, batch_loss_c: 0.1880, batch_loss_s: 0.1202, time:13.3898, lr:0.001\u001b[0m\n",
            "2019-11-25 10:57:05 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2960/3125], step: 12335, 2.980 samples/sec, batch_loss: 0.2590, batch_loss_c: 0.2634, batch_loss_s: 0.2487, time:13.4233, lr:0.001\u001b[0m\n",
            "2019-11-25 10:57:18 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2970/3125], step: 12345, 3.065 samples/sec, batch_loss: 0.5397, batch_loss_c: 0.5383, batch_loss_s: 0.5429, time:13.0526, lr:0.001\u001b[0m\n",
            "2019-11-25 10:57:31 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2980/3125], step: 12355, 3.039 samples/sec, batch_loss: 0.1585, batch_loss_c: 0.1932, batch_loss_s: 0.0776, time:13.1628, lr:0.001\u001b[0m\n",
            "2019-11-25 10:57:44 \u001b[32mINFO     \u001b[0m train.py: [3/10], [2990/3125], step: 12365, 3.041 samples/sec, batch_loss: 0.3134, batch_loss_c: 0.3015, batch_loss_s: 0.3410, time:13.1536, lr:0.001\u001b[0m\n",
            "2019-11-25 10:57:57 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3000/3125], step: 12375, 3.018 samples/sec, batch_loss: 0.1986, batch_loss_c: 0.2181, batch_loss_s: 0.1531, time:13.2527, lr:0.001\u001b[0m\n",
            "2019-11-25 10:58:10 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3010/3125], step: 12385, 3.039 samples/sec, batch_loss: 0.1541, batch_loss_c: 0.1613, batch_loss_s: 0.1373, time:13.1624, lr:0.001\u001b[0m\n",
            "2019-11-25 10:58:24 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3020/3125], step: 12395, 3.061 samples/sec, batch_loss: 0.3597, batch_loss_c: 0.3482, batch_loss_s: 0.3866, time:13.0679, lr:0.001\u001b[0m\n",
            "2019-11-25 10:58:37 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3030/3125], step: 12405, 3.046 samples/sec, batch_loss: 0.2475, batch_loss_c: 0.2291, batch_loss_s: 0.2904, time:13.1312, lr:0.001\u001b[0m\n",
            "2019-11-25 10:58:50 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3040/3125], step: 12415, 3.060 samples/sec, batch_loss: 0.5200, batch_loss_c: 0.5071, batch_loss_s: 0.5499, time:13.0703, lr:0.001\u001b[0m\n",
            "2019-11-25 10:59:03 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3050/3125], step: 12425, 3.064 samples/sec, batch_loss: 0.1395, batch_loss_c: 0.1609, batch_loss_s: 0.0895, time:13.0537, lr:0.001\u001b[0m\n",
            "2019-11-25 10:59:16 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3060/3125], step: 12435, 3.031 samples/sec, batch_loss: 0.5020, batch_loss_c: 0.4876, batch_loss_s: 0.5356, time:13.1978, lr:0.001\u001b[0m\n",
            "2019-11-25 10:59:29 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3070/3125], step: 12445, 3.069 samples/sec, batch_loss: 0.2832, batch_loss_c: 0.2669, batch_loss_s: 0.3213, time:13.0325, lr:0.001\u001b[0m\n",
            "2019-11-25 10:59:42 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3080/3125], step: 12455, 3.045 samples/sec, batch_loss: 0.1238, batch_loss_c: 0.1415, batch_loss_s: 0.0826, time:13.1371, lr:0.001\u001b[0m\n",
            "2019-11-25 10:59:56 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3090/3125], step: 12465, 3.004 samples/sec, batch_loss: 0.2142, batch_loss_c: 0.2013, batch_loss_s: 0.2443, time:13.3178, lr:0.001\u001b[0m\n",
            "2019-11-25 11:00:09 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3100/3125], step: 12475, 2.963 samples/sec, batch_loss: 0.0826, batch_loss_c: 0.0822, batch_loss_s: 0.0834, time:13.4985, lr:0.001\u001b[0m\n",
            "2019-11-25 11:00:22 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3110/3125], step: 12485, 3.085 samples/sec, batch_loss: 0.5095, batch_loss_c: 0.4910, batch_loss_s: 0.5525, time:12.9658, lr:0.001\u001b[0m\n",
            "2019-11-25 11:00:35 \u001b[32mINFO     \u001b[0m train.py: [3/10], [3120/3125], step: 12495, 3.074 samples/sec, batch_loss: 0.1226, batch_loss_c: 0.1233, batch_loss_s: 0.1211, time:13.0123, lr:0.001\u001b[0m\n",
            "2019-11-25 11:00:40 \u001b[32mINFO     \u001b[0m train.py: [3/10], train_loss: 0.2402, time: 4161.5194, lr: 0.001\u001b[0m\n",
            "2019-11-25 11:00:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [0/3125], step: 12500, 4.371 samples/sec, batch_loss: 0.2033, batch_loss_c: 0.2131, batch_loss_s: 0.1804, time:9.1521, lr:0.001\u001b[0m\n",
            "2019-11-25 11:01:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [10/3125], step: 12510, 2.857 samples/sec, batch_loss: 0.1711, batch_loss_c: 0.1910, batch_loss_s: 0.1245, time:14.0012, lr:0.001\u001b[0m\n",
            "2019-11-25 11:01:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [20/3125], step: 12520, 2.971 samples/sec, batch_loss: 0.3113, batch_loss_c: 0.3124, batch_loss_s: 0.3086, time:13.4651, lr:0.001\u001b[0m\n",
            "2019-11-25 11:01:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [30/3125], step: 12530, 2.962 samples/sec, batch_loss: 0.1105, batch_loss_c: 0.1183, batch_loss_s: 0.0924, time:13.5048, lr:0.001\u001b[0m\n",
            "2019-11-25 11:01:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [40/3125], step: 12540, 2.964 samples/sec, batch_loss: 0.1478, batch_loss_c: 0.1600, batch_loss_s: 0.1194, time:13.4940, lr:0.001\u001b[0m\n",
            "2019-11-25 11:01:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [50/3125], step: 12550, 2.907 samples/sec, batch_loss: 0.2133, batch_loss_c: 0.2585, batch_loss_s: 0.1078, time:13.7595, lr:0.001\u001b[0m\n",
            "2019-11-25 11:02:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [60/3125], step: 12560, 3.047 samples/sec, batch_loss: 0.1966, batch_loss_c: 0.2142, batch_loss_s: 0.1554, time:13.1296, lr:0.001\u001b[0m\n",
            "2019-11-25 11:02:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [70/3125], step: 12570, 3.000 samples/sec, batch_loss: 0.1095, batch_loss_c: 0.1031, batch_loss_s: 0.1243, time:13.3346, lr:0.001\u001b[0m\n",
            "2019-11-25 11:02:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [80/3125], step: 12580, 2.996 samples/sec, batch_loss: 0.2045, batch_loss_c: 0.2231, batch_loss_s: 0.1610, time:13.3525, lr:0.001\u001b[0m\n",
            "2019-11-25 11:02:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [90/3125], step: 12590, 2.977 samples/sec, batch_loss: 0.3804, batch_loss_c: 0.3997, batch_loss_s: 0.3354, time:13.4364, lr:0.001\u001b[0m\n",
            "2019-11-25 11:03:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [100/3125], step: 12600, 3.010 samples/sec, batch_loss: 0.2193, batch_loss_c: 0.2548, batch_loss_s: 0.1364, time:13.2881, lr:0.001\u001b[0m\n",
            "2019-11-25 11:03:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [110/3125], step: 12610, 3.011 samples/sec, batch_loss: 0.1184, batch_loss_c: 0.1329, batch_loss_s: 0.0844, time:13.2856, lr:0.001\u001b[0m\n",
            "2019-11-25 11:03:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [120/3125], step: 12620, 2.940 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.1167, batch_loss_s: 0.0616, time:13.6048, lr:0.001\u001b[0m\n",
            "2019-11-25 11:03:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [130/3125], step: 12630, 3.001 samples/sec, batch_loss: 0.3169, batch_loss_c: 0.3184, batch_loss_s: 0.3135, time:13.3309, lr:0.001\u001b[0m\n",
            "2019-11-25 11:03:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [140/3125], step: 12640, 3.047 samples/sec, batch_loss: 0.3248, batch_loss_c: 0.3252, batch_loss_s: 0.3238, time:13.1298, lr:0.001\u001b[0m\n",
            "2019-11-25 11:04:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [150/3125], step: 12650, 3.038 samples/sec, batch_loss: 0.2337, batch_loss_c: 0.2078, batch_loss_s: 0.2939, time:13.1663, lr:0.001\u001b[0m\n",
            "2019-11-25 11:04:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [160/3125], step: 12660, 2.994 samples/sec, batch_loss: 0.1425, batch_loss_c: 0.1587, batch_loss_s: 0.1045, time:13.3610, lr:0.001\u001b[0m\n",
            "2019-11-25 11:04:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [170/3125], step: 12670, 2.991 samples/sec, batch_loss: 0.1510, batch_loss_c: 0.1792, batch_loss_s: 0.0851, time:13.3754, lr:0.001\u001b[0m\n",
            "2019-11-25 11:04:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [180/3125], step: 12680, 3.017 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.0916, batch_loss_s: 0.1100, time:13.2585, lr:0.001\u001b[0m\n",
            "2019-11-25 11:05:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [190/3125], step: 12690, 2.977 samples/sec, batch_loss: 0.1323, batch_loss_c: 0.1573, batch_loss_s: 0.0738, time:13.4360, lr:0.001\u001b[0m\n",
            "2019-11-25 11:05:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [200/3125], step: 12700, 3.013 samples/sec, batch_loss: 0.3287, batch_loss_c: 0.3362, batch_loss_s: 0.3113, time:13.2743, lr:0.001\u001b[0m\n",
            "2019-11-25 11:05:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [210/3125], step: 12710, 3.038 samples/sec, batch_loss: 0.1619, batch_loss_c: 0.1783, batch_loss_s: 0.1237, time:13.1661, lr:0.001\u001b[0m\n",
            "2019-11-25 11:05:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [220/3125], step: 12720, 3.008 samples/sec, batch_loss: 0.1334, batch_loss_c: 0.1336, batch_loss_s: 0.1329, time:13.2987, lr:0.001\u001b[0m\n",
            "2019-11-25 11:05:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [230/3125], step: 12730, 3.006 samples/sec, batch_loss: 0.1931, batch_loss_c: 0.2372, batch_loss_s: 0.0901, time:13.3082, lr:0.001\u001b[0m\n",
            "2019-11-25 11:06:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [240/3125], step: 12740, 3.019 samples/sec, batch_loss: 0.2938, batch_loss_c: 0.2927, batch_loss_s: 0.2962, time:13.2481, lr:0.001\u001b[0m\n",
            "2019-11-25 11:06:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [250/3125], step: 12750, 3.030 samples/sec, batch_loss: 0.5218, batch_loss_c: 0.4960, batch_loss_s: 0.5820, time:13.2010, lr:0.001\u001b[0m\n",
            "2019-11-25 11:06:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [260/3125], step: 12760, 3.070 samples/sec, batch_loss: 0.1417, batch_loss_c: 0.1541, batch_loss_s: 0.1127, time:13.0312, lr:0.001\u001b[0m\n",
            "2019-11-25 11:06:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [270/3125], step: 12770, 3.046 samples/sec, batch_loss: 0.1159, batch_loss_c: 0.1292, batch_loss_s: 0.0851, time:13.1310, lr:0.001\u001b[0m\n",
            "2019-11-25 11:07:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [280/3125], step: 12780, 3.041 samples/sec, batch_loss: 0.3286, batch_loss_c: 0.3392, batch_loss_s: 0.3040, time:13.1521, lr:0.001\u001b[0m\n",
            "2019-11-25 11:07:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [290/3125], step: 12790, 3.058 samples/sec, batch_loss: 0.3815, batch_loss_c: 0.3919, batch_loss_s: 0.3573, time:13.0809, lr:0.001\u001b[0m\n",
            "2019-11-25 11:07:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [300/3125], step: 12800, 3.059 samples/sec, batch_loss: 0.3204, batch_loss_c: 0.3151, batch_loss_s: 0.3327, time:13.0780, lr:0.001\u001b[0m\n",
            "2019-11-25 11:07:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [310/3125], step: 12810, 3.023 samples/sec, batch_loss: 0.1775, batch_loss_c: 0.2037, batch_loss_s: 0.1164, time:13.2324, lr:0.001\u001b[0m\n",
            "2019-11-25 11:07:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [320/3125], step: 12820, 3.009 samples/sec, batch_loss: 0.2746, batch_loss_c: 0.3103, batch_loss_s: 0.1913, time:13.2925, lr:0.001\u001b[0m\n",
            "2019-11-25 11:08:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [330/3125], step: 12830, 3.048 samples/sec, batch_loss: 0.1142, batch_loss_c: 0.1117, batch_loss_s: 0.1200, time:13.1227, lr:0.001\u001b[0m\n",
            "2019-11-25 11:08:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [340/3125], step: 12840, 3.018 samples/sec, batch_loss: 0.3208, batch_loss_c: 0.3134, batch_loss_s: 0.3379, time:13.2521, lr:0.001\u001b[0m\n",
            "2019-11-25 11:08:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [350/3125], step: 12850, 3.010 samples/sec, batch_loss: 0.3446, batch_loss_c: 0.3361, batch_loss_s: 0.3644, time:13.2893, lr:0.001\u001b[0m\n",
            "2019-11-25 11:08:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [360/3125], step: 12860, 3.012 samples/sec, batch_loss: 0.1410, batch_loss_c: 0.1561, batch_loss_s: 0.1059, time:13.2789, lr:0.001\u001b[0m\n",
            "2019-11-25 11:09:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [370/3125], step: 12870, 3.039 samples/sec, batch_loss: 0.5948, batch_loss_c: 0.6041, batch_loss_s: 0.5733, time:13.1613, lr:0.001\u001b[0m\n",
            "2019-11-25 11:09:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [380/3125], step: 12880, 3.000 samples/sec, batch_loss: 0.2101, batch_loss_c: 0.2052, batch_loss_s: 0.2215, time:13.3342, lr:0.001\u001b[0m\n",
            "2019-11-25 11:09:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [390/3125], step: 12890, 3.006 samples/sec, batch_loss: 0.0910, batch_loss_c: 0.0879, batch_loss_s: 0.0983, time:13.3066, lr:0.001\u001b[0m\n",
            "2019-11-25 11:09:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [400/3125], step: 12900, 3.000 samples/sec, batch_loss: 0.3585, batch_loss_c: 0.3690, batch_loss_s: 0.3341, time:13.3344, lr:0.001\u001b[0m\n",
            "2019-11-25 11:09:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [410/3125], step: 12910, 2.981 samples/sec, batch_loss: 0.1172, batch_loss_c: 0.1360, batch_loss_s: 0.0731, time:13.4186, lr:0.001\u001b[0m\n",
            "2019-11-25 11:10:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [420/3125], step: 12920, 3.066 samples/sec, batch_loss: 0.1189, batch_loss_c: 0.1278, batch_loss_s: 0.0980, time:13.0454, lr:0.001\u001b[0m\n",
            "2019-11-25 11:10:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [430/3125], step: 12930, 3.043 samples/sec, batch_loss: 0.2438, batch_loss_c: 0.2377, batch_loss_s: 0.2581, time:13.1437, lr:0.001\u001b[0m\n",
            "2019-11-25 11:10:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [440/3125], step: 12940, 3.033 samples/sec, batch_loss: 0.2790, batch_loss_c: 0.3049, batch_loss_s: 0.2185, time:13.1867, lr:0.001\u001b[0m\n",
            "2019-11-25 11:10:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [450/3125], step: 12950, 2.923 samples/sec, batch_loss: 0.1249, batch_loss_c: 0.1276, batch_loss_s: 0.1187, time:13.6849, lr:0.001\u001b[0m\n",
            "2019-11-25 11:11:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [460/3125], step: 12960, 3.010 samples/sec, batch_loss: 0.1425, batch_loss_c: 0.1454, batch_loss_s: 0.1356, time:13.2880, lr:0.001\u001b[0m\n",
            "2019-11-25 11:11:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [470/3125], step: 12970, 2.966 samples/sec, batch_loss: 0.1166, batch_loss_c: 0.1278, batch_loss_s: 0.0907, time:13.4864, lr:0.001\u001b[0m\n",
            "2019-11-25 11:11:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [480/3125], step: 12980, 3.000 samples/sec, batch_loss: 0.1163, batch_loss_c: 0.1160, batch_loss_s: 0.1168, time:13.3325, lr:0.001\u001b[0m\n",
            "2019-11-25 11:11:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [490/3125], step: 12990, 3.010 samples/sec, batch_loss: 0.2583, batch_loss_c: 0.2930, batch_loss_s: 0.1775, time:13.2889, lr:0.001\u001b[0m\n",
            "2019-11-25 11:11:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [500/3125], step: 13000, 2.956 samples/sec, batch_loss: 0.2095, batch_loss_c: 0.2228, batch_loss_s: 0.1785, time:13.5295, lr:0.001\u001b[0m\n",
            "2019-11-25 11:12:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [510/3125], step: 13010, 2.956 samples/sec, batch_loss: 0.5057, batch_loss_c: 0.5346, batch_loss_s: 0.4382, time:13.5313, lr:0.001\u001b[0m\n",
            "2019-11-25 11:12:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [520/3125], step: 13020, 2.989 samples/sec, batch_loss: 0.3335, batch_loss_c: 0.3345, batch_loss_s: 0.3310, time:13.3804, lr:0.001\u001b[0m\n",
            "2019-11-25 11:12:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [530/3125], step: 13030, 2.994 samples/sec, batch_loss: 0.5168, batch_loss_c: 0.5022, batch_loss_s: 0.5510, time:13.3609, lr:0.001\u001b[0m\n",
            "2019-11-25 11:12:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [540/3125], step: 13040, 2.996 samples/sec, batch_loss: 0.0806, batch_loss_c: 0.0733, batch_loss_s: 0.0975, time:13.3522, lr:0.001\u001b[0m\n",
            "2019-11-25 11:13:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [550/3125], step: 13050, 3.008 samples/sec, batch_loss: 0.1156, batch_loss_c: 0.1163, batch_loss_s: 0.1141, time:13.2995, lr:0.001\u001b[0m\n",
            "2019-11-25 11:13:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [560/3125], step: 13060, 3.046 samples/sec, batch_loss: 0.1178, batch_loss_c: 0.1256, batch_loss_s: 0.0997, time:13.1330, lr:0.001\u001b[0m\n",
            "2019-11-25 11:13:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [570/3125], step: 13070, 2.988 samples/sec, batch_loss: 0.1170, batch_loss_c: 0.1211, batch_loss_s: 0.1072, time:13.3857, lr:0.001\u001b[0m\n",
            "2019-11-25 11:13:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [580/3125], step: 13080, 2.990 samples/sec, batch_loss: 0.1290, batch_loss_c: 0.1463, batch_loss_s: 0.0885, time:13.3781, lr:0.001\u001b[0m\n",
            "2019-11-25 11:13:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [590/3125], step: 13090, 2.972 samples/sec, batch_loss: 0.6227, batch_loss_c: 0.5758, batch_loss_s: 0.7321, time:13.4570, lr:0.001\u001b[0m\n",
            "2019-11-25 11:14:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [600/3125], step: 13100, 2.994 samples/sec, batch_loss: 0.3650, batch_loss_c: 0.3882, batch_loss_s: 0.3110, time:13.3581, lr:0.001\u001b[0m\n",
            "2019-11-25 11:14:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [610/3125], step: 13110, 3.051 samples/sec, batch_loss: 0.5480, batch_loss_c: 0.5478, batch_loss_s: 0.5482, time:13.1124, lr:0.001\u001b[0m\n",
            "2019-11-25 11:14:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [620/3125], step: 13120, 3.037 samples/sec, batch_loss: 0.2848, batch_loss_c: 0.2707, batch_loss_s: 0.3177, time:13.1693, lr:0.001\u001b[0m\n",
            "2019-11-25 11:14:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [630/3125], step: 13130, 3.020 samples/sec, batch_loss: 0.1453, batch_loss_c: 0.1532, batch_loss_s: 0.1269, time:13.2433, lr:0.001\u001b[0m\n",
            "2019-11-25 11:15:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [640/3125], step: 13140, 2.982 samples/sec, batch_loss: 0.1803, batch_loss_c: 0.2182, batch_loss_s: 0.0920, time:13.4125, lr:0.001\u001b[0m\n",
            "2019-11-25 11:15:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [650/3125], step: 13150, 3.016 samples/sec, batch_loss: 0.0944, batch_loss_c: 0.0949, batch_loss_s: 0.0932, time:13.2640, lr:0.001\u001b[0m\n",
            "2019-11-25 11:15:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [660/3125], step: 13160, 3.012 samples/sec, batch_loss: 0.5412, batch_loss_c: 0.5392, batch_loss_s: 0.5460, time:13.2810, lr:0.001\u001b[0m\n",
            "2019-11-25 11:15:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [670/3125], step: 13170, 3.048 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1161, batch_loss_s: 0.1092, time:13.1221, lr:0.001\u001b[0m\n",
            "2019-11-25 11:15:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [680/3125], step: 13180, 2.993 samples/sec, batch_loss: 0.1254, batch_loss_c: 0.1271, batch_loss_s: 0.1215, time:13.3650, lr:0.001\u001b[0m\n",
            "2019-11-25 11:16:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [690/3125], step: 13190, 3.066 samples/sec, batch_loss: 0.5195, batch_loss_c: 0.5041, batch_loss_s: 0.5555, time:13.0481, lr:0.001\u001b[0m\n",
            "2019-11-25 11:16:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [700/3125], step: 13200, 3.028 samples/sec, batch_loss: 0.3169, batch_loss_c: 0.3053, batch_loss_s: 0.3441, time:13.2104, lr:0.001\u001b[0m\n",
            "2019-11-25 11:16:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [710/3125], step: 13210, 3.000 samples/sec, batch_loss: 0.0997, batch_loss_c: 0.0973, batch_loss_s: 0.1054, time:13.3320, lr:0.001\u001b[0m\n",
            "2019-11-25 11:16:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [720/3125], step: 13220, 3.024 samples/sec, batch_loss: 0.0991, batch_loss_c: 0.0946, batch_loss_s: 0.1095, time:13.2260, lr:0.001\u001b[0m\n",
            "2019-11-25 11:17:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [730/3125], step: 13230, 2.984 samples/sec, batch_loss: 0.2178, batch_loss_c: 0.2317, batch_loss_s: 0.1852, time:13.4042, lr:0.001\u001b[0m\n",
            "2019-11-25 11:17:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [740/3125], step: 13240, 3.011 samples/sec, batch_loss: 0.3381, batch_loss_c: 0.3280, batch_loss_s: 0.3618, time:13.2832, lr:0.001\u001b[0m\n",
            "2019-11-25 11:17:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [750/3125], step: 13250, 2.998 samples/sec, batch_loss: 0.1862, batch_loss_c: 0.1856, batch_loss_s: 0.1875, time:13.3418, lr:0.001\u001b[0m\n",
            "2019-11-25 11:17:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [760/3125], step: 13260, 3.018 samples/sec, batch_loss: 0.1036, batch_loss_c: 0.1101, batch_loss_s: 0.0882, time:13.2517, lr:0.001\u001b[0m\n",
            "2019-11-25 11:17:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [770/3125], step: 13270, 2.952 samples/sec, batch_loss: 0.0836, batch_loss_c: 0.0819, batch_loss_s: 0.0874, time:13.5503, lr:0.001\u001b[0m\n",
            "2019-11-25 11:18:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [780/3125], step: 13280, 2.979 samples/sec, batch_loss: 0.1252, batch_loss_c: 0.1386, batch_loss_s: 0.0941, time:13.4256, lr:0.001\u001b[0m\n",
            "2019-11-25 11:18:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [790/3125], step: 13290, 2.984 samples/sec, batch_loss: 0.3493, batch_loss_c: 0.3575, batch_loss_s: 0.3304, time:13.4041, lr:0.001\u001b[0m\n",
            "2019-11-25 11:18:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [800/3125], step: 13300, 2.957 samples/sec, batch_loss: 0.2355, batch_loss_c: 0.2238, batch_loss_s: 0.2629, time:13.5286, lr:0.001\u001b[0m\n",
            "2019-11-25 11:18:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [810/3125], step: 13310, 3.012 samples/sec, batch_loss: 0.0659, batch_loss_c: 0.0642, batch_loss_s: 0.0697, time:13.2818, lr:0.001\u001b[0m\n",
            "2019-11-25 11:19:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [820/3125], step: 13320, 3.020 samples/sec, batch_loss: 0.3180, batch_loss_c: 0.3200, batch_loss_s: 0.3131, time:13.2430, lr:0.001\u001b[0m\n",
            "2019-11-25 11:19:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [830/3125], step: 13330, 3.029 samples/sec, batch_loss: 0.2977, batch_loss_c: 0.2845, batch_loss_s: 0.3285, time:13.2075, lr:0.001\u001b[0m\n",
            "2019-11-25 11:19:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [840/3125], step: 13340, 3.004 samples/sec, batch_loss: 0.3706, batch_loss_c: 0.3672, batch_loss_s: 0.3785, time:13.3177, lr:0.001\u001b[0m\n",
            "2019-11-25 11:19:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [850/3125], step: 13350, 3.019 samples/sec, batch_loss: 0.3422, batch_loss_c: 0.3421, batch_loss_s: 0.3423, time:13.2513, lr:0.001\u001b[0m\n",
            "2019-11-25 11:19:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [860/3125], step: 13360, 2.930 samples/sec, batch_loss: 0.1540, batch_loss_c: 0.1706, batch_loss_s: 0.1153, time:13.6512, lr:0.001\u001b[0m\n",
            "2019-11-25 11:20:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [870/3125], step: 13370, 2.994 samples/sec, batch_loss: 0.1214, batch_loss_c: 0.1292, batch_loss_s: 0.1033, time:13.3605, lr:0.001\u001b[0m\n",
            "2019-11-25 11:20:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [880/3125], step: 13380, 2.995 samples/sec, batch_loss: 0.2675, batch_loss_c: 0.3204, batch_loss_s: 0.1441, time:13.3550, lr:0.001\u001b[0m\n",
            "2019-11-25 11:20:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [890/3125], step: 13390, 2.931 samples/sec, batch_loss: 0.1465, batch_loss_c: 0.1687, batch_loss_s: 0.0948, time:13.6495, lr:0.001\u001b[0m\n",
            "2019-11-25 11:20:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [900/3125], step: 13400, 2.913 samples/sec, batch_loss: 0.4141, batch_loss_c: 0.4244, batch_loss_s: 0.3901, time:13.7313, lr:0.001\u001b[0m\n",
            "2019-11-25 11:21:03 \u001b[32mINFO     \u001b[0m train.py: [4/10], [910/3125], step: 13410, 3.003 samples/sec, batch_loss: 0.1451, batch_loss_c: 0.1490, batch_loss_s: 0.1360, time:13.3210, lr:0.001\u001b[0m\n",
            "2019-11-25 11:21:16 \u001b[32mINFO     \u001b[0m train.py: [4/10], [920/3125], step: 13420, 3.069 samples/sec, batch_loss: 0.1296, batch_loss_c: 0.1463, batch_loss_s: 0.0908, time:13.0332, lr:0.001\u001b[0m\n",
            "2019-11-25 11:21:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [930/3125], step: 13430, 3.009 samples/sec, batch_loss: 0.3466, batch_loss_c: 0.3469, batch_loss_s: 0.3460, time:13.2955, lr:0.001\u001b[0m\n",
            "2019-11-25 11:21:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [940/3125], step: 13440, 3.028 samples/sec, batch_loss: 0.3687, batch_loss_c: 0.3688, batch_loss_s: 0.3685, time:13.2085, lr:0.001\u001b[0m\n",
            "2019-11-25 11:21:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [950/3125], step: 13450, 3.013 samples/sec, batch_loss: 0.1030, batch_loss_c: 0.1161, batch_loss_s: 0.0724, time:13.2739, lr:0.001\u001b[0m\n",
            "2019-11-25 11:22:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [960/3125], step: 13460, 2.951 samples/sec, batch_loss: 0.2483, batch_loss_c: 0.2504, batch_loss_s: 0.2435, time:13.5535, lr:0.001\u001b[0m\n",
            "2019-11-25 11:22:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [970/3125], step: 13470, 3.018 samples/sec, batch_loss: 0.2708, batch_loss_c: 0.2513, batch_loss_s: 0.3165, time:13.2551, lr:0.001\u001b[0m\n",
            "2019-11-25 11:22:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [980/3125], step: 13480, 2.936 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1365, batch_loss_s: 0.1103, time:13.6250, lr:0.001\u001b[0m\n",
            "2019-11-25 11:22:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [990/3125], step: 13490, 3.029 samples/sec, batch_loss: 0.2176, batch_loss_c: 0.2369, batch_loss_s: 0.1726, time:13.2043, lr:0.001\u001b[0m\n",
            "2019-11-25 11:23:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1000/3125], step: 13500, 2.997 samples/sec, batch_loss: 0.3457, batch_loss_c: 0.3469, batch_loss_s: 0.3427, time:13.3450, lr:0.001\u001b[0m\n",
            "2019-11-25 11:23:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1010/3125], step: 13510, 3.033 samples/sec, batch_loss: 0.4882, batch_loss_c: 0.5121, batch_loss_s: 0.4324, time:13.1866, lr:0.001\u001b[0m\n",
            "2019-11-25 11:23:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1020/3125], step: 13520, 2.993 samples/sec, batch_loss: 0.3422, batch_loss_c: 0.3445, batch_loss_s: 0.3369, time:13.3642, lr:0.001\u001b[0m\n",
            "2019-11-25 11:23:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1030/3125], step: 13530, 3.022 samples/sec, batch_loss: 0.0931, batch_loss_c: 0.0988, batch_loss_s: 0.0798, time:13.2363, lr:0.001\u001b[0m\n",
            "2019-11-25 11:23:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1040/3125], step: 13540, 2.992 samples/sec, batch_loss: 0.0797, batch_loss_c: 0.0768, batch_loss_s: 0.0866, time:13.3679, lr:0.001\u001b[0m\n",
            "2019-11-25 11:24:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1050/3125], step: 13550, 2.998 samples/sec, batch_loss: 0.5383, batch_loss_c: 0.5377, batch_loss_s: 0.5396, time:13.3404, lr:0.001\u001b[0m\n",
            "2019-11-25 11:24:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1060/3125], step: 13560, 2.993 samples/sec, batch_loss: 0.1232, batch_loss_c: 0.1351, batch_loss_s: 0.0954, time:13.3626, lr:0.001\u001b[0m\n",
            "2019-11-25 11:24:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1070/3125], step: 13570, 3.019 samples/sec, batch_loss: 0.1529, batch_loss_c: 0.1725, batch_loss_s: 0.1074, time:13.2493, lr:0.001\u001b[0m\n",
            "2019-11-25 11:24:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1080/3125], step: 13580, 3.040 samples/sec, batch_loss: 0.3626, batch_loss_c: 0.3697, batch_loss_s: 0.3461, time:13.1570, lr:0.001\u001b[0m\n",
            "2019-11-25 11:25:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1090/3125], step: 13590, 3.045 samples/sec, batch_loss: 0.0763, batch_loss_c: 0.0694, batch_loss_s: 0.0926, time:13.1373, lr:0.001\u001b[0m\n",
            "2019-11-25 11:25:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1100/3125], step: 13600, 3.038 samples/sec, batch_loss: 0.3562, batch_loss_c: 0.3716, batch_loss_s: 0.3203, time:13.1651, lr:0.001\u001b[0m\n",
            "2019-11-25 11:25:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1110/3125], step: 13610, 2.989 samples/sec, batch_loss: 0.3343, batch_loss_c: 0.3286, batch_loss_s: 0.3476, time:13.3818, lr:0.001\u001b[0m\n",
            "2019-11-25 11:25:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1120/3125], step: 13620, 3.020 samples/sec, batch_loss: 0.1484, batch_loss_c: 0.1671, batch_loss_s: 0.1050, time:13.2445, lr:0.001\u001b[0m\n",
            "2019-11-25 11:25:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1130/3125], step: 13630, 2.991 samples/sec, batch_loss: 0.2747, batch_loss_c: 0.3259, batch_loss_s: 0.1553, time:13.3751, lr:0.001\u001b[0m\n",
            "2019-11-25 11:26:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1140/3125], step: 13640, 3.000 samples/sec, batch_loss: 0.1624, batch_loss_c: 0.1794, batch_loss_s: 0.1226, time:13.3314, lr:0.001\u001b[0m\n",
            "2019-11-25 11:26:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1150/3125], step: 13650, 2.975 samples/sec, batch_loss: 0.0874, batch_loss_c: 0.0829, batch_loss_s: 0.0981, time:13.4432, lr:0.001\u001b[0m\n",
            "2019-11-25 11:26:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1160/3125], step: 13660, 3.020 samples/sec, batch_loss: 0.3312, batch_loss_c: 0.3358, batch_loss_s: 0.3205, time:13.2437, lr:0.001\u001b[0m\n",
            "2019-11-25 11:26:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1170/3125], step: 13670, 3.009 samples/sec, batch_loss: 0.2626, batch_loss_c: 0.3082, batch_loss_s: 0.1561, time:13.2941, lr:0.001\u001b[0m\n",
            "2019-11-25 11:27:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1180/3125], step: 13680, 2.993 samples/sec, batch_loss: 0.1135, batch_loss_c: 0.1142, batch_loss_s: 0.1120, time:13.3660, lr:0.001\u001b[0m\n",
            "2019-11-25 11:27:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1190/3125], step: 13690, 2.997 samples/sec, batch_loss: 0.3156, batch_loss_c: 0.3103, batch_loss_s: 0.3282, time:13.3477, lr:0.001\u001b[0m\n",
            "2019-11-25 11:27:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1200/3125], step: 13700, 2.994 samples/sec, batch_loss: 0.4138, batch_loss_c: 0.4455, batch_loss_s: 0.3399, time:13.3606, lr:0.001\u001b[0m\n",
            "2019-11-25 11:27:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1210/3125], step: 13710, 2.980 samples/sec, batch_loss: 0.4999, batch_loss_c: 0.4781, batch_loss_s: 0.5506, time:13.4232, lr:0.001\u001b[0m\n",
            "2019-11-25 11:27:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1220/3125], step: 13720, 3.041 samples/sec, batch_loss: 0.1248, batch_loss_c: 0.1259, batch_loss_s: 0.1221, time:13.1528, lr:0.001\u001b[0m\n",
            "2019-11-25 11:28:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1230/3125], step: 13730, 3.043 samples/sec, batch_loss: 0.1004, batch_loss_c: 0.1015, batch_loss_s: 0.0978, time:13.1441, lr:0.001\u001b[0m\n",
            "2019-11-25 11:28:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1240/3125], step: 13740, 3.036 samples/sec, batch_loss: 0.0723, batch_loss_c: 0.0658, batch_loss_s: 0.0873, time:13.1731, lr:0.001\u001b[0m\n",
            "2019-11-25 11:28:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1250/3125], step: 13750, 3.007 samples/sec, batch_loss: 0.3162, batch_loss_c: 0.3194, batch_loss_s: 0.3088, time:13.3044, lr:0.001\u001b[0m\n",
            "2019-11-25 11:28:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1260/3125], step: 13760, 3.031 samples/sec, batch_loss: 0.2366, batch_loss_c: 0.2101, batch_loss_s: 0.2986, time:13.1954, lr:0.001\u001b[0m\n",
            "2019-11-25 11:29:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1270/3125], step: 13770, 3.023 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0762, batch_loss_s: 0.0802, time:13.2331, lr:0.001\u001b[0m\n",
            "2019-11-25 11:29:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1280/3125], step: 13780, 3.030 samples/sec, batch_loss: 0.1333, batch_loss_c: 0.1355, batch_loss_s: 0.1281, time:13.1993, lr:0.001\u001b[0m\n",
            "2019-11-25 11:29:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1290/3125], step: 13790, 3.029 samples/sec, batch_loss: 0.1099, batch_loss_c: 0.1195, batch_loss_s: 0.0874, time:13.2043, lr:0.001\u001b[0m\n",
            "2019-11-25 11:29:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1300/3125], step: 13800, 3.021 samples/sec, batch_loss: 0.1076, batch_loss_c: 0.1058, batch_loss_s: 0.1117, time:13.2403, lr:0.001\u001b[0m\n",
            "2019-11-25 11:29:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1310/3125], step: 13810, 3.033 samples/sec, batch_loss: 0.2918, batch_loss_c: 0.2883, batch_loss_s: 0.3001, time:13.1892, lr:0.001\u001b[0m\n",
            "2019-11-25 11:30:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1320/3125], step: 13820, 2.986 samples/sec, batch_loss: 0.3797, batch_loss_c: 0.4080, batch_loss_s: 0.3137, time:13.3976, lr:0.001\u001b[0m\n",
            "2019-11-25 11:30:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1330/3125], step: 13830, 3.012 samples/sec, batch_loss: 0.0760, batch_loss_c: 0.0784, batch_loss_s: 0.0705, time:13.2799, lr:0.001\u001b[0m\n",
            "2019-11-25 11:30:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1340/3125], step: 13840, 2.982 samples/sec, batch_loss: 0.3086, batch_loss_c: 0.3067, batch_loss_s: 0.3131, time:13.4160, lr:0.001\u001b[0m\n",
            "2019-11-25 11:30:47 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1350/3125], step: 13850, 3.024 samples/sec, batch_loss: 0.0876, batch_loss_c: 0.0778, batch_loss_s: 0.1106, time:13.2256, lr:0.001\u001b[0m\n",
            "2019-11-25 11:31:00 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1360/3125], step: 13860, 3.088 samples/sec, batch_loss: 0.1767, batch_loss_c: 0.1981, batch_loss_s: 0.1267, time:12.9527, lr:0.001\u001b[0m\n",
            "2019-11-25 11:31:13 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1370/3125], step: 13870, 3.001 samples/sec, batch_loss: 0.1056, batch_loss_c: 0.1092, batch_loss_s: 0.0970, time:13.3297, lr:0.001\u001b[0m\n",
            "2019-11-25 11:31:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1380/3125], step: 13880, 3.031 samples/sec, batch_loss: 0.1498, batch_loss_c: 0.1640, batch_loss_s: 0.1168, time:13.1979, lr:0.001\u001b[0m\n",
            "2019-11-25 11:31:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1390/3125], step: 13890, 3.027 samples/sec, batch_loss: 0.2001, batch_loss_c: 0.2346, batch_loss_s: 0.1196, time:13.2142, lr:0.001\u001b[0m\n",
            "2019-11-25 11:31:53 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1400/3125], step: 13900, 3.028 samples/sec, batch_loss: 0.2943, batch_loss_c: 0.2764, batch_loss_s: 0.3360, time:13.2082, lr:0.001\u001b[0m\n",
            "2019-11-25 11:32:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1410/3125], step: 13910, 2.998 samples/sec, batch_loss: 0.1219, batch_loss_c: 0.1304, batch_loss_s: 0.1022, time:13.3401, lr:0.001\u001b[0m\n",
            "2019-11-25 11:32:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1420/3125], step: 13920, 3.027 samples/sec, batch_loss: 0.2025, batch_loss_c: 0.2485, batch_loss_s: 0.0950, time:13.2124, lr:0.001\u001b[0m\n",
            "2019-11-25 11:32:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1430/3125], step: 13930, 3.049 samples/sec, batch_loss: 0.3464, batch_loss_c: 0.3488, batch_loss_s: 0.3408, time:13.1188, lr:0.001\u001b[0m\n",
            "2019-11-25 11:32:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1440/3125], step: 13940, 3.016 samples/sec, batch_loss: 0.3666, batch_loss_c: 0.3663, batch_loss_s: 0.3676, time:13.2616, lr:0.001\u001b[0m\n",
            "2019-11-25 11:32:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1450/3125], step: 13950, 2.999 samples/sec, batch_loss: 0.1312, batch_loss_c: 0.1314, batch_loss_s: 0.1307, time:13.3383, lr:0.001\u001b[0m\n",
            "2019-11-25 11:33:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1460/3125], step: 13960, 3.030 samples/sec, batch_loss: 0.3129, batch_loss_c: 0.3106, batch_loss_s: 0.3181, time:13.1993, lr:0.001\u001b[0m\n",
            "2019-11-25 11:33:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1470/3125], step: 13970, 3.005 samples/sec, batch_loss: 0.2187, batch_loss_c: 0.2358, batch_loss_s: 0.1788, time:13.3093, lr:0.001\u001b[0m\n",
            "2019-11-25 11:33:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1480/3125], step: 13980, 3.044 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1065, batch_loss_s: 0.1129, time:13.1425, lr:0.001\u001b[0m\n",
            "2019-11-25 11:33:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1490/3125], step: 13990, 2.998 samples/sec, batch_loss: 0.5143, batch_loss_c: 0.5011, batch_loss_s: 0.5451, time:13.3413, lr:0.001\u001b[0m\n",
            "2019-11-25 11:34:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1500/3125], step: 14000, 3.020 samples/sec, batch_loss: 0.2337, batch_loss_c: 0.2563, batch_loss_s: 0.1810, time:13.2460, lr:0.001\u001b[0m\n",
            "2019-11-25 11:34:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1510/3125], step: 14010, 3.017 samples/sec, batch_loss: 0.3868, batch_loss_c: 0.3891, batch_loss_s: 0.3815, time:13.2586, lr:0.001\u001b[0m\n",
            "2019-11-25 11:34:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1520/3125], step: 14020, 2.993 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1192, batch_loss_s: 0.1011, time:13.3666, lr:0.001\u001b[0m\n",
            "2019-11-25 11:34:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1530/3125], step: 14030, 3.049 samples/sec, batch_loss: 0.2779, batch_loss_c: 0.2595, batch_loss_s: 0.3209, time:13.1174, lr:0.001\u001b[0m\n",
            "2019-11-25 11:34:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1540/3125], step: 14040, 2.954 samples/sec, batch_loss: 0.2950, batch_loss_c: 0.2916, batch_loss_s: 0.3030, time:13.5426, lr:0.001\u001b[0m\n",
            "2019-11-25 11:35:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1550/3125], step: 14050, 2.994 samples/sec, batch_loss: 0.8035, batch_loss_c: 0.7864, batch_loss_s: 0.8434, time:13.3581, lr:0.001\u001b[0m\n",
            "2019-11-25 11:35:26 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1560/3125], step: 14060, 2.971 samples/sec, batch_loss: 0.2405, batch_loss_c: 0.3005, batch_loss_s: 0.1005, time:13.4635, lr:0.001\u001b[0m\n",
            "2019-11-25 11:35:39 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1570/3125], step: 14070, 2.978 samples/sec, batch_loss: 0.1566, batch_loss_c: 0.1667, batch_loss_s: 0.1330, time:13.4305, lr:0.001\u001b[0m\n",
            "2019-11-25 11:35:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1580/3125], step: 14080, 3.026 samples/sec, batch_loss: 0.4065, batch_loss_c: 0.4196, batch_loss_s: 0.3761, time:13.2184, lr:0.001\u001b[0m\n",
            "2019-11-25 11:36:06 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1590/3125], step: 14090, 2.955 samples/sec, batch_loss: 0.3227, batch_loss_c: 0.3170, batch_loss_s: 0.3358, time:13.5382, lr:0.001\u001b[0m\n",
            "2019-11-25 11:36:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1600/3125], step: 14100, 3.005 samples/sec, batch_loss: 0.2083, batch_loss_c: 0.2514, batch_loss_s: 0.1077, time:13.3133, lr:0.001\u001b[0m\n",
            "2019-11-25 11:36:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1610/3125], step: 14110, 3.061 samples/sec, batch_loss: 0.3161, batch_loss_c: 0.3017, batch_loss_s: 0.3497, time:13.0691, lr:0.001\u001b[0m\n",
            "2019-11-25 11:36:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1620/3125], step: 14120, 3.028 samples/sec, batch_loss: 0.3636, batch_loss_c: 0.3677, batch_loss_s: 0.3541, time:13.2119, lr:0.001\u001b[0m\n",
            "2019-11-25 11:36:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1630/3125], step: 14130, 3.050 samples/sec, batch_loss: 0.3622, batch_loss_c: 0.3639, batch_loss_s: 0.3582, time:13.1167, lr:0.001\u001b[0m\n",
            "2019-11-25 11:37:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1640/3125], step: 14140, 2.995 samples/sec, batch_loss: 0.2914, batch_loss_c: 0.2772, batch_loss_s: 0.3245, time:13.3547, lr:0.001\u001b[0m\n",
            "2019-11-25 11:37:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1650/3125], step: 14150, 3.019 samples/sec, batch_loss: 0.1248, batch_loss_c: 0.1262, batch_loss_s: 0.1216, time:13.2476, lr:0.001\u001b[0m\n",
            "2019-11-25 11:37:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1660/3125], step: 14160, 2.992 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1680, batch_loss_s: 0.1270, time:13.3700, lr:0.001\u001b[0m\n",
            "2019-11-25 11:37:52 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1670/3125], step: 14170, 3.021 samples/sec, batch_loss: 0.1065, batch_loss_c: 0.1114, batch_loss_s: 0.0951, time:13.2417, lr:0.001\u001b[0m\n",
            "2019-11-25 11:38:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1680/3125], step: 14180, 3.021 samples/sec, batch_loss: 0.3492, batch_loss_c: 0.3471, batch_loss_s: 0.3539, time:13.2387, lr:0.001\u001b[0m\n",
            "2019-11-25 11:38:19 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1690/3125], step: 14190, 2.946 samples/sec, batch_loss: 0.2709, batch_loss_c: 0.2725, batch_loss_s: 0.2670, time:13.5765, lr:0.001\u001b[0m\n",
            "2019-11-25 11:38:32 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1700/3125], step: 14200, 3.022 samples/sec, batch_loss: 0.5598, batch_loss_c: 0.5650, batch_loss_s: 0.5476, time:13.2384, lr:0.001\u001b[0m\n",
            "2019-11-25 11:38:45 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1710/3125], step: 14210, 2.972 samples/sec, batch_loss: 0.1098, batch_loss_c: 0.1169, batch_loss_s: 0.0933, time:13.4579, lr:0.001\u001b[0m\n",
            "2019-11-25 11:38:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1720/3125], step: 14220, 3.023 samples/sec, batch_loss: 0.3748, batch_loss_c: 0.4031, batch_loss_s: 0.3089, time:13.2337, lr:0.001\u001b[0m\n",
            "2019-11-25 11:39:12 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1730/3125], step: 14230, 3.053 samples/sec, batch_loss: 0.2570, batch_loss_c: 0.2452, batch_loss_s: 0.2846, time:13.1016, lr:0.001\u001b[0m\n",
            "2019-11-25 11:39:25 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1740/3125], step: 14240, 3.058 samples/sec, batch_loss: 0.2375, batch_loss_c: 0.2598, batch_loss_s: 0.1852, time:13.0791, lr:0.001\u001b[0m\n",
            "2019-11-25 11:39:38 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1750/3125], step: 14250, 3.053 samples/sec, batch_loss: 0.1204, batch_loss_c: 0.1293, batch_loss_s: 0.0996, time:13.1038, lr:0.001\u001b[0m\n",
            "2019-11-25 11:39:51 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1760/3125], step: 14260, 2.987 samples/sec, batch_loss: 0.1002, batch_loss_c: 0.1076, batch_loss_s: 0.0829, time:13.3935, lr:0.001\u001b[0m\n",
            "2019-11-25 11:40:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1770/3125], step: 14270, 3.029 samples/sec, batch_loss: 0.1297, batch_loss_c: 0.1452, batch_loss_s: 0.0937, time:13.2066, lr:0.001\u001b[0m\n",
            "2019-11-25 11:40:18 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1780/3125], step: 14280, 3.008 samples/sec, batch_loss: 0.2609, batch_loss_c: 0.2423, batch_loss_s: 0.3043, time:13.2968, lr:0.001\u001b[0m\n",
            "2019-11-25 11:40:31 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1790/3125], step: 14290, 3.001 samples/sec, batch_loss: 0.1605, batch_loss_c: 0.1637, batch_loss_s: 0.1529, time:13.3297, lr:0.001\u001b[0m\n",
            "2019-11-25 11:40:44 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1800/3125], step: 14300, 3.007 samples/sec, batch_loss: 0.1448, batch_loss_c: 0.1586, batch_loss_s: 0.1126, time:13.3021, lr:0.001\u001b[0m\n",
            "2019-11-25 11:40:58 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1810/3125], step: 14310, 2.994 samples/sec, batch_loss: 0.1048, batch_loss_c: 0.1035, batch_loss_s: 0.1079, time:13.3579, lr:0.001\u001b[0m\n",
            "2019-11-25 11:41:11 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1820/3125], step: 14320, 3.019 samples/sec, batch_loss: 0.3657, batch_loss_c: 0.3806, batch_loss_s: 0.3307, time:13.2505, lr:0.001\u001b[0m\n",
            "2019-11-25 11:41:24 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1830/3125], step: 14330, 3.014 samples/sec, batch_loss: 0.0863, batch_loss_c: 0.0876, batch_loss_s: 0.0834, time:13.2731, lr:0.001\u001b[0m\n",
            "2019-11-25 11:41:37 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1840/3125], step: 14340, 3.070 samples/sec, batch_loss: 0.0976, batch_loss_c: 0.1013, batch_loss_s: 0.0891, time:13.0273, lr:0.001\u001b[0m\n",
            "2019-11-25 11:41:50 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1850/3125], step: 14350, 3.009 samples/sec, batch_loss: 0.6203, batch_loss_c: 0.6412, batch_loss_s: 0.5714, time:13.2921, lr:0.001\u001b[0m\n",
            "2019-11-25 11:42:04 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1860/3125], step: 14360, 3.010 samples/sec, batch_loss: 0.3628, batch_loss_c: 0.3659, batch_loss_s: 0.3555, time:13.2899, lr:0.001\u001b[0m\n",
            "2019-11-25 11:42:17 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1870/3125], step: 14370, 3.024 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1682, batch_loss_s: 0.1098, time:13.2257, lr:0.001\u001b[0m\n",
            "2019-11-25 11:42:30 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1880/3125], step: 14380, 3.019 samples/sec, batch_loss: 0.0971, batch_loss_c: 0.1009, batch_loss_s: 0.0883, time:13.2475, lr:0.001\u001b[0m\n",
            "2019-11-25 11:42:43 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1890/3125], step: 14390, 3.048 samples/sec, batch_loss: 0.1653, batch_loss_c: 0.1854, batch_loss_s: 0.1185, time:13.1248, lr:0.001\u001b[0m\n",
            "2019-11-25 11:42:56 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1900/3125], step: 14400, 3.061 samples/sec, batch_loss: 0.2085, batch_loss_c: 0.2495, batch_loss_s: 0.1129, time:13.0691, lr:0.001\u001b[0m\n",
            "2019-11-25 11:43:10 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1910/3125], step: 14410, 3.036 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1537, batch_loss_s: 0.1603, time:13.1751, lr:0.001\u001b[0m\n",
            "2019-11-25 11:43:23 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1920/3125], step: 14420, 3.069 samples/sec, batch_loss: 0.1304, batch_loss_c: 0.1268, batch_loss_s: 0.1388, time:13.0328, lr:0.001\u001b[0m\n",
            "2019-11-25 11:43:36 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1930/3125], step: 14430, 3.062 samples/sec, batch_loss: 0.1641, batch_loss_c: 0.1679, batch_loss_s: 0.1552, time:13.0655, lr:0.001\u001b[0m\n",
            "2019-11-25 11:43:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1940/3125], step: 14440, 3.026 samples/sec, batch_loss: 0.1853, batch_loss_c: 0.2076, batch_loss_s: 0.1333, time:13.2200, lr:0.001\u001b[0m\n",
            "2019-11-25 11:44:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1950/3125], step: 14450, 3.031 samples/sec, batch_loss: 0.4652, batch_loss_c: 0.5267, batch_loss_s: 0.3219, time:13.1990, lr:0.001\u001b[0m\n",
            "2019-11-25 11:44:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1960/3125], step: 14460, 3.039 samples/sec, batch_loss: 0.2976, batch_loss_c: 0.2843, batch_loss_s: 0.3287, time:13.1615, lr:0.001\u001b[0m\n",
            "2019-11-25 11:44:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1970/3125], step: 14470, 3.010 samples/sec, batch_loss: 0.1605, batch_loss_c: 0.1849, batch_loss_s: 0.1037, time:13.2899, lr:0.001\u001b[0m\n",
            "2019-11-25 11:44:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1980/3125], step: 14480, 2.978 samples/sec, batch_loss: 0.3902, batch_loss_c: 0.3876, batch_loss_s: 0.3961, time:13.4310, lr:0.001\u001b[0m\n",
            "2019-11-25 11:44:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [1990/3125], step: 14490, 3.032 samples/sec, batch_loss: 0.0970, batch_loss_c: 0.0951, batch_loss_s: 0.1016, time:13.1931, lr:0.001\u001b[0m\n",
            "2019-11-25 11:45:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2000/3125], step: 14500, 3.009 samples/sec, batch_loss: 0.3179, batch_loss_c: 0.3184, batch_loss_s: 0.3168, time:13.2935, lr:0.001\u001b[0m\n",
            "2019-11-25 11:45:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2010/3125], step: 14510, 2.960 samples/sec, batch_loss: 0.3895, batch_loss_c: 0.4064, batch_loss_s: 0.3499, time:13.5145, lr:0.001\u001b[0m\n",
            "2019-11-25 11:45:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2020/3125], step: 14520, 2.982 samples/sec, batch_loss: 0.5186, batch_loss_c: 0.5119, batch_loss_s: 0.5343, time:13.4132, lr:0.001\u001b[0m\n",
            "2019-11-25 11:45:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2030/3125], step: 14530, 3.037 samples/sec, batch_loss: 0.3083, batch_loss_c: 0.3037, batch_loss_s: 0.3190, time:13.1721, lr:0.001\u001b[0m\n",
            "2019-11-25 11:46:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2040/3125], step: 14540, 2.997 samples/sec, batch_loss: 0.2899, batch_loss_c: 0.2782, batch_loss_s: 0.3174, time:13.3460, lr:0.001\u001b[0m\n",
            "2019-11-25 11:46:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2050/3125], step: 14550, 3.038 samples/sec, batch_loss: 0.0929, batch_loss_c: 0.0999, batch_loss_s: 0.0766, time:13.1644, lr:0.001\u001b[0m\n",
            "2019-11-25 11:46:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2060/3125], step: 14560, 3.003 samples/sec, batch_loss: 0.5162, batch_loss_c: 0.5095, batch_loss_s: 0.5318, time:13.3186, lr:0.001\u001b[0m\n",
            "2019-11-25 11:46:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2070/3125], step: 14570, 3.031 samples/sec, batch_loss: 0.1500, batch_loss_c: 0.1678, batch_loss_s: 0.1087, time:13.1973, lr:0.001\u001b[0m\n",
            "2019-11-25 11:46:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2080/3125], step: 14580, 2.998 samples/sec, batch_loss: 0.1017, batch_loss_c: 0.1089, batch_loss_s: 0.0847, time:13.3429, lr:0.001\u001b[0m\n",
            "2019-11-25 11:47:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2090/3125], step: 14590, 3.014 samples/sec, batch_loss: 0.0674, batch_loss_c: 0.0663, batch_loss_s: 0.0698, time:13.2713, lr:0.001\u001b[0m\n",
            "2019-11-25 11:47:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2100/3125], step: 14600, 3.059 samples/sec, batch_loss: 0.2741, batch_loss_c: 0.2631, batch_loss_s: 0.2999, time:13.0782, lr:0.001\u001b[0m\n",
            "2019-11-25 11:47:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2110/3125], step: 14610, 2.988 samples/sec, batch_loss: 0.4986, batch_loss_c: 0.4776, batch_loss_s: 0.5477, time:13.3876, lr:0.001\u001b[0m\n",
            "2019-11-25 11:47:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2120/3125], step: 14620, 2.987 samples/sec, batch_loss: 0.1639, batch_loss_c: 0.1657, batch_loss_s: 0.1595, time:13.3922, lr:0.001\u001b[0m\n",
            "2019-11-25 11:48:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2130/3125], step: 14630, 3.091 samples/sec, batch_loss: 0.5314, batch_loss_c: 0.5273, batch_loss_s: 0.5411, time:12.9402, lr:0.001\u001b[0m\n",
            "2019-11-25 11:48:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2140/3125], step: 14640, 2.986 samples/sec, batch_loss: 0.1804, batch_loss_c: 0.1807, batch_loss_s: 0.1796, time:13.3959, lr:0.001\u001b[0m\n",
            "2019-11-25 11:48:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2150/3125], step: 14650, 2.994 samples/sec, batch_loss: 0.3467, batch_loss_c: 0.3500, batch_loss_s: 0.3389, time:13.3622, lr:0.001\u001b[0m\n",
            "2019-11-25 11:48:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2160/3125], step: 14660, 2.979 samples/sec, batch_loss: 0.5221, batch_loss_c: 0.5168, batch_loss_s: 0.5344, time:13.4295, lr:0.001\u001b[0m\n",
            "2019-11-25 11:48:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2170/3125], step: 14670, 2.963 samples/sec, batch_loss: 0.1276, batch_loss_c: 0.1221, batch_loss_s: 0.1405, time:13.5021, lr:0.001\u001b[0m\n",
            "2019-11-25 11:49:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2180/3125], step: 14680, 3.050 samples/sec, batch_loss: 0.3070, batch_loss_c: 0.3052, batch_loss_s: 0.3110, time:13.1166, lr:0.001\u001b[0m\n",
            "2019-11-25 11:49:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2190/3125], step: 14690, 2.961 samples/sec, batch_loss: 0.1334, batch_loss_c: 0.1459, batch_loss_s: 0.1041, time:13.5110, lr:0.001\u001b[0m\n",
            "2019-11-25 11:49:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2200/3125], step: 14700, 2.980 samples/sec, batch_loss: 0.3768, batch_loss_c: 0.3907, batch_loss_s: 0.3442, time:13.4224, lr:0.001\u001b[0m\n",
            "2019-11-25 11:49:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2210/3125], step: 14710, 2.977 samples/sec, batch_loss: 0.3362, batch_loss_c: 0.3336, batch_loss_s: 0.3423, time:13.4346, lr:0.001\u001b[0m\n",
            "2019-11-25 11:50:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2220/3125], step: 14720, 2.981 samples/sec, batch_loss: 0.0960, batch_loss_c: 0.0948, batch_loss_s: 0.0987, time:13.4175, lr:0.001\u001b[0m\n",
            "2019-11-25 11:50:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2230/3125], step: 14730, 2.991 samples/sec, batch_loss: 0.1182, batch_loss_c: 0.1379, batch_loss_s: 0.0723, time:13.3750, lr:0.001\u001b[0m\n",
            "2019-11-25 11:50:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2240/3125], step: 14740, 3.007 samples/sec, batch_loss: 0.3806, batch_loss_c: 0.3926, batch_loss_s: 0.3527, time:13.3005, lr:0.001\u001b[0m\n",
            "2019-11-25 11:50:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2250/3125], step: 14750, 2.974 samples/sec, batch_loss: 0.3731, batch_loss_c: 0.3909, batch_loss_s: 0.3317, time:13.4490, lr:0.001\u001b[0m\n",
            "2019-11-25 11:50:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2260/3125], step: 14760, 2.991 samples/sec, batch_loss: 0.3383, batch_loss_c: 0.3424, batch_loss_s: 0.3289, time:13.3721, lr:0.001\u001b[0m\n",
            "2019-11-25 11:51:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2270/3125], step: 14770, 3.065 samples/sec, batch_loss: 0.3900, batch_loss_c: 0.3915, batch_loss_s: 0.3863, time:13.0525, lr:0.001\u001b[0m\n",
            "2019-11-25 11:51:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2280/3125], step: 14780, 2.992 samples/sec, batch_loss: 0.3172, batch_loss_c: 0.3151, batch_loss_s: 0.3222, time:13.3710, lr:0.001\u001b[0m\n",
            "2019-11-25 11:51:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2290/3125], step: 14790, 2.965 samples/sec, batch_loss: 0.0864, batch_loss_c: 0.0893, batch_loss_s: 0.0795, time:13.4901, lr:0.001\u001b[0m\n",
            "2019-11-25 11:51:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2300/3125], step: 14800, 2.942 samples/sec, batch_loss: 0.1291, batch_loss_c: 0.1341, batch_loss_s: 0.1172, time:13.5971, lr:0.001\u001b[0m\n",
            "2019-11-25 11:52:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2310/3125], step: 14810, 2.965 samples/sec, batch_loss: 0.1939, batch_loss_c: 0.2211, batch_loss_s: 0.1304, time:13.4909, lr:0.001\u001b[0m\n",
            "2019-11-25 11:52:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2320/3125], step: 14820, 3.067 samples/sec, batch_loss: 0.4000, batch_loss_c: 0.4020, batch_loss_s: 0.3953, time:13.0429, lr:0.001\u001b[0m\n",
            "2019-11-25 11:52:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2330/3125], step: 14830, 3.014 samples/sec, batch_loss: 0.3840, batch_loss_c: 0.4029, batch_loss_s: 0.3400, time:13.2697, lr:0.001\u001b[0m\n",
            "2019-11-25 11:52:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2340/3125], step: 14840, 3.044 samples/sec, batch_loss: 0.1493, batch_loss_c: 0.1497, batch_loss_s: 0.1484, time:13.1393, lr:0.001\u001b[0m\n",
            "2019-11-25 11:52:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2350/3125], step: 14850, 2.964 samples/sec, batch_loss: 0.0785, batch_loss_c: 0.0747, batch_loss_s: 0.0874, time:13.4942, lr:0.001\u001b[0m\n",
            "2019-11-25 11:53:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2360/3125], step: 14860, 2.989 samples/sec, batch_loss: 0.1307, batch_loss_c: 0.1522, batch_loss_s: 0.0808, time:13.3832, lr:0.001\u001b[0m\n",
            "2019-11-25 11:53:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2370/3125], step: 14870, 3.006 samples/sec, batch_loss: 0.2481, batch_loss_c: 0.2247, batch_loss_s: 0.3025, time:13.3082, lr:0.001\u001b[0m\n",
            "2019-11-25 11:53:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2380/3125], step: 14880, 2.937 samples/sec, batch_loss: 0.4940, batch_loss_c: 0.5154, batch_loss_s: 0.4442, time:13.6207, lr:0.001\u001b[0m\n",
            "2019-11-25 11:53:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2390/3125], step: 14890, 3.021 samples/sec, batch_loss: 0.3277, batch_loss_c: 0.3279, batch_loss_s: 0.3274, time:13.2387, lr:0.001\u001b[0m\n",
            "2019-11-25 11:54:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2400/3125], step: 14900, 3.032 samples/sec, batch_loss: 0.1332, batch_loss_c: 0.1441, batch_loss_s: 0.1077, time:13.1932, lr:0.001\u001b[0m\n",
            "2019-11-25 11:54:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2410/3125], step: 14910, 2.997 samples/sec, batch_loss: 0.2495, batch_loss_c: 0.2471, batch_loss_s: 0.2549, time:13.3481, lr:0.001\u001b[0m\n",
            "2019-11-25 11:54:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2420/3125], step: 14920, 2.954 samples/sec, batch_loss: 0.3846, batch_loss_c: 0.3680, batch_loss_s: 0.4235, time:13.5404, lr:0.001\u001b[0m\n",
            "2019-11-25 11:54:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2430/3125], step: 14930, 3.011 samples/sec, batch_loss: 0.1458, batch_loss_c: 0.1721, batch_loss_s: 0.0843, time:13.2857, lr:0.001\u001b[0m\n",
            "2019-11-25 11:54:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2440/3125], step: 14940, 3.019 samples/sec, batch_loss: 0.1783, batch_loss_c: 0.1853, batch_loss_s: 0.1621, time:13.2478, lr:0.001\u001b[0m\n",
            "2019-11-25 11:55:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2450/3125], step: 14950, 3.065 samples/sec, batch_loss: 0.0993, batch_loss_c: 0.0982, batch_loss_s: 0.1016, time:13.0489, lr:0.001\u001b[0m\n",
            "2019-11-25 11:55:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2460/3125], step: 14960, 2.945 samples/sec, batch_loss: 0.3232, batch_loss_c: 0.3166, batch_loss_s: 0.3386, time:13.5810, lr:0.001\u001b[0m\n",
            "2019-11-25 11:55:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2470/3125], step: 14970, 2.995 samples/sec, batch_loss: 0.2541, batch_loss_c: 0.2374, batch_loss_s: 0.2930, time:13.3540, lr:0.001\u001b[0m\n",
            "2019-11-25 11:55:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2480/3125], step: 14980, 3.038 samples/sec, batch_loss: 0.1475, batch_loss_c: 0.1561, batch_loss_s: 0.1273, time:13.1679, lr:0.001\u001b[0m\n",
            "2019-11-25 11:56:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2490/3125], step: 14990, 2.995 samples/sec, batch_loss: 0.0942, batch_loss_c: 0.0964, batch_loss_s: 0.0892, time:13.3540, lr:0.001\u001b[0m\n",
            "2019-11-25 11:56:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2500/3125], step: 15000, 3.056 samples/sec, batch_loss: 0.2086, batch_loss_c: 0.2060, batch_loss_s: 0.2146, time:13.0870, lr:0.001\u001b[0m\n",
            "2019-11-25 11:56:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2510/3125], step: 15010, 3.072 samples/sec, batch_loss: 0.1804, batch_loss_c: 0.2064, batch_loss_s: 0.1197, time:13.0200, lr:0.001\u001b[0m\n",
            "2019-11-25 11:56:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2520/3125], step: 15020, 3.027 samples/sec, batch_loss: 0.1399, batch_loss_c: 0.1433, batch_loss_s: 0.1322, time:13.2145, lr:0.001\u001b[0m\n",
            "2019-11-25 11:56:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2530/3125], step: 15030, 3.051 samples/sec, batch_loss: 0.5293, batch_loss_c: 0.5058, batch_loss_s: 0.5840, time:13.1091, lr:0.001\u001b[0m\n",
            "2019-11-25 11:57:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2540/3125], step: 15040, 2.983 samples/sec, batch_loss: 0.2771, batch_loss_c: 0.3269, batch_loss_s: 0.1610, time:13.4074, lr:0.001\u001b[0m\n",
            "2019-11-25 11:57:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2550/3125], step: 15050, 2.940 samples/sec, batch_loss: 0.3240, batch_loss_c: 0.3192, batch_loss_s: 0.3353, time:13.6060, lr:0.001\u001b[0m\n",
            "2019-11-25 11:57:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2560/3125], step: 15060, 3.042 samples/sec, batch_loss: 0.1073, batch_loss_c: 0.1167, batch_loss_s: 0.0851, time:13.1472, lr:0.001\u001b[0m\n",
            "2019-11-25 11:57:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2570/3125], step: 15070, 2.971 samples/sec, batch_loss: 0.1515, batch_loss_c: 0.1834, batch_loss_s: 0.0771, time:13.4657, lr:0.001\u001b[0m\n",
            "2019-11-25 11:58:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2580/3125], step: 15080, 2.889 samples/sec, batch_loss: 0.1542, batch_loss_c: 0.1822, batch_loss_s: 0.0890, time:13.8470, lr:0.001\u001b[0m\n",
            "2019-11-25 11:58:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2590/3125], step: 15090, 2.957 samples/sec, batch_loss: 0.3603, batch_loss_c: 0.3440, batch_loss_s: 0.3983, time:13.5260, lr:0.001\u001b[0m\n",
            "2019-11-25 11:58:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2600/3125], step: 15100, 2.986 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1061, batch_loss_s: 0.1115, time:13.3952, lr:0.001\u001b[0m\n",
            "2019-11-25 11:58:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2610/3125], step: 15110, 3.049 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.0935, batch_loss_s: 0.1088, time:13.1207, lr:0.001\u001b[0m\n",
            "2019-11-25 11:58:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2620/3125], step: 15120, 3.006 samples/sec, batch_loss: 0.3296, batch_loss_c: 0.3378, batch_loss_s: 0.3104, time:13.3065, lr:0.001\u001b[0m\n",
            "2019-11-25 11:59:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2630/3125], step: 15130, 3.014 samples/sec, batch_loss: 0.2028, batch_loss_c: 0.2281, batch_loss_s: 0.1438, time:13.2708, lr:0.001\u001b[0m\n",
            "2019-11-25 11:59:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2640/3125], step: 15140, 3.022 samples/sec, batch_loss: 0.4297, batch_loss_c: 0.4489, batch_loss_s: 0.3850, time:13.2352, lr:0.001\u001b[0m\n",
            "2019-11-25 11:59:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2650/3125], step: 15150, 3.036 samples/sec, batch_loss: 0.3196, batch_loss_c: 0.3208, batch_loss_s: 0.3168, time:13.1734, lr:0.001\u001b[0m\n",
            "2019-11-25 11:59:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2660/3125], step: 15160, 3.002 samples/sec, batch_loss: 0.3325, batch_loss_c: 0.3327, batch_loss_s: 0.3320, time:13.3260, lr:0.001\u001b[0m\n",
            "2019-11-25 12:00:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2670/3125], step: 15170, 3.060 samples/sec, batch_loss: 0.0669, batch_loss_c: 0.0646, batch_loss_s: 0.0723, time:13.0711, lr:0.001\u001b[0m\n",
            "2019-11-25 12:00:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2680/3125], step: 15180, 2.986 samples/sec, batch_loss: 0.0688, batch_loss_c: 0.0625, batch_loss_s: 0.0835, time:13.3958, lr:0.001\u001b[0m\n",
            "2019-11-25 12:00:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2690/3125], step: 15190, 3.006 samples/sec, batch_loss: 0.1109, batch_loss_c: 0.1076, batch_loss_s: 0.1186, time:13.3087, lr:0.001\u001b[0m\n",
            "2019-11-25 12:00:41 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2700/3125], step: 15200, 2.960 samples/sec, batch_loss: 0.1122, batch_loss_c: 0.1209, batch_loss_s: 0.0920, time:13.5155, lr:0.001\u001b[0m\n",
            "2019-11-25 12:00:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2710/3125], step: 15210, 3.027 samples/sec, batch_loss: 0.2365, batch_loss_c: 0.2201, batch_loss_s: 0.2748, time:13.2148, lr:0.001\u001b[0m\n",
            "2019-11-25 12:01:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2720/3125], step: 15220, 2.929 samples/sec, batch_loss: 0.1634, batch_loss_c: 0.1831, batch_loss_s: 0.1175, time:13.6544, lr:0.001\u001b[0m\n",
            "2019-11-25 12:01:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2730/3125], step: 15230, 2.998 samples/sec, batch_loss: 0.1770, batch_loss_c: 0.1931, batch_loss_s: 0.1393, time:13.3435, lr:0.001\u001b[0m\n",
            "2019-11-25 12:01:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2740/3125], step: 15240, 2.977 samples/sec, batch_loss: 0.3499, batch_loss_c: 0.3527, batch_loss_s: 0.3435, time:13.4372, lr:0.001\u001b[0m\n",
            "2019-11-25 12:01:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2750/3125], step: 15250, 3.043 samples/sec, batch_loss: 0.1895, batch_loss_c: 0.1939, batch_loss_s: 0.1792, time:13.1430, lr:0.001\u001b[0m\n",
            "2019-11-25 12:02:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2760/3125], step: 15260, 2.987 samples/sec, batch_loss: 0.4353, batch_loss_c: 0.4154, batch_loss_s: 0.4816, time:13.3928, lr:0.001\u001b[0m\n",
            "2019-11-25 12:02:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2770/3125], step: 15270, 2.986 samples/sec, batch_loss: 0.2424, batch_loss_c: 0.2973, batch_loss_s: 0.1145, time:13.3939, lr:0.001\u001b[0m\n",
            "2019-11-25 12:02:28 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2780/3125], step: 15280, 2.959 samples/sec, batch_loss: 0.1561, batch_loss_c: 0.1781, batch_loss_s: 0.1048, time:13.5197, lr:0.001\u001b[0m\n",
            "2019-11-25 12:02:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2790/3125], step: 15290, 2.991 samples/sec, batch_loss: 0.3656, batch_loss_c: 0.3743, batch_loss_s: 0.3453, time:13.3746, lr:0.001\u001b[0m\n",
            "2019-11-25 12:02:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2800/3125], step: 15300, 2.973 samples/sec, batch_loss: 0.0761, batch_loss_c: 0.0739, batch_loss_s: 0.0814, time:13.4527, lr:0.001\u001b[0m\n",
            "2019-11-25 12:03:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2810/3125], step: 15310, 2.964 samples/sec, batch_loss: 0.3263, batch_loss_c: 0.3141, batch_loss_s: 0.3550, time:13.4960, lr:0.001\u001b[0m\n",
            "2019-11-25 12:03:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2820/3125], step: 15320, 2.995 samples/sec, batch_loss: 0.0894, batch_loss_c: 0.0868, batch_loss_s: 0.0956, time:13.3539, lr:0.001\u001b[0m\n",
            "2019-11-25 12:03:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2830/3125], step: 15330, 3.070 samples/sec, batch_loss: 0.4900, batch_loss_c: 0.5211, batch_loss_s: 0.4172, time:13.0288, lr:0.001\u001b[0m\n",
            "2019-11-25 12:03:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2840/3125], step: 15340, 3.044 samples/sec, batch_loss: 0.2979, batch_loss_c: 0.2886, batch_loss_s: 0.3195, time:13.1405, lr:0.001\u001b[0m\n",
            "2019-11-25 12:04:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2850/3125], step: 15350, 3.014 samples/sec, batch_loss: 0.1356, batch_loss_c: 0.1555, batch_loss_s: 0.0892, time:13.2736, lr:0.001\u001b[0m\n",
            "2019-11-25 12:04:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2860/3125], step: 15360, 2.984 samples/sec, batch_loss: 0.1283, batch_loss_c: 0.1416, batch_loss_s: 0.0972, time:13.4070, lr:0.001\u001b[0m\n",
            "2019-11-25 12:04:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2870/3125], step: 15370, 2.944 samples/sec, batch_loss: 0.1301, batch_loss_c: 0.1368, batch_loss_s: 0.1145, time:13.5866, lr:0.001\u001b[0m\n",
            "2019-11-25 12:04:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2880/3125], step: 15380, 2.994 samples/sec, batch_loss: 0.3644, batch_loss_c: 0.3807, batch_loss_s: 0.3262, time:13.3612, lr:0.001\u001b[0m\n",
            "2019-11-25 12:04:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2890/3125], step: 15390, 3.007 samples/sec, batch_loss: 0.1448, batch_loss_c: 0.1506, batch_loss_s: 0.1313, time:13.3007, lr:0.001\u001b[0m\n",
            "2019-11-25 12:05:09 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2900/3125], step: 15400, 3.002 samples/sec, batch_loss: 0.1453, batch_loss_c: 0.1526, batch_loss_s: 0.1284, time:13.3256, lr:0.001\u001b[0m\n",
            "2019-11-25 12:05:22 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2910/3125], step: 15410, 2.997 samples/sec, batch_loss: 0.3525, batch_loss_c: 0.3562, batch_loss_s: 0.3438, time:13.3479, lr:0.001\u001b[0m\n",
            "2019-11-25 12:05:35 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2920/3125], step: 15420, 2.979 samples/sec, batch_loss: 0.5415, batch_loss_c: 0.5288, batch_loss_s: 0.5710, time:13.4294, lr:0.001\u001b[0m\n",
            "2019-11-25 12:05:49 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2930/3125], step: 15430, 2.990 samples/sec, batch_loss: 0.3587, batch_loss_c: 0.3591, batch_loss_s: 0.3578, time:13.3789, lr:0.001\u001b[0m\n",
            "2019-11-25 12:06:02 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2940/3125], step: 15440, 3.030 samples/sec, batch_loss: 0.3262, batch_loss_c: 0.3272, batch_loss_s: 0.3238, time:13.1992, lr:0.001\u001b[0m\n",
            "2019-11-25 12:06:15 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2950/3125], step: 15450, 2.974 samples/sec, batch_loss: 0.1546, batch_loss_c: 0.1784, batch_loss_s: 0.0991, time:13.4517, lr:0.001\u001b[0m\n",
            "2019-11-25 12:06:29 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2960/3125], step: 15460, 3.037 samples/sec, batch_loss: 0.1867, batch_loss_c: 0.1868, batch_loss_s: 0.1866, time:13.1719, lr:0.001\u001b[0m\n",
            "2019-11-25 12:06:42 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2970/3125], step: 15470, 3.021 samples/sec, batch_loss: 0.2504, batch_loss_c: 0.2881, batch_loss_s: 0.1624, time:13.2403, lr:0.001\u001b[0m\n",
            "2019-11-25 12:06:55 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2980/3125], step: 15480, 3.065 samples/sec, batch_loss: 0.3996, batch_loss_c: 0.4293, batch_loss_s: 0.3302, time:13.0503, lr:0.001\u001b[0m\n",
            "2019-11-25 12:07:08 \u001b[32mINFO     \u001b[0m train.py: [4/10], [2990/3125], step: 15490, 3.017 samples/sec, batch_loss: 0.1287, batch_loss_c: 0.1413, batch_loss_s: 0.0992, time:13.2571, lr:0.001\u001b[0m\n",
            "2019-11-25 12:07:21 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3000/3125], step: 15500, 3.062 samples/sec, batch_loss: 0.1510, batch_loss_c: 0.1664, batch_loss_s: 0.1152, time:13.0655, lr:0.001\u001b[0m\n",
            "2019-11-25 12:07:34 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3010/3125], step: 15510, 3.035 samples/sec, batch_loss: 0.1614, batch_loss_c: 0.1917, batch_loss_s: 0.0909, time:13.1812, lr:0.001\u001b[0m\n",
            "2019-11-25 12:07:48 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3020/3125], step: 15520, 3.025 samples/sec, batch_loss: 0.0887, batch_loss_c: 0.0861, batch_loss_s: 0.0946, time:13.2226, lr:0.001\u001b[0m\n",
            "2019-11-25 12:08:01 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3030/3125], step: 15530, 3.046 samples/sec, batch_loss: 0.3139, batch_loss_c: 0.3123, batch_loss_s: 0.3176, time:13.1320, lr:0.001\u001b[0m\n",
            "2019-11-25 12:08:14 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3040/3125], step: 15540, 3.037 samples/sec, batch_loss: 0.3211, batch_loss_c: 0.3180, batch_loss_s: 0.3284, time:13.1694, lr:0.001\u001b[0m\n",
            "2019-11-25 12:08:27 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3050/3125], step: 15550, 3.031 samples/sec, batch_loss: 0.3891, batch_loss_c: 0.4123, batch_loss_s: 0.3348, time:13.1980, lr:0.001\u001b[0m\n",
            "2019-11-25 12:08:40 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3060/3125], step: 15560, 3.021 samples/sec, batch_loss: 0.3924, batch_loss_c: 0.3789, batch_loss_s: 0.4238, time:13.2416, lr:0.001\u001b[0m\n",
            "2019-11-25 12:08:54 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3070/3125], step: 15570, 2.972 samples/sec, batch_loss: 0.1240, batch_loss_c: 0.1354, batch_loss_s: 0.0971, time:13.4582, lr:0.001\u001b[0m\n",
            "2019-11-25 12:09:07 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3080/3125], step: 15580, 3.030 samples/sec, batch_loss: 0.1186, batch_loss_c: 0.1307, batch_loss_s: 0.0903, time:13.1995, lr:0.001\u001b[0m\n",
            "2019-11-25 12:09:20 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3090/3125], step: 15590, 3.033 samples/sec, batch_loss: 0.1825, batch_loss_c: 0.2021, batch_loss_s: 0.1367, time:13.1897, lr:0.001\u001b[0m\n",
            "2019-11-25 12:09:33 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3100/3125], step: 15600, 3.018 samples/sec, batch_loss: 0.1233, batch_loss_c: 0.1302, batch_loss_s: 0.1074, time:13.2554, lr:0.001\u001b[0m\n",
            "2019-11-25 12:09:46 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3110/3125], step: 15610, 3.082 samples/sec, batch_loss: 0.2194, batch_loss_c: 0.2591, batch_loss_s: 0.1266, time:12.9772, lr:0.001\u001b[0m\n",
            "2019-11-25 12:09:59 \u001b[32mINFO     \u001b[0m train.py: [4/10], [3120/3125], step: 15620, 3.065 samples/sec, batch_loss: 0.3054, batch_loss_c: 0.2865, batch_loss_s: 0.3495, time:13.0487, lr:0.001\u001b[0m\n",
            "2019-11-25 12:10:05 \u001b[32mINFO     \u001b[0m train.py: [4/10], train_loss: 0.2299, time: 4164.3280, lr: 0.001\u001b[0m\n",
            "2019-11-25 12:10:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [0/3125], step: 15625, 4.584 samples/sec, batch_loss: 0.3347, batch_loss_c: 0.3304, batch_loss_s: 0.3445, time:8.7264, lr:0.001\u001b[0m\n",
            "2019-11-25 12:10:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [10/3125], step: 15635, 2.857 samples/sec, batch_loss: 0.1148, batch_loss_c: 0.1193, batch_loss_s: 0.1043, time:14.0022, lr:0.001\u001b[0m\n",
            "2019-11-25 12:10:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [20/3125], step: 15645, 2.996 samples/sec, batch_loss: 0.1716, batch_loss_c: 0.2107, batch_loss_s: 0.0806, time:13.3528, lr:0.001\u001b[0m\n",
            "2019-11-25 12:10:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [30/3125], step: 15655, 3.011 samples/sec, batch_loss: 0.1227, batch_loss_c: 0.1302, batch_loss_s: 0.1051, time:13.2854, lr:0.001\u001b[0m\n",
            "2019-11-25 12:11:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [40/3125], step: 15665, 3.006 samples/sec, batch_loss: 0.1503, batch_loss_c: 0.1714, batch_loss_s: 0.1009, time:13.3050, lr:0.001\u001b[0m\n",
            "2019-11-25 12:11:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [50/3125], step: 15675, 2.939 samples/sec, batch_loss: 0.2296, batch_loss_c: 0.2532, batch_loss_s: 0.1745, time:13.6086, lr:0.001\u001b[0m\n",
            "2019-11-25 12:11:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [60/3125], step: 15685, 3.007 samples/sec, batch_loss: 0.1138, batch_loss_c: 0.1178, batch_loss_s: 0.1046, time:13.3019, lr:0.001\u001b[0m\n",
            "2019-11-25 12:11:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [70/3125], step: 15695, 2.941 samples/sec, batch_loss: 0.1202, batch_loss_c: 0.1343, batch_loss_s: 0.0872, time:13.6024, lr:0.001\u001b[0m\n",
            "2019-11-25 12:12:02 \u001b[32mINFO     \u001b[0m train.py: [5/10], [80/3125], step: 15705, 2.971 samples/sec, batch_loss: 0.3617, batch_loss_c: 0.3873, batch_loss_s: 0.3018, time:13.4636, lr:0.001\u001b[0m\n",
            "2019-11-25 12:12:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [90/3125], step: 15715, 3.012 samples/sec, batch_loss: 0.1443, batch_loss_c: 0.1400, batch_loss_s: 0.1543, time:13.2806, lr:0.001\u001b[0m\n",
            "2019-11-25 12:12:29 \u001b[32mINFO     \u001b[0m train.py: [5/10], [100/3125], step: 15725, 2.959 samples/sec, batch_loss: 0.3553, batch_loss_c: 0.3447, batch_loss_s: 0.3798, time:13.5188, lr:0.001\u001b[0m\n",
            "2019-11-25 12:12:42 \u001b[32mINFO     \u001b[0m train.py: [5/10], [110/3125], step: 15735, 3.017 samples/sec, batch_loss: 0.2655, batch_loss_c: 0.3350, batch_loss_s: 0.1033, time:13.2593, lr:0.001\u001b[0m\n",
            "2019-11-25 12:12:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [120/3125], step: 15745, 2.996 samples/sec, batch_loss: 0.2639, batch_loss_c: 0.2405, batch_loss_s: 0.3186, time:13.3517, lr:0.001\u001b[0m\n",
            "2019-11-25 12:13:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [130/3125], step: 15755, 3.037 samples/sec, batch_loss: 0.2920, batch_loss_c: 0.2817, batch_loss_s: 0.3160, time:13.1729, lr:0.001\u001b[0m\n",
            "2019-11-25 12:13:22 \u001b[32mINFO     \u001b[0m train.py: [5/10], [140/3125], step: 15765, 3.040 samples/sec, batch_loss: 0.1511, batch_loss_c: 0.1752, batch_loss_s: 0.0951, time:13.1558, lr:0.001\u001b[0m\n",
            "2019-11-25 12:13:35 \u001b[32mINFO     \u001b[0m train.py: [5/10], [150/3125], step: 15775, 3.028 samples/sec, batch_loss: 0.0719, batch_loss_c: 0.0690, batch_loss_s: 0.0787, time:13.2080, lr:0.001\u001b[0m\n",
            "2019-11-25 12:13:48 \u001b[32mINFO     \u001b[0m train.py: [5/10], [160/3125], step: 15785, 3.039 samples/sec, batch_loss: 0.1328, batch_loss_c: 0.1434, batch_loss_s: 0.1081, time:13.1606, lr:0.001\u001b[0m\n",
            "2019-11-25 12:14:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [170/3125], step: 15795, 2.981 samples/sec, batch_loss: 0.2716, batch_loss_c: 0.2752, batch_loss_s: 0.2630, time:13.4192, lr:0.001\u001b[0m\n",
            "2019-11-25 12:14:15 \u001b[32mINFO     \u001b[0m train.py: [5/10], [180/3125], step: 15805, 2.978 samples/sec, batch_loss: 0.1140, batch_loss_c: 0.1260, batch_loss_s: 0.0860, time:13.4336, lr:0.001\u001b[0m\n",
            "2019-11-25 12:14:28 \u001b[32mINFO     \u001b[0m train.py: [5/10], [190/3125], step: 15815, 3.021 samples/sec, batch_loss: 0.3107, batch_loss_c: 0.3056, batch_loss_s: 0.3226, time:13.2390, lr:0.001\u001b[0m\n",
            "2019-11-25 12:14:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [200/3125], step: 15825, 2.977 samples/sec, batch_loss: 0.1109, batch_loss_c: 0.1174, batch_loss_s: 0.0956, time:13.4384, lr:0.001\u001b[0m\n",
            "2019-11-25 12:14:55 \u001b[32mINFO     \u001b[0m train.py: [5/10], [210/3125], step: 15835, 3.025 samples/sec, batch_loss: 0.1807, batch_loss_c: 0.2052, batch_loss_s: 0.1234, time:13.2223, lr:0.001\u001b[0m\n",
            "2019-11-25 12:15:08 \u001b[32mINFO     \u001b[0m train.py: [5/10], [220/3125], step: 15845, 3.093 samples/sec, batch_loss: 0.3116, batch_loss_c: 0.2997, batch_loss_s: 0.3394, time:12.9329, lr:0.001\u001b[0m\n",
            "2019-11-25 12:15:21 \u001b[32mINFO     \u001b[0m train.py: [5/10], [230/3125], step: 15855, 3.040 samples/sec, batch_loss: 0.1667, batch_loss_c: 0.1730, batch_loss_s: 0.1521, time:13.1589, lr:0.001\u001b[0m\n",
            "2019-11-25 12:15:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [240/3125], step: 15865, 3.019 samples/sec, batch_loss: 0.4708, batch_loss_c: 0.5249, batch_loss_s: 0.3446, time:13.2506, lr:0.001\u001b[0m\n",
            "2019-11-25 12:15:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [250/3125], step: 15875, 3.013 samples/sec, batch_loss: 0.2025, batch_loss_c: 0.2195, batch_loss_s: 0.1628, time:13.2749, lr:0.001\u001b[0m\n",
            "2019-11-25 12:16:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [260/3125], step: 15885, 3.043 samples/sec, batch_loss: 0.1971, batch_loss_c: 0.2206, batch_loss_s: 0.1424, time:13.1453, lr:0.001\u001b[0m\n",
            "2019-11-25 12:16:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [270/3125], step: 15895, 3.002 samples/sec, batch_loss: 0.3374, batch_loss_c: 0.3439, batch_loss_s: 0.3221, time:13.3248, lr:0.001\u001b[0m\n",
            "2019-11-25 12:16:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [280/3125], step: 15905, 3.017 samples/sec, batch_loss: 0.1283, batch_loss_c: 0.1324, batch_loss_s: 0.1187, time:13.2586, lr:0.001\u001b[0m\n",
            "2019-11-25 12:16:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [290/3125], step: 15915, 3.047 samples/sec, batch_loss: 0.1586, batch_loss_c: 0.1731, batch_loss_s: 0.1247, time:13.1298, lr:0.001\u001b[0m\n",
            "2019-11-25 12:16:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [300/3125], step: 15925, 3.011 samples/sec, batch_loss: 0.0701, batch_loss_c: 0.0665, batch_loss_s: 0.0784, time:13.2841, lr:0.001\u001b[0m\n",
            "2019-11-25 12:17:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [310/3125], step: 15935, 2.961 samples/sec, batch_loss: 0.1507, batch_loss_c: 0.1784, batch_loss_s: 0.0861, time:13.5112, lr:0.001\u001b[0m\n",
            "2019-11-25 12:17:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [320/3125], step: 15945, 2.983 samples/sec, batch_loss: 0.2099, batch_loss_c: 0.2417, batch_loss_s: 0.1357, time:13.4075, lr:0.001\u001b[0m\n",
            "2019-11-25 12:17:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [330/3125], step: 15955, 3.031 samples/sec, batch_loss: 0.5191, batch_loss_c: 0.5048, batch_loss_s: 0.5525, time:13.1976, lr:0.001\u001b[0m\n",
            "2019-11-25 12:17:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [340/3125], step: 15965, 3.000 samples/sec, batch_loss: 0.1309, batch_loss_c: 0.1495, batch_loss_s: 0.0876, time:13.3341, lr:0.001\u001b[0m\n",
            "2019-11-25 12:18:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [350/3125], step: 15975, 3.011 samples/sec, batch_loss: 0.1273, batch_loss_c: 0.1410, batch_loss_s: 0.0955, time:13.2827, lr:0.001\u001b[0m\n",
            "2019-11-25 12:18:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [360/3125], step: 15985, 3.000 samples/sec, batch_loss: 0.1819, batch_loss_c: 0.2162, batch_loss_s: 0.1019, time:13.3354, lr:0.001\u001b[0m\n",
            "2019-11-25 12:18:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [370/3125], step: 15995, 2.944 samples/sec, batch_loss: 0.1085, batch_loss_c: 0.1109, batch_loss_s: 0.1027, time:13.5858, lr:0.001\u001b[0m\n",
            "2019-11-25 12:18:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [380/3125], step: 16005, 3.016 samples/sec, batch_loss: 0.1447, batch_loss_c: 0.1451, batch_loss_s: 0.1437, time:13.2624, lr:0.001\u001b[0m\n",
            "2019-11-25 12:18:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [390/3125], step: 16015, 2.989 samples/sec, batch_loss: 0.3093, batch_loss_c: 0.2856, batch_loss_s: 0.3646, time:13.3841, lr:0.001\u001b[0m\n",
            "2019-11-25 12:19:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [400/3125], step: 16025, 3.006 samples/sec, batch_loss: 0.1961, batch_loss_c: 0.2176, batch_loss_s: 0.1461, time:13.3053, lr:0.001\u001b[0m\n",
            "2019-11-25 12:19:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [410/3125], step: 16035, 3.042 samples/sec, batch_loss: 0.3568, batch_loss_c: 0.3592, batch_loss_s: 0.3511, time:13.1493, lr:0.001\u001b[0m\n",
            "2019-11-25 12:19:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [420/3125], step: 16045, 3.020 samples/sec, batch_loss: 0.1344, batch_loss_c: 0.1560, batch_loss_s: 0.0838, time:13.2462, lr:0.001\u001b[0m\n",
            "2019-11-25 12:19:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [430/3125], step: 16055, 3.015 samples/sec, batch_loss: 0.2120, batch_loss_c: 0.2155, batch_loss_s: 0.2040, time:13.2675, lr:0.001\u001b[0m\n",
            "2019-11-25 12:20:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [440/3125], step: 16065, 2.970 samples/sec, batch_loss: 0.1843, batch_loss_c: 0.1865, batch_loss_s: 0.1790, time:13.4664, lr:0.001\u001b[0m\n",
            "2019-11-25 12:20:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [450/3125], step: 16075, 3.018 samples/sec, batch_loss: 0.1678, batch_loss_c: 0.1691, batch_loss_s: 0.1648, time:13.2554, lr:0.001\u001b[0m\n",
            "2019-11-25 12:20:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [460/3125], step: 16085, 3.038 samples/sec, batch_loss: 0.1353, batch_loss_c: 0.1377, batch_loss_s: 0.1298, time:13.1654, lr:0.001\u001b[0m\n",
            "2019-11-25 12:20:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [470/3125], step: 16095, 2.970 samples/sec, batch_loss: 0.1502, batch_loss_c: 0.1578, batch_loss_s: 0.1324, time:13.4681, lr:0.001\u001b[0m\n",
            "2019-11-25 12:20:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [480/3125], step: 16105, 3.007 samples/sec, batch_loss: 0.5668, batch_loss_c: 0.5511, batch_loss_s: 0.6033, time:13.3019, lr:0.001\u001b[0m\n",
            "2019-11-25 12:21:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [490/3125], step: 16115, 2.981 samples/sec, batch_loss: 0.2481, batch_loss_c: 0.3045, batch_loss_s: 0.1163, time:13.4171, lr:0.001\u001b[0m\n",
            "2019-11-25 12:21:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [500/3125], step: 16125, 2.952 samples/sec, batch_loss: 0.1543, batch_loss_c: 0.1837, batch_loss_s: 0.0855, time:13.5484, lr:0.001\u001b[0m\n",
            "2019-11-25 12:21:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [510/3125], step: 16135, 2.968 samples/sec, batch_loss: 0.4990, batch_loss_c: 0.4601, batch_loss_s: 0.5897, time:13.4771, lr:0.001\u001b[0m\n",
            "2019-11-25 12:21:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [520/3125], step: 16145, 2.979 samples/sec, batch_loss: 0.1077, batch_loss_c: 0.1116, batch_loss_s: 0.0984, time:13.4289, lr:0.001\u001b[0m\n",
            "2019-11-25 12:22:01 \u001b[32mINFO     \u001b[0m train.py: [5/10], [530/3125], step: 16155, 3.002 samples/sec, batch_loss: 0.1577, batch_loss_c: 0.1876, batch_loss_s: 0.0879, time:13.3262, lr:0.001\u001b[0m\n",
            "2019-11-25 12:22:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [540/3125], step: 16165, 2.964 samples/sec, batch_loss: 0.3247, batch_loss_c: 0.3232, batch_loss_s: 0.3283, time:13.4965, lr:0.001\u001b[0m\n",
            "2019-11-25 12:22:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [550/3125], step: 16175, 3.018 samples/sec, batch_loss: 0.1007, batch_loss_c: 0.1103, batch_loss_s: 0.0783, time:13.2524, lr:0.001\u001b[0m\n",
            "2019-11-25 12:22:41 \u001b[32mINFO     \u001b[0m train.py: [5/10], [560/3125], step: 16185, 3.017 samples/sec, batch_loss: 0.3292, batch_loss_c: 0.3312, batch_loss_s: 0.3246, time:13.2574, lr:0.001\u001b[0m\n",
            "2019-11-25 12:22:54 \u001b[32mINFO     \u001b[0m train.py: [5/10], [570/3125], step: 16195, 3.007 samples/sec, batch_loss: 0.0979, batch_loss_c: 0.1046, batch_loss_s: 0.0824, time:13.3027, lr:0.001\u001b[0m\n",
            "2019-11-25 12:23:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [580/3125], step: 16205, 3.025 samples/sec, batch_loss: 0.2184, batch_loss_c: 0.2627, batch_loss_s: 0.1151, time:13.2248, lr:0.001\u001b[0m\n",
            "2019-11-25 12:23:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [590/3125], step: 16215, 3.008 samples/sec, batch_loss: 0.7268, batch_loss_c: 0.7085, batch_loss_s: 0.7693, time:13.2970, lr:0.001\u001b[0m\n",
            "2019-11-25 12:23:34 \u001b[32mINFO     \u001b[0m train.py: [5/10], [600/3125], step: 16225, 3.002 samples/sec, batch_loss: 0.1915, batch_loss_c: 0.2245, batch_loss_s: 0.1146, time:13.3249, lr:0.001\u001b[0m\n",
            "2019-11-25 12:23:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [610/3125], step: 16235, 3.020 samples/sec, batch_loss: 0.1190, batch_loss_c: 0.1264, batch_loss_s: 0.1017, time:13.2459, lr:0.001\u001b[0m\n",
            "2019-11-25 12:24:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [620/3125], step: 16245, 2.980 samples/sec, batch_loss: 0.2118, batch_loss_c: 0.2414, batch_loss_s: 0.1429, time:13.4228, lr:0.001\u001b[0m\n",
            "2019-11-25 12:24:14 \u001b[32mINFO     \u001b[0m train.py: [5/10], [630/3125], step: 16255, 3.054 samples/sec, batch_loss: 0.0809, batch_loss_c: 0.0864, batch_loss_s: 0.0683, time:13.0973, lr:0.001\u001b[0m\n",
            "2019-11-25 12:24:27 \u001b[32mINFO     \u001b[0m train.py: [5/10], [640/3125], step: 16265, 3.040 samples/sec, batch_loss: 0.3534, batch_loss_c: 0.3648, batch_loss_s: 0.3268, time:13.1595, lr:0.001\u001b[0m\n",
            "2019-11-25 12:24:40 \u001b[32mINFO     \u001b[0m train.py: [5/10], [650/3125], step: 16275, 2.999 samples/sec, batch_loss: 0.3035, batch_loss_c: 0.2972, batch_loss_s: 0.3184, time:13.3370, lr:0.001\u001b[0m\n",
            "2019-11-25 12:24:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [660/3125], step: 16285, 3.037 samples/sec, batch_loss: 0.1216, batch_loss_c: 0.1368, batch_loss_s: 0.0863, time:13.1730, lr:0.001\u001b[0m\n",
            "2019-11-25 12:25:07 \u001b[32mINFO     \u001b[0m train.py: [5/10], [670/3125], step: 16295, 2.987 samples/sec, batch_loss: 0.0981, batch_loss_c: 0.0951, batch_loss_s: 0.1050, time:13.3935, lr:0.001\u001b[0m\n",
            "2019-11-25 12:25:20 \u001b[32mINFO     \u001b[0m train.py: [5/10], [680/3125], step: 16305, 3.048 samples/sec, batch_loss: 0.2382, batch_loss_c: 0.2793, batch_loss_s: 0.1423, time:13.1238, lr:0.001\u001b[0m\n",
            "2019-11-25 12:25:33 \u001b[32mINFO     \u001b[0m train.py: [5/10], [690/3125], step: 16315, 2.954 samples/sec, batch_loss: 0.2277, batch_loss_c: 0.2215, batch_loss_s: 0.2421, time:13.5396, lr:0.001\u001b[0m\n",
            "2019-11-25 12:25:47 \u001b[32mINFO     \u001b[0m train.py: [5/10], [700/3125], step: 16325, 2.982 samples/sec, batch_loss: 0.1841, batch_loss_c: 0.2029, batch_loss_s: 0.1404, time:13.4120, lr:0.001\u001b[0m\n",
            "2019-11-25 12:26:00 \u001b[32mINFO     \u001b[0m train.py: [5/10], [710/3125], step: 16335, 3.004 samples/sec, batch_loss: 0.1281, batch_loss_c: 0.1274, batch_loss_s: 0.1296, time:13.3151, lr:0.001\u001b[0m\n",
            "2019-11-25 12:26:13 \u001b[32mINFO     \u001b[0m train.py: [5/10], [720/3125], step: 16345, 3.050 samples/sec, batch_loss: 0.1015, batch_loss_c: 0.1047, batch_loss_s: 0.0940, time:13.1132, lr:0.001\u001b[0m\n",
            "2019-11-25 12:26:26 \u001b[32mINFO     \u001b[0m train.py: [5/10], [730/3125], step: 16355, 3.029 samples/sec, batch_loss: 0.2212, batch_loss_c: 0.2393, batch_loss_s: 0.1789, time:13.2053, lr:0.001\u001b[0m\n",
            "2019-11-25 12:26:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [740/3125], step: 16365, 3.048 samples/sec, batch_loss: 0.1557, batch_loss_c: 0.1790, batch_loss_s: 0.1014, time:13.1216, lr:0.001\u001b[0m\n",
            "2019-11-25 12:26:53 \u001b[32mINFO     \u001b[0m train.py: [5/10], [750/3125], step: 16375, 3.055 samples/sec, batch_loss: 0.1412, batch_loss_c: 0.1576, batch_loss_s: 0.1030, time:13.0915, lr:0.001\u001b[0m\n",
            "2019-11-25 12:27:06 \u001b[32mINFO     \u001b[0m train.py: [5/10], [760/3125], step: 16385, 3.070 samples/sec, batch_loss: 0.5048, batch_loss_c: 0.4830, batch_loss_s: 0.5556, time:13.0313, lr:0.001\u001b[0m\n",
            "2019-11-25 12:27:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [770/3125], step: 16395, 3.035 samples/sec, batch_loss: 0.1040, batch_loss_c: 0.1111, batch_loss_s: 0.0876, time:13.1787, lr:0.001\u001b[0m\n",
            "2019-11-25 12:27:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [780/3125], step: 16405, 3.018 samples/sec, batch_loss: 0.0774, batch_loss_c: 0.0763, batch_loss_s: 0.0798, time:13.2533, lr:0.001\u001b[0m\n",
            "2019-11-25 12:27:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [790/3125], step: 16415, 3.021 samples/sec, batch_loss: 0.0975, batch_loss_c: 0.1073, batch_loss_s: 0.0744, time:13.2427, lr:0.001\u001b[0m\n",
            "2019-11-25 12:27:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [800/3125], step: 16425, 2.959 samples/sec, batch_loss: 0.2196, batch_loss_c: 0.2689, batch_loss_s: 0.1044, time:13.5203, lr:0.001\u001b[0m\n",
            "2019-11-25 12:28:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [810/3125], step: 16435, 3.004 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1072, batch_loss_s: 0.0997, time:13.3170, lr:0.001\u001b[0m\n",
            "2019-11-25 12:28:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [820/3125], step: 16445, 3.017 samples/sec, batch_loss: 0.2081, batch_loss_c: 0.2358, batch_loss_s: 0.1435, time:13.2561, lr:0.001\u001b[0m\n",
            "2019-11-25 12:28:39 \u001b[32mINFO     \u001b[0m train.py: [5/10], [830/3125], step: 16455, 2.997 samples/sec, batch_loss: 0.3493, batch_loss_c: 0.3583, batch_loss_s: 0.3285, time:13.3482, lr:0.001\u001b[0m\n",
            "2019-11-25 12:28:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [840/3125], step: 16465, 2.978 samples/sec, batch_loss: 0.2217, batch_loss_c: 0.2265, batch_loss_s: 0.2103, time:13.4307, lr:0.001\u001b[0m\n",
            "2019-11-25 12:29:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [850/3125], step: 16475, 3.033 samples/sec, batch_loss: 0.2242, batch_loss_c: 0.2635, batch_loss_s: 0.1324, time:13.1879, lr:0.001\u001b[0m\n",
            "2019-11-25 12:29:19 \u001b[32mINFO     \u001b[0m train.py: [5/10], [860/3125], step: 16485, 2.973 samples/sec, batch_loss: 0.1574, batch_loss_c: 0.1895, batch_loss_s: 0.0825, time:13.4547, lr:0.001\u001b[0m\n",
            "2019-11-25 12:29:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [870/3125], step: 16495, 2.994 samples/sec, batch_loss: 0.1050, batch_loss_c: 0.1013, batch_loss_s: 0.1135, time:13.3582, lr:0.001\u001b[0m\n",
            "2019-11-25 12:29:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [880/3125], step: 16505, 3.019 samples/sec, batch_loss: 0.3444, batch_loss_c: 0.3544, batch_loss_s: 0.3209, time:13.2487, lr:0.001\u001b[0m\n",
            "2019-11-25 12:29:59 \u001b[32mINFO     \u001b[0m train.py: [5/10], [890/3125], step: 16515, 2.958 samples/sec, batch_loss: 0.4197, batch_loss_c: 0.4347, batch_loss_s: 0.3846, time:13.5216, lr:0.001\u001b[0m\n",
            "2019-11-25 12:30:12 \u001b[32mINFO     \u001b[0m train.py: [5/10], [900/3125], step: 16525, 3.031 samples/sec, batch_loss: 0.3124, batch_loss_c: 0.2916, batch_loss_s: 0.3609, time:13.1970, lr:0.001\u001b[0m\n",
            "2019-11-25 12:30:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [910/3125], step: 16535, 3.061 samples/sec, batch_loss: 0.3105, batch_loss_c: 0.3156, batch_loss_s: 0.2989, time:13.0686, lr:0.001\u001b[0m\n",
            "2019-11-25 12:30:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [920/3125], step: 16545, 3.043 samples/sec, batch_loss: 0.3226, batch_loss_c: 0.3292, batch_loss_s: 0.3074, time:13.1462, lr:0.001\u001b[0m\n",
            "2019-11-25 12:30:52 \u001b[32mINFO     \u001b[0m train.py: [5/10], [930/3125], step: 16555, 2.945 samples/sec, batch_loss: 0.1532, batch_loss_c: 0.1810, batch_loss_s: 0.0885, time:13.5836, lr:0.001\u001b[0m\n",
            "2019-11-25 12:31:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [940/3125], step: 16565, 2.987 samples/sec, batch_loss: 0.1089, batch_loss_c: 0.1010, batch_loss_s: 0.1274, time:13.3911, lr:0.001\u001b[0m\n",
            "2019-11-25 12:31:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [950/3125], step: 16575, 3.033 samples/sec, batch_loss: 0.0977, batch_loss_c: 0.1001, batch_loss_s: 0.0919, time:13.1894, lr:0.001\u001b[0m\n",
            "2019-11-25 12:31:32 \u001b[32mINFO     \u001b[0m train.py: [5/10], [960/3125], step: 16585, 3.060 samples/sec, batch_loss: 0.3361, batch_loss_c: 0.3344, batch_loss_s: 0.3402, time:13.0700, lr:0.001\u001b[0m\n",
            "2019-11-25 12:31:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [970/3125], step: 16595, 3.012 samples/sec, batch_loss: 0.2132, batch_loss_c: 0.2395, batch_loss_s: 0.1519, time:13.2818, lr:0.001\u001b[0m\n",
            "2019-11-25 12:31:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [980/3125], step: 16605, 3.057 samples/sec, batch_loss: 0.5059, batch_loss_c: 0.4890, batch_loss_s: 0.5454, time:13.0845, lr:0.001\u001b[0m\n",
            "2019-11-25 12:32:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [990/3125], step: 16615, 3.030 samples/sec, batch_loss: 0.1832, batch_loss_c: 0.2046, batch_loss_s: 0.1332, time:13.2034, lr:0.001\u001b[0m\n",
            "2019-11-25 12:32:25 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1000/3125], step: 16625, 2.973 samples/sec, batch_loss: 0.0961, batch_loss_c: 0.0910, batch_loss_s: 0.1078, time:13.4562, lr:0.001\u001b[0m\n",
            "2019-11-25 12:32:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1010/3125], step: 16635, 2.963 samples/sec, batch_loss: 0.3624, batch_loss_c: 0.3499, batch_loss_s: 0.3914, time:13.4981, lr:0.001\u001b[0m\n",
            "2019-11-25 12:32:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1020/3125], step: 16645, 3.000 samples/sec, batch_loss: 0.1121, batch_loss_c: 0.1131, batch_loss_s: 0.1097, time:13.3332, lr:0.001\u001b[0m\n",
            "2019-11-25 12:33:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1030/3125], step: 16655, 3.067 samples/sec, batch_loss: 0.1409, batch_loss_c: 0.1547, batch_loss_s: 0.1085, time:13.0419, lr:0.001\u001b[0m\n",
            "2019-11-25 12:33:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1040/3125], step: 16665, 3.061 samples/sec, batch_loss: 0.2183, batch_loss_c: 0.2446, batch_loss_s: 0.1570, time:13.0681, lr:0.001\u001b[0m\n",
            "2019-11-25 12:33:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1050/3125], step: 16675, 2.995 samples/sec, batch_loss: 0.0539, batch_loss_c: 0.0533, batch_loss_s: 0.0553, time:13.3540, lr:0.001\u001b[0m\n",
            "2019-11-25 12:33:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1060/3125], step: 16685, 2.969 samples/sec, batch_loss: 0.1301, batch_loss_c: 0.1443, batch_loss_s: 0.0972, time:13.4745, lr:0.001\u001b[0m\n",
            "2019-11-25 12:33:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1070/3125], step: 16695, 3.014 samples/sec, batch_loss: 0.1193, batch_loss_c: 0.1277, batch_loss_s: 0.0996, time:13.2705, lr:0.001\u001b[0m\n",
            "2019-11-25 12:34:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1080/3125], step: 16705, 3.018 samples/sec, batch_loss: 0.2900, batch_loss_c: 0.2801, batch_loss_s: 0.3132, time:13.2519, lr:0.001\u001b[0m\n",
            "2019-11-25 12:34:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1090/3125], step: 16715, 3.057 samples/sec, batch_loss: 0.3515, batch_loss_c: 0.3608, batch_loss_s: 0.3297, time:13.0838, lr:0.001\u001b[0m\n",
            "2019-11-25 12:34:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1100/3125], step: 16725, 3.011 samples/sec, batch_loss: 0.2815, batch_loss_c: 0.2718, batch_loss_s: 0.3043, time:13.2865, lr:0.001\u001b[0m\n",
            "2019-11-25 12:34:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1110/3125], step: 16735, 2.965 samples/sec, batch_loss: 0.1265, batch_loss_c: 0.1352, batch_loss_s: 0.1062, time:13.4890, lr:0.001\u001b[0m\n",
            "2019-11-25 12:35:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1120/3125], step: 16745, 2.959 samples/sec, batch_loss: 0.3376, batch_loss_c: 0.3472, batch_loss_s: 0.3151, time:13.5180, lr:0.001\u001b[0m\n",
            "2019-11-25 12:35:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1130/3125], step: 16755, 2.931 samples/sec, batch_loss: 0.3338, batch_loss_c: 0.3377, batch_loss_s: 0.3248, time:13.6476, lr:0.001\u001b[0m\n",
            "2019-11-25 12:35:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1140/3125], step: 16765, 2.982 samples/sec, batch_loss: 0.1155, batch_loss_c: 0.1062, batch_loss_s: 0.1373, time:13.4132, lr:0.001\u001b[0m\n",
            "2019-11-25 12:35:45 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1150/3125], step: 16775, 2.980 samples/sec, batch_loss: 0.1462, batch_loss_c: 0.1645, batch_loss_s: 0.1034, time:13.4224, lr:0.001\u001b[0m\n",
            "2019-11-25 12:35:58 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1160/3125], step: 16785, 3.030 samples/sec, batch_loss: 0.1872, batch_loss_c: 0.1958, batch_loss_s: 0.1672, time:13.2003, lr:0.001\u001b[0m\n",
            "2019-11-25 12:36:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1170/3125], step: 16795, 3.025 samples/sec, batch_loss: 0.2136, batch_loss_c: 0.2143, batch_loss_s: 0.2121, time:13.2210, lr:0.001\u001b[0m\n",
            "2019-11-25 12:36:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1180/3125], step: 16805, 3.008 samples/sec, batch_loss: 0.2248, batch_loss_c: 0.2314, batch_loss_s: 0.2094, time:13.2999, lr:0.001\u001b[0m\n",
            "2019-11-25 12:36:38 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1190/3125], step: 16815, 2.976 samples/sec, batch_loss: 0.3474, batch_loss_c: 0.3479, batch_loss_s: 0.3464, time:13.4405, lr:0.001\u001b[0m\n",
            "2019-11-25 12:36:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1200/3125], step: 16825, 2.997 samples/sec, batch_loss: 0.0819, batch_loss_c: 0.0803, batch_loss_s: 0.0855, time:13.3462, lr:0.001\u001b[0m\n",
            "2019-11-25 12:37:05 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1210/3125], step: 16835, 3.014 samples/sec, batch_loss: 0.3107, batch_loss_c: 0.3097, batch_loss_s: 0.3133, time:13.2724, lr:0.001\u001b[0m\n",
            "2019-11-25 12:37:18 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1220/3125], step: 16845, 3.047 samples/sec, batch_loss: 0.3718, batch_loss_c: 0.3808, batch_loss_s: 0.3508, time:13.1262, lr:0.001\u001b[0m\n",
            "2019-11-25 12:37:31 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1230/3125], step: 16855, 2.993 samples/sec, batch_loss: 0.1716, batch_loss_c: 0.1779, batch_loss_s: 0.1570, time:13.3661, lr:0.001\u001b[0m\n",
            "2019-11-25 12:37:44 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1240/3125], step: 16865, 3.041 samples/sec, batch_loss: 0.3026, batch_loss_c: 0.3308, batch_loss_s: 0.2369, time:13.1536, lr:0.001\u001b[0m\n",
            "2019-11-25 12:37:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1250/3125], step: 16875, 3.016 samples/sec, batch_loss: 0.1361, batch_loss_c: 0.1337, batch_loss_s: 0.1416, time:13.2639, lr:0.001\u001b[0m\n",
            "2019-11-25 12:38:11 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1260/3125], step: 16885, 3.032 samples/sec, batch_loss: 0.1472, batch_loss_c: 0.1459, batch_loss_s: 0.1500, time:13.1928, lr:0.001\u001b[0m\n",
            "2019-11-25 12:38:24 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1270/3125], step: 16895, 2.953 samples/sec, batch_loss: 0.1573, batch_loss_c: 0.1733, batch_loss_s: 0.1198, time:13.5448, lr:0.001\u001b[0m\n",
            "2019-11-25 12:38:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1280/3125], step: 16905, 3.044 samples/sec, batch_loss: 0.4365, batch_loss_c: 0.4813, batch_loss_s: 0.3320, time:13.1425, lr:0.001\u001b[0m\n",
            "2019-11-25 12:38:51 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1290/3125], step: 16915, 3.029 samples/sec, batch_loss: 0.1457, batch_loss_c: 0.1672, batch_loss_s: 0.0957, time:13.2056, lr:0.001\u001b[0m\n",
            "2019-11-25 12:39:04 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1300/3125], step: 16925, 3.013 samples/sec, batch_loss: 0.3468, batch_loss_c: 0.3582, batch_loss_s: 0.3201, time:13.2764, lr:0.001\u001b[0m\n",
            "2019-11-25 12:39:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1310/3125], step: 16935, 3.034 samples/sec, batch_loss: 0.1022, batch_loss_c: 0.1093, batch_loss_s: 0.0856, time:13.1841, lr:0.001\u001b[0m\n",
            "2019-11-25 12:39:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1320/3125], step: 16945, 3.014 samples/sec, batch_loss: 0.2776, batch_loss_c: 0.3066, batch_loss_s: 0.2099, time:13.2712, lr:0.001\u001b[0m\n",
            "2019-11-25 12:39:43 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1330/3125], step: 16955, 3.022 samples/sec, batch_loss: 0.3148, batch_loss_c: 0.3159, batch_loss_s: 0.3123, time:13.2371, lr:0.001\u001b[0m\n",
            "2019-11-25 12:39:57 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1340/3125], step: 16965, 2.994 samples/sec, batch_loss: 0.3859, batch_loss_c: 0.3924, batch_loss_s: 0.3706, time:13.3612, lr:0.001\u001b[0m\n",
            "2019-11-25 12:40:10 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1350/3125], step: 16975, 2.989 samples/sec, batch_loss: 0.1197, batch_loss_c: 0.1283, batch_loss_s: 0.0996, time:13.3834, lr:0.001\u001b[0m\n",
            "2019-11-25 12:40:23 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1360/3125], step: 16985, 3.025 samples/sec, batch_loss: 0.1203, batch_loss_c: 0.1317, batch_loss_s: 0.0939, time:13.2218, lr:0.001\u001b[0m\n",
            "2019-11-25 12:40:37 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1370/3125], step: 16995, 3.023 samples/sec, batch_loss: 0.3628, batch_loss_c: 0.3607, batch_loss_s: 0.3676, time:13.2299, lr:0.001\u001b[0m\n",
            "2019-11-25 12:40:50 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1380/3125], step: 17005, 3.006 samples/sec, batch_loss: 0.0853, batch_loss_c: 0.0868, batch_loss_s: 0.0816, time:13.3077, lr:0.001\u001b[0m\n",
            "2019-11-25 12:41:03 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1390/3125], step: 17015, 3.017 samples/sec, batch_loss: 0.2877, batch_loss_c: 0.2791, batch_loss_s: 0.3078, time:13.2595, lr:0.001\u001b[0m\n",
            "2019-11-25 12:41:17 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1400/3125], step: 17025, 2.999 samples/sec, batch_loss: 0.3718, batch_loss_c: 0.3867, batch_loss_s: 0.3370, time:13.3363, lr:0.001\u001b[0m\n",
            "2019-11-25 12:41:30 \u001b[32mINFO     \u001b[0m train.py: [5/10], [1410/3125], step: 17035, 3.040 samples/sec, batch_loss: 0.1241, batch_loss_c: 0.1193, batch_loss_s: 0.1352, time:13.1563, lr:0.001\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}